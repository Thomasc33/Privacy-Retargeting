{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from SGN.model import SGN\n",
    "from SGN.data import NTUDataLoaders, AverageMeter\n",
    "from SGN.util import make_dir, get_num_classes\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "dataset = 'NTU'\n",
    "device = torch.device('cuda:0')\n",
    "# device = torch.device('cpu')\n",
    "seg = 20\n",
    "lr = 5e-5\n",
    "epochs = 500\n",
    "utility_classes = 120\n",
    "privacy_classes = 106\n",
    "validation_acc_freq = 10 #-1 to disable\n",
    "encoded_channels = 16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to delete 28814\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "with open('ntu/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "# clean data\n",
    "to_del = []\n",
    "for file in X:\n",
    "    if type(X[file]) == list:\n",
    "        to_del.append(file)\n",
    "print('to delete', len(to_del))\n",
    "for file in to_del:\n",
    "    del X[file]\n",
    "\n",
    "# pad or trim data to 75 frames. when padding, repeat the last frame\n",
    "# input is of shape (frames, 75)\n",
    "T = 75\n",
    "for file in X:\n",
    "    if X[file].shape[0] < T:\n",
    "        X[file] = np.pad(X[file], ((0, T - X[file].shape[0]), (0, 0)), mode='edge')\n",
    "    elif X[file].shape[0] > T:\n",
    "        X[file] = X[file][:T, :]\n",
    "\n",
    "# convert to tensor\n",
    "for file in X:\n",
    "    X[file] = torch.tensor(X[file]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {}\n",
    "p = {}\n",
    "for file in X:\n",
    "    if file[16:20] not in a:\n",
    "        a[file[16:20]] = {}\n",
    "    if file[8:12] not in a[file[16:20]]:\n",
    "        a[file[16:20]][file[8:12]] = []\n",
    "    a[file[16:20]][file[8:12]].append(file)\n",
    "    \n",
    "    if file[8:12] not in p:\n",
    "        p[file[8:12]] = set()\n",
    "    p[file[8:12]].add(file[16:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_samples(samples):\n",
    "    x, y = [], []\n",
    "    for _ in range(samples):\n",
    "        # sample two random p\n",
    "        p1, p2 = random.sample(list(p.keys()), 2)\n",
    "        # find overlapping a\n",
    "        a1 = p[p1]\n",
    "        a2 = p[p2]\n",
    "        a12 = a1.intersection(a2)\n",
    "        if len(a12) == 0:\n",
    "            continue\n",
    "        # sample two random a\n",
    "        a1, a2 = random.sample(list(a12), 2)\n",
    "        # sample x and y\n",
    "        x1 = random.sample(a[a1][p1], 1)[0]\n",
    "        x2 = random.sample(a[a2][p2], 1)[0]\n",
    "        y1 = random.sample(a[a1][p2], 1)[0]\n",
    "        y2 = random.sample(a[a2][p1], 1)[0]\n",
    "        x.append([x1, x2])\n",
    "        y.append([y1, y2])\n",
    "    return x, y\n",
    "\n",
    "batch_size = 32\n",
    "train_x, train_y = gen_samples(30000)\n",
    "val_x, val_y = gen_samples(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        actors = [float(self.X[index][0][9:12]), float(self.X[index][1][9:12])]\n",
    "        actions = [float(self.X[index][0][17:20]), float(self.X[index][1][17:20])]\n",
    "        return X[self.X[index][0]], X[self.X[index][1]], X[self.y[index][0]],  X[self.y[index][1]], actors, actions\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "train_data = Data(train_x, train_y)\n",
    "train_dl = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_data = Data(val_x, val_y)\n",
    "val_dl = DataLoader(val_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
