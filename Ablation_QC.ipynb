{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = 'Ablation_QC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import plotly\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from SGN.model import SGN\n",
    "from SGN.data import NTUDataLoaders, AverageMeter\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import mlflow\n",
    "import time\n",
    "_=mlflow.set_experiment(\"Privacy Retargeting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "only_use_pos = True # True uses SGN preprocessing, False uses my preprocessing\n",
    "remove_two_actor_actions = True\n",
    "one_dimension_conv = False\n",
    "ntu_120 = False\n",
    "only_ntu_120 = False\n",
    "seperate_train_test = True\n",
    "sgn_eval_after_each_stage = False\n",
    "binary_data = False\n",
    "train_cameras = [2, 3]\n",
    "test_cameras = [1]\n",
    "train_actors = [1, 2, 4, 5, 8, 9, 13, 14, 15, 16, 17, 18, 19, 25, 27, 28, 31, 34, 35, 38, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 70, 74, 78, 80, 81, 82, 83, 84, 85, 86, 89, 91, 92, 93, 94, 95, 97, 98, 100, 103] #https://ar5iv.labs.arxiv.org/html/1905.04757\n",
    "T = 75\n",
    "k = 5\n",
    "setting = 'cv'\n",
    "dataset = 'NTU'\n",
    "metric = 'val_utility_acc_coop'\n",
    "matric_minimize = False\n",
    "device = torch.device('cuda:0')\n",
    "seg = 20\n",
    "lr = 1e-5\n",
    "adv_lr = 1e-5\n",
    "util_classifier_alpha = 10\n",
    "priv_classifier_alpha = .1\n",
    "if ntu_120:\n",
    "    utility_classes = 120\n",
    "    privacy_classes = 106\n",
    "else:\n",
    "    utility_classes = 60\n",
    "    privacy_classes = 40\n",
    "validation_acc_freq = -1 #-1 to disable\n",
    "emb_clf_update_per_epoch_paired = 1\n",
    "emb_clf_update_per_epoch_unpaired = 3\n",
    "encoded_channels = (128, 16) # default\n",
    "dmr_encoded_channels = (256, 32) # dmr\n",
    "batch_size = 32\n",
    "workers=0\n",
    "cross_samples_train = 50000\n",
    "cross_samples_test = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate parameters\n",
    "assert len(train_cameras) > 0 and len(test_cameras) > 0\n",
    "assert emb_clf_update_per_epoch_paired > 0 and emb_clf_update_per_epoch_unpaired > 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Organize\n",
    "\n",
    "X = (frames, joints, pos + orientation)\n",
    "    \n",
    "    (frames, 25, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "if only_use_pos:\n",
    "    with open('ntu/SGN/X_full.pkl', 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "else:\n",
    "    with open('ntu/X.pkl', 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "\n",
    "# pad/trim data to T frames and convert to tensor\n",
    "for file, value in X.items():\n",
    "    # If SGN preprocessing, remove zero padding\n",
    "    if only_use_pos:\n",
    "        first_zero_index = value.shape[0]\n",
    "        for i in range(value.shape[0]):\n",
    "            if np.all(value[i] == 0):\n",
    "                first_zero_index = i\n",
    "                break\n",
    "        value = value[:first_zero_index]\n",
    "\n",
    "    num_frames = value.shape[0]\n",
    "\n",
    "    # Pad or trim\n",
    "    if num_frames < T:\n",
    "        if only_use_pos: padding = np.repeat(value[-1][np.newaxis, :], T - num_frames, axis=0)\n",
    "        else: padding = np.repeat(value[-1][np.newaxis, :, :], T - num_frames, axis=0)\n",
    "        value = np.concatenate((value, padding), axis=0)\n",
    "    elif num_frames > T:\n",
    "        # Randomly sample T frames\n",
    "        start = random.randint(0, num_frames - T)\n",
    "        value = value[start:start+T]\n",
    "    \n",
    "    # Convert to tensor and store back\n",
    "    X[file] = torch.from_numpy(value).float()\n",
    "\n",
    "if not ntu_120:\n",
    "    to_rem = []\n",
    "    for file in X.keys():\n",
    "        if int(str(file).split('A')[1][:3]) > 60:\n",
    "            to_rem.append(file)\n",
    "    for file in to_rem:\n",
    "        del X[file]\n",
    "\n",
    "if only_ntu_120:\n",
    "    to_rem = []\n",
    "    for file in X.keys():\n",
    "        if int(str(file).split('A')[1][:3]) <= 60:\n",
    "            to_rem.append(file)\n",
    "    for file in to_rem:\n",
    "        del X[file]\n",
    "\n",
    "# chop off second actor and convert to 3d\n",
    "if only_use_pos:\n",
    "    for file, value in X.items():\n",
    "        value = value[:, :75]\n",
    "        value = value.view(-1, 25, 3)\n",
    "        X[file] = value\n",
    "\n",
    "# remove two actor actions\n",
    "two_action_files = set([50,51,52,53,54,55,56,57,58,59,60,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120])\n",
    "if remove_two_actor_actions:\n",
    "    to_rem = []\n",
    "    for file in X.keys():\n",
    "        if int(str(file).split('A')[1][:3]) in two_action_files:\n",
    "            to_rem.append(file)\n",
    "    for file in to_rem:\n",
    "        del X[file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only allow two actors and two actions for testing out training stages\n",
    "if binary_data:\n",
    "    actors = set([8,11])\n",
    "    actions = set([1,2])\n",
    "    to_rem = []\n",
    "    for file in X.keys():\n",
    "        if int(str(file.decode('utf-8')).split('P')[1][:3]) not in actors or int(str(file.decode('utf-8')).split('A')[1][:3]) not in actions:\n",
    "            to_rem.append(file)\n",
    "    for file in to_rem:\n",
    "        del X[file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Data Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file_name(file_name):\n",
    "    \"\"\"Parses the filename into a dictionary of parts.\"\"\"\n",
    "    file_name = str(file_name)\n",
    "    if file_name[0] == 'b': # SGN preprocessing\n",
    "        S = int(file_name[3:6])\n",
    "        C = int(file_name[7:10])\n",
    "        P = int(file_name[11:14])\n",
    "        R = int(file_name[15:18])\n",
    "        A = int(file_name[19:22])\n",
    "    else:\n",
    "        S = int(file_name[1:4])\n",
    "        C = int(file_name[5:8])\n",
    "        P = int(file_name[9:12])\n",
    "        R = int(file_name[13:16])\n",
    "        A = int(file_name[17:20])\n",
    "    return {'S': S, 'C': C, 'P': P, 'R': R, 'A': A}\n",
    "\n",
    "def organize_data(data):\n",
    "    train_data = defaultdict(list)\n",
    "    test_data = defaultdict(list)\n",
    "\n",
    "    organized_data = defaultdict(list)\n",
    "    for file_name, content in data.items():\n",
    "        parts = parse_file_name(file_name)\n",
    "        if not ntu_120: # NTU 60\n",
    "            if int(parts['A']) > 60:\n",
    "                continue\n",
    "        organized_data[parts['C']].append((parts['P'], parts['A'], content))\n",
    "        if setting == 'cs':\n",
    "            if parts['P'] in train_actors:\n",
    "                train_data[parts['C']].append((parts['P'], parts['A'], content))\n",
    "            else:\n",
    "                test_data[parts['C']].append((parts['P'], parts['A'], content))\n",
    "\n",
    "        \n",
    "    if setting == 'cv':\n",
    "        for camera in train_cameras:\n",
    "            train_data[camera].extend(organized_data[camera])\n",
    "\n",
    "        for camera in test_cameras:\n",
    "            test_data[camera].extend(organized_data[camera])\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "def sample_data(organized_data):\n",
    "    # Pick a random C pair\n",
    "    C = random.choice(list(organized_data.keys()))\n",
    "\n",
    "    # Get all (P, A, content) tuples for this C \n",
    "    pa_list = organized_data[C]\n",
    "\n",
    "    # Pick 2 unique P values, find two overlapping A's\n",
    "    \n",
    "\n",
    "    # Pick 2 unique P values and 2 unique A values\n",
    "    random.shuffle(pa_list)\n",
    "    unique_p = set()\n",
    "    unique_a = set()\n",
    "    for p, a, _ in pa_list:\n",
    "        if len(unique_p) < 2:\n",
    "            unique_p.add(p)\n",
    "        if len(unique_a) < 2:\n",
    "            unique_a.add(a)\n",
    "        if len(unique_p) == 2 and len(unique_a) == 2:\n",
    "            break\n",
    "\n",
    "    if len(unique_p) < 2 or len(unique_a) < 2:\n",
    "        raise Exception(f'Not enough unique P or A values for C pair {C}')\n",
    "\n",
    "    # Form all four (P, A) pairs and get the corresponding content\n",
    "    sampled_data = [] #(p1, a1) (p1, a2) (p2, a1) (p2, a2)\n",
    "    for p in unique_p:\n",
    "        for a in unique_a:\n",
    "            for pa_content in pa_list:\n",
    "                if pa_content[0] == p and pa_content[1] == a:\n",
    "                    sampled_data.append(pa_content)\n",
    "                    break\n",
    "\n",
    "    return sampled_data\n",
    "\n",
    "def gen_samples(samples, data):\n",
    "    d = []\n",
    "    unique_samples = set()  # Set to track unique samples\n",
    "    for _ in range(samples):\n",
    "        failed = 0\n",
    "        while True:\n",
    "            d_ = sample_data(data)\n",
    "            d_tuple = tuple(tuple(x) for x in d_)\n",
    "            if d_tuple not in unique_samples and len(d_tuple) == 4:\n",
    "                unique_samples.add(d_tuple)  # Add the unique sample to the set\n",
    "                d.append(d_)  # Add the unique sample to the dataset\n",
    "                break\n",
    "            failed += 1\n",
    "            if failed > 100:\n",
    "                print('failed to sample data')\n",
    "                break\n",
    "    return np.array(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_rec_data(X):\n",
    "    # Remove NTU 120 if needed\n",
    "    if not ntu_120:\n",
    "        X = {k: v for k, v in X.items() if int(parse_file_name(k)['A']) <= 60}\n",
    "\n",
    "    # Split data into train and test\n",
    "    # X_train_keys, X_test_keys = train_test_split(list(X.keys()), test_size=0.2, random_state=42)\n",
    "\n",
    "    # Split by camera views\n",
    "    X_train_keys = []\n",
    "    X_test_keys = []\n",
    "    if setting == 'cs':\n",
    "        for key in X.keys():\n",
    "            if parse_file_name(key)['P'] in train_actors:\n",
    "                X_train_keys.append(key)\n",
    "            else:\n",
    "                X_test_keys.append(key)\n",
    "    elif setting == 'cv':\n",
    "        for key in X.keys():\n",
    "            if parse_file_name(key)['C'] in train_cameras:\n",
    "                X_train_keys.append(key)\n",
    "            else:\n",
    "                X_test_keys.append(key)\n",
    "    \n",
    "    # Create train and test sets\n",
    "    X_train = np.zeros((len(X_train_keys), T, 25, 3 if only_use_pos else 7))\n",
    "    X_test = np.zeros((len(X_test_keys), T, 25, 3 if only_use_pos else 7))\n",
    "    for i, key in enumerate(X_train_keys):\n",
    "        X_train[i] = X[key]\n",
    "    for i, key in enumerate(X_test_keys):\n",
    "        X_test[i] = X[key]\n",
    "\n",
    "    # Get actor and action names\n",
    "    train_actors = [parse_file_name(key)['P'] for key in X_train_keys]\n",
    "    test_actors = [parse_file_name(key)['P'] for key in X_test_keys]\n",
    "    train_actions = [parse_file_name(key)['A'] for key in X_train_keys]\n",
    "    test_actions = [parse_file_name(key)['A'] for key in X_test_keys]\n",
    "    \n",
    "    return X_train, X_test, train_actors, train_actions, test_actors, test_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cross_Data(Dataset):\n",
    "    def __init__(self, sampled_data):\n",
    "        self.data = sampled_data # the tuple is actor, action, frames\n",
    "        self.x1 = sampled_data[:, 0, 2] # P1, A1\n",
    "        self.x2 = sampled_data[:, 3, 2] # P2, A2\n",
    "        self.y1 = sampled_data[:, 1, 2] # P1, A2\n",
    "        self.y2 = sampled_data[:, 2, 2] # P2, A1\n",
    "        self.none = torch.zeros(1)\n",
    "\n",
    "    def __getitem__(self, index): # data, actors, actions\n",
    "        if only_use_pos:\n",
    "            return self.x1[index], self.none,\\\n",
    "                    self.x2[index], self.none,\\\n",
    "                    self.y1[index], self.none,\\\n",
    "                    self.y2[index], self.none,\\\n",
    "                    [float(self.data[index][0][0]), float(self.data[index][3][0])], [float(self.data[index][0][1]), float(self.data[index][3][1])]\n",
    "        return self.x1[index][:, :, 0:3], self.x1[index][:, :, 3:7],\\\n",
    "                self.x2[index][:, :, 0:3], self.x2[index][:, :, 3:7],\\\n",
    "                self.y1[index][:, :, 0:3], self.y1[index][:, :, 3:7],\\\n",
    "                self.y2[index][:, :, 0:3], self.y2[index][:, :, 3:7],\\\n",
    "                [float(self.data[index][0][0]), float(self.data[index][3][0])], [float(self.data[index][0][1]), float(self.data[index][3][1])]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class Rec_Data(Dataset):\n",
    "    def __init__(self, X, Actor, Action):\n",
    "        self.X = X\n",
    "        self.Actor = Actor\n",
    "        self.Action = Action\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], float(self.Actor[index]), float(self.Action[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "\n",
    "# Cross Data\n",
    "# organized_data_train, organized_data_test = organize_data(X)\n",
    "# train_data = gen_samples(cross_samples_train, organized_data_train)\n",
    "# if seperate_train_test: val_data = gen_samples(cross_samples_test, organized_data_test)\n",
    "# else: val_data = train_data\n",
    "# train_dataset = Cross_Data(train_data)\n",
    "# val_dataset = Cross_Data(val_data)\n",
    "# train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # Rec Data\n",
    "# rec_train_data, rec_val_data, t_actors, t_actions, v_actors, v_actions = sample_rec_data(X)\n",
    "# rec_train_dataset = Rec_Data(rec_train_data, t_actors, t_actions)\n",
    "# rec_val_dataset = Rec_Data(rec_val_data, v_actors, v_actions)\n",
    "# rec_train_dl = DataLoader(rec_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# rec_val_dl = DataLoader(rec_val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input is size of latent space\n",
    "class Adversary_Emb(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Adversary_Emb, self).__init__()\n",
    "        self.channels = [encoded_channels[0], 128, 256, 512]\n",
    "        self.conv1 = nn.ConvTranspose1d(self.channels[0], self.channels[1], 3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv2 = nn.ConvTranspose1d(self.channels[1], self.channels[2], 3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv3 = nn.ConvTranspose1d(self.channels[2], self.channels[3], 3, stride=2, padding=1, output_padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(self.channels[1])\n",
    "        self.bn2 = nn.BatchNorm1d(self.channels[2])\n",
    "        self.bn3 = nn.BatchNorm1d(self.channels[3])\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(self.channels[3], 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose1d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.xavier_normal_(m.weight)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.dropout(F.relu(self.fc1(x)), p=0.5, training=self.training)\n",
    "        x = F.dropout(F.relu(self.fc2(x)), p=0.5, training=self.training)\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        # x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "class Discriminator(nn.Module): # 1 = real, 0 = fake\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.enc1 = nn.Conv1d(in_channels=T, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc2 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc3 = nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc4 = nn.Conv1d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.ref1 = nn.ReflectionPad1d(3)\n",
    "        self.ref2 = nn.ReflectionPad1d(3)\n",
    "        self.ref3 = nn.ReflectionPad1d(3)\n",
    "        self.ref4 = nn.ReflectionPad1d(3)\n",
    "        self.fc1 = nn.Linear(80, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.acti = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.xavier_normal_(m.weight)\n",
    "                init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref1(x)\n",
    "        x = self.acti(self.enc1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.ref2(x)\n",
    "        x = self.acti(self.enc2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.ref3(x)\n",
    "        x = self.acti(self.enc3(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.ref4(x)\n",
    "        x = self.acti(self.enc4(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        #flatten\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Retargeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder1D, self).__init__()\n",
    "\n",
    "        self.enc1 = nn.Conv1d(in_channels=T, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc2 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc3 = nn.Conv1d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc4 = nn.Conv1d(in_channels=512, out_channels=encoded_channels[0], kernel_size=3, stride=1, padding=1)\n",
    "        self.ref1 = nn.ReflectionPad1d(3)\n",
    "        self.ref2 = nn.ReflectionPad1d(3)\n",
    "        self.ref3 = nn.ReflectionPad1d(3)\n",
    "        self.ref4 = nn.ReflectionPad1d(3)\n",
    "\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.acti = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(encoded_channels[0], encoded_channels[0] * encoded_channels[1])\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.xavier_normal_(m.weight)\n",
    "                init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref1(x)\n",
    "        x = self.acti(self.enc1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.ref2(x)\n",
    "        x = self.acti(self.enc2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.ref3(x)\n",
    "        x = self.acti(self.enc3(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.ref4(x)\n",
    "        x = self.acti(self.enc4(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.squeeze(-1) \n",
    "        x = self.fc1(x)\n",
    "        x = x.view(-1, *encoded_channels)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Decoder1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder1D, self).__init__()\n",
    "\n",
    "        self.dec1 = nn.ConvTranspose1d(in_channels=encoded_channels[0]*2, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.dec2 = nn.ConvTranspose1d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.dec3 = nn.ConvTranspose1d(in_channels=128, out_channels=96, kernel_size=3, stride=1, padding=1)\n",
    "        self.dec4 = nn.ConvTranspose1d(in_channels=96, out_channels=T, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.ref1 = nn.ReflectionPad1d(3)\n",
    "        self.ref2 = nn.ReflectionPad1d(3)\n",
    "        self.ref3 = nn.ReflectionPad1d(3)\n",
    "        self.ref4 = nn.ReflectionPad1d(3)\n",
    " \n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.up75 = nn.Upsample(size=75, mode='nearest') \n",
    "\n",
    "        self.acti = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose1d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref1(x)\n",
    "        x = self.acti(self.dec1(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref2(x)\n",
    "        x = self.acti(self.dec2(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref3(x)\n",
    "        x = self.acti(self.dec3(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref4(x)\n",
    "        x = self.acti(self.dec4(x))\n",
    "        x = self.up75(x)\n",
    "        return x\n",
    "    \n",
    "class Encoder2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder2D, self).__init__()\n",
    "\n",
    "        self.enc1 = nn.Conv2d(in_channels=T, out_channels=12, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.enc2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.enc3 = nn.Conv2d(in_channels=24, out_channels=32, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.enc4 = nn.Conv2d(in_channels=32, out_channels=encoded_channels[0], kernel_size=(3,3), stride=1, padding=1)\n",
    "\n",
    "        self.ref = nn.ReflectionPad2d(1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "        self.acti = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc1 = nn.Linear(encoded_channels[0], encoded_channels[0] * encoded_channels[1])\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.xavier_normal_(m.weight)\n",
    "                init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.enc1(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.enc2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.enc3(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.enc4(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = x.view(-1, *encoded_channels)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Decoder2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder2D, self).__init__()\n",
    "\n",
    "        self.dec1 = nn.ConvTranspose2d(in_channels=encoded_channels[0]*2, out_channels=256, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.dec2 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.dec3 = nn.ConvTranspose2d(in_channels=128, out_channels=96, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.dec4 = nn.ConvTranspose2d(in_channels=96, out_channels=75, kernel_size=(3,3), stride=1, padding=1)\n",
    "\n",
    "        self.ref = nn.ReflectionPad2d(3)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.up75 = nn.Upsample(size=75, mode='nearest') \n",
    "        self.acti = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.dec1(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.dec2(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.dec3(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.dec4(x))\n",
    "        x = self.up75(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, adv_lr=1e-4, use_adv=True):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        # AutoEncoder Models\n",
    "        if one_dimension_conv:\n",
    "            self.static_encoder = Encoder1D()\n",
    "            self.advamic_encoder = Encoder1D()\n",
    "            self.decoder = Decoder1D()\n",
    "        else:\n",
    "            self.static_encoder = Encoder2D()\n",
    "            self.dynamic_encoder = Encoder2D()\n",
    "            self.decoder = Decoder1D()\n",
    "\n",
    "        # Adversarial Models\n",
    "        self.use_adv = use_adv\n",
    "        if use_adv:\n",
    "            self.priv_adv = Adversary_Emb(privacy_classes).to(device) # input = dynamic embedding, output = privacy class\n",
    "            self.priv_coop = Adversary_Emb(privacy_classes).to(device) # input = static embedding, output = privacy class\n",
    "            self.util_adv = Adversary_Emb(utility_classes).to(device) # input = static embedding, output = utility class\n",
    "            self.util_coop = Adversary_Emb(utility_classes).to(device) # input = dynamic embedding, output = utility class\n",
    "            # self.discriminator = Discriminator().to(device)\n",
    "\n",
    "            self.priv_optim = torch.optim.AdamW(self.priv_adv.parameters(), lr=adv_lr)\n",
    "            self.priv_coop_optim = torch.optim.AdamW(self.priv_coop.parameters(), lr=adv_lr)\n",
    "            self.util_optim = torch.optim.AdamW(self.util_adv.parameters(), lr=adv_lr)\n",
    "            self.util_coop_optim = torch.optim.AdamW(self.util_coop.parameters(), lr=adv_lr)\n",
    "            # self.discriminator_optim = torch.optim.AdamW(self.discriminator.parameters(), lr=adv_lr)\n",
    "\n",
    "            # Freeze Adversarial Models\n",
    "            self.priv_adv.eval()\n",
    "            self.priv_coop.eval()\n",
    "            self.util_adv.eval()\n",
    "            self.util_coop.eval()\n",
    "            # self.discriminator.eval()\n",
    "\n",
    "        # Loss Functions\n",
    "        self.triplet_loss = nn.TripletMarginLoss()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Info for loss functions\n",
    "        self.end_effectors = torch.tensor([19, 15, 23, 24, 21, 22, 3]).to(device) * 3\n",
    "        self.chain_lengths = torch.tensor([5, 5, 8, 8, 8, 8, 5]).to(device)\n",
    "\n",
    "        # Lambdas for discounted loss\n",
    "        self.lambda_rec = 2\n",
    "        self.lambda_cross = 0.1\n",
    "        self.lambda_ee = 1\n",
    "        self.lambda_smoothing = 3\n",
    "        self.lambda_trip = 1\n",
    "        self.lambda_latent = 10\n",
    "        self.lambda_adv_util_coop = util_classifier_alpha\n",
    "        self.lambda_adv_priv_coop = priv_classifier_alpha\n",
    "        self.lambda_adv_util_adv = util_classifier_alpha\n",
    "        self.lambda_adv_priv_adv = priv_classifier_alpha\n",
    "        self.lambda_adv_disc = 1\n",
    "\n",
    "        # Loss Toggles\n",
    "        self.use_rec_loss = True\n",
    "        self.use_cross_loss = True\n",
    "        self.use_ee_loss = True \n",
    "        self.use_trip_loss_paired = True \n",
    "        self.use_trip_loss_unpaired = True\n",
    "        self.use_smoothing_loss = True\n",
    "        self.use_latent_consistency = True\n",
    "\n",
    "    def get_loss_params(self):\n",
    "        return {\n",
    "            'lambda_rec': self.lambda_rec,\n",
    "            'lambda_cross': self.lambda_cross,\n",
    "            'lambda_ee': self.lambda_ee,\n",
    "            'lambda_trip': self.lambda_trip,\n",
    "            'lambda_latent': self.lambda_latent,\n",
    "            'lambda_adv_util_coop': self.lambda_adv_util_coop,\n",
    "            'lambda_adv_priv_coop': self.lambda_adv_priv_coop,\n",
    "            'lambda_adv_util_adv': self.lambda_adv_util_adv,\n",
    "            'lambda_adv_priv_adv': self.lambda_adv_priv_adv,\n",
    "            'lambda_adv_disc': self.lambda_adv_disc,\n",
    "            'use_rec_loss': self.use_rec_loss,\n",
    "            'use_cross_loss': self.use_cross_loss,\n",
    "            'use_ee_loss': self.use_ee_loss,\n",
    "            'use_trip_loss_paired': self.use_trip_loss_paired,\n",
    "            'use_trip_loss_unpaired': self.use_trip_loss_unpaired,\n",
    "            'use_smoothing_loss': self.use_smoothing_loss,\n",
    "            'use_latent_consistency': self.use_latent_consistency\n",
    "        }\n",
    "\n",
    "    def cross(self, x1, x1_rot, x2, x2_rot):\n",
    "        d1 = self.dynamic_encoder(x1_rot)\n",
    "        d2 = self.dynamic_encoder(x2_rot)\n",
    "        s1 = self.static_encoder(x1)\n",
    "        s2 = self.static_encoder(x2)\n",
    "        \n",
    "        x1_hat = self.decoder(torch.cat((d1, s1), dim=1))\n",
    "        x2_hat = self.decoder(torch.cat((d2, s2), dim=1))\n",
    "        y1_hat = self.decoder(torch.cat((d1, s2), dim=1))\n",
    "        y2_hat = self.decoder(torch.cat((d2, s1), dim=1))\n",
    "\n",
    "        return x1_hat, x2_hat, y1_hat, y2_hat\n",
    "    \n",
    "    def eval(self, x1_rot, x2):\n",
    "        dynamic = self.dynamic_encoder(x1_rot)\n",
    "        static = self.static_encoder(x2)\n",
    "        return self.decoder(torch.cat((dynamic, static), dim=1))\n",
    "\n",
    "    def rec_loss(self, x, x_rot):\n",
    "        d = self.dynamic_encoder(x_rot)\n",
    "        s = self.static_encoder(x)\n",
    "        x_hat = self.decoder(torch.cat((d, s), dim=1))\n",
    "        if not one_dimension_conv:\n",
    "            x_ = x.reshape(x.size(0), T, -1)\n",
    "        return self.reconstruction_loss(x_, x_hat)\n",
    "    \n",
    "    def loss_paired(self, x1, x1_rot, x2, x2_rot, y1, y1_rot, y2, y2_rot, actors, actions, cross = True, reconstruction = True, emb_adv = True, discrim_adv = False, verbose = False):\n",
    "        d1 = self.dynamic_encoder(x1_rot) # A1\n",
    "        d2 = self.dynamic_encoder(x2_rot) # A2\n",
    "        s1 = self.static_encoder(x1) # P1\n",
    "        s2 = self.static_encoder(x2) # P2\n",
    "\n",
    "        x1_hat = self.decoder(torch.cat((d1, s1), dim=1)) # P1, A1\n",
    "        x2_hat = self.decoder(torch.cat((d2, s2), dim=1)) # P2, A2\n",
    "        y1_hat = self.decoder(torch.cat((d1, s2), dim=1)) # P2, A1\n",
    "        y2_hat = self.decoder(torch.cat((d2, s1), dim=1)) # P1, A2\n",
    "\n",
    "        d12 = self.dynamic_encoder(y1_rot) # A1\n",
    "        d21 = self.dynamic_encoder(y2_rot) # A2\n",
    "        s12 = self.static_encoder(y1) # P2\n",
    "        s21 = self.static_encoder(y2) # P1\n",
    "\n",
    "        x1_hat_ = self.decoder(torch.cat((d12, s21), dim=1)) # P1, A1\n",
    "        x2_hat_ = self.decoder(torch.cat((d21, s12), dim=1)) # P2, A2\n",
    "        y1_hat_ = self.decoder(torch.cat((d12, s12), dim=1)) # P2, A1\n",
    "        y2_hat_ = self.decoder(torch.cat((d21, s21), dim=1)) # P1, A2\n",
    "\n",
    "        # flatten data if 2D\n",
    "        if not one_dimension_conv:\n",
    "            x1 = x1.view(x1.size(0), T, -1)\n",
    "            x2 = x2.view(x2.size(0), T, -1)\n",
    "            y1 = y1.view(y1.size(0), T, -1)\n",
    "            y2 = y2.view(y2.size(0), T, -1)\n",
    "        \n",
    "        # initialize all losses to 0 tensor\n",
    "        rec_loss = torch.zeros(1).to(device)\n",
    "        cross_loss = torch.zeros(1).to(device)\n",
    "        end_effector_loss = torch.zeros(1).to(device)\n",
    "        triplet_loss = torch.zeros(1).to(device)\n",
    "        smoothing_loss = torch.zeros(1).to(device)\n",
    "        latent_consistency_loss = torch.zeros(1).to(device)\n",
    "        privacy_loss = torch.zeros(1).to(device)\n",
    "        privacy_loss_adv = torch.zeros(1).to(device)\n",
    "        privacy_loss_coop = torch.zeros(1).to(device)\n",
    "        utility_loss = torch.zeros(1).to(device)\n",
    "        utility_loss_adv = torch.zeros(1).to(device)\n",
    "        utility_loss_coop = torch.zeros(1).to(device)\n",
    "        privacy_acc_adv = torch.zeros(1).to(device)\n",
    "        privacy_acc_coop = torch.zeros(1).to(device)\n",
    "        utility_acc_adv = torch.zeros(1).to(device)\n",
    "        utility_acc_coop = torch.zeros(1).to(device)\n",
    "        discriminator_loss = torch.zeros(1).to(device)\n",
    "        discriminator_acc = torch.zeros(1).to(device)\n",
    "                        \n",
    "        # reconstruction loss\n",
    "        if self.use_rec_loss and reconstruction:\n",
    "            rec_loss = (self.reconstruction_loss(x1, x1_hat) + self.reconstruction_loss(x2, x2_hat) + self.reconstruction_loss(y1, y1_hat_) + self.reconstruction_loss(y2, y2_hat_)) / 4\n",
    "            if verbose: print('Reconstruction Loss: ', rec_loss.item())\n",
    "        \n",
    "        # cross reconstruction loss\n",
    "        if self.use_cross_loss and cross:\n",
    "            # could move this to its own function, but since cross is basically reconstruction, its fine like this\n",
    "            cross_loss = (self.reconstruction_loss(y1, y1_hat) + self.reconstruction_loss(y2, y2_hat) + self.reconstruction_loss(x1, x1_hat_) + self.reconstruction_loss(x2, x2_hat_)) / 4\n",
    "            if verbose: print('Cross Reconstruction Loss: ', cross_loss.item())\n",
    "        \n",
    "        # end effector loss\n",
    "        if self.use_ee_loss:\n",
    "            if reconstruction:\n",
    "                end_effector_loss += (self.end_effector_loss(x1_hat, x1) + self.end_effector_loss(x2_hat, x2)) / 2\n",
    "            if cross:\n",
    "                end_effector_loss += (self.end_effector_loss(y1_hat, y1) + self.end_effector_loss(y2_hat, y2)) / 2\n",
    "            if verbose: print('End Effector Loss: ', end_effector_loss.item())\n",
    "\n",
    "        # triplet loss\n",
    "        if self.use_trip_loss_paired: # anchor, positive, negative\n",
    "            # d1 = A1, d2 = A2, d12 = A1, d21 = A2\n",
    "            # s1 = P1, s2 = P2, s12 = P2, s21 = P1\n",
    "            # d12,s12 = y1, d21,s21 = y2\n",
    "            # y1 = jk, y2 = il\n",
    "            triplet_loss = self.triplet_loss(d12, d1, d2) \\\n",
    "                            + self.triplet_loss(d21, d2, d1) \\\n",
    "                            + self.triplet_loss(s12, s2, s1) \\\n",
    "                            + self.triplet_loss(s21, s1, s2) \n",
    "            if verbose: print('Triplet Loss: ', triplet_loss.item())\n",
    "\n",
    "        if self.use_smoothing_loss:\n",
    "            smoothing_loss = (self.smoothing_loss(x1, x1_hat) + self.smoothing_loss(x2, x2_hat) + self.smoothing_loss(y1, y1_hat_) + self.smoothing_loss(y2, y2_hat_) + \\\n",
    "                                self.smoothing_loss(x1, x1_hat_) + self.smoothing_loss(x2, x2_hat_) + self.smoothing_loss(y1, y1_hat) + self.smoothing_loss(y2, y2_hat)) / 8\n",
    "            if verbose: print('Smoothing Loss: ', smoothing_loss.item())\n",
    "\n",
    "        # latent consistency loss\n",
    "        if self.use_latent_consistency:\n",
    "            latent_consistency_loss = (self.latent_consistency_loss(d1, d12) + self.latent_consistency_loss(d2, d21) + self.latent_consistency_loss(s1, s21) + self.latent_consistency_loss(s2, s12)) / 4\n",
    "            if verbose: print('Latent Consistency Loss: ', latent_consistency_loss.item())\n",
    "\n",
    "        # adversarial loss\n",
    "        if self.use_adv and emb_adv:\n",
    "            actor_y1, actor_y2 = actors[0] - 1, actors[1] - 1\n",
    "            actor_y1, actor_y2 = torch.eye(privacy_classes)[actor_y1.long()].to(device), torch.eye(privacy_classes)[actor_y2.long()].to(device)\n",
    "            action_y1, action_y2 = actions[0] - 1, actions[1] - 1\n",
    "            action_y1, action_y2 = torch.eye(utility_classes)[action_y1.long()].to(device), torch.eye(utility_classes)[action_y2.long()].to(device)\n",
    "\n",
    "\n",
    "            # privacy loss (adversarial)\n",
    "            privacy_loss_adv = (-self.adv_loss(self.priv_adv, d1, actor_y1) -self.adv_loss(self.priv_adv, d2, actor_y2))/2\n",
    "            privacy_acc_adv = (self.adv_accuracy(self.priv_adv, d1, actor_y1) + self.adv_accuracy(self.priv_adv, d2, actor_y2))/2\n",
    "\n",
    "            # privacy loss (coop)\n",
    "            privacy_loss_coop = (self.adv_loss(self.priv_coop, s1, actor_y1) + self.adv_loss(self.priv_coop, s2, actor_y2))/2\n",
    "            privacy_acc_coop = (self.adv_accuracy(self.priv_coop, s1, actor_y1) + self.adv_accuracy(self.priv_coop, s2, actor_y2))/2\n",
    "\n",
    "            # utility loss (adversarial)\n",
    "            utility_loss_adv = (-self.adv_loss(self.util_adv, s1, action_y1) -self.adv_loss(self.util_adv, s2, action_y2))/2\n",
    "            utility_acc_adv = (self.adv_accuracy(self.util_adv, s1, action_y1) + self.adv_accuracy(self.util_adv, s2, action_y2))/2\n",
    "\n",
    "            # utility loss (coop)\n",
    "            utility_loss_coop = (self.adv_loss(self.util_coop, d1, action_y1) + self.adv_loss(self.util_coop, d2, action_y2))/2\n",
    "            utility_acc_coop = (self.adv_accuracy(self.util_coop, d1, action_y1) + self.adv_accuracy(self.util_coop, d2, action_y2))/2\n",
    "\n",
    "            privacy_loss = privacy_loss_adv * self.lambda_adv_priv_adv + privacy_loss_coop * self.lambda_adv_priv_coop\n",
    "            utility_loss = utility_loss_adv * self.lambda_adv_util_adv + utility_loss_coop * self.lambda_adv_util_coop\n",
    "\n",
    "            if verbose: \n",
    "                print('Privacy Loss (Adversarial): ', privacy_loss_adv.item(), '\\tPrivacy Loss (Coop): ', privacy_loss_coop.item())\n",
    "                print('Utility Loss (Adversarial): ', utility_loss_adv.item(), '\\tUtility Loss (Coop): ', utility_loss_coop.item())\n",
    "                print('Privacy Accuracy (Adversarial): ', privacy_acc_adv.item(), '\\tPrivacy Accuracy (Coop): ', privacy_acc_coop.item())\n",
    "                print('Utility Accuracy (Adversarial): ', utility_acc_adv.item(), '\\tUtility Accuracy (Coop): ', utility_acc_coop.item())\n",
    "            \n",
    "\n",
    "        # if self.use_adv and discrim_adv:\n",
    "        #     # discrimnator (adversarial)\n",
    "        #     discrim_out_fake = self.discriminator(torch.cat((x1_hat, x2_hat, y1_hat, y2_hat, x1_hat_, x2_hat_, y1_hat_, y2_hat_)))\n",
    "        #     discriminator_loss = self.bce_loss(discrim_out_fake, torch.ones_like(discrim_out_fake))\n",
    "        #     discriminator_acc = torch.sum(torch.round(discrim_out_fake) == 0).float() / (8 * batch_size)\n",
    "        #     if verbose: print('Discriminator Loss: ', discriminator_loss.item(), '\\tDiscriminator Accuracy: ', discriminator_acc.item())\n",
    "\n",
    "        losses = {\n",
    "            'rec_loss': rec_loss.item(),\n",
    "            'cross_loss': cross_loss.item(),\n",
    "            'end_effector_loss': end_effector_loss.item(),\n",
    "            'triplet_loss': triplet_loss.item(),\n",
    "            'smoothing_loss': smoothing_loss.item(),\n",
    "            'latent_consistency_loss': latent_consistency_loss.item(),\n",
    "            'privacy_loss': privacy_loss.item(),\n",
    "            'privacy_loss_adv': privacy_loss_adv.item(),\n",
    "            'privacy_loss_coop': privacy_loss_coop.item(),\n",
    "            'privacy_acc_adv': privacy_acc_adv.item(),\n",
    "            'privacy_acc_coop': privacy_acc_coop.item(),\n",
    "            'utility_loss': utility_loss.item(),\n",
    "            'utility_loss_adv': utility_loss_adv.item(),\n",
    "            'utility_loss_coop': utility_loss_coop.item(),\n",
    "            'utility_acc_adv': utility_acc_adv.item(),\n",
    "            'utility_acc_coop': utility_acc_coop.item(),\n",
    "            'discriminator_loss': discriminator_loss.item(),\n",
    "            'discriminator_acc': discriminator_acc.item()\n",
    "        }\n",
    "\n",
    "        return rec_loss * self.lambda_rec \\\n",
    "                + cross_loss * self.lambda_cross \\\n",
    "                + end_effector_loss * self.lambda_ee \\\n",
    "                + triplet_loss * self.lambda_trip \\\n",
    "                + latent_consistency_loss * self.lambda_latent \\\n",
    "                + privacy_loss \\\n",
    "                + utility_loss \\\n",
    "                + discriminator_loss * self.lambda_adv_disc \\\n",
    "                + smoothing_loss * self.lambda_smoothing, \\\n",
    "                x1_hat, x2_hat, y1_hat, y2_hat, losses\n",
    "\n",
    "    def loss_unpaired(self, x_pos, x_rot, actors, actions, reconstruction = True, emb_adv = False, discrim_adv = False, ee = False, triplet = False, verbose = False):\n",
    "        d = self.dynamic_encoder(x_rot)\n",
    "        s = self.static_encoder(x_pos)\n",
    "        x_hat = self.decoder(torch.cat((d, s), dim=1))\n",
    "\n",
    "        if not one_dimension_conv:\n",
    "            x = x_pos.reshape(x_pos.size(0), T, -1)\n",
    "\n",
    "        # initialize all losses to 0 tensor\n",
    "        rec_loss = torch.zeros(1).to(device)\n",
    "        end_effector_loss = torch.zeros(1).to(device)\n",
    "        triplet_loss = torch.zeros(1).to(device)\n",
    "        smoothing_loss = torch.zeros(1).to(device)\n",
    "        privacy_loss = torch.zeros(1).to(device)\n",
    "        privacy_loss_adv = torch.zeros(1).to(device)\n",
    "        privacy_loss_coop = torch.zeros(1).to(device)\n",
    "        utility_loss = torch.zeros(1).to(device)\n",
    "        utility_loss_adv = torch.zeros(1).to(device)\n",
    "        utility_loss_coop = torch.zeros(1).to(device)\n",
    "        privacy_acc_adv = torch.zeros(1).to(device)\n",
    "        privacy_acc_coop = torch.zeros(1).to(device)\n",
    "        utility_acc_adv = torch.zeros(1).to(device)\n",
    "        utility_acc_coop = torch.zeros(1).to(device)\n",
    "        discriminator_loss = torch.zeros(1).to(device)\n",
    "        discriminator_acc = torch.zeros(1).to(device)\n",
    "\n",
    "        # Reconstruction Loss\n",
    "        if self.use_rec_loss and reconstruction:\n",
    "            rec_loss = self.reconstruction_loss(x, x_hat)\n",
    "            if verbose: print('Reconstruction Loss: ', rec_loss.item())\n",
    "\n",
    "        # End Effector Loss\n",
    "        if self.use_ee_loss and ee:\n",
    "            end_effector_loss = self.end_effector_loss(x_hat, x)\n",
    "            if verbose: print('End Effector Loss: ', end_effector_loss.item())\n",
    "\n",
    "        # Triplet Loss\n",
    "        if self.use_trip_loss_unpaired and triplet: # anchor, positive, negative\n",
    "            triplet_loss = (self.triplet_loss(d, d, s) + self.triplet_loss(s, s, d)) / 2\n",
    "            if verbose: print('Triplet Loss: ', triplet_loss.item())\n",
    "\n",
    "        # Smoothing Loss\n",
    "        if self.use_smoothing_loss:\n",
    "            smoothing_loss = self.smoothing_loss(x, x_hat)\n",
    "            if verbose: print('Smoothing Loss: ', smoothing_loss.item())\n",
    "\n",
    "        # Adversarial Loss\n",
    "        if self.use_adv and emb_adv:\n",
    "            actor_y = actors - 1\n",
    "            actor_y = torch.eye(privacy_classes)[actor_y.long()].to(device)\n",
    "            action_y = actions - 1\n",
    "            action_y = torch.eye(utility_classes)[action_y.long()].to(device)\n",
    "\n",
    "            # latent privacy loss (adv)\n",
    "            privacy_loss_adv = -self.adv_loss(self.priv_adv, d, actor_y)\n",
    "            privacy_acc_adv = self.adv_accuracy(self.priv_adv, d, actor_y)\n",
    "\n",
    "            # latent privacy loss (coop)\n",
    "            privacy_loss_coop = self.adv_loss(self.priv_coop, s, actor_y)\n",
    "            privacy_acc_coop = self.adv_accuracy(self.priv_coop, s, actor_y)\n",
    "\n",
    "            # latent utility loss (adv)\n",
    "            utility_loss_adv = -self.adv_loss(self.util_adv, s, action_y)\n",
    "            utility_acc_adv = self.adv_accuracy(self.util_adv, s, action_y)\n",
    "\n",
    "            # latent utility loss (coop)\n",
    "            utility_loss_coop = self.adv_loss(self.util_coop, d, action_y)\n",
    "            utility_acc_coop = self.adv_accuracy(self.util_coop, d, action_y)\n",
    "\n",
    "            privacy_loss = privacy_loss_adv * self.lambda_adv_priv_adv + privacy_loss_coop * self.lambda_adv_priv_coop\n",
    "            utility_loss = utility_loss_adv * self.lambda_adv_util_adv + utility_loss_coop * self.lambda_adv_util_coop\n",
    "\n",
    "            if verbose: \n",
    "                print('Privacy Loss Adv: ', privacy_loss_adv.item(), '\\tPrivacy Loss Coop: ', privacy_loss_coop.item(), '\\tPrivacy Loss: ', privacy_loss.item())\n",
    "                print('Utility Loss Adv: ', utility_loss_adv.item(), '\\tUtility Loss Coop: ', utility_loss_coop.item(), '\\tUtility Loss: ', utility_loss.item())\n",
    "                print('Privacy Accuracy Adv: ', privacy_acc_adv.item(), '\\tPrivacy Accuracy Coop: ', privacy_acc_coop.item())\n",
    "                print('Utility Accuracy Adv: ', utility_acc_adv.item(), '\\tUtility Accuracy Coop: ', utility_acc_coop.item())\n",
    "\n",
    "\n",
    "        # if self.use_adv and discrim_adv:\n",
    "        #     # discrimnator (adversarial)\n",
    "        #     discrim_out_fake = self.discriminator(x_hat)\n",
    "        #     discriminator_loss = self.bce_loss(discrim_out_fake, torch.ones_like(discrim_out_fake))\n",
    "        #     discriminator_acc = torch.sum(torch.round(discrim_out_fake) == 0).float() / (batch_size)\n",
    "        #     if verbose: print('Discriminator Loss: ', discriminator_loss.item(), '\\tDiscriminator Accuracy: ', discriminator_acc.item())\n",
    "\n",
    "        losses = {\n",
    "            'rec_loss': rec_loss.item(),\n",
    "            'end_effector_loss': end_effector_loss.item(),\n",
    "            'triplet_loss': triplet_loss.item(),\n",
    "            'smoothing_loss': smoothing_loss.item(),\n",
    "            'privacy_loss': privacy_loss.item(),\n",
    "            'privacy_loss_adv': privacy_loss_adv.item(),\n",
    "            'privacy_loss_coop': privacy_loss_coop.item(),\n",
    "            'privacy_acc_adv': privacy_acc_adv.item(),\n",
    "            'privacy_acc_coop': privacy_acc_coop.item(),\n",
    "            'utility_loss': utility_loss.item(),\n",
    "            'utility_loss_adv': utility_loss_adv.item(),\n",
    "            'utility_loss_coop': utility_loss_coop.item(),\n",
    "            'utility_acc_adv': utility_acc_adv.item(),\n",
    "            'utility_acc_coop': utility_acc_coop.item(),\n",
    "            'discriminator_loss': discriminator_loss.item(),\n",
    "            'discriminator_acc': discriminator_acc.item()\n",
    "        }\n",
    "\n",
    "        return rec_loss * self.lambda_rec \\\n",
    "                + end_effector_loss * self.lambda_ee \\\n",
    "                + triplet_loss * self.lambda_trip \\\n",
    "                + privacy_loss \\\n",
    "                + utility_loss \\\n",
    "                + discriminator_loss * self.lambda_adv_disc \\\n",
    "                + smoothing_loss * self.lambda_smoothing, \\\n",
    "                x_hat, losses\n",
    "\n",
    "    def reconstruction_loss(self, x, y):\n",
    "        # return F.mse_loss(x, y)\n",
    "        return torch.square(torch.norm(x - y, dim=1)).mean()\n",
    "    \n",
    "    def latent_consistency_loss(self, x, y):\n",
    "        return F.mse_loss(x, y)\n",
    "    \n",
    "    def end_effector_loss(self, x, y):\n",
    "        # slice to get the end effector joints\n",
    "        x_ee = x[:, :, self.end_effectors.unsqueeze(-1) + torch.arange(3).to(device)] \n",
    "        y_ee = y[:, :, self.end_effectors.unsqueeze(-1) + torch.arange(3).to(device)]\n",
    "\n",
    "        # calculate velocities\n",
    "        x_vel = torch.norm(x_ee[:, 1:] - x_ee[:, :-1], dim=-1) / self.chain_lengths.unsqueeze(0)\n",
    "        y_vel = torch.norm(y_ee[:, 1:] - y_ee[:, :-1], dim=-1) / self.chain_lengths.unsqueeze(0)\n",
    "        \n",
    "        # compute mse loss for each joint\n",
    "        losses = F.mse_loss(x_vel, y_vel, reduction='none')\n",
    "\n",
    "        # take sum over end effectors\n",
    "        loss = losses.sum(dim=1)\n",
    "\n",
    "        # take mean over batch\n",
    "        loss = loss.mean()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def smoothing_loss(self, y, y_pred):\n",
    "        # (batch, T, 75)\n",
    "        # Calculate the squared sum of differences for y and y_pred\n",
    "        diff_y = torch.sum(y[:, :-1] - y[:, 1:], dim=2) ** 2\n",
    "        diff_y_pred = torch.sum(y_pred[:, :-1] - y_pred[:, 1:], dim=2) ** 2\n",
    "\n",
    "        # Calculate the absolute difference\n",
    "        abs_diff = torch.abs(diff_y - diff_y_pred)\n",
    "\n",
    "        # Sum over all batches and sequence elements\n",
    "        loss = torch.sum(abs_diff)\n",
    "\n",
    "        # Normalize by the total number of elements (batch_size * sequence_length)\n",
    "        total_loss = torch.sqrt(loss) / (y.size(0) * y.size(1))\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def adv_loss(self, model, x, y):\n",
    "        return self.cross_entropy(model(x), y)#.long().to(device))\n",
    "    \n",
    "    def adv_accuracy(self, model, x, y):\n",
    "        return (model(x).argmax(dim=1) == y.argmax(dim=1).to(device)).float().mean()\n",
    "\n",
    "    def train_adv_paired(self, x1, x1_rot, x2, x2_rot, y1, y1_rot, y2, y2_rot, actors, actions, train_emb = True, train_discrim = True):\n",
    "        if not self.use_adv: return 0,0\n",
    "        # freeze encoders/decoder\n",
    "        self.dynamic_encoder.eval()\n",
    "        self.static_encoder.eval()\n",
    "        self.decoder.eval()\n",
    "\n",
    "        # unfreeze adversaries\n",
    "        self.priv_adv.train()\n",
    "        self.util_adv.train()\n",
    "        # self.discriminator.train()\n",
    "\n",
    "        # zero out gradients\n",
    "        self.priv_optim.zero_grad()\n",
    "        self.util_optim.zero_grad()\n",
    "        # self.discriminator_optim.zero_grad()\n",
    "\n",
    "        # encode\n",
    "        d1 = self.dynamic_encoder(x1_rot) # A1\n",
    "        d2 = self.dynamic_encoder(x2_rot) # A2\n",
    "        d3 = self.dynamic_encoder(y1_rot) # A2\n",
    "        d4 = self.dynamic_encoder(y2_rot) # A1\n",
    "        s1 = self.static_encoder(x1) # P1\n",
    "        s2 = self.static_encoder(x2) # P2\n",
    "        s3 = self.static_encoder(y1) # P1\n",
    "        s4 = self.static_encoder(y2) # P2\n",
    "\n",
    "        # decode\n",
    "        x1_hat = self.decoder(torch.cat((d1, s1), dim=1)) # P1, A1\n",
    "        x2_hat = self.decoder(torch.cat((d2, s2), dim=1)) # P2, A2\n",
    "        y1_hat = self.decoder(torch.cat((d3, s3), dim=1)) # P1, A2\n",
    "        y2_hat = self.decoder(torch.cat((d4, s4), dim=1)) # P2, A1\n",
    "\n",
    "        # instantiate losses\n",
    "        priv_loss = torch.zeros(1).to(device)\n",
    "        priv_coop_loss = torch.zeros(1).to(device)\n",
    "        priv_acc = torch.zeros(1).to(device)\n",
    "        priv_coop_acc = torch.zeros(1).to(device)\n",
    "        util_loss = torch.zeros(1).to(device)\n",
    "        util_coop_loss = torch.zeros(1).to(device)\n",
    "        util_acc = torch.zeros(1).to(device)\n",
    "        util_coop_acc = torch.zeros(1).to(device)\n",
    "        discriminator_loss = torch.zeros(1).to(device)\n",
    "        discriminator_acc = torch.zeros(1).to(device)\n",
    "\n",
    "        if train_emb:\n",
    "            # train privacy adversary\n",
    "            p1, p2 = actors[0] - 1, actors[1] - 1\n",
    "            p1, p2 = torch.eye(privacy_classes)[p1.long()].to(device), torch.eye(privacy_classes)[p2.long()].to(device)\n",
    "            priv_loss = (self.cross_entropy(self.priv_adv(d1), p1) + \\\n",
    "                        self.cross_entropy(self.priv_adv(d2), p2) + \\\n",
    "                        self.cross_entropy(self.priv_adv(d3), p1) + \\\n",
    "                        self.cross_entropy(self.priv_adv(d4), p2)) / 4\n",
    "            priv_acc = (self.adv_accuracy(self.priv_adv, d1, p1) + self.adv_accuracy(self.priv_adv, d2, p2) + self.adv_accuracy(self.priv_adv, d3, p1) + self.adv_accuracy(self.priv_adv, d4, p2)) / 4\n",
    "            priv_loss.backward(retain_graph=True)\n",
    "            self.priv_optim.step()\n",
    "\n",
    "            # train privacy cooperative\n",
    "            priv_coop_loss = (self.cross_entropy(self.priv_coop(s1), p1) + \\\n",
    "                            self.cross_entropy(self.priv_coop(s2), p2) + \\\n",
    "                            self.cross_entropy(self.priv_coop(s3), p1) + \\\n",
    "                            self.cross_entropy(self.priv_coop(s4), p2)) / 4\n",
    "            priv_coop_acc = (self.adv_accuracy(self.priv_coop, s1, p1) + self.adv_accuracy(self.priv_coop, s2, p2) + self.adv_accuracy(self.priv_coop, s3, p1) + self.adv_accuracy(self.priv_coop, s4, p2)) / 4\n",
    "            priv_coop_loss.backward(retain_graph=True)\n",
    "            self.priv_coop_optim.step()\n",
    "                        \n",
    "            # train utility adversary\n",
    "            a1, a2 = actions[0] - 1, actions[1] - 1\n",
    "            a1, a2 = torch.eye(utility_classes)[a1.long()].to(device), torch.eye(utility_classes)[a2.long()].to(device)\n",
    "            util_loss = (self.cross_entropy(self.util_adv(s1), a1) + \\\n",
    "                        self.cross_entropy(self.util_adv(s2), a2) + \\\n",
    "                        self.cross_entropy(self.util_adv(s3), a2) + \\\n",
    "                        self.cross_entropy(self.util_adv(s4), a1)) / 4\n",
    "            util_acc = (self.adv_accuracy(self.util_adv, s1, a1) + self.adv_accuracy(self.util_adv, s2, a2) + self.adv_accuracy(self.util_adv, s3, a2) + self.adv_accuracy(self.util_adv, s4, a1)) / 4\n",
    "            util_loss.backward(retain_graph=True)\n",
    "            self.util_optim.step()\n",
    "\n",
    "            # train utility cooperative\n",
    "            util_coop_loss = (self.cross_entropy(self.util_coop(d1), a1) + \\\n",
    "                            self.cross_entropy(self.util_coop(d2), a2) + \\\n",
    "                            self.cross_entropy(self.util_coop(d3), a2) + \\\n",
    "                            self.cross_entropy(self.util_coop(d4), a1)) / 4\n",
    "            util_coop_acc = (self.adv_accuracy(self.util_coop, d1, a1) + self.adv_accuracy(self.util_coop, d2, a2) + self.adv_accuracy(self.util_coop, d3, a2) + self.adv_accuracy(self.util_coop, d4, a1)) / 4\n",
    "            util_coop_loss.backward(retain_graph=True)\n",
    "            self.util_coop_optim.step()\n",
    "\n",
    "\n",
    "        # if train_discrim:\n",
    "        #     # train discriminator\n",
    "        #     output_real = self.discriminator(torch.cat((x1.view(x1.size(0), T, -1), x2.view(x2.size(0), T, -1), y1.view(y1.size(0), T, -1), y2.view(y1.size(0), T, -1))))\n",
    "        #     output_fake = self.discriminator(torch.cat((x1_hat, x2_hat, y1_hat, y2_hat)))\n",
    "        #     discriminator_loss = self.bce_loss(output_real, torch.ones_like(output_real)) + self.bce_loss(output_fake, torch.zeros_like(output_fake))\n",
    "        #     discriminator_acc = ((torch.sum(torch.round(output_fake) == 0).float() / (4 * batch_size)) + (torch.sum(torch.round(output_real) == 1).float() / (4 * batch_size))) / 2\n",
    "        #     discriminator_loss.backward()\n",
    "        #     self.discriminator_optim.step()\n",
    "\n",
    "        # unfreeze encoders/decoder\n",
    "        self.dynamic_encoder.train()\n",
    "        self.static_encoder.train()\n",
    "        self.decoder.train()\n",
    "\n",
    "        # freeze adversaries\n",
    "        self.priv_adv.eval()\n",
    "        self.priv_coop.eval()\n",
    "        self.util_adv.eval()\n",
    "        self.util_coop.eval()\n",
    "        # self.discriminator.eval()\n",
    "\n",
    "        return priv_loss.item(), priv_coop_loss.item(), util_loss.item(), util_coop_loss.item(), discriminator_loss.item(), priv_acc.item(), util_acc.item(), priv_coop_acc.item(), util_coop_acc.item(), discriminator_acc.item()\n",
    "\n",
    "    def train_adv_unpaired(self, x_pos, x_rot, actor, action, train_emb = True, train_discrim = True):\n",
    "        # ensure one training method is enabled\n",
    "        assert train_emb or train_discrim, 'At least one training method must be enabled'\n",
    "\n",
    "        # freeze encoders/decoder\n",
    "        self.dynamic_encoder.eval()\n",
    "        self.static_encoder.eval()\n",
    "        self.decoder.eval()\n",
    "\n",
    "        # unfreeze adversaries\n",
    "        self.priv_adv.train()\n",
    "        self.priv_coop.train()\n",
    "        self.util_adv.train()\n",
    "        self.util_coop.train()\n",
    "        # self.discriminator.train()\n",
    "\n",
    "        # zero out gradients\n",
    "        self.priv_optim.zero_grad()\n",
    "        self.priv_coop_optim.zero_grad()\n",
    "        self.util_optim.zero_grad()\n",
    "        self.util_coop_optim.zero_grad()\n",
    "        # self.discriminator_optim.zero_grad()\n",
    "\n",
    "        # instantiate losses\n",
    "        priv_loss = torch.zeros(1).to(device)\n",
    "        priv_coop_loss = torch.zeros(1).to(device)\n",
    "        priv_acc = torch.zeros(1).to(device)\n",
    "        priv_coop_acc = torch.zeros(1).to(device)\n",
    "        util_loss = torch.zeros(1).to(device)\n",
    "        util_coop_loss = torch.zeros(1).to(device)\n",
    "        util_acc = torch.zeros(1).to(device)\n",
    "        util_coop_acc = torch.zeros(1).to(device)\n",
    "        discriminator_loss = torch.zeros(1).to(device)\n",
    "        discriminator_acc = torch.zeros(1).to(device)\n",
    "\n",
    "        if train_emb:\n",
    "            p = actor - 1\n",
    "            p = torch.eye(privacy_classes)[p.long()].to(device)\n",
    "            a = action - 1\n",
    "            a = torch.eye(utility_classes)[a.long()].to(device)\n",
    "\n",
    "            # train privacy adversary\n",
    "            priv_loss = self.adv_loss(self.priv_adv, self.dynamic_encoder(x_rot), p)\n",
    "            priv_acc = self.adv_accuracy(self.priv_adv, self.dynamic_encoder(x_rot), p)\n",
    "            priv_loss.backward()\n",
    "            self.priv_optim.step()\n",
    "\n",
    "            # tain privacy cooperative\n",
    "            priv_coop_loss = self.adv_loss(self.priv_coop, self.static_encoder(x_pos), p)\n",
    "            priv_coop_acc = self.adv_accuracy(self.priv_coop, self.static_encoder(x_pos), p)\n",
    "            priv_coop_loss.backward()\n",
    "            self.priv_coop_optim.step()\n",
    "            \n",
    "            # train utility adversary\n",
    "            util_loss = self.adv_loss(self.util_adv, self.static_encoder(x_pos), a)\n",
    "            util_acc = self.adv_accuracy(self.util_adv, self.static_encoder(x_pos), a)\n",
    "            util_loss.backward()\n",
    "            self.util_optim.step()\n",
    "\n",
    "            # train utility cooperative\n",
    "            util_coop_loss = self.adv_loss(self.util_coop, self.dynamic_encoder(x_rot), a)\n",
    "            util_coop_acc = self.adv_accuracy(self.util_coop, self.dynamic_encoder(x_rot), a)\n",
    "            util_coop_loss.backward()\n",
    "            self.util_coop_optim.step()\n",
    "\n",
    "        if train_discrim:\n",
    "            # encode\n",
    "            d = self.dynamic_encoder(x_rot)\n",
    "            s = self.static_encoder(x_pos)\n",
    "\n",
    "            # decode\n",
    "            x_hat = self.decoder(torch.cat((d, s), dim=1))\n",
    "\n",
    "            # train discriminator\n",
    "            # output_real = self.discriminator(x_pos.reshape(x_pos.size(0), T, -1))\n",
    "            # output_fake = self.discriminator(x_hat)\n",
    "            # discriminator_loss = self.bce_loss(output_real, torch.ones_like(output_real)) + self.bce_loss(output_fake, torch.zeros_like(output_fake))\n",
    "            # discriminator_acc = ((torch.sum(torch.round(output_fake) == 0).float() / batch_size) + (torch.sum(torch.round(output_real) == 1).float() / batch_size)) / 2\n",
    "            # discriminator_loss.backward()\n",
    "            # self.discriminator_optim.step()\n",
    "\n",
    "        # unfreeze encoders/decoder\n",
    "        self.dynamic_encoder.train()\n",
    "        self.static_encoder.train()\n",
    "        self.decoder.train()\n",
    "\n",
    "        # freeze adversaries\n",
    "        self.priv_adv.eval()\n",
    "        self.priv_coop.eval()\n",
    "        self.util_adv.eval()\n",
    "        self.util_coop.eval()\n",
    "        # self.discriminator.eval()\n",
    "\n",
    "        return priv_loss.item(), priv_coop_loss.item(), util_loss.item(), util_coop_loss.item(), discriminator_loss.item(), priv_acc.item(), util_acc.item(), priv_coop_acc.item(), util_coop_acc.item(), discriminator_acc.item()\n",
    "\n",
    "    def val_adv_paired(self, x1, x1_rot, x2, x2_rot, y1, y1_rot, y2, y2_rot, actors, actions, train_emb = True, train_discrim = True):\n",
    "        if not self.use_adv: return 0,0\n",
    "\n",
    "        # freeze encoders/decoder\n",
    "        self.set_eval()\n",
    "\n",
    "        # Encode\n",
    "        d1, d2, d3, d4 = [self.dynamic_encoder(x) for x in [x1_rot, x2_rot, y1_rot, y2_rot]]\n",
    "        s1, s2, s3, s4 = [self.static_encoder(x) for x in [x1, x2, y1, y2]]\n",
    "\n",
    "        # Decode\n",
    "        x1_hat, x2_hat, y1_hat, y2_hat = [self.decoder(torch.cat((d, s), dim=1)) for d, s in zip([d1, d2, d3, d4], [s1, s2, s3, s4])]\n",
    "\n",
    "        # instantiate losses\n",
    "        priv_loss = torch.zeros(1).to(device)\n",
    "        priv_coop_loss = torch.zeros(1).to(device)\n",
    "        priv_acc = torch.zeros(1).to(device)\n",
    "        priv_coop_acc = torch.zeros(1).to(device)\n",
    "        util_loss = torch.zeros(1).to(device)\n",
    "        util_coop_loss = torch.zeros(1).to(device)\n",
    "        util_acc = torch.zeros(1).to(device)\n",
    "        util_coop_acc = torch.zeros(1).to(device)\n",
    "        discriminator_loss = torch.zeros(1).to(device)\n",
    "        discriminator_acc = torch.zeros(1).to(device)\n",
    "\n",
    "        if train_emb:\n",
    "            # privacy adversary\n",
    "            p1, p2 = actors[0] - 1, actors[1] - 1\n",
    "            p1, p2 = torch.eye(privacy_classes)[p1.long()].to(device), torch.eye(privacy_classes)[p2.long()].to(device)\n",
    "            priv_loss = (self.cross_entropy(self.priv_adv(d1), p1) + \\\n",
    "                        self.cross_entropy(self.priv_adv(d2), p2) + \\\n",
    "                        self.cross_entropy(self.priv_adv(d3), p1) + \\\n",
    "                        self.cross_entropy(self.priv_adv(d4), p2)) / 4\n",
    "            priv_acc = (self.adv_accuracy(self.priv_adv, d1, p1) + self.adv_accuracy(self.priv_adv, d2, p2) + self.adv_accuracy(self.priv_adv, d3, p1) + self.adv_accuracy(self.priv_adv, d4, p2)) / 4\n",
    "\n",
    "            # privacy cooperative\n",
    "            priv_coop_loss = (self.cross_entropy(self.priv_coop(s1), p1) + \\\n",
    "                            self.cross_entropy(self.priv_coop(s2), p2) + \\\n",
    "                            self.cross_entropy(self.priv_coop(s3), p1) + \\\n",
    "                            self.cross_entropy(self.priv_coop(s4), p2)) / 4\n",
    "            priv_coop_acc = (self.adv_accuracy(self.priv_coop, s1, p1) + self.adv_accuracy(self.priv_coop, s2, p2) + self.adv_accuracy(self.priv_coop, s3, p1) + self.adv_accuracy(self.priv_coop, s4, p2)) / 4\n",
    "                        \n",
    "            # utility adversary\n",
    "            a1, a2 = actions[0] - 1, actions[1] - 1\n",
    "            a1, a2 = torch.eye(utility_classes)[a1.long()].to(device), torch.eye(utility_classes)[a2.long()].to(device)\n",
    "            util_loss = (self.cross_entropy(self.util_adv(s1), a1) + \\\n",
    "                        self.cross_entropy(self.util_adv(s2), a2) + \\\n",
    "                        self.cross_entropy(self.util_adv(s3), a2) + \\\n",
    "                        self.cross_entropy(self.util_adv(s4), a1)) / 4\n",
    "            util_acc = (self.adv_accuracy(self.util_adv, s1, a1) + self.adv_accuracy(self.util_adv, s2, a2) + self.adv_accuracy(self.util_adv, s3, a2) + self.adv_accuracy(self.util_adv, s4, a1)) / 4\n",
    "\n",
    "            # utility cooperative\n",
    "            util_coop_loss = (self.cross_entropy(self.util_coop(d1), a1) + \\\n",
    "                            self.cross_entropy(self.util_coop(d2), a2) + \\\n",
    "                            self.cross_entropy(self.util_coop(d3), a2) + \\\n",
    "                            self.cross_entropy(self.util_coop(d4), a1)) / 4\n",
    "            util_coop_acc = (self.adv_accuracy(self.util_coop, d1, a1) + self.adv_accuracy(self.util_coop, d2, a2) + self.adv_accuracy(self.util_coop, d3, a2) + self.adv_accuracy(self.util_coop, d4, a1)) / 4\n",
    "\n",
    "\n",
    "        # if train_discrim:\n",
    "        #     # discriminator\n",
    "        #     output_real = self.discriminator(torch.cat((x1.view(x1.size(0), T, -1), x2.view(x2.size(0), T, -1), y1.view(y1.size(0), T, -1), y2.view(y1.size(0), T, -1))))\n",
    "        #     output_fake = self.discriminator(torch.cat((x1_hat, x2_hat, y1_hat, y2_hat)))\n",
    "        #     discriminator_loss = self.bce_loss(output_real, torch.ones_like(output_real)) + self.bce_loss(output_fake, torch.zeros_like(output_fake))\n",
    "        #     discriminator_acc = ((torch.sum(torch.round(output_fake) == 0).float() / (4 * batch_size)) + (torch.sum(torch.round(output_real) == 1).float() / (4 * batch_size))) / 2\n",
    "\n",
    "        # unfreeze encoders/decoder\n",
    "        self.set_eval(False)\n",
    "\n",
    "        return priv_loss.item(), priv_coop_loss.item(), util_loss.item(), util_coop_loss.item(), discriminator_loss.item(), priv_acc.item(), util_acc.item(), priv_coop_acc.item(), util_coop_acc.item(), discriminator_acc.item()\n",
    "\n",
    "    def val_adv_unpaired(self, x_pos, x_rot, actor, action, train_emb = True, train_discrim = True):\n",
    "        # ensure one training method is enabled\n",
    "        assert train_emb or train_discrim, 'At least one training method must be enabled'\n",
    "\n",
    "        # freeze encoders/decoder\n",
    "        self.set_eval()\n",
    "\n",
    "        # Encode\n",
    "        d = self.dynamic_encoder(x_rot)\n",
    "        s = self.static_encoder(x_pos)\n",
    "\n",
    "        # Decode\n",
    "        x_hat = self.decoder(torch.cat((d, s), dim=1))\n",
    "\n",
    "        # instantiate losses\n",
    "        priv_loss = torch.zeros(1).to(device)\n",
    "        priv_coop_loss = torch.zeros(1).to(device)\n",
    "        priv_acc = torch.zeros(1).to(device)\n",
    "        priv_coop_acc = torch.zeros(1).to(device)\n",
    "        util_loss = torch.zeros(1).to(device)\n",
    "        util_coop_loss = torch.zeros(1).to(device)\n",
    "        util_acc = torch.zeros(1).to(device)\n",
    "        util_coop_acc = torch.zeros(1).to(device)\n",
    "        discriminator_loss = torch.zeros(1).to(device)\n",
    "        discriminator_acc = torch.zeros(1).to(device)\n",
    "\n",
    "        if train_emb:\n",
    "            p = actor - 1\n",
    "            p = torch.eye(privacy_classes)[p.long()].to(device)\n",
    "            a = action - 1\n",
    "            a = torch.eye(utility_classes)[a.long()].to(device)\n",
    "\n",
    "            # privacy adversary\n",
    "            priv_loss = self.adv_loss(self.priv_adv, self.dynamic_encoder(x_rot), p)\n",
    "            priv_acc = self.adv_accuracy(self.priv_adv, self.dynamic_encoder(x_rot), p)\n",
    "\n",
    "            # privacy cooperative\n",
    "            priv_coop_loss = self.adv_loss(self.priv_coop, self.static_encoder(x_pos), p)\n",
    "            priv_coop_acc = self.adv_accuracy(self.priv_coop, self.static_encoder(x_pos), p)\n",
    "            \n",
    "            # utility adversary\n",
    "            util_loss = self.adv_loss(self.util_adv, self.static_encoder(x_pos), a)\n",
    "            util_acc = self.adv_accuracy(self.util_adv, self.static_encoder(x_pos), a)\n",
    "\n",
    "            # utility cooperative\n",
    "            util_coop_loss = self.adv_loss(self.util_coop, self.dynamic_encoder(x_rot), a)\n",
    "            util_coop_acc = self.adv_accuracy(self.util_coop, self.dynamic_encoder(x_rot), a)\n",
    "\n",
    "        # if train_discrim:\n",
    "        #     # encode\n",
    "        #     d = self.dynamic_encoder(x_rot)\n",
    "        #     s = self.static_encoder(x_pos)\n",
    "\n",
    "        #     # decode\n",
    "        #     x_hat = self.decoder(torch.cat((d, s), dim=1))\n",
    "\n",
    "            # # train discriminator\n",
    "            # output_real = self.discriminator(x_pos.reshape(x_pos.size(0), T, -1))\n",
    "            # output_fake = self.discriminator(x_hat)\n",
    "            # discriminator_loss = self.bce_loss(output_real, torch.ones_like(output_real)) + self.bce_loss(output_fake, torch.zeros_like(output_fake))\n",
    "            # discriminator_acc = ((torch.sum(torch.round(output_fake) == 0).float() / batch_size) + (torch.sum(torch.round(output_real) == 1).float() / batch_size)) / 2\n",
    "\n",
    "        # unfreeze encoders/decoder\n",
    "        self.set_eval(False)\n",
    "\n",
    "        return priv_loss.item(), priv_coop_loss.item(), util_loss.item(), util_coop_loss.item(), discriminator_loss.item(), priv_acc.item(), util_acc.item(), priv_coop_acc.item(), util_coop_acc.item(), discriminator_acc.item()\n",
    "\n",
    "    def forward(self, x, x_rot):\n",
    "        dyn = self.dynamic_encoder(x_rot)\n",
    "        sta = self.static_encoder(x)\n",
    "        x = self.decoder(torch.cat((dyn, sta), dim=1))\n",
    "        return x\n",
    "    \n",
    "    def set_eval(self, eval=True):\n",
    "        if eval:\n",
    "            self.static_encoder.eval()\n",
    "            self.dynamic_encoder.eval()\n",
    "            self.decoder.eval()\n",
    "            self.priv_adv.eval()\n",
    "            self.priv_coop.eval()\n",
    "            self.util_adv.eval()\n",
    "            self.util_coop.eval()\n",
    "            # self.discriminator.eval()\n",
    "        else:\n",
    "            self.static_encoder.train()\n",
    "            self.dynamic_encoder.train()\n",
    "            self.decoder.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility/Privacy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, k=3):\n",
    "    acces = AverageMeter()\n",
    "    topk_acces = AverageMeter()\n",
    "    # load learnt model that obtained best performance on validation set\n",
    "    model.eval()\n",
    "\n",
    "    label_output = list()\n",
    "    pred_output = list()\n",
    "\n",
    "    for i, t in enumerate(test_loader):\n",
    "        inputs = t[0]\n",
    "        target = t[1]\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs.cuda())\n",
    "            output = output.view(\n",
    "                (-1, inputs.size(0)//target.size(0), output.size(1)))\n",
    "            output = output.mean(1)\n",
    "\n",
    "        label_output.append(target.cpu().numpy())\n",
    "        pred_output.append(output.cpu().numpy())\n",
    "\n",
    "        acc = accuracy(output.data, target.cuda())\n",
    "        acces.update(acc[0], inputs.size(0))\n",
    "        topk_acc = top_k_accuracy(output.data, target.cuda(), k=k)\n",
    "        topk_acces.update(topk_acc[0], inputs.size(0))\n",
    "\n",
    "    label_output = np.concatenate(label_output, axis=0)\n",
    "    pred_output = np.concatenate(pred_output, axis=0)\n",
    "\n",
    "    label_index = np.argmax(label_output, axis=1)\n",
    "    pred_index = np.argmax(pred_output, axis=1)\n",
    "\n",
    "    f1 = f1_score(label_index, pred_index, average='macro', zero_division=0)\n",
    "    precision = precision_score(label_index, pred_index, average='macro', zero_division=0)\n",
    "    recall = recall_score(label_index, pred_index, average='macro', zero_division=0)\n",
    "\n",
    "    return acces.avg, f1, precision, recall, topk_acces.avg\n",
    "    \n",
    "def accuracy(output, target):\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    target = torch.argmax(target, dim=1)  # Add this line to convert one-hot targets to class indices\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    correct = correct.view(-1).float().sum(0, keepdim=True)\n",
    "    return correct.mul_(100.0 / batch_size)\n",
    "\n",
    "def top_k_accuracy(output, target, k=3):\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(k, 1, True, True) \n",
    "    pred = pred.t()\n",
    "    target = torch.argmax(target, dim=1) \n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "    return correct_k.mul_(100.0 / batch_size)\n",
    "    \n",
    "def run_sgn_eval(train_x, train_y, test_x, test_y, val_x, val_y, case, model, k=3):\n",
    "    # Data loading\n",
    "    ntu_loaders = NTUDataLoaders(dataset, case, seg=20, train_X=train_x, train_Y=train_y, test_X=test_x, test_Y=test_y, val_X=val_x, val_Y=val_y, aug=0)\n",
    "    test_loader = ntu_loaders.get_test_loader(batch_size, 16)\n",
    "\n",
    "    # Test\n",
    "    return test(test_loader, model, k=k)\n",
    "\n",
    "def run_sgn_gender_eval(train_x, train_y, test_x, test_y, val_x, val_y, model, k=1):\n",
    "    # Data loading\n",
    "    ntu_loaders = NTUDataLoaders(dataset, 0, seg=20, train_X=train_x, train_Y=train_y, test_X=test_x, test_Y=test_y, val_X=val_x, val_Y=val_y, aug=0)\n",
    "    test_loader = ntu_loaders.get_test_loader(batch_size, 16)\n",
    "\n",
    "    acces = AverageMeter()\n",
    "    # load learnt model that obtained best performance on validation set\n",
    "    model.eval()\n",
    "\n",
    "    label_output = list()\n",
    "    pred_output = list()\n",
    "\n",
    "    for i, t in enumerate(test_loader):\n",
    "        inputs = t[0]\n",
    "        target = t[1]\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs.cuda())\n",
    "            output = output.view(\n",
    "                (-1, inputs.size(0)//target.size(0), output.size(1)))\n",
    "            output = output.mean(1)\n",
    "\n",
    "        label_output.append(target.cpu().numpy())\n",
    "        pred_output.append(output.cpu().numpy())\n",
    "\n",
    "        acc = accuracy(output.data, target.cuda())\n",
    "        acces.update(acc[0], inputs.size(0))\n",
    "\n",
    "    label_output = np.concatenate(label_output, axis=0)\n",
    "    pred_output = np.concatenate(pred_output, axis=0)\n",
    "\n",
    "    label_index = np.argmax(label_output, axis=1)\n",
    "    pred_index = np.argmax(pred_output, axis=1)\n",
    "\n",
    "    f1 = f1_score(label_index, pred_index, average='macro', zero_division=0)\n",
    "\n",
    "    return acces.avg, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(adv_lr=adv_lr).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_util = True\n",
    "sgn_ar = SGN(utility_classes, None, seg, batch_size, 0).to(device)\n",
    "sgn_priv = SGN(privacy_classes, None, seg, batch_size, 0).to(device)\n",
    "\n",
    "if ntu_120:\n",
    "    if only_use_pos: # Assumes SGN preprocessing\n",
    "        raise NotImplementedError\n",
    "        sgn_priv.load_state_dict(torch.load('SGN/pretrained/privacy_sgnpt.pt')['state_dict'])\n",
    "        sgn_ar.load_state_dict(torch.load('SGN/pretrained/action_sgnpt.pt')['state_dict'])\n",
    "    else:\n",
    "        sgn_priv.load_state_dict(torch.load('SGN/pretrained/privacy.pt')['state_dict'])\n",
    "        sgn_ar.load_state_dict(torch.load('SGN/pretrained/action.pt')['state_dict'])\n",
    "else:\n",
    "    if only_use_pos:\n",
    "        if remove_two_actor_actions: sgn_ar.load_state_dict(torch.load('SGN/pretrained/action_60_sgnpt_no_two_actor.pt')['state_dict'])\n",
    "        else: sgn_ar.load_state_dict(torch.load('SGN/pretrained/action_60_sgnpt.pt')['state_dict'])\n",
    "        sgn_priv.load_state_dict(torch.load('SGN/pretrained/privacy_60_sgnpt.pt')['state_dict'])\n",
    "    else: \n",
    "        sgn_priv.load_state_dict(torch.load('SGN/pretrained/privacy_60.pt')['state_dict'])\n",
    "        sgn_ar.load_state_dict(torch.load('SGN/pretrained/action_60.pt')['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Motion Retargeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgn_train_x, sgn_train_y, sgn_val_x, sgn_val_y = np.zeros((batch_size, 300, 150)), np.zeros((batch_size, 1)), np.zeros((batch_size, 300, 150)), np.zeros((batch_size, 1))\n",
    "\n",
    "best_metric = float('inf')\n",
    "total_epochs = -1\n",
    "cur_tot_epoch = 0\n",
    "\n",
    "def train_paired(train_ae = True, train_cross = True, train_discrim = True, train_emb_adv = True, run_eval = True, use_emb_adv = True, use_discrim_adv = True, run_sgn_eval = False, save = True, k=3):\n",
    "    global best_metric\n",
    "    global total_epochs\n",
    "    global cur_tot_epoch\n",
    "    # Assertions\n",
    "    # assert train_ae or train_cross or train_discrim or train_emb_adv, \"At least one of the training objectives must be True\"\n",
    "    assert not (run_sgn_eval and not run_eval), \"If run_sgn_eval is True, then run_eval must be True\"\n",
    "    \n",
    "    # Store eval values for validation\n",
    "    eval_X_known, eval_Y_known_action, eval_Y_known_actor, eval_X_rec, eval_Y_rec_action, eval_Y_rec_actor, eval_X, eval_Y_action, eval_Y_actor, eval_Y_initial_actor = [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "    # Losses for printing\n",
    "    losses = []\n",
    "    rec_loss, cross_loss, end_effector_loss, smoothing_loss, triplet_loss, latent_consistency_loss, privacy_loss, privacy_loss_adv, privacy_loss_coop, privacy_acc_adv, privacy_acc_coop, priv_training_loss, utility_loss, utility_loss_adv, utility_loss_coop, utility_acc_adv, utility_acc_coop, util_training_loss, discriminator_loss, discriminator_train_losses, discriminator_training_acc, priv_coop_training_loss, priv_training_acc, priv_coop_training_acc, util_coop_training_loss, util_training_acc, util_coop_training_acc = [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "    # Determine if adversaries need to be trained\n",
    "    train_emb_this_epoch = True\n",
    "    if emb_clf_update_per_epoch_paired < 1:\n",
    "        if cur_tot_epoch % round(1 / emb_clf_update_per_epoch_paired) != 0:\n",
    "            train_emb_this_epoch = False\n",
    "\n",
    "    for (x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot, actors, actions) in train_dl:\n",
    "        # Move tensors to the configured device\n",
    "        x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot = x1_pos.float().to(device), x1_rot.float().to(device), x2_pos.float().to(device), x2_rot.float().to(device), y1_pos.float().to(device), y1_rot.float().to(device), y2_pos.float().to(device), y2_rot.float().to(device)\n",
    "        \n",
    "        # Remove rotation data if only using position data\n",
    "        if only_use_pos:\n",
    "            x1_rot, x2_rot, y1_rot, y2_rot = x1_pos, x2_pos, y1_pos, y2_pos\n",
    "\n",
    "        # For 1D convolutions, flatten the data\n",
    "        if one_dimension_conv:\n",
    "            x1_pos = x1_pos.view(x1_pos.size(0), T, -1)\n",
    "            x1_rot = x1_rot.view(x1_rot.size(0), T, -1)\n",
    "            x2_pos = x2_pos.view(x2_pos.size(0), T, -1)\n",
    "            x2_rot = x2_rot.view(x2_rot.size(0), T, -1)\n",
    "            y1_pos = y1_pos.view(y1_pos.size(0), T, -1)\n",
    "            y1_rot = y1_rot.view(y1_rot.size(0), T, -1)\n",
    "            y2_pos = y2_pos.view(y2_pos.size(0), T, -1)\n",
    "            y2_rot = y2_rot.view(y2_rot.size(0), T, -1)\n",
    "\n",
    "        \n",
    "        if train_discrim or train_emb_adv:\n",
    "            # Train the discriminator\n",
    "            if train_emb_this_epoch:\n",
    "                it = 1\n",
    "                if emb_clf_update_per_epoch_paired > 1: it = emb_clf_update_per_epoch_paired\n",
    "                for _ in range(int(it)):\n",
    "                    t_priv_loss, t_priv_coop_loss, t_util_loss, t_util_coop_loss, t_discriminator_loss, t_priv_acc, t_util_acc, t_priv_coop_acc, t_util_coop_acc, t_discriminator_acc  = model.train_adv_paired(x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot, actors, actions, train_emb=train_emb_adv, train_discrim=train_discrim)\n",
    "                \n",
    "                # Track the loss\n",
    "                priv_training_loss.append(t_priv_loss)\n",
    "                priv_coop_training_loss.append(t_priv_coop_loss)\n",
    "                priv_training_acc.append(t_priv_acc)\n",
    "                priv_coop_training_acc.append(t_priv_coop_acc)\n",
    "                util_training_loss.append(t_util_loss)\n",
    "                util_coop_training_loss.append(t_util_coop_loss)\n",
    "                util_training_acc.append(t_util_acc)\n",
    "                util_coop_training_acc.append(t_util_coop_acc)\n",
    "                discriminator_train_losses.append(t_discriminator_loss)\n",
    "                discriminator_training_acc.append(t_discriminator_acc)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Train the autoencoder/cross reconstruction\n",
    "        if train_ae or train_cross:\n",
    "            # Forward pass\n",
    "            loss, _, _, _, _, losses_ = model.loss_paired(x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot, actors, actions, cross=train_cross, reconstruction=train_ae, emb_adv=use_emb_adv, discrim_adv=use_discrim_adv)\n",
    "\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track the loss\n",
    "            losses.append(loss.item())\n",
    "            rec_loss.append(losses_['rec_loss'])\n",
    "            cross_loss.append(losses_['cross_loss'])\n",
    "            end_effector_loss.append(losses_['end_effector_loss'])\n",
    "            smoothing_loss.append(losses_['smoothing_loss'])\n",
    "            latent_consistency_loss.append(losses_['latent_consistency_loss'])\n",
    "            triplet_loss.append(losses_['triplet_loss'])\n",
    "            privacy_loss.append(losses_['privacy_loss'])\n",
    "            privacy_loss_adv.append(losses_['privacy_loss_adv'])\n",
    "            privacy_loss_coop.append(losses_['privacy_loss_coop'])\n",
    "            privacy_acc_adv.append(losses_['privacy_acc_adv'])\n",
    "            privacy_acc_coop.append(losses_['privacy_acc_coop'])\n",
    "            utility_loss.append(losses_['utility_loss'])\n",
    "            utility_loss_adv.append(losses_['utility_loss_adv'])\n",
    "            utility_loss_coop.append(losses_['utility_loss_coop'])\n",
    "            utility_acc_adv.append(losses_['utility_acc_adv'])\n",
    "            utility_acc_coop.append(losses_['utility_acc_coop'])\n",
    "            discriminator_loss.append(losses_['discriminator_loss'])\n",
    "            discriminator_training_acc.append(losses_['discriminator_acc'])\n",
    "        \n",
    "    # Decay learning rate (disabled for training stages)\n",
    "    # scheduler.step() \n",
    "\n",
    "    # Validation\n",
    "    if run_eval:\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "            val_rec_loss, val_cross_loss, val_end_effector_loss, val_smoothing_loss, val_triplet_loss, val_latent_consistency_loss, val_privacy_loss, val_privacy_loss_adv, val_privacy_loss_coop, val_privacy_acc_adv, val_privacy_acc_coop, val_utility_loss, val_utility_loss_adv, val_utility_loss_coop, val_utility_acc_adv, val_utility_acc_coop, val_discriminator_loss, val_discriminator_acc = [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "            \n",
    "            for (x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot, actors, actions) in val_dl:\n",
    "                x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot = x1_pos.float().to(device), x1_rot.float().to(device), x2_pos.float().to(device), x2_rot.float().to(device), y1_pos.float().to(device), y1_rot.float().to(device), y2_pos.float().to(device), y2_rot.float().to(device)\n",
    "\n",
    "                # Remove rotation data if only using position data\n",
    "                if only_use_pos:\n",
    "                    x1_rot, x2_rot, y1_rot, y2_rot = x1_pos, x2_pos, y1_pos, y2_pos\n",
    "\n",
    "                # For 1D convolutions, flatten the data\n",
    "                if one_dimension_conv:\n",
    "                    x1_pos = x1_pos.view(x1_pos.size(0), T, -1)\n",
    "                    x1_rot = x1_rot.view(x1_rot.size(0), T, -1)\n",
    "                    x2_pos = x2_pos.view(x2_pos.size(0), T, -1)\n",
    "                    x2_rot = x2_rot.view(x2_rot.size(0), T, -1)\n",
    "                    y1_pos = y1_pos.view(y1_pos.size(0), T, -1)\n",
    "                    y1_rot = y1_rot.view(y1_rot.size(0), T, -1)\n",
    "                    y2_pos = y2_pos.view(y2_pos.size(0), T, -1)\n",
    "                    y2_rot = y2_rot.view(y2_rot.size(0), T, -1)\n",
    "                \n",
    "                loss, x1_hat, x2_hat, y1_hat, y2_hat, losses_ = model.loss_paired(x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot, actors, actions, cross=train_cross, reconstruction=train_ae, emb_adv=use_emb_adv, discrim_adv=use_discrim_adv)\n",
    "                val_losses.append(loss.item())\n",
    "                val_rec_loss.append(losses_['rec_loss'])\n",
    "                val_cross_loss.append(losses_['cross_loss'])\n",
    "                val_end_effector_loss.append(losses_['end_effector_loss'])\n",
    "                val_smoothing_loss.append(losses_['smoothing_loss'])\n",
    "                val_triplet_loss.append(losses_['triplet_loss'])\n",
    "                val_latent_consistency_loss.append(losses_['latent_consistency_loss'])\n",
    "                val_privacy_loss.append(losses_['privacy_loss'])\n",
    "                val_privacy_loss_adv.append(losses_['privacy_loss_adv'])\n",
    "                val_privacy_loss_coop.append(losses_['privacy_loss_coop'])\n",
    "                val_privacy_acc_adv.append(losses_['privacy_acc_adv'])\n",
    "                val_privacy_acc_coop.append(losses_['privacy_acc_coop'])\n",
    "                val_utility_loss.append(losses_['utility_loss'])\n",
    "                val_utility_loss_adv.append(losses_['utility_loss_adv'])\n",
    "                val_utility_loss_coop.append(losses_['utility_loss_coop'])\n",
    "                val_utility_acc_adv.append(losses_['utility_acc_adv'])\n",
    "                val_utility_acc_coop.append(losses_['utility_acc_coop'])\n",
    "                val_discriminator_loss.append(losses_['discriminator_loss'])\n",
    "                val_discriminator_acc.append(losses_['discriminator_acc'])\n",
    "\n",
    "                if run_sgn_eval:\n",
    "                    if not one_dimension_conv:\n",
    "                        x1_pos = x1_pos.view(x1_pos.size(0), T, -1)\n",
    "                        x2_pos = x2_pos.view(x2_pos.size(0), T, -1)\n",
    "                        y1_pos = y1_pos.view(y1_pos.size(0), T, -1)\n",
    "                        y2_pos = y2_pos.view(y2_pos.size(0), T, -1)\n",
    "\n",
    "                    # x1 = P1, A1\n",
    "                    # x2 = P2, A2\n",
    "                    # y1 = P1, A2\n",
    "                    # y2 = P2, A1\n",
    "                    # actors = A1, A2\n",
    "                    # actions = P1, P2\n",
    "                    # x1hat = P1, A1\n",
    "                    # x2hat = P2, A2\n",
    "                    # y1hat = P2, A1\n",
    "                    # y2hat = P1, A2\n",
    "                        \n",
    "                    # Raw Data X\n",
    "                    eval_X_known.append(x1_pos.cpu().numpy())\n",
    "                    eval_X_known.append(x2_pos.cpu().numpy())\n",
    "                    eval_X_known.append(y1_pos.cpu().numpy())\n",
    "                    eval_X_known.append(y2_pos.cpu().numpy())\n",
    "\n",
    "                    # Raw Data Utility\n",
    "                    eval_Y_known_action.append(actions[0].cpu().numpy())\n",
    "                    eval_Y_known_action.append(actions[1].cpu().numpy())\n",
    "                    eval_Y_known_action.append(actions[1].cpu().numpy())\n",
    "                    eval_Y_known_action.append(actions[0].cpu().numpy())\n",
    "\n",
    "                    # Raw Data Privacy\n",
    "                    eval_Y_known_actor.append(actors[0].cpu().numpy())\n",
    "                    eval_Y_known_actor.append(actors[1].cpu().numpy())\n",
    "                    eval_Y_known_actor.append(actors[0].cpu().numpy())\n",
    "                    eval_Y_known_actor.append(actors[1].cpu().numpy())\n",
    "\n",
    "                    # Reconstruction X\n",
    "                    eval_X_rec.append(x1_hat.cpu().numpy())\n",
    "                    eval_X_rec.append(x2_hat.cpu().numpy())\n",
    "                    # Cross X\n",
    "                    eval_X.append(y1_hat.cpu().numpy()) # P2, A1\n",
    "                    eval_X.append(y2_hat.cpu().numpy()) # P1, A2\n",
    "\n",
    "                    # Reconstruction Utility\n",
    "                    eval_Y_rec_action.append(actions[0].cpu().numpy())\n",
    "                    eval_Y_rec_action.append(actions[1].cpu().numpy())\n",
    "                    # Cross Utility\n",
    "                    eval_Y_action.append(actions[0].cpu().numpy())\n",
    "                    eval_Y_action.append(actions[1].cpu().numpy())\n",
    "\n",
    "                    # Reconstruction Privacy\n",
    "                    eval_Y_rec_actor.append(actors[0].cpu().numpy())\n",
    "                    eval_Y_rec_actor.append(actors[1].cpu().numpy())\n",
    "                    # Cross Privacy\n",
    "                    eval_Y_actor.append(actors[1].cpu().numpy())\n",
    "                    eval_Y_actor.append(actors[0].cpu().numpy())\n",
    "                    # Initial Privacy\n",
    "                    eval_Y_initial_actor.append(actors[0].cpu().numpy())\n",
    "                    eval_Y_initial_actor.append(actors[1].cpu().numpy())\n",
    "\n",
    "    # Print loss/accuracy\n",
    "    print(f'--------------------\\nEpoch {cur_tot_epoch+1}/{total_epochs}\\n--------------------')\n",
    "    cur_tot_epoch += 1\n",
    "    \n",
    "    if train_ae or train_cross:\n",
    "        print(f'Training Loss:\\t\\t\\t{np.mean(losses)}')\n",
    "        if run_eval: print(f'Validation Loss:\\t\\t{np.mean(val_losses)}')\n",
    "        print('\\nTraining Losses:')\n",
    "        print(f'Reconstruction Loss:\\t\\t{np.mean(rec_loss)}\\nCross Reconstruction Loss:\\t{np.mean(cross_loss)}\\nEnd Effector Loss:\\t\\t{np.mean(end_effector_loss)}\\nSmoothing Loss:\\t\\t\\t{np.mean(smoothing_loss)}\\nTriplet Loss:\\t\\t\\t{np.mean(triplet_loss)}\\nLatent Consistency Loss:\\t{np.mean(latent_consistency_loss)}')\n",
    "        if use_emb_adv:\n",
    "            print(f'Privacy Loss:\\t\\t\\t{np.mean(privacy_loss)}\\nPrivacy Loss Dyn:\\t\\t{np.mean(privacy_loss_adv)}\\nPrivacy Loss Stat:\\t\\t{np.mean(privacy_loss_coop)}')\n",
    "            print(f'Utility Loss:\\t\\t\\t{np.mean(utility_loss)}\\nUtility Loss Dyn:\\t\\t{np.mean(utility_loss_adv)}\\nUtility Loss Stat:\\t\\t{np.mean(utility_loss_coop)}')\n",
    "        if use_discrim_adv: print(f'Discriminator Loss:\\t\\t{np.mean(discriminator_loss)}')\n",
    "\n",
    "    if run_eval:\n",
    "        print('\\nValidation Losses:')\n",
    "        print(f'Val Reconstruction Loss:\\t{np.mean(val_rec_loss)}\\nVal Cross Reconstruction Loss:\\t{np.mean(val_cross_loss)}\\nVal End Effector Loss:\\t\\t{np.mean(val_end_effector_loss)}\\nVal Smoothing Loss:\\t\\t{np.mean(val_smoothing_loss)}\\nVal Triplet Loss:\\t\\t{np.mean(val_triplet_loss)}\\nVal Latent Consistency Loss:\\t{np.mean(val_latent_consistency_loss)}')\n",
    "        if use_emb_adv:\n",
    "            print(f'Val Privacy Loss:\\t\\t{np.mean(val_privacy_loss)}\\nVal Privacy Loss Dyn:\\t\\t{np.mean(val_privacy_loss_adv)}\\nVal Privacy Loss Stat:\\t\\t{np.mean(val_privacy_loss_coop)}')\n",
    "            print(f'Val Utility Loss:\\t\\t{np.mean(val_utility_loss)}\\nVal Utility Loss Dyn:\\t\\t{np.mean(val_utility_loss_adv)}\\nVal Utility Loss Stat:\\t\\t{np.mean(val_utility_loss_coop)}')\n",
    "        if use_discrim_adv: print(f'Val Discriminator Loss:\\t\\t{np.mean(val_discriminator_loss)}')\n",
    "    \n",
    "    if train_emb_adv or train_discrim:\n",
    "        print('\\nEmbedding Classifers')\n",
    "        if train_emb_adv and train_emb_this_epoch:\n",
    "            print(f'Adv Privacy Training Loss:\\t\\t{np.mean(priv_training_loss)}\\nAdv Utility Training Loss:\\t\\t{np.mean(util_training_loss)}\\nCoop Privacy Training Loss:\\t{np.mean(priv_coop_training_loss)}\\nCoop Utility Training Loss:\\t{np.mean(util_coop_training_loss)}\\nDiscriminator Training Loss:\\t{np.mean(discriminator_train_losses)}')\n",
    "            print(f'Adv Privacy Training Acc:\\t\\t{np.mean(priv_training_acc)}\\nAdv Utility Training Acc:\\t\\t{np.mean(util_training_acc)}\\nCoop Privacy Training Acc:\\t\\t{np.mean(priv_coop_training_acc)}\\nCoop Utility Training Acc:\\t\\t{np.mean(util_coop_training_acc)}\\nDiscriminator Training Acc:\\t{np.mean(discriminator_training_acc)}')\n",
    "            if train_ae or train_cross: print(f'Privacy Acc Adv:\\t\\t{np.mean(privacy_acc_adv)}\\nPrivacy Acc Coop:\\t\\t{np.mean(privacy_acc_coop)}\\nUtility Acc Adv:\\t\\t{np.mean(utility_acc_adv)}\\nUtility Acc Coop:\\t\\t{np.mean(utility_acc_coop)}')\n",
    "            if run_eval: print(f'Val Privacy Acc Adv:\\t\\t{np.mean(val_privacy_acc_adv)}\\nVal Privacy Acc Coop:\\t\\t{np.mean(val_privacy_acc_coop)}\\nVal Utility Acc Adv:\\t\\t{np.mean(val_utility_acc_adv)}\\nVal Utility Acc Coop:\\t\\t{np.mean(val_utility_acc_coop)}')\n",
    "    \n",
    "    if train_ae or train_cross: print(f'Discriminator Acc:\\t\\t{np.mean(discriminator_training_acc)}')\n",
    "    if run_eval: print(f'Val Discriminator Acc:\\t\\t{np.mean(val_discriminator_acc)}')\n",
    "\n",
    "    # Test Accuracy\n",
    "    if run_sgn_eval and run_eval:\n",
    "        print('\\n')\n",
    "        sgn_acc_known_acc, sgn_acc_known_f1, sgn_acc_known_prec, sgn_acc_known_recall, sgn_acc_known_topk = sgn_eval(eval_X_known, eval_Y_known_action, 'Known Action', is_action=True, k=k)\n",
    "        sgn_acc_rec_acc, sgn_acc_rec_f1, sgn_acc_rec_prec, sgn_acc_rec_recall, sgn_acc_rec_topk = sgn_eval(eval_X_rec, eval_Y_rec_action, 'Reconstructed Action', is_action=True, k=k)\n",
    "        sgn_acc_cross_acc, sgn_acc_cross_f1, sgn_acc_cross_prec, sgn_acc_cross_recall, sgn_acc_cross_topk = sgn_eval(eval_X, eval_Y_action, 'Generated Action', is_action=True, k=k)\n",
    "        print('\\n')\n",
    "        sgn_priv_known_acc, sgn_priv_known_f1, sgn_priv_known_prec, sgn_priv_known_recall, sgn_priv_known_topk = sgn_eval(eval_X_known, eval_Y_known_actor, 'Known Actor', is_actor=True, k=k)\n",
    "        sgn_priv_rec_acc, sgn_priv_rec_f1, sgn_priv_rec_prec, sgn_priv_rec_recall, sgn_priv_rec_topk = sgn_eval(eval_X_rec, eval_Y_rec_actor, 'Reconstructed Actor', is_actor=True, k=k)\n",
    "        sgn_priv_cross_acc, sgn_priv_cross_f1, sgn_priv_cross_prec, sgn_priv_cross_recall, sgn_priv_cross_topk = sgn_eval(eval_X, eval_Y_actor, 'Generated Actor', is_actor=True, k=k)\n",
    "        sgn_priv_initial_acc, sgn_priv_initial_f1, sgn_priv_initial_prec, sgn_priv_initial_recall, sgn_priv_initial_topk = sgn_eval(eval_X, eval_Y_initial_actor, 'Initial Actor', is_actor=True, k=k)\n",
    "    else: print('\\n')\n",
    "\n",
    "    # Return dict with all losses and accuracies for plotting\n",
    "    losses_dict = {}\n",
    "    if train_ae or train_cross:\n",
    "        losses_dict['loss'] = np.mean(losses)\n",
    "        if run_eval: losses_dict['val_loss'] = np.mean(val_losses)\n",
    "        losses_dict['rec_loss'] = np.mean(rec_loss)\n",
    "        losses_dict['cross_loss'] = np.mean(cross_loss)\n",
    "        losses_dict['end_effector_loss'] = np.mean(end_effector_loss)\n",
    "        losses_dict['smoothing_loss'] = np.mean(smoothing_loss)\n",
    "        losses_dict['triplet_loss'] = np.mean(triplet_loss)\n",
    "        losses_dict['latent_consistency_loss'] = np.mean(latent_consistency_loss)\n",
    "        losses_dict['privacy_loss'] = np.mean(privacy_loss)\n",
    "        losses_dict['privacy_loss_adv'] = np.mean(privacy_loss_adv)\n",
    "        losses_dict['privacy_loss_coop'] = np.mean(privacy_loss_coop)\n",
    "        losses_dict['utility_loss'] = np.mean(utility_loss)\n",
    "        losses_dict['utility_loss_adv'] = np.mean(utility_loss_adv)\n",
    "        losses_dict['utility_loss_coop'] = np.mean(utility_loss_coop)\n",
    "        losses_dict['discriminator_loss'] = np.mean(discriminator_loss)\n",
    "    if run_eval:\n",
    "        losses_dict['val_rec_loss'] = np.mean(val_rec_loss)\n",
    "        losses_dict['val_cross_loss'] = np.mean(val_cross_loss)\n",
    "        losses_dict['val_end_effector_loss'] = np.mean(val_end_effector_loss)\n",
    "        losses_dict['val_smoothing_loss'] = np.mean(val_smoothing_loss)\n",
    "        losses_dict['val_triplet_loss'] = np.mean(val_triplet_loss)\n",
    "        losses_dict['val_latent_consistency_loss'] = np.mean(val_latent_consistency_loss)\n",
    "        losses_dict['val_privacy_loss'] = np.mean(val_privacy_loss)\n",
    "        losses_dict['val_privacy_loss_adv'] = np.mean(val_privacy_loss_adv)\n",
    "        losses_dict['val_privacy_loss_coop'] = np.mean(val_privacy_loss_coop)\n",
    "        losses_dict['val_utility_loss'] = np.mean(val_utility_loss)\n",
    "        losses_dict['val_utility_loss_adv'] = np.mean(val_utility_loss_adv)\n",
    "        losses_dict['val_utility_loss_coop'] = np.mean(val_utility_loss_coop)\n",
    "        losses_dict['val_discriminator_loss'] = np.mean(val_discriminator_loss)\n",
    "    if (train_emb_adv or train_discrim) and train_emb_this_epoch:\n",
    "        losses_dict['priv_training_loss'] = np.mean(priv_training_loss)\n",
    "        losses_dict['util_training_loss'] = np.mean(util_training_loss)\n",
    "        losses_dict['discriminator_train_loss'] = np.mean(discriminator_train_losses)\n",
    "        losses_dict['priv_training_acc'] = np.mean(priv_training_acc)\n",
    "        losses_dict['util_training_acc'] = np.mean(util_training_acc)\n",
    "        losses_dict['priv_coop_training_loss'] = np.mean(priv_coop_training_loss)\n",
    "        losses_dict['priv_coop_training_acc'] = np.mean(priv_coop_training_acc)\n",
    "        losses_dict['util_coop_training_loss'] = np.mean(util_coop_training_loss)\n",
    "        losses_dict['util_coop_training_acc'] = np.mean(util_coop_training_acc)\n",
    "        losses_dict['discriminator_training_acc'] = np.mean(discriminator_training_acc)\n",
    "        if train_ae or train_cross:\n",
    "            losses_dict['privacy_acc_adv'] = np.mean(privacy_acc_adv)\n",
    "            losses_dict['privacy_acc_coop'] = np.mean(privacy_acc_coop)\n",
    "            losses_dict['utility_acc_adv'] = np.mean(utility_acc_adv)\n",
    "            losses_dict['utility_acc_coop'] = np.mean(utility_acc_coop)\n",
    "        if run_eval:\n",
    "            losses_dict['val_privacy_acc_adv'] = np.mean(val_privacy_acc_adv)\n",
    "            losses_dict['val_privacy_acc_coop'] = np.mean(val_privacy_acc_coop)\n",
    "            losses_dict['val_utility_acc_adv'] = np.mean(val_utility_acc_adv)\n",
    "            losses_dict['val_utility_acc_coop'] = np.mean(val_utility_acc_coop)\n",
    "    if train_ae or train_cross:\n",
    "        losses_dict['discriminator_acc'] = np.mean(discriminator_training_acc)\n",
    "    if run_eval:\n",
    "        losses_dict['val_discriminator_acc'] = np.mean(val_discriminator_acc)\n",
    "    if run_sgn_eval and run_eval:\n",
    "        losses_dict['sgn_acc_known_acc'] = sgn_acc_known_acc\n",
    "        losses_dict['sgn_acc_known_f1'] = sgn_acc_known_f1\n",
    "        losses_dict['sgn_acc_known_prec'] = sgn_acc_known_prec\n",
    "        losses_dict['sgn_acc_known_recall'] = sgn_acc_known_recall\n",
    "        losses_dict['sgn_acc_rec_acc'] = sgn_acc_rec_acc\n",
    "        losses_dict['sgn_acc_rec_f1'] = sgn_acc_rec_f1\n",
    "        losses_dict['sgn_acc_rec_prec'] = sgn_acc_rec_prec\n",
    "        losses_dict['sgn_acc_rec_recall'] = sgn_acc_rec_recall\n",
    "        losses_dict['sgn_acc_cross_acc'] = sgn_acc_cross_acc\n",
    "        losses_dict['sgn_acc_cross_f1'] = sgn_acc_cross_f1\n",
    "        losses_dict['sgn_acc_cross_prec'] = sgn_acc_cross_prec\n",
    "        losses_dict['sgn_acc_cross_recall'] = sgn_acc_cross_recall\n",
    "        losses_dict['sgn_priv_known_acc'] = sgn_priv_known_acc\n",
    "        losses_dict['sgn_priv_known_f1'] = sgn_priv_known_f1\n",
    "        losses_dict['sgn_priv_known_prec'] = sgn_priv_known_prec\n",
    "        losses_dict['sgn_priv_known_recall'] = sgn_priv_known_recall\n",
    "        losses_dict['sgn_priv_rec_acc'] = sgn_priv_rec_acc\n",
    "        losses_dict['sgn_priv_rec_f1'] = sgn_priv_rec_f1\n",
    "        losses_dict['sgn_priv_rec_prec'] = sgn_priv_rec_prec\n",
    "        losses_dict['sgn_priv_rec_recall'] = sgn_priv_rec_recall\n",
    "        losses_dict['sgn_priv_cross_acc'] = sgn_priv_cross_acc\n",
    "        losses_dict['sgn_priv_cross_f1'] = sgn_priv_cross_f1\n",
    "        losses_dict['sgn_priv_cross_prec'] = sgn_priv_cross_prec\n",
    "        losses_dict['sgn_priv_cross_recall'] = sgn_priv_cross_recall\n",
    "        losses_dict['sgn_acc_known_topk'] = sgn_acc_known_topk\n",
    "        losses_dict['sgn_acc_rec_topk'] = sgn_acc_rec_topk\n",
    "        losses_dict['sgn_acc_cross_topk'] = sgn_acc_cross_topk\n",
    "        losses_dict['sgn_priv_known_topk'] = sgn_priv_known_topk\n",
    "        losses_dict['sgn_priv_rec_topk'] = sgn_priv_rec_topk\n",
    "        losses_dict['sgn_priv_cross_topk'] = sgn_priv_cross_topk\n",
    "        losses_dict['sgn_priv_initial_acc'] = sgn_priv_initial_acc\n",
    "        losses_dict['sgn_priv_initial_f1'] = sgn_priv_initial_f1\n",
    "        losses_dict['sgn_priv_initial_prec'] = sgn_priv_initial_prec\n",
    "        losses_dict['sgn_priv_initial_recall'] = sgn_priv_initial_recall\n",
    "        losses_dict['sgn_priv_initial_topk'] = sgn_priv_initial_topk\n",
    "    \n",
    "    # Save model\n",
    "    if save and metric in losses_dict and losses_dict[metric] > 0:\n",
    "        if matric_minimize:\n",
    "            if np.mean(val_losses) < best_metric:\n",
    "                best_metric = np.mean(val_losses)\n",
    "                torch.save(model.state_dict(), 'pretrained/MR.pt')\n",
    "        elif np.mean(val_losses) > best_metric:\n",
    "            best_metric = np.mean(val_losses)\n",
    "            torch.save(model.state_dict(), 'pretrained/MR.pt')\n",
    "\n",
    "    return losses_dict\n",
    "\n",
    "\n",
    "def sgn_eval(X, Y, label='Undefined', is_actor=False, is_action=False, k=3):\n",
    "    assert is_actor != is_action, \"is_actor and is_action cannot both be True\"\n",
    "    assert is_actor or is_action, \"Either is_actor or is_action must be True\"\n",
    "\n",
    "    if is_actor:\n",
    "        classes = privacy_classes\n",
    "        sgn = sgn_priv\n",
    "    elif is_action:\n",
    "        classes = utility_classes\n",
    "        sgn = sgn_ar\n",
    "\n",
    "    X = np.concatenate(X)\n",
    "    X = np.pad(X, ((0,0), (0,225), (0,75)), 'constant')\n",
    "\n",
    "    Y = np.concatenate(Y) - 1\n",
    "    Y = np.eye(classes)[Y.astype(int)]\n",
    "\n",
    "    acc, f1, prec, recall, topk = run_sgn_eval(sgn_train_x, sgn_train_y, X, Y, sgn_val_x, sgn_val_y, 1, sgn, k=k)\n",
    "    print(f'\\n{label} Accuracy:\\t\\t{acc}\\n{label} F1:\\t\\t\\t{f1*100}\\n{label} Precision:\\t\\t{prec*100}\\n{label} Recall:\\t\\t{recall*100}\\n{label} Top-{k} Accuracy:\\t{topk}\\n')\n",
    "    return acc, f1, prec, recall, topk\n",
    "\n",
    "# Simplified training loop for only AE\n",
    "def train_unpaired(run_eval=True, run_sgn_eval=True, save=True, ae=True, ee=False, triplet=False, use_emb_adv=False, use_discrim_adv=False, emb_adv=False, discrim_adv=False, k=3, smoothing=True):\n",
    "    global best_metric\n",
    "    global total_epochs\n",
    "    global cur_tot_epoch\n",
    "\n",
    "    # Store eval values for validation\n",
    "    eval_X_known, eval_Y_known_action, eval_Y_known_actor, eval_X_rec, eval_Y_rec_action, eval_Y_rec_actor = [], [], [], [], [], []\n",
    "    \n",
    "    # Losses for printing\n",
    "    rec_loss, end_effector_loss, smoothing_loss, triplet_loss, privacy_loss, privacy_loss_adv, privacy_loss_coop, privacy_acc_adv, privacy_acc_coop, priv_training_loss, utility_loss, utility_loss_adv, utility_loss_coop, utility_acc_adv, utility_acc_coop, util_training_loss, discriminator_loss, discriminator_train_losses, discriminator_acc, discriminator_train_accs, priv_coop_training_loss, priv_training_acc, priv_coop_training_acc, util_coop_training_loss, util_training_acc, util_coop_training_acc = [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "    val_rec_loss, val_end_effector_loss, val_smoothing_loss, val_triplet_loss, val_privacy_loss, val_privacy_loss_adv, val_privacy_loss_coop, val_privacy_acc_adv, val_privacy_acc_coop, val_utility_loss, val_utility_loss_adv, val_utility_loss_coop, val_utility_acc_adv, val_utility_acc_coop, val_discriminator_loss, val_discriminator_acc = [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "    losses, val_losses = [], []\n",
    "\n",
    "    # Determine if adversaries need to be trained\n",
    "    train_emb_this_epoch = True\n",
    "    if emb_clf_update_per_epoch_unpaired < 1 and ae:\n",
    "        if cur_tot_epoch % round(1 / emb_clf_update_per_epoch_unpaired) != 0:\n",
    "            train_emb_this_epoch = False\n",
    "\n",
    "    for (x, actors, actions) in rec_train_dl:\n",
    "        # Move tensors to the configured device\n",
    "        x = x.float().to(device)\n",
    "\n",
    "        # Split into position and rotation\n",
    "        if only_use_pos:\n",
    "            x_pos = x\n",
    "            x_rot = x\n",
    "        else:\n",
    "            x_pos = x[:, :, :, :3]\n",
    "            x_rot = x[:, :, :, 3:]\n",
    "\n",
    "        # Train adversaries\n",
    "        if emb_adv or discrim_adv:\n",
    "            # Train the discriminator\n",
    "            if train_emb_this_epoch:\n",
    "                it = 1\n",
    "                if emb_clf_update_per_epoch_unpaired > 1: it = emb_clf_update_per_epoch_unpaired\n",
    "                for _ in range(int(it)):\n",
    "                    priv_train_loss, priv_train_coop_loss, util_train_loss, util_train_coop_loss, discriminator_train_loss, priv_acc, util_acc, priv_coop_acc, util_coop_acc, discriminator_train_acc = model.train_adv_unpaired(x_pos, x_rot, actors, actions, train_emb=emb_adv, train_discrim=discrim_adv)\n",
    "            \n",
    "                # Track the loss\n",
    "                priv_training_loss.append(priv_train_loss)\n",
    "                priv_coop_training_loss.append(priv_train_coop_loss)\n",
    "                priv_training_acc.append(priv_acc)\n",
    "                priv_coop_training_acc.append(priv_coop_acc)\n",
    "                util_training_loss.append(util_train_loss)\n",
    "                util_coop_training_loss.append(util_train_coop_loss)\n",
    "                util_training_acc.append(util_acc)\n",
    "                util_coop_training_acc.append(util_coop_acc)\n",
    "                discriminator_train_losses.append(discriminator_train_loss)\n",
    "                discriminator_train_accs.append(discriminator_train_acc)\n",
    "        \n",
    "        if not ae: continue\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        loss, _, losses_ = model.loss_unpaired(x_pos, x_rot, actors, actions, reconstruction=ae, emb_adv=use_emb_adv, discrim_adv=use_discrim_adv, ee=ee, triplet=triplet)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        rec_loss.append(losses_['rec_loss'])\n",
    "        end_effector_loss.append(losses_['end_effector_loss'])\n",
    "        smoothing_loss.append(losses_['smoothing_loss'])\n",
    "        triplet_loss.append(losses_['triplet_loss'])\n",
    "        privacy_loss.append(losses_['privacy_loss'])\n",
    "        privacy_loss_adv.append(losses_['privacy_loss_adv'])\n",
    "        privacy_loss_coop.append(losses_['privacy_loss_coop'])\n",
    "        privacy_acc_adv.append(losses_['privacy_acc_adv'])\n",
    "        privacy_acc_coop.append(losses_['privacy_acc_coop'])\n",
    "        utility_loss.append(losses_['utility_loss'])\n",
    "        utility_loss_adv.append(losses_['utility_loss_adv'])\n",
    "        utility_loss_coop.append(losses_['utility_loss_coop'])\n",
    "        utility_acc_adv.append(losses_['utility_acc_adv'])\n",
    "        utility_acc_coop.append(losses_['utility_acc_coop'])\n",
    "        discriminator_loss.append(losses_['discriminator_loss'])\n",
    "        discriminator_acc.append(losses_['discriminator_acc'])\n",
    "\n",
    "\n",
    "    # Decay learning rate\n",
    "    # scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    if run_eval:\n",
    "        with torch.no_grad():\n",
    "            for (x, actors, actions) in rec_val_dl:\n",
    "                x = x.float().to(device)\n",
    "\n",
    "                # Split into position and rotation\n",
    "                if only_use_pos:\n",
    "                    x_pos = x\n",
    "                    x_rot = x\n",
    "                else:\n",
    "                    x_pos = x[:, :, :, :3]\n",
    "                    x_rot = x[:, :, :, 3:]\n",
    "                \n",
    "                loss, _, losses_ = model.loss_unpaired(x_pos, x_rot, actors, actions, reconstruction=ae, emb_adv=use_emb_adv, discrim_adv=use_discrim_adv, ee=ee, triplet=triplet)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "                if run_sgn_eval:\n",
    "                    eval_X_known.append(x_pos.contiguous().view(x_pos.size(0), T, -1).cpu().numpy())\n",
    "                    eval_Y_known_action.append(np.array(actions))\n",
    "                    eval_Y_known_actor.append(np.array(actors))\n",
    "\n",
    "                    eval_X_rec.append(model(x_pos, x_rot).cpu().numpy())\n",
    "                    eval_Y_rec_action.append(np.array(actions))\n",
    "                    eval_Y_rec_actor.append(np.array(actors))\n",
    "                \n",
    "                val_rec_loss.append(losses_['rec_loss'])\n",
    "                val_end_effector_loss.append(losses_['end_effector_loss'])\n",
    "                val_smoothing_loss.append(losses_['smoothing_loss'])\n",
    "                val_triplet_loss.append(losses_['triplet_loss'])\n",
    "                val_privacy_loss.append(losses_['privacy_loss'])\n",
    "                val_privacy_loss_adv.append(losses_['privacy_loss_adv'])\n",
    "                val_privacy_loss_coop.append(losses_['privacy_loss_coop'])\n",
    "                val_privacy_acc_adv.append(losses_['privacy_acc_adv'])\n",
    "                val_privacy_acc_coop.append(losses_['privacy_acc_coop'])\n",
    "                val_utility_loss.append(losses_['utility_loss'])\n",
    "                val_utility_loss_adv.append(losses_['utility_loss_adv'])\n",
    "                val_utility_loss_coop.append(losses_['utility_loss_coop'])\n",
    "                val_utility_acc_adv.append(losses_['utility_acc_adv'])\n",
    "                val_utility_acc_coop.append(losses_['utility_acc_coop'])\n",
    "                val_discriminator_loss.append(losses_['discriminator_loss'])\n",
    "                val_discriminator_acc.append(losses_['discriminator_acc'])\n",
    "\n",
    "    # Print loss/accuracy\n",
    "    print(f'--------------------\\nEpoch {cur_tot_epoch+1}/{total_epochs}\\n--------------------')\n",
    "    cur_tot_epoch += 1\n",
    "    if ae:\n",
    "        print(f'Training Loss:\\t\\t\\t{np.mean(losses)}\\nValidation Loss:\\t\\t{np.mean(val_losses)}\\n')\n",
    "        print('Training Losses:')\n",
    "        print(f'Reconstruction Loss:\\t\\t{np.mean(rec_loss)}\\nEnd Effector Loss:\\t\\t{np.mean(end_effector_loss)}\\nSmoothing Loss:\\t\\t\\t{np.mean(smoothing_loss)}\\nTriplet Loss:\\t\\t\\t{np.mean(triplet_loss)}')\n",
    "        if use_emb_adv:\n",
    "            print(f'Privacy Loss:\\t\\t\\t{np.mean(privacy_loss)}\\nPrivacy Loss Dyn:\\t\\t{np.mean(privacy_loss_adv)}\\nPrivacy Loss Stat:\\t\\t{np.mean(privacy_loss_coop)}')\n",
    "            print(f'Utility Loss:\\t\\t\\t{np.mean(utility_loss)}\\nUtility Loss Dyn:\\t\\t{np.mean(utility_loss_adv)}\\nUtility Loss Stat:\\t\\t{np.mean(utility_loss_coop)}')\n",
    "        if use_discrim_adv: print(f'Discriminator Loss:\\t\\t{np.mean(discriminator_loss)}')\n",
    "    if run_eval:\n",
    "        print('\\nValidation Losses:')\n",
    "        print(f'Val Reconstruction Loss:\\t{np.mean(val_rec_loss)}\\nVal End Effector Loss:\\t\\t{np.mean(val_end_effector_loss)}\\nVal Smoothing Loss:\\t\\t{np.mean(val_smoothing_loss)}\\nVal Triplet Loss:\\t\\t{np.mean(val_triplet_loss)}')\n",
    "        if use_emb_adv:\n",
    "            print(f'Val Privacy Loss:\\t\\t{np.mean(val_privacy_loss)}\\nVal Privacy Loss Dyn:\\t\\t{np.mean(val_privacy_loss_adv)}\\nVal Privacy Loss Stat:\\t\\t{np.mean(val_privacy_loss_coop)}')\n",
    "            print(f'Val Utility Loss:\\t\\t{np.mean(val_utility_loss)}\\nVal Utility Loss Dyn:\\t\\t{np.mean(val_utility_loss_adv)}\\nVal Utility Loss Stat:\\t\\t{np.mean(val_utility_loss_coop)}')\n",
    "        if use_discrim_adv: print(f'Val Discriminator Loss:\\t\\t{np.mean(val_discriminator_loss)}')\n",
    "    if (emb_adv or discrim_adv) and train_emb_this_epoch:\n",
    "        print('\\nAdversary Losses')\n",
    "        print(f'Privacy Training Loss:\\t\\t{np.mean(priv_training_loss)}\\nUtility Training Loss:\\t\\t{np.mean(util_training_loss)}\\nDiscriminator Training Loss:\\t{np.mean(discriminator_train_losses)}')\n",
    "        print(f'Privacy Training Acc:\\t\\t{np.mean(priv_training_acc)}\\nUtility Training Acc:\\t\\t{np.mean(util_training_acc)}\\nDiscriminator Training Acc:\\t{np.mean(discriminator_train_accs)}')\n",
    "        print(f'Privacy Training Coop Loss:\\t{np.mean(priv_coop_training_loss)}\\nUtility Training Coop Loss:\\t{np.mean(util_coop_training_loss)}')\n",
    "        print(f'Privacy Training Coop Acc:\\t{np.mean(priv_coop_training_acc)}\\nUtility Training Coop Acc:\\t{np.mean(util_coop_training_acc)}')\n",
    "        if emb_adv and ae:\n",
    "            print(f'Privacy Acc Adv:\\t\\t{np.mean(privacy_acc_adv)}\\nPrivacy Acc Coop:\\t\\t{np.mean(privacy_acc_coop)}\\nUtility Acc Adv:\\t\\t{np.mean(utility_acc_adv)}\\nUtility Acc Coop:\\t\\t{np.mean(utility_acc_coop)}')\n",
    "            if run_eval: print(f'Val Privacy Acc Adv:\\t\\t{np.mean(val_privacy_acc_adv)}\\nVal Privacy Acc Coop:\\t\\t{np.mean(val_privacy_acc_coop)}\\nVal Utility Acc Adv:\\t\\t{np.mean(val_utility_acc_adv)}\\nVal Utility Acc Coop:\\t\\t{np.mean(val_utility_acc_coop)}')\n",
    "        if discrim_adv and ae:\n",
    "            print(f'Discriminator Acc:\\t\\t{np.mean(discriminator_acc)}')\n",
    "            if run_eval: print(f'Val Discriminator Acc:\\t\\t{np.mean(val_discriminator_acc)}')\n",
    "\n",
    "\n",
    "    # Test Accuracy\n",
    "    if run_sgn_eval and run_eval:\n",
    "        print('\\n')\n",
    "        sgn_acc_known_acc, sgn_acc_known_f1, sgn_acc_known_prec, sgn_acc_known_recall, sgn_acc_known_topk = sgn_eval(eval_X_known, eval_Y_known_action, 'Known Action', is_action=True, k=k)\n",
    "        sgn_acc_rec_acc, sgn_acc_rec_f1, sgn_acc_rec_prec, sgn_acc_rec_recall, sgn_acc_rec_topk = sgn_eval(eval_X_rec, eval_Y_rec_action, 'Reconstructed Action', is_action=True, k=k)\n",
    "        print('\\n')\n",
    "        sgn_priv_known_acc, sgn_priv_known_f1, sgn_priv_known_prec, sgn_priv_known_recall, sgn_priv_known_topk = sgn_eval(eval_X_known, eval_Y_known_actor, 'Known Actor', is_actor=True, k=k)\n",
    "        sgn_priv_rec_acc, sgn_priv_rec_f1, sgn_priv_rec_prec, sgn_priv_rec_recall, sgn_priv_rec_topk = sgn_eval(eval_X_rec, eval_Y_rec_actor, 'Reconstructed Actor', is_actor=True, k=k)\n",
    "        print('\\n')\n",
    "    else: print('\\n')\n",
    "\n",
    "    losses_dict = {}\n",
    "    losses_dict['loss'] = np.mean(losses)\n",
    "\n",
    "    if ae: losses_dict['rec_loss'] = np.mean(rec_loss)\n",
    "    if ee: losses_dict['end_effector_loss'] = np.mean(end_effector_loss)\n",
    "    if smoothing: losses_dict['smoothing_loss'] = np.mean(smoothing_loss)\n",
    "    if triplet: losses_dict['triplet_loss'] = np.mean(triplet_loss)\n",
    "    if run_eval:\n",
    "        losses_dict['val_loss'] = np.mean(val_losses)\n",
    "        if ae: losses_dict['val_rec_loss'] = np.mean(val_rec_loss)\n",
    "        if ee: losses_dict['val_end_effector_loss'] = np.mean(val_end_effector_loss)\n",
    "        if smoothing: losses_dict['val_smoothing_loss'] = np.mean(val_smoothing_loss)\n",
    "        if triplet: losses_dict['val_triplet_loss'] = np.mean(val_triplet_loss)\n",
    "        if run_sgn_eval:\n",
    "            losses_dict['sgn_acc_known_acc'] = sgn_acc_known_acc\n",
    "            losses_dict['sgn_acc_known_f1'] = sgn_acc_known_f1\n",
    "            losses_dict['sgn_acc_known_prec'] = sgn_acc_known_prec\n",
    "            losses_dict['sgn_acc_known_recall'] = sgn_acc_known_recall\n",
    "            losses_dict['sgn_acc_rec_acc'] = sgn_acc_rec_acc\n",
    "            losses_dict['sgn_acc_rec_f1'] = sgn_acc_rec_f1\n",
    "            losses_dict['sgn_acc_rec_prec'] = sgn_acc_rec_prec\n",
    "            losses_dict['sgn_acc_rec_recall'] = sgn_acc_rec_recall\n",
    "            losses_dict['sgn_acc_known_topk'] = sgn_acc_known_topk\n",
    "            losses_dict['sgn_acc_rec_topk'] = sgn_acc_rec_topk\n",
    "            losses_dict['sgn_priv_known_acc'] = sgn_priv_known_acc\n",
    "            losses_dict['sgn_priv_known_f1'] = sgn_priv_known_f1\n",
    "            losses_dict['sgn_priv_known_prec'] = sgn_priv_known_prec\n",
    "            losses_dict['sgn_priv_known_recall'] = sgn_priv_known_recall\n",
    "            losses_dict['sgn_priv_rec_acc'] = sgn_priv_rec_acc\n",
    "            losses_dict['sgn_priv_rec_f1'] = sgn_priv_rec_f1\n",
    "            losses_dict['sgn_priv_rec_prec'] = sgn_priv_rec_prec\n",
    "            losses_dict['sgn_priv_rec_recall'] = sgn_priv_rec_recall\n",
    "            losses_dict['sgn_priv_known_topk'] = sgn_priv_known_topk\n",
    "            losses_dict['sgn_priv_rec_topk'] = sgn_priv_rec_topk\n",
    "    if use_emb_adv:\n",
    "        losses_dict['privacy_loss'] = np.mean(privacy_loss)\n",
    "        losses_dict['privacy_loss_adv'] = np.mean(privacy_loss_adv)\n",
    "        losses_dict['privacy_loss_coop'] = np.mean(privacy_loss_coop)\n",
    "        losses_dict['utility_loss'] = np.mean(utility_loss)\n",
    "        losses_dict['utility_loss_adv'] = np.mean(utility_loss_adv)\n",
    "        losses_dict['utility_loss_coop'] = np.mean(utility_loss_coop)\n",
    "        losses_dict['privacy_acc_adv'] = np.mean(privacy_acc_adv)\n",
    "        losses_dict['privacy_acc_coop'] = np.mean(privacy_acc_coop)\n",
    "        losses_dict['utility_acc_adv'] = np.mean(utility_acc_adv)\n",
    "        losses_dict['utility_acc_coop'] = np.mean(utility_acc_coop)\n",
    "        if run_eval:    \n",
    "            losses_dict['val_privacy_acc_adv'] = np.mean(val_privacy_acc_adv)\n",
    "            losses_dict['val_privacy_acc_coop'] = np.mean(val_privacy_acc_coop)\n",
    "            losses_dict['val_utility_acc_adv'] = np.mean(val_utility_acc_adv)\n",
    "            losses_dict['val_utility_acc_coop'] = np.mean(val_utility_acc_coop)\n",
    "            losses_dict['val_privacy_loss'] = np.mean(val_privacy_loss)\n",
    "            losses_dict['val_privacy_loss_adv'] = np.mean(val_privacy_loss_adv)\n",
    "            losses_dict['val_privacy_loss_coop'] = np.mean(val_privacy_loss_coop)\n",
    "            losses_dict['val_utility_loss'] = np.mean(val_utility_loss)\n",
    "            losses_dict['val_utility_loss_adv'] = np.mean(val_utility_loss_adv)\n",
    "            losses_dict['val_utility_loss_coop'] = np.mean(val_utility_loss_coop)\n",
    "    if emb_adv and train_emb_this_epoch:\n",
    "        losses_dict['priv_training_loss'] = np.mean(priv_training_loss)\n",
    "        losses_dict['priv_training_acc'] = np.mean(priv_training_acc)\n",
    "        losses_dict['priv_coop_training_loss'] = np.mean(priv_coop_training_loss)\n",
    "        losses_dict['priv_coop_training_acc'] = np.mean(priv_coop_training_acc)\n",
    "        losses_dict['util_training_loss'] = np.mean(util_training_loss)\n",
    "        losses_dict['util_training_acc'] = np.mean(util_training_acc)\n",
    "        losses_dict['util_coop_training_loss'] = np.mean(util_coop_training_loss)\n",
    "        losses_dict['util_coop_training_acc'] = np.mean(util_coop_training_acc)\n",
    "    if use_discrim_adv:\n",
    "        losses_dict['discriminator_loss'] = np.mean(discriminator_loss)\n",
    "        losses_dict['discriminator_acc'] = np.mean(discriminator_acc)\n",
    "        if run_eval:\n",
    "            losses_dict['val_discriminator_loss'] = np.mean(val_discriminator_loss)\n",
    "            losses_dict['val_discriminator_acc'] = np.mean(val_discriminator_acc)\n",
    "    if discrim_adv and train_emb_this_epoch:\n",
    "        losses_dict['discriminator_train_loss'] = np.mean(discriminator_train_losses)\n",
    "        losses_dict['discriminator_train_acc'] = np.mean(discriminator_train_accs)\n",
    "        \n",
    "    # Save model\n",
    "    if save and metric in losses_dict and losses_dict[metric] > 0:\n",
    "        if matric_minimize:\n",
    "            if np.mean(val_losses) < best_metric:\n",
    "                best_metric = np.mean(val_losses)\n",
    "                torch.save(model.state_dict(), 'pretrained/MR.pt')\n",
    "        elif np.mean(val_losses) > best_metric:\n",
    "            best_metric = np.mean(val_losses)\n",
    "            torch.save(model.state_dict(), 'pretrained/MR.pt')\n",
    "\n",
    "    return losses_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Moving to new stage\n",
      "{'epochs': 5, 'paired': True, 'ae': True, 'ee': True, 'cross': True, 'triplet': True, 'train_emb_adv': False, 'train_discrim_adv': False, 'emb_adv': False, 'discrim_adv': False, 'eval': False, 'sgn_eval': False, 'save': False} \n",
      "\n",
      "--------------------\n",
      "Epoch 1/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t14.304880388715064\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t4.866613493923643\n",
      "Cross Reconstruction Loss:\t5.045424295554768\n",
      "End Effector Loss:\t\t0.0841279611532515\n",
      "Smoothing Loss:\t\t\t0.02608328681589317\n",
      "Triplet Loss:\t\t\t3.7885243395392285\n",
      "Latent Consistency Loss:\t0.011620878273760037\n",
      "Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 2/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t7.922105539935717\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t2.015087886186113\n",
      "Cross Reconstruction Loss:\t2.6893761881024734\n",
      "End Effector Loss:\t\t0.03923669946752369\n",
      "Smoothing Loss:\t\t\t0.014075314741097843\n",
      "Triplet Loss:\t\t\t3.3202017987300705\n",
      "Latent Consistency Loss:\t0.022132770217936044\n",
      "Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 3/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t6.629805423934263\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t1.4569815450651251\n",
      "Cross Reconstruction Loss:\t2.5482091944872076\n",
      "End Effector Loss:\t\t0.027534891777956098\n",
      "Smoothing Loss:\t\t\t0.012762724690649346\n",
      "Triplet Loss:\t\t\t3.1739816003629815\n",
      "Latent Consistency Loss:\t0.02212167448964225\n",
      "Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 4/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t6.037395543191804\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t1.197776917647034\n",
      "Cross Reconstruction Loss:\t2.537496899155112\n",
      "End Effector Loss:\t\t0.021704623279634266\n",
      "Smoothing Loss:\t\t\t0.012146887539272802\n",
      "Triplet Loss:\t\t\t3.112931083885432\n",
      "Latent Consistency Loss:\t0.021701564135831936\n",
      "Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 5/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t5.625755015353095\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t1.029318728015275\n",
      "Cross Reconstruction Loss:\t2.5540010868092033\n",
      "End Effector Loss:\t\t0.01818406012955569\n",
      "Smoothing Loss:\t\t\t0.011827185063581777\n",
      "Triplet Loss:\t\t\t3.036932673884445\n",
      "Latent Consistency Loss:\t0.022111916508208616\n",
      "Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "\n",
      "Moving to new stage\n",
      "{'epochs': 20, 'paired': False, 'ae': True, 'ee': True, 'cross': False, 'triplet': True, 'train_emb_adv': False, 'train_discrim_adv': False, 'emb_adv': False, 'discrim_adv': False, 'eval': False, 'sgn_eval': False, 'save': False} \n",
      "\n",
      "--------------------\n",
      "Epoch 6/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.911535246208651\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.933894390995438\n",
      "End Effector Loss:\t\t0.008626838816376306\n",
      "Smoothing Loss:\t\t\t0.011706520708881923\n",
      "Triplet Loss:\t\t\t6.403686772071584e-08\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tcarr23\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\tcarr23\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Epoch 7/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.8047548437068963\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.880856768938707\n",
      "End Effector Loss:\t\t0.008225405142446999\n",
      "Smoothing Loss:\t\t\t0.011605202308478387\n",
      "Triplet Loss:\t\t\t2.966177463555697e-07\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 8/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.7281585930538772\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.8428687693051637\n",
      "End Effector Loss:\t\t0.007868205453704834\n",
      "Smoothing Loss:\t\t\t0.011517493530581251\n",
      "Triplet Loss:\t\t\t3.660589639531166e-07\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 9/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.6637575773835926\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.8109551419711163\n",
      "End Effector Loss:\t\t0.007536526920908981\n",
      "Smoothing Loss:\t\t\t0.011436734825814154\n",
      "Triplet Loss:\t\t\t5.618004741756102e-07\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 10/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.6082702524448877\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.7834618555347043\n",
      "End Effector Loss:\t\t0.007262707518010929\n",
      "Smoothing Loss:\t\t\t0.011361053274468114\n",
      "Triplet Loss:\t\t\t6.743059822758989e-07\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 11/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.559699029783697\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.7594158335002197\n",
      "End Effector Loss:\t\t0.007018915003866515\n",
      "Smoothing Loss:\t\t\t0.011282548525713369\n",
      "Triplet Loss:\t\t\t8.018914570938989e-07\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 12/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.5163879604572565\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.737962446440778\n",
      "End Effector Loss:\t\t0.006804386316943844\n",
      "Smoothing Loss:\t\t\t0.011219270377789707\n",
      "Triplet Loss:\t\t\t8.694407063741585e-07\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 13/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.4771139249980079\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.7185235423289564\n",
      "End Effector Loss:\t\t0.006619607388833828\n",
      "Smoothing Loss:\t\t\t0.011148751919543112\n",
      "Triplet Loss:\t\t\t9.756207223129681e-07\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 14/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.4424991524640836\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.7013456031153454\n",
      "End Effector Loss:\t\t0.00646340712641604\n",
      "Smoothing Loss:\t\t\t0.0111145202274746\n",
      "Triplet Loss:\t\t\t9.782828454493609e-07\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 15/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.4109837225098125\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6857054789014269\n",
      "End Effector Loss:\t\t0.00632139891647422\n",
      "Smoothing Loss:\t\t\t0.011083446799345672\n",
      "Triplet Loss:\t\t\t1.0239185365192832e-06\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 16/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.38283052935174\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6717706810597818\n",
      "End Effector Loss:\t\t0.006190545857920778\n",
      "Smoothing Loss:\t\t\t0.011032535118997686\n",
      "Triplet Loss:\t\t\t1.0164848222274319e-06\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 17/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.355897101939592\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6583896420911544\n",
      "End Effector Loss:\t\t0.006074539396869263\n",
      "Smoothing Loss:\t\t\t0.011014087884657844\n",
      "Triplet Loss:\t\t\t1.0146022627368305e-06\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 18/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.3306217249986287\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6458689039747333\n",
      "End Effector Loss:\t\t0.005968364148513025\n",
      "Smoothing Loss:\t\t\t0.01097151763415789\n",
      "Triplet Loss:\t\t\t9.999765290611514e-07\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 19/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.3083438223959751\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6348087219153521\n",
      "End Effector Loss:\t\t0.00586970059879767\n",
      "Smoothing Loss:\t\t\t0.01095189867742561\n",
      "Triplet Loss:\t\t\t9.827778216382671e-07\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 20/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.2865968492819218\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6240555829293019\n",
      "End Effector Loss:\t\t0.0057880608885299235\n",
      "Smoothing Loss:\t\t\t0.010898899819930384\n",
      "Triplet Loss:\t\t\t9.269257936009018e-07\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 21/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.2663244345455804\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6139545832255279\n",
      "End Effector Loss:\t\t0.005706431864995099\n",
      "Smoothing Loss:\t\t\t0.010902633732223492\n",
      "Triplet Loss:\t\t\t9.35244474600199e-07\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 22/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.2479358000715657\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6048399205329265\n",
      "End Effector Loss:\t\t0.005637502011682319\n",
      "Smoothing Loss:\t\t\t0.010872513449338426\n",
      "Triplet Loss:\t\t\t9.157138908322583e-07\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 23/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.2298946745554276\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5958477664514292\n",
      "End Effector Loss:\t\t0.005572425697449974\n",
      "Smoothing Loss:\t\t\t0.010875273286316567\n",
      "Triplet Loss:\t\t\t8.964116753223245e-07\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 24/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.2133674350201216\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5876193348930184\n",
      "End Effector Loss:\t\t0.0055188103368420645\n",
      "Smoothing Loss:\t\t\t0.01086970890790859\n",
      "Triplet Loss:\t\t\t8.251466428940407e-07\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 25/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.198199472903214\n",
      "Validation Loss:\t\tnan\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5800826933056797\n",
      "End Effector Loss:\t\t0.005462186070490172\n",
      "Smoothing Loss:\t\t\t0.010857029859143118\n",
      "Triplet Loss:\t\t\t8.118738894197865e-07\n",
      "\n",
      "\n",
      "\n",
      "Moving to new stage\n",
      "{'epochs': 20, 'paired': True, 'ae': False, 'ee': False, 'cross': False, 'triplet': False, 'train_emb_adv': True, 'train_discrim_adv': False, 'emb_adv': False, 'discrim_adv': False, 'eval': False, 'sgn_eval': False, 'save': False} \n",
      "\n",
      "--------------------\n",
      "Epoch 26/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.595342330572625\n",
      "Adv Utility Training Loss:\t\t4.065805514958602\n",
      "Coop Privacy Training Loss:\t3.62956793050467\n",
      "Coop Utility Training Loss:\t4.090935866343083\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.13947536788227768\n",
      "Adv Utility Training Acc:\t\t0.05141354766474728\n",
      "Coop Privacy Training Acc:\t\t0.0976137635956494\n",
      "Coop Utility Training Acc:\t\t0.020323496481126038\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 27/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5596072669221437\n",
      "Adv Utility Training Loss:\t\t4.032554310861491\n",
      "Coop Privacy Training Loss:\t3.6192783154666386\n",
      "Coop Utility Training Loss:\t4.089879874609559\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.17239483365323097\n",
      "Adv Utility Training Acc:\t\t0.08858665227127319\n",
      "Coop Privacy Training Acc:\t\t0.10022292866282789\n",
      "Coop Utility Training Acc:\t\t0.02055842130518234\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 28/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5499745263400477\n",
      "Adv Utility Training Loss:\t\t4.02113147569023\n",
      "Coop Privacy Training Loss:\t3.618223668517627\n",
      "Coop Utility Training Loss:\t4.089730641663418\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18168186180422266\n",
      "Adv Utility Training Acc:\t\t0.10070277511196417\n",
      "Coop Privacy Training Acc:\t\t0.10074276231605886\n",
      "Coop Utility Training Acc:\t\t0.020593410108765194\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 29/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5423650560055644\n",
      "Adv Utility Training Loss:\t\t4.0089002325225165\n",
      "Coop Privacy Training Loss:\t3.616416966693949\n",
      "Coop Utility Training Loss:\t4.08961850042459\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1892244481765835\n",
      "Adv Utility Training Acc:\t\t0.11537807901471529\n",
      "Coop Privacy Training Acc:\t\t0.10423164587332054\n",
      "Coop Utility Training Acc:\t\t0.020593410108765194\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 30/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.538897876013416\n",
      "Adv Utility Training Loss:\t\t3.9939687331364997\n",
      "Coop Privacy Training Loss:\t3.6128292869316487\n",
      "Coop Utility Training Loss:\t4.089453307924862\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.19273332533589252\n",
      "Adv Utility Training Acc:\t\t0.13276251599488165\n",
      "Coop Privacy Training Acc:\t\t0.11422844689699296\n",
      "Coop Utility Training Acc:\t\t0.02057341650671785\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 31/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.531659502290566\n",
      "Adv Utility Training Loss:\t\t3.976604375485343\n",
      "Coop Privacy Training Loss:\t3.6058956065089447\n",
      "Coop Utility Training Loss:\t4.089274877473779\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.20058081413947537\n",
      "Adv Utility Training Acc:\t\t0.1514165467050544\n",
      "Coop Privacy Training Acc:\t\t0.12537987843889956\n",
      "Coop Utility Training Acc:\t\t0.02061340371081254\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 32/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5275747365701373\n",
      "Adv Utility Training Loss:\t\t3.959527001194823\n",
      "Coop Privacy Training Loss:\t3.5960662232250717\n",
      "Coop Utility Training Loss:\t4.0890423581909845\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.20358485284708894\n",
      "Adv Utility Training Acc:\t\t0.16715650991682662\n",
      "Coop Privacy Training Acc:\t\t0.13867062539987204\n",
      "Coop Utility Training Acc:\t\t0.020618402111324378\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 33/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5250793253849197\n",
      "Adv Utility Training Loss:\t\t3.9504089001578087\n",
      "Coop Privacy Training Loss:\t3.5851320944302216\n",
      "Coop Utility Training Loss:\t4.0886854127821675\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.20666386756238003\n",
      "Adv Utility Training Acc:\t\t0.17516394753678824\n",
      "Coop Privacy Training Acc:\t\t0.15306601887396032\n",
      "Coop Utility Training Acc:\t\t0.020578414907229687\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 34/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5237195926527143\n",
      "Adv Utility Training Loss:\t\t3.943694933972447\n",
      "Coop Privacy Training Loss:\t3.5759965706847834\n",
      "Coop Utility Training Loss:\t4.087927777417867\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.20747860684580935\n",
      "Adv Utility Training Acc:\t\t0.1826415547024952\n",
      "Coop Privacy Training Acc:\t\t0.16262296065259116\n",
      "Coop Utility Training Acc:\t\t0.020698376519513756\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 35/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5227438628635417\n",
      "Adv Utility Training Loss:\t\t3.9382189395560414\n",
      "Coop Privacy Training Loss:\t3.567962009786263\n",
      "Coop Utility Training Loss:\t4.0866732694976085\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.2085382677543186\n",
      "Adv Utility Training Acc:\t\t0.18752999040307103\n",
      "Coop Privacy Training Acc:\t\t0.17219489763275753\n",
      "Coop Utility Training Acc:\t\t0.020968290147152912\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 36/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5214975073943133\n",
      "Adv Utility Training Loss:\t\t3.933802397984842\n",
      "Coop Privacy Training Loss:\t3.5604598885229284\n",
      "Coop Utility Training Loss:\t4.08495237304092\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.20940798944337813\n",
      "Adv Utility Training Acc:\t\t0.19174364203454894\n",
      "Coop Privacy Training Acc:\t\t0.17969249840051182\n",
      "Coop Utility Training Acc:\t\t0.02545685380678183\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 37/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5212361387007527\n",
      "Adv Utility Training Loss:\t\t3.9300824866718918\n",
      "Coop Privacy Training Loss:\t3.5540739435914688\n",
      "Coop Utility Training Loss:\t4.083138826788806\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.20968789987204095\n",
      "Adv Utility Training Acc:\t\t0.19441778630838133\n",
      "Coop Privacy Training Acc:\t\t0.18550563819577734\n",
      "Coop Utility Training Acc:\t\t0.030090371081253998\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 38/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5189995547555153\n",
      "Adv Utility Training Loss:\t\t3.926620245895093\n",
      "Coop Privacy Training Loss:\t3.5490260964696865\n",
      "Coop Utility Training Loss:\t4.081548147451702\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.21216210812539987\n",
      "Adv Utility Training Acc:\t\t0.19862643953934742\n",
      "Coop Privacy Training Acc:\t\t0.18926943378119002\n",
      "Coop Utility Training Acc:\t\t0.034359005118362124\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 39/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.511988640594238\n",
      "Adv Utility Training Loss:\t\t3.9235521979768233\n",
      "Coop Privacy Training Loss:\t3.5448444949764513\n",
      "Coop Utility Training Loss:\t4.080019096037706\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.22019453774792067\n",
      "Adv Utility Training Acc:\t\t0.20148552463211772\n",
      "Coop Privacy Training Acc:\t\t0.1923434500959693\n",
      "Coop Utility Training Acc:\t\t0.03510376679462572\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 40/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5084240474688726\n",
      "Adv Utility Training Loss:\t\t3.919591267903646\n",
      "Coop Privacy Training Loss:\t3.5421288853948574\n",
      "Coop Utility Training Loss:\t4.078264145536905\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.22311360364683303\n",
      "Adv Utility Training Acc:\t\t0.20563419705694178\n",
      "Coop Privacy Training Acc:\t\t0.19399292226487524\n",
      "Coop Utility Training Acc:\t\t0.03888755598208573\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 41/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5065323163970343\n",
      "Adv Utility Training Loss:\t\t3.914800337164812\n",
      "Coop Privacy Training Loss:\t3.539414652173365\n",
      "Coop Utility Training Loss:\t4.076601111423641\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.2252229286628279\n",
      "Adv Utility Training Acc:\t\t0.21090750959692897\n",
      "Coop Privacy Training Acc:\t\t0.1958773192578375\n",
      "Coop Utility Training Acc:\t\t0.04116182821497121\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 42/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5047534601244497\n",
      "Adv Utility Training Loss:\t\t3.9094844836114846\n",
      "Coop Privacy Training Loss:\t3.5376081602434586\n",
      "Coop Utility Training Loss:\t4.07524586212002\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.22720729366602688\n",
      "Adv Utility Training Acc:\t\t0.2169855646193218\n",
      "Coop Privacy Training Acc:\t\t0.19713691618682022\n",
      "Coop Utility Training Acc:\t\t0.04334612923864364\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 43/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.502567754673485\n",
      "Adv Utility Training Loss:\t\t3.9059956740356756\n",
      "Coop Privacy Training Loss:\t3.5362319493248\n",
      "Coop Utility Training Loss:\t4.0736856600907245\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.22978646833013436\n",
      "Adv Utility Training Acc:\t\t0.22092430422264875\n",
      "Coop Privacy Training Acc:\t\t0.19773172584772872\n",
      "Coop Utility Training Acc:\t\t0.044545745361484326\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 44/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.502048253097827\n",
      "Adv Utility Training Loss:\t\t3.9023075961029385\n",
      "Coop Privacy Training Loss:\t3.5345738068346937\n",
      "Coop Utility Training Loss:\t4.0725425807467195\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.22988143793985924\n",
      "Adv Utility Training Acc:\t\t0.22426323576455534\n",
      "Coop Privacy Training Acc:\t\t0.19914627319257838\n",
      "Coop Utility Training Acc:\t\t0.04549044305822137\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 45/295\n",
      "--------------------\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.4991061608149163\n",
      "Adv Utility Training Loss:\t\t3.898676549633268\n",
      "Coop Privacy Training Loss:\t3.5336779208802596\n",
      "Coop Utility Training Loss:\t4.071403024140185\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.23245061580294304\n",
      "Adv Utility Training Acc:\t\t0.22754718490083173\n",
      "Coop Privacy Training Acc:\t\t0.19958113403710812\n",
      "Coop Utility Training Acc:\t\t0.04720989283429303\n",
      "Discriminator Training Acc:\t0.0\n",
      "\n",
      "\n",
      "\n",
      "Moving to new stage\n",
      "{'epochs': 50, 'paired': False, 'ae': False, 'ee': False, 'cross': False, 'triplet': False, 'train_emb_adv': True, 'train_discrim_adv': False, 'emb_adv': False, 'discrim_adv': False, 'eval': False, 'sgn_eval': False, 'save': False} \n",
      "\n",
      "--------------------\n",
      "Epoch 46/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4923431028199543\n",
      "Utility Training Loss:\t\t3.901700506339202\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24031314969434558\n",
      "Utility Training Acc:\t\t0.22659173596983392\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.555768586245991\n",
      "Utility Training Coop Loss:\t4.072990285879361\n",
      "Privacy Training Coop Acc:\t0.17669568607378403\n",
      "Utility Training Coop Acc:\t0.042587058212058215\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 47/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4912714579001287\n",
      "Utility Training Loss:\t\t3.8990948329100736\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24302884615694412\n",
      "Utility Training Acc:\t\t0.22521439708939708\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5466465818658937\n",
      "Utility Training Coop Loss:\t4.069859015718567\n",
      "Privacy Training Coop Acc:\t0.18386174636174638\n",
      "Utility Training Coop Acc:\t0.04771959459459459\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 48/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4900532118248098\n",
      "Utility Training Loss:\t\t3.896745485724134\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2418139293139293\n",
      "Utility Training Acc:\t\t0.22901507276507277\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5441255415799464\n",
      "Utility Training Coop Loss:\t4.066948323884278\n",
      "Privacy Training Coop Acc:\t0.18506366943866945\n",
      "Utility Training Coop Acc:\t0.052527286902286904\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 49/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.488769584782654\n",
      "Utility Training Loss:\t\t3.8942240736836453\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24360706863185225\n",
      "Utility Training Acc:\t\t0.23125000000619592\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5378307460995075\n",
      "Utility Training Coop Loss:\t4.060298843096299\n",
      "Privacy Training Coop Acc:\t0.19313279626089422\n",
      "Utility Training Coop Acc:\t0.06058341995841996\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 50/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4906476332095457\n",
      "Utility Training Loss:\t\t3.89331333701675\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24049506237316032\n",
      "Utility Training Acc:\t\t0.2335628898128898\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5373276618315126\n",
      "Utility Training Coop Loss:\t4.052256151445195\n",
      "Privacy Training Coop Acc:\t0.19514682952492748\n",
      "Utility Training Coop Acc:\t0.0685745841995842\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 51/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.490182173722995\n",
      "Utility Training Loss:\t\t3.8905885740030333\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2408199064480044\n",
      "Utility Training Acc:\t\t0.2330236486517466\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5338481290424686\n",
      "Utility Training Coop Loss:\t4.042170047264337\n",
      "Privacy Training Coop Acc:\t0.19712837838147634\n",
      "Utility Training Coop Acc:\t0.08078872141372141\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 52/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4873783526450333\n",
      "Utility Training Loss:\t\t3.8887287078429162\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24442567567877363\n",
      "Utility Training Acc:\t\t0.23677884615384615\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5307451142094983\n",
      "Utility Training Coop Loss:\t4.034814891349253\n",
      "Privacy Training Coop Acc:\t0.2001169438700418\n",
      "Utility Training Coop Acc:\t0.08650597713097713\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 53/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.485919919430342\n",
      "Utility Training Loss:\t\t3.8860545133602593\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24530275468085264\n",
      "Utility Training Acc:\t\t0.23841606029415824\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.529524517158461\n",
      "Utility Training Coop Loss:\t4.031151164346326\n",
      "Privacy Training Coop Acc:\t0.20057172557482353\n",
      "Utility Training Coop Acc:\t0.09310031185031185\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 54/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.484699675298282\n",
      "Utility Training Loss:\t\t3.8865642165939427\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24727130977130976\n",
      "Utility Training Acc:\t\t0.23986486486486486\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5285148335593655\n",
      "Utility Training Coop Loss:\t4.0267241335708235\n",
      "Privacy Training Coop Acc:\t0.2017281704781705\n",
      "Utility Training Coop Acc:\t0.09524428274428275\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 55/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.486142364708153\n",
      "Utility Training Loss:\t\t3.882889251699071\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24413331601141397\n",
      "Utility Training Acc:\t\t0.24406185033663394\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5248681262228443\n",
      "Utility Training Coop Loss:\t4.021913894496688\n",
      "Privacy Training Coop Acc:\t0.20606159043968839\n",
      "Utility Training Coop Acc:\t0.1015787422037422\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 56/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.486091065555501\n",
      "Utility Training Loss:\t\t3.880459504167156\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2453742203866122\n",
      "Utility Training Acc:\t\t0.24632926195426194\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5256130844044833\n",
      "Utility Training Coop Loss:\t4.0183051948487885\n",
      "Privacy Training Coop Acc:\t0.20626949065068656\n",
      "Utility Training Coop Acc:\t0.10484017671827467\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 57/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4850985052184105\n",
      "Utility Training Loss:\t\t3.8783132737490837\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24671257796877388\n",
      "Utility Training Acc:\t\t0.24770660083469878\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5241908070451258\n",
      "Utility Training Coop Loss:\t4.014512332957897\n",
      "Privacy Training Coop Acc:\t0.2095179313991273\n",
      "Utility Training Coop Acc:\t0.11008965696465696\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 58/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4836341635848775\n",
      "Utility Training Loss:\t\t3.876403442539445\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24795348232848233\n",
      "Utility Training Acc:\t\t0.2504028066559046\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.522073437419106\n",
      "Utility Training Coop Loss:\t4.01025534047902\n",
      "Privacy Training Coop Acc:\t0.20858238045738045\n",
      "Utility Training Coop Acc:\t0.11233108108108109\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 59/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.481961594054208\n",
      "Utility Training Loss:\t\t3.873196196655226\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2509160603158439\n",
      "Utility Training Acc:\t\t0.2524493243274223\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.518050793302778\n",
      "Utility Training Coop Loss:\t4.0076494898468935\n",
      "Privacy Training Coop Acc:\t0.21294178796657157\n",
      "Utility Training Coop Acc:\t0.11619672557172557\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 60/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4825102938435926\n",
      "Utility Training Loss:\t\t3.8709730695538114\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24845374220684016\n",
      "Utility Training Acc:\t\t0.25594464656964655\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.519096198547903\n",
      "Utility Training Coop Loss:\t4.004526649592076\n",
      "Privacy Training Coop Acc:\t0.21273388774008364\n",
      "Utility Training Coop Acc:\t0.12117983368293163\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 61/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4843738079071045\n",
      "Utility Training Loss:\t\t3.8668229921939714\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24658913721413722\n",
      "Utility Training Acc:\t\t0.259920738048836\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5179561775588195\n",
      "Utility Training Coop Loss:\t4.001969452211614\n",
      "Privacy Training Coop Acc:\t0.21291580041889838\n",
      "Utility Training Coop Acc:\t0.12244672557482353\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 62/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4819657559702155\n",
      "Utility Training Loss:\t\t3.864583461547344\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.250435291063389\n",
      "Utility Training Acc:\t\t0.26441658004777596\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5177987759425586\n",
      "Utility Training Coop Loss:\t3.999527629100855\n",
      "Privacy Training Coop Acc:\t0.21291580041889838\n",
      "Utility Training Coop Acc:\t0.12487006237006237\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 63/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4804899063031045\n",
      "Utility Training Loss:\t\t3.8606208909821857\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.25071465696465695\n",
      "Utility Training Acc:\t\t0.26560550935860733\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.516552200932017\n",
      "Utility Training Coop Loss:\t3.9972141059173616\n",
      "Privacy Training Coop Acc:\t0.2143321205821206\n",
      "Utility Training Coop Acc:\t0.1266567047817048\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 64/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.479147961630395\n",
      "Utility Training Loss:\t\t3.857356066763277\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.25235187110496904\n",
      "Utility Training Acc:\t\t0.2704132016662996\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5153298962884536\n",
      "Utility Training Coop Loss:\t3.996345201054135\n",
      "Privacy Training Coop Acc:\t0.21563149688149688\n",
      "Utility Training Coop Acc:\t0.1293204261954262\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 65/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.478717747696224\n",
      "Utility Training Loss:\t\t3.8545193535870177\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2515722453253433\n",
      "Utility Training Acc:\t\t0.27082250519750517\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5132085840816063\n",
      "Utility Training Coop Loss:\t3.993397473297595\n",
      "Privacy Training Coop Acc:\t0.21834069646879442\n",
      "Utility Training Coop Acc:\t0.12902806652806653\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 66/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.478397817968579\n",
      "Utility Training Loss:\t\t3.8516303630479904\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2538136694417674\n",
      "Utility Training Acc:\t\t0.27526637214756805\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.513438464945914\n",
      "Utility Training Coop Loss:\t3.991821880647893\n",
      "Privacy Training Coop Acc:\t0.21758056133056133\n",
      "Utility Training Coop Acc:\t0.13254937630247426\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 67/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.47954077086181\n",
      "Utility Training Loss:\t\t3.8488008019334314\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.25386564449064447\n",
      "Utility Training Acc:\t\t0.2781899688211647\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.512580983851903\n",
      "Utility Training Coop Loss:\t3.9913379070416806\n",
      "Privacy Training Coop Acc:\t0.21946465696465697\n",
      "Utility Training Coop Acc:\t0.13163981289291085\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 68/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4797030273445433\n",
      "Utility Training Loss:\t\t3.844625740933567\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2521114864864865\n",
      "Utility Training Acc:\t\t0.2829521829552809\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.51163050191566\n",
      "Utility Training Coop Loss:\t3.9911349897820836\n",
      "Privacy Training Coop Acc:\t0.21910732848232847\n",
      "Utility Training Coop Acc:\t0.13299116424116425\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 69/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4788693335844423\n",
      "Utility Training Loss:\t\t3.8432644920388777\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2530470374282333\n",
      "Utility Training Acc:\t\t0.2841021309833269\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5096844427303067\n",
      "Utility Training Coop Loss:\t3.987907268153407\n",
      "Privacy Training Coop Acc:\t0.22275857588667383\n",
      "Utility Training Coop Acc:\t0.13584329522449112\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 70/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.479534100593995\n",
      "Utility Training Loss:\t\t3.841463064453458\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.25181262994382586\n",
      "Utility Training Acc:\t\t0.28816268191887784\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5094250586820985\n",
      "Utility Training Coop Loss:\t3.98858003234665\n",
      "Privacy Training Coop Acc:\t0.2229339916901876\n",
      "Utility Training Coop Acc:\t0.13568737006237006\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 71/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.477882943381391\n",
      "Utility Training Loss:\t\t3.8383170326633413\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2534238565519545\n",
      "Utility Training Acc:\t\t0.29174896052374416\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5078646918592233\n",
      "Utility Training Coop Loss:\t3.985728957301118\n",
      "Privacy Training Coop Acc:\t0.22322635135754726\n",
      "Utility Training Coop Acc:\t0.1365254677816637\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 72/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.477027785009753\n",
      "Utility Training Loss:\t\t3.8355656445893827\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2550610706922666\n",
      "Utility Training Acc:\t\t0.29365904365904366\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.507028903634038\n",
      "Utility Training Coop Loss:\t3.9860531195781337\n",
      "Privacy Training Coop Acc:\t0.2247726091507071\n",
      "Utility Training Coop Acc:\t0.13825363825363826\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 73/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4749346783156208\n",
      "Utility Training Loss:\t\t3.833435629360889\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2560031185093144\n",
      "Utility Training Acc:\t\t0.29569906445526034\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.507068080862446\n",
      "Utility Training Coop Loss:\t3.984292291058324\n",
      "Privacy Training Coop Acc:\t0.22398648651127012\n",
      "Utility Training Coop Acc:\t0.13899428275047865\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 74/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.476877220703014\n",
      "Utility Training Loss:\t\t3.8315811836298193\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.25696465696775495\n",
      "Utility Training Acc:\t\t0.29551065488565487\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5059935273350895\n",
      "Utility Training Coop Loss:\t3.983984432696305\n",
      "Privacy Training Coop Acc:\t0.22548726611536407\n",
      "Utility Training Coop Acc:\t0.13909173597293187\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 75/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.474686047143599\n",
      "Utility Training Loss:\t\t3.8270390653312827\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2564579002140961\n",
      "Utility Training Acc:\t\t0.3033264033387951\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5054235884652565\n",
      "Utility Training Coop Loss:\t3.980405655075755\n",
      "Privacy Training Coop Acc:\t0.22574714137523932\n",
      "Utility Training Coop Acc:\t0.14279495842615433\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 76/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.47628747574257\n",
      "Utility Training Loss:\t\t3.821690599288861\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2550155925186905\n",
      "Utility Training Acc:\t\t0.30790020790330586\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5063000040093977\n",
      "Utility Training Coop Loss:\t3.977909445019125\n",
      "Privacy Training Coop Acc:\t0.22529235967045763\n",
      "Utility Training Coop Acc:\t0.14514033264033263\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 77/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4733901063518564\n",
      "Utility Training Loss:\t\t3.8192026337566096\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2593685031216011\n",
      "Utility Training Acc:\t\t0.3115189709001668\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5032884284017487\n",
      "Utility Training Coop Loss:\t3.9779819170799176\n",
      "Privacy Training Coop Acc:\t0.22740384615694412\n",
      "Utility Training Coop Acc:\t0.14601741164241164\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 78/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.474850559928561\n",
      "Utility Training Loss:\t\t3.8165937778607724\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.25591216216216217\n",
      "Utility Training Acc:\t\t0.31276637216615577\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5033121577419513\n",
      "Utility Training Coop Loss:\t3.9765130288883457\n",
      "Privacy Training Coop Acc:\t0.22817047817047817\n",
      "Utility Training Coop Acc:\t0.14559511434511435\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 79/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4748005638994943\n",
      "Utility Training Loss:\t\t3.811109220163738\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.25655535343654934\n",
      "Utility Training Acc:\t\t0.31617723495201855\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.502568398096953\n",
      "Utility Training Coop Loss:\t3.975659755560068\n",
      "Privacy Training Coop Acc:\t0.2286837318149277\n",
      "Utility Training Coop Acc:\t0.14738175675675674\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 80/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.474836704141137\n",
      "Utility Training Loss:\t\t3.812121656729129\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2563344594594595\n",
      "Utility Training Acc:\t\t0.31641761955501135\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.504393272984796\n",
      "Utility Training Coop Loss:\t3.974636348270329\n",
      "Privacy Training Coop Acc:\t0.22664371101871103\n",
      "Utility Training Coop Acc:\t0.147472713103909\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 81/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4743642901184653\n",
      "Utility Training Loss:\t\t3.8099752600128585\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.25704911642411643\n",
      "Utility Training Acc:\t\t0.32103690229309817\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5016063355110787\n",
      "Utility Training Coop Loss:\t3.9723054249916157\n",
      "Privacy Training Coop Acc:\t0.22989215176715178\n",
      "Utility Training Coop Acc:\t0.1504937629999589\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 82/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4742628023678943\n",
      "Utility Training Loss:\t\t3.808454656055712\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2571465696465696\n",
      "Utility Training Acc:\t\t0.3198414760914761\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.4994270756933643\n",
      "Utility Training Coop Loss:\t3.972420081775055\n",
      "Privacy Training Coop Acc:\t0.23115904365904366\n",
      "Utility Training Coop Acc:\t0.14855119542619544\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 83/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.472804278940768\n",
      "Utility Training Loss:\t\t3.8064005887929713\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2579067047848027\n",
      "Utility Training Acc:\t\t0.3249870062401042\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.500612167459516\n",
      "Utility Training Coop Loss:\t3.9712624413555724\n",
      "Privacy Training Coop Acc:\t0.23031444906444906\n",
      "Utility Training Coop Acc:\t0.15173466735966737\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 84/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.471846564643844\n",
      "Utility Training Loss:\t\t3.805043219280838\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2594204781704782\n",
      "Utility Training Acc:\t\t0.32355769231079023\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.499194408404852\n",
      "Utility Training Coop Loss:\t3.9706960951216255\n",
      "Privacy Training Coop Acc:\t0.23245841995841995\n",
      "Utility Training Coop Acc:\t0.15194256757066552\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 85/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.471871525482923\n",
      "Utility Training Loss:\t\t3.8036980690926376\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2603950103950104\n",
      "Utility Training Acc:\t\t0.3223882536413516\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.4987027830988353\n",
      "Utility Training Coop Loss:\t3.9696097939029307\n",
      "Privacy Training Coop Acc:\t0.23252338877338877\n",
      "Utility Training Coop Acc:\t0.1541060291060291\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 86/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.471124178654439\n",
      "Utility Training Loss:\t\t3.8015616921525983\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.25903066528066526\n",
      "Utility Training Acc:\t\t0.3265267671579631\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.4985085126020308\n",
      "Utility Training Coop Loss:\t3.968163793151443\n",
      "Privacy Training Coop Acc:\t0.23232848232848233\n",
      "Utility Training Coop Acc:\t0.1574454262016221\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 87/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.471660269273294\n",
      "Utility Training Loss:\t\t3.7996368517251122\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2603690228938065\n",
      "Utility Training Acc:\t\t0.3294698544729524\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.496656519211751\n",
      "Utility Training Coop Loss:\t3.9686677433596826\n",
      "Privacy Training Coop Acc:\t0.23503118505596868\n",
      "Utility Training Coop Acc:\t0.1565553534334514\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 88/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.472020810706204\n",
      "Utility Training Loss:\t\t3.796825194804931\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2587837837868817\n",
      "Utility Training Acc:\t\t0.3287097193347193\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.4967817184583065\n",
      "Utility Training Coop Loss:\t3.9678047994566064\n",
      "Privacy Training Coop Acc:\t0.23445296258106052\n",
      "Utility Training Coop Acc:\t0.15465826403326402\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 89/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4716205780322733\n",
      "Utility Training Loss:\t\t3.7952755706969517\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2587188149719129\n",
      "Utility Training Acc:\t\t0.3321855509355509\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.495896270765832\n",
      "Utility Training Coop Loss:\t3.9665844514811113\n",
      "Privacy Training Coop Acc:\t0.23527806653426245\n",
      "Utility Training Coop Acc:\t0.1591670997982957\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 90/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4717816203646747\n",
      "Utility Training Loss:\t\t3.7943663537626207\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2590761434542414\n",
      "Utility Training Acc:\t\t0.33345244282744285\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.4951112300095586\n",
      "Utility Training Coop Loss:\t3.964422570940363\n",
      "Privacy Training Coop Acc:\t0.236564449067547\n",
      "Utility Training Coop Acc:\t0.15816658004158005\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 91/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.470588290765727\n",
      "Utility Training Loss:\t\t3.791535960413562\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.26176585241563605\n",
      "Utility Training Acc:\t\t0.3345569126819127\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.493543283855097\n",
      "Utility Training Coop Loss:\t3.963709429495052\n",
      "Privacy Training Coop Acc:\t0.2382016632078591\n",
      "Utility Training Coop Acc:\t0.15946595634095634\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 92/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4709630133952025\n",
      "Utility Training Loss:\t\t3.791160615466984\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.26134355511833873\n",
      "Utility Training Acc:\t\t0.33856548856858654\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.4943043395040436\n",
      "Utility Training Coop Loss:\t3.962646965673213\n",
      "Privacy Training Coop Acc:\t0.23735706861326453\n",
      "Utility Training Coop Acc:\t0.160635395010395\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 93/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.470072019868482\n",
      "Utility Training Loss:\t\t3.788563632419848\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2618178274490234\n",
      "Utility Training Acc:\t\t0.3385330041611021\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.4942482613228463\n",
      "Utility Training Coop Loss:\t3.96172194917088\n",
      "Privacy Training Coop Acc:\t0.23696725572345162\n",
      "Utility Training Coop Acc:\t0.16051845114654908\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 94/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4700073147514012\n",
      "Utility Training Loss:\t\t3.787098832041211\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2616294178794179\n",
      "Utility Training Acc:\t\t0.34088487526607114\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.4937418020192896\n",
      "Utility Training Coop Loss:\t3.961547126888981\n",
      "Privacy Training Coop Acc:\t0.23632406444906445\n",
      "Utility Training Coop Acc:\t0.1628443347193347\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 95/295\n",
      "--------------------\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4683959181739983\n",
      "Utility Training Loss:\t\t3.7861797888908466\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2641567047879007\n",
      "Utility Training Acc:\t\t0.3398583680081516\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.4944989879512987\n",
      "Utility Training Coop Loss:\t3.9600827381665393\n",
      "Privacy Training Coop Acc:\t0.23722713098332687\n",
      "Utility Training Coop Acc:\t0.16407224532844122\n",
      "\n",
      "\n",
      "\n",
      "Moving to new stage\n",
      "{'epochs': 100, 'paired': False, 'ae': True, 'ee': True, 'cross': False, 'triplet': True, 'train_emb_adv': True, 'train_discrim_adv': False, 'emb_adv': True, 'discrim_adv': False, 'eval': True, 'sgn_eval': True, 'save': True} \n",
      "\n",
      "--------------------\n",
      "Epoch 96/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.04807515484193754\n",
      "Validation Loss:\t\t-0.08403314436855149\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6132718781919341\n",
      "End Effector Loss:\t\t0.006149999100304443\n",
      "Smoothing Loss:\t\t\t0.011040359445539712\n",
      "Triplet Loss:\t\t\t1.0799069244733076e-06\n",
      "Privacy Loss:\t\t\t0.004880775099236851\n",
      "Privacy Loss Dyn:\t\t-3.4749274667731935\n",
      "Privacy Loss Stat:\t\t3.5237352223505347\n",
      "Utility Loss:\t\t\t-1.3187718460812639\n",
      "Utility Loss Dyn:\t\t-4.09571259457951\n",
      "Utility Loss Stat:\t\t3.96383540967398\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5665135353434184\n",
      "Val End Effector Loss:\t\t0.005522846563215067\n",
      "Val Smoothing Loss:\t\t0.009926578675566072\n",
      "Val Triplet Loss:\t\t1.1229609254235786e-07\n",
      "Val Privacy Loss:\t\t0.002490209400161239\n",
      "Val Privacy Loss Dyn:\t\t-3.479763207849392\n",
      "Val Privacy Loss Stat:\t\t3.504665299388003\n",
      "Val Utility Loss:\t\t-1.2548531224904966\n",
      "Val Utility Loss Dyn:\t\t-4.084923840751332\n",
      "Val Utility Loss Stat:\t\t3.959438533822367\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.478286869064934\n",
      "Utility Training Loss:\t\t4.093853032266772\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2534563409594389\n",
      "Utility Training Acc:\t\t0.0251754158004158\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.527009665346443\n",
      "Utility Training Coop Loss:\t3.9709925631723384\n",
      "Privacy Training Coop Acc:\t0.20520400207900208\n",
      "Utility Training Coop Acc:\t0.15370971934091524\n",
      "Privacy Acc Adv:\t\t0.25587318087937677\n",
      "Privacy Acc Coop:\t\t0.20682172557792147\n",
      "Utility Acc Adv:\t\t0.023941008316008316\n",
      "Utility Acc Coop:\t\t0.1595569126881086\n",
      "Val Privacy Acc Adv:\t\t0.25129849633032625\n",
      "Val Privacy Acc Coop:\t\t0.2274090335204089\n",
      "Val Utility Acc Adv:\t\t0.03460743801652893\n",
      "Val Utility Acc Coop:\t\t0.16395488981742504\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 97/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.03127975864703777\n",
      "Validation Loss:\t\t0.08028498996618735\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6229093048156176\n",
      "End Effector Loss:\t\t0.006361404721859432\n",
      "Smoothing Loss:\t\t\t0.011049987116088924\n",
      "Triplet Loss:\t\t\t1.2159090410006037e-06\n",
      "Privacy Loss:\t\t\t0.005454032374023152\n",
      "Privacy Loss Dyn:\t\t-3.473596914642318\n",
      "Privacy Loss Stat:\t\t3.528137235284595\n",
      "Utility Loss:\t\t\t-1.259505464232637\n",
      "Utility Loss Dyn:\t\t-4.072157269456035\n",
      "Utility Loss Stat:\t\t3.946206726304211\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6224139700990078\n",
      "Val End Effector Loss:\t\t0.006676722620036607\n",
      "Val Smoothing Loss:\t\t0.01016373195866323\n",
      "Val Triplet Loss:\t\t2.8078115861747443e-08\n",
      "Val Privacy Loss:\t\t0.0052479851590700385\n",
      "Val Privacy Loss Dyn:\t\t-3.4756358393952866\n",
      "Val Privacy Loss Stat:\t\t3.528115684335882\n",
      "Val Utility Loss:\t\t-1.206958881094436\n",
      "Val Utility Loss Dyn:\t\t-4.0682969497255055\n",
      "Val Utility Loss Stat:\t\t3.9476010622071827\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4792168757523916\n",
      "Utility Training Loss:\t\t4.072045962676684\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2515592515592516\n",
      "Utility Training Acc:\t\t0.04765462577962578\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5297956052788084\n",
      "Utility Training Coop Loss:\t3.9566558584601865\n",
      "Privacy Training Coop Acc:\t0.20166320166320167\n",
      "Utility Training Coop Acc:\t0.16819776507896098\n",
      "Privacy Acc Adv:\t\t0.2573739604989605\n",
      "Privacy Acc Coop:\t\t0.2030600311850312\n",
      "Utility Acc Adv:\t\t0.04706990644490645\n",
      "Utility Acc Coop:\t\t0.17698804574114368\n",
      "Val Privacy Acc Adv:\t\t0.2545268021154502\n",
      "Val Privacy Acc Coop:\t\t0.20248651285925187\n",
      "Val Utility Acc Adv:\t\t0.05178202479338843\n",
      "Val Utility Acc Coop:\t\t0.17435003444552422\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 98/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.2315641482149613\n",
      "Validation Loss:\t\t0.3006997876454237\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6554920909744291\n",
      "End Effector Loss:\t\t0.006852671807039366\n",
      "Smoothing Loss:\t\t\t0.011196906305171875\n",
      "Triplet Loss:\t\t\t1.7590011751256e-07\n",
      "Privacy Loss:\t\t\t0.00742348638245073\n",
      "Privacy Loss Dyn:\t\t-3.4720223371303502\n",
      "Privacy Loss Stat:\t\t3.5462572051680756\n",
      "Utility Loss:\t\t\t-1.1272870854875403\n",
      "Utility Loss Dyn:\t\t-4.0543471445908414\n",
      "Utility Loss Stat:\t\t3.9416184375786734\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6327969590740755\n",
      "Val End Effector Loss:\t\t0.006703878154454768\n",
      "Val Smoothing Loss:\t\t0.01018925350590432\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.006983797966448729\n",
      "Val Privacy Loss Dyn:\t\t-3.4564516229077804\n",
      "Val Privacy Loss Stat:\t\t3.5262896009713165\n",
      "Val Utility Loss:\t\t-1.0091495671548134\n",
      "Val Utility Loss Dyn:\t\t-4.0603852065141535\n",
      "Val Utility Loss Stat:\t\t3.959470261227001\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4776646367229693\n",
      "Utility Training Loss:\t\t4.05786489870345\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.25387863825673623\n",
      "Utility Training Acc:\t\t0.06240254677754678\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5425138324808927\n",
      "Utility Training Coop Loss:\t3.9520333482421113\n",
      "Privacy Training Coop Acc:\t0.18954651767151767\n",
      "Utility Training Coop Acc:\t0.17159563409873205\n",
      "Privacy Acc Adv:\t\t0.25956340956650753\n",
      "Privacy Acc Coop:\t\t0.1844139812889813\n",
      "Utility Acc Adv:\t\t0.0645595114376094\n",
      "Utility Acc Coop:\t\t0.1826208420020379\n",
      "Val Privacy Acc Adv:\t\t0.2752668732884994\n",
      "Val Privacy Acc Coop:\t\t0.21060032139663115\n",
      "Val Utility Acc Adv:\t\t0.05858298899097876\n",
      "Val Utility Acc Coop:\t\t0.16082702022938689\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 99/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.2361014394337416\n",
      "Validation Loss:\t\t0.13015542786245135\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.669714981391871\n",
      "End Effector Loss:\t\t0.006901131441870901\n",
      "Smoothing Loss:\t\t\t0.01113555342512759\n",
      "Triplet Loss:\t\t\t7.628879375298838e-09\n",
      "Privacy Loss:\t\t\t0.008019257360089594\n",
      "Privacy Loss Dyn:\t\t-3.474692864378376\n",
      "Privacy Loss Stat:\t\t3.554885441944654\n",
      "Utility Loss:\t\t\t-1.1516555817855867\n",
      "Utility Loss Dyn:\t\t-4.053718358464152\n",
      "Utility Loss Stat:\t\t3.9385527917600225\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6290558558727098\n",
      "Val End Effector Loss:\t\t0.00625130414485562\n",
      "Val Smoothing Loss:\t\t0.010101354954194678\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.004474413665858182\n",
      "Val Privacy Loss Dyn:\t\t-3.4872945980592207\n",
      "Val Privacy Loss Stat:\t\t3.5320387320085005\n",
      "Val Utility Loss:\t\t-1.168986068284216\n",
      "Val Utility Loss Dyn:\t\t-4.049971747004296\n",
      "Val Utility Loss Stat:\t\t3.93307313396911\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.479191182556866\n",
      "Utility Training Loss:\t\t4.056192958429301\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.25142931392931395\n",
      "Utility Training Acc:\t\t0.063377079002079\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5494184818684187\n",
      "Utility Training Coop Loss:\t3.9501664383247834\n",
      "Privacy Training Coop Acc:\t0.1839591995841996\n",
      "Utility Training Coop Acc:\t0.17343425155925155\n",
      "Privacy Acc Adv:\t\t0.2564968814968815\n",
      "Privacy Acc Coop:\t\t0.17593555093555094\n",
      "Utility Acc Adv:\t\t0.06506626819126819\n",
      "Utility Acc Coop:\t\t0.1843944906475886\n",
      "Val Privacy Acc Adv:\t\t0.2423883723633841\n",
      "Val Privacy Acc Coop:\t\t0.20255107897495436\n",
      "Val Utility Acc Adv:\t\t0.06713441230572206\n",
      "Val Utility Acc Coop:\t\t0.19065656568393236\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 100/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.27821876875971\n",
      "Validation Loss:\t\t0.24866359350694853\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6658721580760643\n",
      "End Effector Loss:\t\t0.006837883464635782\n",
      "Smoothing Loss:\t\t\t0.011161175466930637\n",
      "Triplet Loss:\t\t\t1.4885497463890303e-08\n",
      "Privacy Loss:\t\t\t0.007665534494076846\n",
      "Privacy Loss Dyn:\t\t-3.474501518350629\n",
      "Privacy Loss Stat:\t\t3.551156867814411\n",
      "Utility Loss:\t\t\t-1.101512508431988\n",
      "Utility Loss Dyn:\t\t-4.045155749995099\n",
      "Utility Loss Stat:\t\t3.9350044937986346\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6230289258740165\n",
      "Val End Effector Loss:\t\t0.006336484413232254\n",
      "Val Smoothing Loss:\t\t0.010074345813486879\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.00989602062820403\n",
      "Val Privacy Loss Dyn:\t\t-3.4719388849479107\n",
      "Val Privacy Loss Stat:\t\t3.5708990983726565\n",
      "Val Utility Loss:\t\t-1.043849795317847\n",
      "Val Utility Loss Dyn:\t\t-4.048991512168538\n",
      "Val Utility Loss Stat:\t\t3.9446065411094793\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.476120442709655\n",
      "Utility Training Loss:\t\t4.048741858119528\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.25631496881806676\n",
      "Utility Training Acc:\t\t0.07067957381076971\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5455114553971003\n",
      "Utility Training Coop Loss:\t3.947677232867219\n",
      "Privacy Training Coop Acc:\t0.1874155405436385\n",
      "Utility Training Coop Acc:\t0.17546127858937655\n",
      "Privacy Acc Adv:\t\t0.25608757796567594\n",
      "Privacy Acc Coop:\t\t0.17993113305613306\n",
      "Utility Acc Adv:\t\t0.07532484408103998\n",
      "Utility Acc Coop:\t\t0.18884485447295243\n",
      "Val Privacy Acc Adv:\t\t0.258687729554728\n",
      "Val Privacy Acc Coop:\t\t0.1562213039502871\n",
      "Val Utility Acc Adv:\t\t0.0699609733717747\n",
      "Val Utility Acc Coop:\t\t0.17830291552053504\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 101/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.3036205650979107\n",
      "Validation Loss:\t\t0.5224697218076442\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6643332270847289\n",
      "End Effector Loss:\t\t0.006662586267036531\n",
      "Smoothing Loss:\t\t\t0.011124100373949461\n",
      "Triplet Loss:\t\t\t2.2832446612065305e-08\n",
      "Privacy Loss:\t\t\t0.006823270955353417\n",
      "Privacy Loss Dyn:\t\t-3.478975477436724\n",
      "Privacy Loss Stat:\t\t3.5472081802986763\n",
      "Utility Loss:\t\t\t-1.0719040733860832\n",
      "Utility Loss Dyn:\t\t-4.037191783811843\n",
      "Utility Loss Stat:\t\t3.930001384998805\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6229938977390281\n",
      "Val End Effector Loss:\t\t0.006232196679204117\n",
      "Val Smoothing Loss:\t\t0.009998097374057782\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.008004713649592123\n",
      "Val Privacy Loss Dyn:\t\t-3.460959861593798\n",
      "Val Privacy Loss Stat:\t\t3.5410070010453216\n",
      "Val Utility Loss:\t\t-0.7677492740725683\n",
      "Val Utility Loss Dyn:\t\t-4.040015489109291\n",
      "Val Utility Loss Stat:\t\t3.963240567317679\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.48199766762787\n",
      "Utility Training Loss:\t\t4.0418674559206575\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2494282744313724\n",
      "Utility Training Acc:\t\t0.07974922037422037\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5423666823678603\n",
      "Utility Training Coop Loss:\t3.9436406826526857\n",
      "Privacy Training Coop Acc:\t0.18990384615384615\n",
      "Utility Training Coop Acc:\t0.17997661122970918\n",
      "Privacy Acc Adv:\t\t0.25225441788251585\n",
      "Privacy Acc Coop:\t\t0.18340696465696466\n",
      "Utility Acc Adv:\t\t0.08380977130977131\n",
      "Utility Acc Coop:\t\t0.19397739085548882\n",
      "Val Privacy Acc Adv:\t\t0.2692478764956155\n",
      "Val Privacy Acc Coop:\t\t0.18846131775004804\n",
      "Val Utility Acc Adv:\t\t0.08016241965276644\n",
      "Val Utility Acc Coop:\t\t0.15804350321481297\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 102/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.2750258026722036\n",
      "Validation Loss:\t\t0.1486230079769657\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6688645441789884\n",
      "End Effector Loss:\t\t0.006678419476161999\n",
      "Smoothing Loss:\t\t\t0.011099297708682638\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006791719280012928\n",
      "Privacy Loss Dyn:\t\t-3.478358072947068\n",
      "Privacy Loss Stat:\t\t3.5462752764041605\n",
      "Utility Loss:\t\t\t-1.1094713151578843\n",
      "Utility Loss Dyn:\t\t-4.041360294248855\n",
      "Utility Loss Stat:\t\t3.9304131611469133\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.634786975900989\n",
      "Val End Effector Loss:\t\t0.006434569357555698\n",
      "Val Smoothing Loss:\t\t0.010049742394442524\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0015496261233140613\n",
      "Val Privacy Loss Dyn:\t\t-3.5252392454580828\n",
      "Val Privacy Loss Stat:\t\t3.540735500903169\n",
      "Val Utility Loss:\t\t-1.159084367357995\n",
      "Val Utility Loss Dyn:\t\t-4.042318063334\n",
      "Val Utility Loss Stat:\t\t3.926409629750843\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4822010461109345\n",
      "Utility Training Loss:\t\t4.046280651231318\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24903846154155948\n",
      "Utility Training Acc:\t\t0.07640332640332641\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.544731469263406\n",
      "Utility Training Coop Loss:\t3.9439350673909495\n",
      "Privacy Training Coop Acc:\t0.18686330561640357\n",
      "Utility Training Coop Acc:\t0.18051585239085238\n",
      "Privacy Acc Adv:\t\t0.25306652806962604\n",
      "Privacy Acc Coop:\t\t0.18406964657274452\n",
      "Utility Acc Adv:\t\t0.08036642411642411\n",
      "Utility Acc Coop:\t\t0.19425675675675674\n",
      "Val Privacy Acc Adv:\t\t0.20466741279137035\n",
      "Val Privacy Acc Coop:\t\t0.1907067837670815\n",
      "Val Utility Acc Adv:\t\t0.07651802112371468\n",
      "Val Utility Acc Coop:\t\t0.19572141874304488\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 103/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.31114201180892465\n",
      "Validation Loss:\t\t0.19141581084594622\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6692547737127035\n",
      "End Effector Loss:\t\t0.006526064320095658\n",
      "Smoothing Loss:\t\t\t0.01104433591024497\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.00660746914805097\n",
      "Privacy Loss Dyn:\t\t-3.4816868823184293\n",
      "Privacy Loss Stat:\t\t3.547761568904171\n",
      "Utility Loss:\t\t\t-1.073634078249862\n",
      "Utility Loss Dyn:\t\t-4.036459949309018\n",
      "Utility Loss Stat:\t\t3.929096542624079\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6444314707162951\n",
      "Val End Effector Loss:\t\t0.0060363246497413345\n",
      "Val Smoothing Loss:\t\t0.009976838061139604\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.00394080930258617\n",
      "Val Privacy Loss Dyn:\t\t-3.496225961476318\n",
      "Val Privacy Loss Stat:\t\t3.5356340492067257\n",
      "Val Utility Loss:\t\t-1.1373547798345898\n",
      "Val Utility Loss Dyn:\t\t-4.041012858556321\n",
      "Val Utility Loss Stat:\t\t3.927277375351299\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.483316436131134\n",
      "Utility Training Loss:\t\t4.040773681444339\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24903846154155948\n",
      "Utility Training Acc:\t\t0.08205561330561331\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.537655032350219\n",
      "Utility Training Coop Loss:\t3.9443044840917767\n",
      "Privacy Training Coop Acc:\t0.1948219854500834\n",
      "Utility Training Coop Acc:\t0.17957380457380456\n",
      "Privacy Acc Adv:\t\t0.2499155405436385\n",
      "Privacy Acc Coop:\t\t0.18332250520060314\n",
      "Utility Acc Adv:\t\t0.08494672557172557\n",
      "Utility Acc Coop:\t\t0.19536122661122662\n",
      "Val Privacy Acc Adv:\t\t0.2336934687923794\n",
      "Val Privacy Acc Coop:\t\t0.19596533517330145\n",
      "Val Utility Acc Adv:\t\t0.07709194214876033\n",
      "Val Utility Acc Coop:\t\t0.19554206841309701\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 104/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.41808790424664405\n",
      "Validation Loss:\t\t0.23529319263502094\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6619359301925944\n",
      "End Effector Loss:\t\t0.006037988859226854\n",
      "Smoothing Loss:\t\t\t0.010970089497459035\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.00583589346517892\n",
      "Privacy Loss Dyn:\t\t-3.4835889369187383\n",
      "Privacy Loss Stat:\t\t3.5419478726238323\n",
      "Utility Loss:\t\t\t-0.9505681059712432\n",
      "Utility Loss Dyn:\t\t-4.021445841402621\n",
      "Utility Loss Stat:\t\t3.9263890354648203\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6209312469259767\n",
      "Val End Effector Loss:\t\t0.005503374440999594\n",
      "Val Smoothing Loss:\t\t0.009879787276452792\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0042979023919617835\n",
      "Val Privacy Loss Dyn:\t\t-3.4800039849990654\n",
      "Val Privacy Loss Stat:\t\t3.5229830047315804\n",
      "Val Utility Loss:\t\t-1.0460099385789603\n",
      "Val Utility Loss Dyn:\t\t-4.028717268596996\n",
      "Val Utility Loss Stat:\t\t3.92411627503466\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4873643037930844\n",
      "Utility Training Loss:\t\t4.0266327848057735\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24534823285442875\n",
      "Utility Training Acc:\t\t0.09781055093555094\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5347638985223435\n",
      "Utility Training Coop Loss:\t3.9419885021237473\n",
      "Privacy Training Coop Acc:\t0.19680353430663225\n",
      "Utility Training Coop Acc:\t0.18345244283054077\n",
      "Privacy Acc Adv:\t\t0.24836928275047865\n",
      "Privacy Acc Coop:\t\t0.18799376301854662\n",
      "Utility Acc Adv:\t\t0.10265072765072765\n",
      "Utility Acc Coop:\t\t0.19782354470474062\n",
      "Val Privacy Acc Adv:\t\t0.25033000459478905\n",
      "Val Privacy Acc Coop:\t\t0.20806789485937802\n",
      "Val Utility Acc Adv:\t\t0.08981146694214875\n",
      "Val Utility Acc Coop:\t\t0.19912907484272294\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 105/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.38062945250886454\n",
      "Validation Loss:\t\t0.6344660070670907\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6639076166490011\n",
      "End Effector Loss:\t\t0.006040679550102356\n",
      "Smoothing Loss:\t\t\t0.010922621453970887\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006122695247249643\n",
      "Privacy Loss Dyn:\t\t-3.48349008589921\n",
      "Privacy Loss Stat:\t\t3.5447170322997157\n",
      "Utility Loss:\t\t\t-0.9921170193043667\n",
      "Utility Loss Dyn:\t\t-4.024324309801114\n",
      "Utility Loss Stat:\t\t3.9251126120343276\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6241601385360906\n",
      "Val End Effector Loss:\t\t0.005424639155745722\n",
      "Val Smoothing Loss:\t\t0.009804923993666188\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0014370004377089257\n",
      "Val Privacy Loss Dyn:\t\t-3.5011691510184737\n",
      "Val Privacy Loss Stat:\t\t3.515539155518713\n",
      "Val Utility Loss:\t\t-0.650130681755129\n",
      "Val Utility Loss Dyn:\t\t-4.023542140633607\n",
      "Val Utility Loss Stat:\t\t3.9585290694039714\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4852198473876825\n",
      "Utility Training Loss:\t\t4.029128485063009\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24655665280665282\n",
      "Utility Training Acc:\t\t0.09710888773698569\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5358460655827035\n",
      "Utility Training Coop Loss:\t3.940062389056549\n",
      "Privacy Training Coop Acc:\t0.19581600831600832\n",
      "Utility Training Coop Acc:\t0.18408913721413722\n",
      "Privacy Acc Adv:\t\t0.24684901247401247\n",
      "Privacy Acc Coop:\t\t0.1857783264033264\n",
      "Utility Acc Adv:\t\t0.10116943867253662\n",
      "Utility Acc Coop:\t\t0.19797297297607092\n",
      "Val Privacy Acc Adv:\t\t0.22786099633032625\n",
      "Val Privacy Acc Coop:\t\t0.21591626492536758\n",
      "Val Utility Acc Adv:\t\t0.09727244031392346\n",
      "Val Utility Acc Coop:\t\t0.16216856062658563\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 106/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.3304076543941381\n",
      "Validation Loss:\t\t0.23694651738609657\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6578062269023451\n",
      "End Effector Loss:\t\t0.005877684336881736\n",
      "Smoothing Loss:\t\t\t0.010871151651462962\n",
      "Triplet Loss:\t\t\t6.574742871640626e-09\n",
      "Privacy Loss:\t\t\t0.006449356334373014\n",
      "Privacy Loss Dyn:\t\t-3.4782864881404474\n",
      "Privacy Loss Stat:\t\t3.5427800545821317\n",
      "Utility Loss:\t\t\t-1.0301453041187691\n",
      "Utility Loss Dyn:\t\t-4.024843308881018\n",
      "Utility Loss Stat:\t\t3.9218287688530906\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.639751140305326\n",
      "Val End Effector Loss:\t\t0.005916551300055109\n",
      "Val Smoothing Loss:\t\t0.009855211232327047\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.009137761371194824\n",
      "Val Privacy Loss Dyn:\t\t-3.4790832375691942\n",
      "Val Privacy Loss Stat:\t\t3.5704608500496415\n",
      "Val Utility Loss:\t\t-1.08717570817175\n",
      "Val Utility Loss Dyn:\t\t-4.02983753888075\n",
      "Val Utility Loss Stat:\t\t3.9211199697384163\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.482739159818003\n",
      "Utility Training Loss:\t\t4.028842932221299\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2509030665342624\n",
      "Utility Training Acc:\t\t0.09473752599062395\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.533213857057932\n",
      "Utility Training Coop Loss:\t3.9368129492797377\n",
      "Privacy Training Coop Acc:\t0.19821985446985446\n",
      "Utility Training Coop Acc:\t0.18728560291370086\n",
      "Privacy Acc Adv:\t\t0.25488565488875287\n",
      "Privacy Acc Coop:\t\t0.1870127338877339\n",
      "Utility Acc Adv:\t\t0.09600441788251583\n",
      "Utility Acc Coop:\t\t0.20196855509665304\n",
      "Val Privacy Acc Adv:\t\t0.25187959137164856\n",
      "Val Privacy Acc Coop:\t\t0.1586748163469813\n",
      "Val Utility Acc Adv:\t\t0.08858471074380166\n",
      "Val Utility Acc Coop:\t\t0.20195563593186622\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 107/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.33063114448808706\n",
      "Validation Loss:\t\t0.05327536883833241\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6544512376468048\n",
      "End Effector Loss:\t\t0.005781896647381482\n",
      "Smoothing Loss:\t\t\t0.010844689775006595\n",
      "Triplet Loss:\t\t\t5.702846416121198e-08\n",
      "Privacy Loss:\t\t\t0.006834287901182432\n",
      "Privacy Loss Dyn:\t\t-3.4812290095985556\n",
      "Privacy Loss Stat:\t\t3.5495718829101435\n",
      "Utility Loss:\t\t\t-1.0234216424382898\n",
      "Utility Loss Dyn:\t\t-4.022180031094383\n",
      "Utility Loss Stat:\t\t3.9198378681393025\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.630084184575672\n",
      "Val End Effector Loss:\t\t0.005735641714832014\n",
      "Val Smoothing Loss:\t\t0.00986917812496516\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.004630081478721839\n",
      "Val Privacy Loss Dyn:\t\t-3.4981805568884226\n",
      "Val Privacy Loss Stat:\t\t3.544481369089489\n",
      "Val Utility Loss:\t\t-1.2468662577227128\n",
      "Val Utility Loss Dyn:\t\t-4.035614032390689\n",
      "Val Utility Loss Stat:\t\t3.910927393712288\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4858515287387397\n",
      "Utility Training Loss:\t\t4.026687444123805\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24703742204361795\n",
      "Utility Training Acc:\t\t0.0972258316008316\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.537679159219944\n",
      "Utility Training Coop Loss:\t3.9330601045346807\n",
      "Privacy Training Coop Acc:\t0.19560161122970918\n",
      "Utility Training Coop Acc:\t0.19096933472553063\n",
      "Privacy Acc Adv:\t\t0.2511174636205616\n",
      "Privacy Acc Coop:\t\t0.18078872141681937\n",
      "Utility Acc Adv:\t\t0.09959719334719334\n",
      "Utility Acc Coop:\t\t0.20456730769540565\n",
      "Val Privacy Acc Adv:\t\t0.2318282254378904\n",
      "Val Privacy Acc Coop:\t\t0.18598628328913006\n",
      "Val Utility Acc Adv:\t\t0.08565053948747718\n",
      "Val Utility Acc Coop:\t\t0.21286013544621793\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 108/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.29257444767262053\n",
      "Validation Loss:\t\t0.5177660149806911\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6592991187579914\n",
      "End Effector Loss:\t\t0.005740246973426436\n",
      "Smoothing Loss:\t\t\t0.01088832538059899\n",
      "Triplet Loss:\t\t\t8.479152925180855e-09\n",
      "Privacy Loss:\t\t\t0.005985569929134821\n",
      "Privacy Loss Dyn:\t\t-3.4852120070844084\n",
      "Privacy Loss Stat:\t\t3.5450677056322473\n",
      "Utility Loss:\t\t\t-1.0704145927191275\n",
      "Utility Loss Dyn:\t\t-4.024810019005361\n",
      "Utility Loss Stat:\t\t3.9177685614187356\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6398442555064997\n",
      "Val End Effector Loss:\t\t0.005729286890084401\n",
      "Val Smoothing Loss:\t\t0.00982892231954154\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.004228018901564858\n",
      "Val Privacy Loss Dyn:\t\t-3.475096699127481\n",
      "Val Privacy Loss Stat:\t\t3.517376884941227\n",
      "Val Utility Loss:\t\t-0.8013665695820958\n",
      "Val Utility Loss Dyn:\t\t-4.035846602325597\n",
      "Val Utility Loss Stat:\t\t3.9557099317716173\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.487205328415932\n",
      "Utility Training Loss:\t\t4.0284165773471035\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24612785863405454\n",
      "Utility Training Acc:\t\t0.09547167359667359\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.535623180395352\n",
      "Utility Training Coop Loss:\t3.9335543271657585\n",
      "Privacy Training Coop Acc:\t0.19571205821825413\n",
      "Utility Training Coop Acc:\t0.1896439708939709\n",
      "Privacy Acc Adv:\t\t0.24567307692927284\n",
      "Privacy Acc Coop:\t\t0.18408264033883623\n",
      "Utility Acc Adv:\t\t0.09712837837837837\n",
      "Utility Acc Coop:\t\t0.20667879418189214\n",
      "Val Privacy Acc Adv:\t\t0.25512224518932586\n",
      "Val Privacy Acc Coop:\t\t0.21555756428086562\n",
      "Val Utility Acc Adv:\t\t0.0843879132231405\n",
      "Val Utility Acc Coop:\t\t0.16592056933051544\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 109/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.22452032392391483\n",
      "Validation Loss:\t\t0.25728031759696807\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6601200942685846\n",
      "End Effector Loss:\t\t0.005728766725354067\n",
      "Smoothing Loss:\t\t\t0.010878438347846022\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006346409323309663\n",
      "Privacy Loss Dyn:\t\t-3.4804066595565257\n",
      "Privacy Loss Stat:\t\t3.5438707469654678\n",
      "Utility Loss:\t\t\t-1.1404303552702906\n",
      "Utility Loss Dyn:\t\t-4.028603628122881\n",
      "Utility Loss Stat:\t\t3.9145605863999426\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6321853764416757\n",
      "Val End Effector Loss:\t\t0.005497953989196661\n",
      "Val Smoothing Loss:\t\t0.009901877009686975\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0013537950013294694\n",
      "Val Privacy Loss Dyn:\t\t-3.507014856358205\n",
      "Val Privacy Loss Stat:\t\t3.5205528036621976\n",
      "Val Utility Loss:\t\t-1.0436478134029168\n",
      "Val Utility Loss Dyn:\t\t-4.035043164225649\n",
      "Val Utility Loss Stat:\t\t3.930678380914956\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.484979640917074\n",
      "Utility Training Loss:\t\t4.030797392811448\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24665410602910603\n",
      "Utility Training Acc:\t\t0.09057952183261979\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.533721192958697\n",
      "Utility Training Coop Loss:\t3.9298239889362994\n",
      "Privacy Training Coop Acc:\t0.19857718295218296\n",
      "Utility Training Coop Acc:\t0.19121621621931417\n",
      "Privacy Acc Adv:\t\t0.2526117463648443\n",
      "Privacy Acc Coop:\t\t0.18652546777546777\n",
      "Utility Acc Adv:\t\t0.09204132016941811\n",
      "Utility Acc Coop:\t\t0.21028456341266136\n",
      "Val Privacy Acc Adv:\t\t0.22238722452816884\n",
      "Val Privacy Acc Coop:\t\t0.21050705923891264\n",
      "Val Utility Acc Adv:\t\t0.08204918503299478\n",
      "Val Utility Acc Coop:\t\t0.19112287649561552\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 110/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.17888826530682322\n",
      "Validation Loss:\t\t0.05853036827646381\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.674704752072475\n",
      "End Effector Loss:\t\t0.005938234465998325\n",
      "Smoothing Loss:\t\t\t0.010906876839325607\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006605763290379499\n",
      "Privacy Loss Dyn:\t\t-3.481417314426319\n",
      "Privacy Loss Stat:\t\t3.547474946648564\n",
      "Utility Loss:\t\t\t-1.2157858691939196\n",
      "Utility Loss Dyn:\t\t-4.036112226964034\n",
      "Utility Loss Stat:\t\t3.914533647578868\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6348477207308958\n",
      "Val End Effector Loss:\t\t0.005591880730237843\n",
      "Val Smoothing Loss:\t\t0.009803253422252649\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.003805675782448004\n",
      "Val Privacy Loss Dyn:\t\t-3.480416073779429\n",
      "Val Privacy Loss Stat:\t\t3.518472834066911\n",
      "Val Utility Loss:\t\t-1.2499723907344598\n",
      "Val Utility Loss Dyn:\t\t-4.029700578244264\n",
      "Val Utility Loss Stat:\t\t3.9047033279395302\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.486474550191677\n",
      "Utility Training Loss:\t\t4.038985011483429\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24614085241563602\n",
      "Utility Training Acc:\t\t0.08458290021409612\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5358411328956145\n",
      "Utility Training Coop Loss:\t3.9312629459305763\n",
      "Privacy Training Coop Acc:\t0.19499740125359716\n",
      "Utility Training Coop Acc:\t0.19469204782014576\n",
      "Privacy Acc Adv:\t\t0.2509810291308127\n",
      "Privacy Acc Coop:\t\t0.1826208420020379\n",
      "Utility Acc Adv:\t\t0.08397219334719334\n",
      "Utility Acc Coop:\t\t0.2113240644521624\n",
      "Val Privacy Acc Adv:\t\t0.24941173097318856\n",
      "Val Privacy Acc Coop:\t\t0.2126090450227753\n",
      "Val Utility Acc Adv:\t\t0.09006973140495868\n",
      "Val Utility Acc Coop:\t\t0.2201632805599654\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 111/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.20231664784082257\n",
      "Validation Loss:\t\t0.37871393947746634\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6577619528572177\n",
      "End Effector Loss:\t\t0.005752320703663118\n",
      "Smoothing Loss:\t\t\t0.010841098850740123\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006979426047658227\n",
      "Privacy Loss Dyn:\t\t-3.4813490605403876\n",
      "Privacy Loss Stat:\t\t3.551143324548638\n",
      "Utility Loss:\t\t\t-1.1584622983873014\n",
      "Utility Loss Dyn:\t\t-4.028739489289678\n",
      "Utility Loss Stat:\t\t3.9128932652998865\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6175666444065157\n",
      "Val End Effector Loss:\t\t0.005378720610333253\n",
      "Val Smoothing Loss:\t\t0.009752529206654934\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.006039837421464526\n",
      "Val Privacy Loss Dyn:\t\t-3.4619462795494016\n",
      "Val Privacy Loss Stat:\t\t3.522344655241848\n",
      "Val Utility Loss:\t\t-0.8970954989598803\n",
      "Val Utility Loss Dyn:\t\t-4.026606619358063\n",
      "Val Utility Loss Stat:\t\t3.936897071432476\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.485154791582151\n",
      "Utility Training Loss:\t\t4.032578460887663\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2482783264033264\n",
      "Utility Training Acc:\t\t0.08772089397399192\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5385866717836216\n",
      "Utility Training Coop Loss:\t3.930537559882023\n",
      "Privacy Training Coop Acc:\t0.19253508316008316\n",
      "Utility Training Coop Acc:\t0.1955821205883165\n",
      "Privacy Acc Adv:\t\t0.25084459459459457\n",
      "Privacy Acc Coop:\t\t0.17954132016632016\n",
      "Utility Acc Adv:\t\t0.09007926195426195\n",
      "Utility Acc Coop:\t\t0.21149948025567616\n",
      "Val Privacy Acc Adv:\t\t0.27083333335385834\n",
      "Val Privacy Acc Coop:\t\t0.20976096189249893\n",
      "Val Utility Acc Adv:\t\t0.09730113636363637\n",
      "Val Utility Acc Coop:\t\t0.18772956841309701\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 112/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.17830189654561004\n",
      "Validation Loss:\t\t0.3437972054662845\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6488793634823107\n",
      "End Effector Loss:\t\t0.005652278261898151\n",
      "Smoothing Loss:\t\t\t0.010796605636464458\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006805554094284835\n",
      "Privacy Loss Dyn:\t\t-3.482704375984763\n",
      "Privacy Loss Stat:\t\t3.5507599135198613\n",
      "Utility Loss:\t\t\t-1.1643044794919337\n",
      "Utility Loss Dyn:\t\t-4.026922999697267\n",
      "Utility Loss Stat:\t\t3.9104925475844228\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6081851025627665\n",
      "Val End Effector Loss:\t\t0.005206976070507499\n",
      "Val Smoothing Loss:\t\t0.009756106992967981\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.011002663553746279\n",
      "Val Privacy Loss Dyn:\t\t-3.461080275783854\n",
      "Val Privacy Loss Stat:\t\t3.5711069111981666\n",
      "Val Utility Loss:\t\t-0.9180509630313589\n",
      "Val Utility Loss Dyn:\t\t-4.025081252756197\n",
      "Val Utility Loss Stat:\t\t3.933276160689425\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.486883249699202\n",
      "Utility Training Loss:\t\t4.0307622860474295\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24604989605299402\n",
      "Utility Training Acc:\t\t0.08832510395010396\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.53905150969658\n",
      "Utility Training Coop Loss:\t3.9282639931244563\n",
      "Privacy Training Coop Acc:\t0.19234017671517672\n",
      "Utility Training Coop Acc:\t0.19555613305613306\n",
      "Privacy Acc Adv:\t\t0.2500779625810605\n",
      "Privacy Acc Coop:\t\t0.17973622661122662\n",
      "Utility Acc Adv:\t\t0.09053404365904366\n",
      "Utility Acc Coop:\t\t0.21421517671827467\n",
      "Val Privacy Acc Adv:\t\t0.27113464188354075\n",
      "Val Privacy Acc Coop:\t\t0.1553173783304524\n",
      "Val Utility Acc Adv:\t\t0.0966124311397391\n",
      "Val Utility Acc Coop:\t\t0.1892361111384778\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 113/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.13509452953671344\n",
      "Validation Loss:\t\t-0.06485803438011896\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6484226182939605\n",
      "End Effector Loss:\t\t0.005638440656320825\n",
      "Smoothing Loss:\t\t\t0.010831832748754511\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.007352943046177251\n",
      "Privacy Loss Dyn:\t\t-3.4817775520118506\n",
      "Privacy Loss Stat:\t\t3.5553069855715775\n",
      "Utility Loss:\t\t\t-1.207237588640558\n",
      "Utility Loss Dyn:\t\t-4.028391135457648\n",
      "Utility Loss Stat:\t\t3.9076673838304137\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6260802803083885\n",
      "Val End Effector Loss:\t\t0.0053178221526101604\n",
      "Val Smoothing Loss:\t\t0.00977748943866069\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.00861619369796485\n",
      "Val Privacy Loss Dyn:\t\t-3.463092421204591\n",
      "Val Privacy Loss Stat:\t\t3.549254355351787\n",
      "Val Utility Loss:\t\t-1.3602850811540588\n",
      "Val Utility Loss Dyn:\t\t-4.037018992191504\n",
      "Val Utility Loss Stat:\t\t3.9009904950118264\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4854883907242775\n",
      "Utility Training Loss:\t\t4.031691875874129\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.245614604989605\n",
      "Utility Training Acc:\t\t0.08830561330871126\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.54289966040986\n",
      "Utility Training Coop Loss:\t3.9260488027346607\n",
      "Privacy Training Coop Acc:\t0.1892216735966736\n",
      "Utility Training Coop Acc:\t0.19968165280665282\n",
      "Privacy Acc Adv:\t\t0.2492203742203742\n",
      "Privacy Acc Coop:\t\t0.17518840956340956\n",
      "Utility Acc Adv:\t\t0.08996231809041604\n",
      "Utility Acc Coop:\t\t0.2182107588388568\n",
      "Val Privacy Acc Adv:\t\t0.26808568641297087\n",
      "Val Privacy Acc Coop:\t\t0.18054838155296224\n",
      "Val Utility Acc Adv:\t\t0.0835987718098543\n",
      "Val Utility Acc Coop:\t\t0.22517791552053504\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 114/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.10624782696343076\n",
      "Validation Loss:\t\t-0.06980248554494263\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6479763778356405\n",
      "End Effector Loss:\t\t0.0055942684692754695\n",
      "Smoothing Loss:\t\t\t0.010825753855284713\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008033947891356296\n",
      "Privacy Loss Dyn:\t\t-3.482854184886274\n",
      "Privacy Loss Stat:\t\t3.56319366770326\n",
      "Utility Loss:\t\t\t-1.235810408721099\n",
      "Utility Loss Dyn:\t\t-4.030826352985882\n",
      "Utility Loss Stat:\t\t3.9072453113206955\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6080436319851679\n",
      "Val End Effector Loss:\t\t0.005067455792541747\n",
      "Val Smoothing Loss:\t\t0.009740713378606934\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.009871133349158547\n",
      "Val Privacy Loss Dyn:\t\t-3.485555956186342\n",
      "Val Privacy Loss Stat:\t\t3.5842672857371243\n",
      "Val Utility Loss:\t\t-1.330050484208036\n",
      "Val Utility Loss Dyn:\t\t-4.041388435797258\n",
      "Val Utility Loss Stat:\t\t3.90838339506102\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4866917537304567\n",
      "Utility Training Loss:\t\t4.0331451404615155\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2456211018958855\n",
      "Utility Training Acc:\t\t0.08577182952492747\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.544497818064541\n",
      "Utility Training Coop Loss:\t3.9248734705165615\n",
      "Privacy Training Coop Acc:\t0.18714916842395204\n",
      "Utility Training Coop Acc:\t0.2025337837899797\n",
      "Privacy Acc Adv:\t\t0.248609667384451\n",
      "Privacy Acc Coop:\t\t0.1656769750767587\n",
      "Utility Acc Adv:\t\t0.08814319127128922\n",
      "Utility Acc Coop:\t\t0.21785343035652832\n",
      "Val Privacy Acc Adv:\t\t0.2447055785123967\n",
      "Val Privacy Acc Coop:\t\t0.14320764462809918\n",
      "Val Utility Acc Adv:\t\t0.079789370983408\n",
      "Val Utility Acc Coop:\t\t0.21715736915626802\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 115/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.07346327635585456\n",
      "Validation Loss:\t\t-0.004748849171283077\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6503663025254272\n",
      "End Effector Loss:\t\t0.0055980435589506545\n",
      "Smoothing Loss:\t\t\t0.01079372783373507\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.00824729289681401\n",
      "Privacy Loss Dyn:\t\t-3.4838650120023384\n",
      "Privacy Loss Stat:\t\t3.566337942829251\n",
      "Utility Loss:\t\t\t-1.2734958505927896\n",
      "Utility Loss Dyn:\t\t-4.031946244457903\n",
      "Utility Loss Stat:\t\t3.9045966563750207\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6294470060585944\n",
      "Val End Effector Loss:\t\t0.005320240025243083\n",
      "Val Smoothing Loss:\t\t0.009789994670547668\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.005024317374899368\n",
      "Val Privacy Loss Dyn:\t\t-3.5375459987269946\n",
      "Val Privacy Loss Stat:\t\t3.587789165579583\n",
      "Val Utility Loss:\t\t-1.3033574001848205\n",
      "Val Utility Loss Dyn:\t\t-4.039191167709256\n",
      "Val Utility Loss Stat:\t\t3.9088554214840094\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.48732567998327\n",
      "Utility Training Loss:\t\t4.034689084160105\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2448349792099792\n",
      "Utility Training Acc:\t\t0.08491424116424116\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5485078837420487\n",
      "Utility Training Coop Loss:\t3.9219858044150464\n",
      "Privacy Training Coop Acc:\t0.18322505197814992\n",
      "Utility Training Coop Acc:\t0.20235836798646595\n",
      "Privacy Acc Adv:\t\t0.24662162162162163\n",
      "Privacy Acc Coop:\t\t0.16307172557172558\n",
      "Utility Acc Adv:\t\t0.08713617463927259\n",
      "Utility Acc Coop:\t\t0.22104989605609196\n",
      "Val Privacy Acc Adv:\t\t0.19102961434559387\n",
      "Val Privacy Acc Coop:\t\t0.1399219467435494\n",
      "Val Utility Acc Adv:\t\t0.08080808080979122\n",
      "Val Utility Acc Coop:\t\t0.21670540634635066\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 116/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.020158628733700872\n",
      "Validation Loss:\t\t-0.24371797658795538\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6532062128217205\n",
      "End Effector Loss:\t\t0.0056212941052008756\n",
      "Smoothing Loss:\t\t\t0.01079056938779066\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008228304511296278\n",
      "Privacy Loss Dyn:\t\t-3.4853369969092385\n",
      "Privacy Loss Stat:\t\t3.567620041960242\n",
      "Utility Loss:\t\t\t-1.3324751031126154\n",
      "Utility Loss Dyn:\t\t-4.035167788765286\n",
      "Utility Loss Stat:\t\t3.9019202734972978\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.624095493665904\n",
      "Val End Effector Loss:\t\t0.005227169234590405\n",
      "Val Smoothing Loss:\t\t0.009733618485302594\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0024801715592707484\n",
      "Val Privacy Loss Dyn:\t\t-3.5125941919886374\n",
      "Val Privacy Loss Stat:\t\t3.5373959083202458\n",
      "Val Utility Loss:\t\t-1.5288171610556358\n",
      "Val Utility Loss Dyn:\t\t-4.053253235403171\n",
      "Val Utility Loss Stat:\t\t3.900371524913252\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.487730543975275\n",
      "Utility Training Loss:\t\t4.0372506670049715\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24597843037821399\n",
      "Utility Training Acc:\t\t0.08180873181182977\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.552846280799834\n",
      "Utility Training Coop Loss:\t3.920522409020739\n",
      "Privacy Training Coop Acc:\t0.17707900210378572\n",
      "Utility Training Coop Acc:\t0.2047817047817048\n",
      "Privacy Acc Adv:\t\t0.24701793141771503\n",
      "Privacy Acc Coop:\t\t0.1612136174698134\n",
      "Utility Acc Adv:\t\t0.08294568607378403\n",
      "Utility Acc Coop:\t\t0.22402546777856572\n",
      "Val Privacy Acc Adv:\t\t0.2166408402306482\n",
      "Val Privacy Acc Coop:\t\t0.19383465335511965\n",
      "Val Utility Acc Adv:\t\t0.0625\n",
      "Val Utility Acc Coop:\t\t0.22518508955220545\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 117/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.020383073899918187\n",
      "Validation Loss:\t\t0.32425311423283965\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6538098263951201\n",
      "End Effector Loss:\t\t0.005513651125140783\n",
      "Smoothing Loss:\t\t\t0.010791789087817352\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008227582502018141\n",
      "Privacy Loss Dyn:\t\t-3.4834830057100548\n",
      "Privacy Loss Stat:\t\t3.565758829553013\n",
      "Utility Loss:\t\t\t-1.3741193283620348\n",
      "Utility Loss Dyn:\t\t-4.037567511665598\n",
      "Utility Loss Stat:\t\t3.9001555722865144\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6167289568496145\n",
      "Val End Effector Loss:\t\t0.005157503335975295\n",
      "Val Smoothing Loss:\t\t0.009706267947523493\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0030000923463135713\n",
      "Val Privacy Loss Dyn:\t\t-3.525381668540072\n",
      "Val Privacy Loss Stat:\t\t3.5553825881855547\n",
      "Val Utility Loss:\t\t-0.9464812002891352\n",
      "Val Utility Loss Dyn:\t\t-4.034411244648547\n",
      "Val Utility Loss Stat:\t\t3.9397631203832706\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.485302395235724\n",
      "Utility Training Loss:\t\t4.038905228993501\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24551065489185078\n",
      "Utility Training Acc:\t\t0.07922946985446985\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.551501282783159\n",
      "Utility Training Coop Loss:\t3.9185213755173396\n",
      "Privacy Training Coop Acc:\t0.1792489604989605\n",
      "Utility Training Coop Acc:\t0.20763383576503167\n",
      "Privacy Acc Adv:\t\t0.24786252601230963\n",
      "Privacy Acc Coop:\t\t0.1645140332671312\n",
      "Utility Acc Adv:\t\t0.08189319126819126\n",
      "Utility Acc Coop:\t\t0.22624740125359716\n",
      "Val Privacy Acc Adv:\t\t0.20390696740470643\n",
      "Val Privacy Acc Coop:\t\t0.17431416437183775\n",
      "Val Utility Acc Adv:\t\t0.08720012626433668\n",
      "Val Utility Acc Coop:\t\t0.1830808080825185\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 118/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.08860697285533571\n",
      "Validation Loss:\t\t-0.25259434379452517\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6534890559445795\n",
      "End Effector Loss:\t\t0.0054755227017291895\n",
      "Smoothing Loss:\t\t\t0.010780982977639023\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008568275371361175\n",
      "Privacy Loss Dyn:\t\t-3.4819923673994575\n",
      "Privacy Loss Stat:\t\t3.5676751213609057\n",
      "Utility Loss:\t\t\t-1.4419718324022828\n",
      "Utility Loss Dyn:\t\t-4.041438849948796\n",
      "Utility Loss Stat:\t\t3.8972416697321712\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6207408773258698\n",
      "Val End Effector Loss:\t\t0.005347690205878678\n",
      "Val Smoothing Loss:\t\t0.009738082287463644\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0054133772726886525\n",
      "Val Privacy Loss Dyn:\t\t-3.4970373885690673\n",
      "Val Privacy Loss Stat:\t\t3.551171161911704\n",
      "Val Utility Loss:\t\t-1.5340514143636403\n",
      "Val Utility Loss Dyn:\t\t-4.063566591621431\n",
      "Val Utility Loss Stat:\t\t3.910161439052298\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4848678186380937\n",
      "Utility Training Loss:\t\t4.042454994641817\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2486161642442622\n",
      "Utility Training Acc:\t\t0.07874220374220374\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5523330810907723\n",
      "Utility Training Coop Loss:\t3.916605271569409\n",
      "Privacy Training Coop Acc:\t0.17895010395629987\n",
      "Utility Training Coop Acc:\t0.20797817048126843\n",
      "Privacy Acc Adv:\t\t0.250435291063389\n",
      "Privacy Acc Coop:\t\t0.16241554054673646\n",
      "Utility Acc Adv:\t\t0.07705301455301455\n",
      "Utility Acc Coop:\t\t0.2287032224563204\n",
      "Val Privacy Acc Adv:\t\t0.2331912878993129\n",
      "Val Privacy Acc Coop:\t\t0.17820965335511965\n",
      "Val Utility Acc Adv:\t\t0.05462293388429752\n",
      "Val Utility Acc Coop:\t\t0.21428776403103977\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 119/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.09778129024404002\n",
      "Validation Loss:\t\t-0.25819743167963033\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6509306986279894\n",
      "End Effector Loss:\t\t0.005406176204272311\n",
      "Smoothing Loss:\t\t\t0.010762048881837861\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008718255527797708\n",
      "Privacy Loss Dyn:\t\t-3.4827587483082887\n",
      "Privacy Loss Stat:\t\t3.5699413028427567\n",
      "Utility Loss:\t\t\t-1.4460532650382505\n",
      "Utility Loss Dyn:\t\t-4.042486874576418\n",
      "Utility Loss Stat:\t\t3.897881556449462\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6193916701580867\n",
      "Val End Effector Loss:\t\t0.004987489804914144\n",
      "Val Smoothing Loss:\t\t0.009675499886920876\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0007164627313613892\n",
      "Val Privacy Loss Dyn:\t\t-3.5443531801877928\n",
      "Val Privacy Loss Stat:\t\t3.551517808732908\n",
      "Val Utility Loss:\t\t-1.5317112236968742\n",
      "Val Utility Loss Dyn:\t\t-4.045961367689873\n",
      "Val Utility Loss Stat:\t\t3.892790236256339\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.485680514214688\n",
      "Utility Training Loss:\t\t4.044442966177657\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24536772349582145\n",
      "Utility Training Acc:\t\t0.07643581081081081\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.55639838577556\n",
      "Utility Training Coop Loss:\t3.916837229798093\n",
      "Privacy Training Coop Acc:\t0.17449974013093603\n",
      "Utility Training Coop Acc:\t0.20867983367983367\n",
      "Privacy Acc Adv:\t\t0.24844074844074845\n",
      "Privacy Acc Coop:\t\t0.15990124740434536\n",
      "Utility Acc Adv:\t\t0.07624090436590436\n",
      "Utility Acc Coop:\t\t0.22716346153846154\n",
      "Val Privacy Acc Adv:\t\t0.18505366161958245\n",
      "Val Privacy Acc Coop:\t\t0.17912792700750768\n",
      "Val Utility Acc Adv:\t\t0.07165404040489562\n",
      "Val Utility Acc Coop:\t\t0.23288280535335384\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 120/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.1551177491455217\n",
      "Validation Loss:\t\t-0.2350564012919699\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6545615427955025\n",
      "End Effector Loss:\t\t0.005435480160170124\n",
      "Smoothing Loss:\t\t\t0.010743045164349638\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008629394606096581\n",
      "Privacy Loss Dyn:\t\t-3.485074204119724\n",
      "Privacy Loss Stat:\t\t3.571368145347881\n",
      "Utility Loss:\t\t\t-1.5105348416524718\n",
      "Utility Loss Dyn:\t\t-4.046134232483386\n",
      "Utility Loss Stat:\t\t3.89508074212223\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6233534803690989\n",
      "Val End Effector Loss:\t\t0.005176715197788228\n",
      "Val Smoothing Loss:\t\t0.009677082216482578\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.003599006959722062\n",
      "Val Privacy Loss Dyn:\t\t-3.5166635616751742\n",
      "Val Privacy Loss Stat:\t\t3.552653635828948\n",
      "Val Utility Loss:\t\t-1.519570327002155\n",
      "Val Utility Loss Dyn:\t\t-4.04307872007701\n",
      "Val Utility Loss Stat:\t\t3.891121698312523\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.486789655536723\n",
      "Utility Training Loss:\t\t4.046766874943851\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24551715176715178\n",
      "Utility Training Acc:\t\t0.07227780665280666\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5553039081874855\n",
      "Utility Training Coop Loss:\t3.913263746457883\n",
      "Privacy Training Coop Acc:\t0.17640332640642437\n",
      "Utility Training Coop Acc:\t0.21095374220374222\n",
      "Privacy Acc Adv:\t\t0.24632276507896098\n",
      "Privacy Acc Coop:\t\t0.1578872141403121\n",
      "Utility Acc Adv:\t\t0.07179054054054054\n",
      "Utility Acc Coop:\t\t0.23031444906444906\n",
      "Val Privacy Acc Adv:\t\t0.21348427457750335\n",
      "Val Privacy Acc Coop:\t\t0.17692550505734672\n",
      "Val Utility Acc Adv:\t\t0.07605888429752067\n",
      "Val Utility Acc Coop:\t\t0.23429608585944106\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 121/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.16438770532151084\n",
      "Validation Loss:\t\t-0.20430304239742642\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6539263541262264\n",
      "End Effector Loss:\t\t0.005461410546226121\n",
      "Smoothing Loss:\t\t\t0.010777293824979923\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008732257383776802\n",
      "Privacy Loss Dyn:\t\t-3.4828362673087327\n",
      "Privacy Loss Stat:\t\t3.5701588451738417\n",
      "Utility Loss:\t\t\t-1.5187659670062472\n",
      "Utility Loss Dyn:\t\t-4.044686888210987\n",
      "Utility Loss Stat:\t\t3.8928102909155546\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.618758867102221\n",
      "Val End Effector Loss:\t\t0.005058690824753736\n",
      "Val Smoothing Loss:\t\t0.009648905604238783\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.008084513801188508\n",
      "Val Privacy Loss Dyn:\t\t-3.4681542658608806\n",
      "Val Privacy Loss Stat:\t\t3.548999401656064\n",
      "Val Utility Loss:\t\t-1.4839106945952107\n",
      "Val Utility Loss Dyn:\t\t-4.043300889247705\n",
      "Val Utility Loss Stat:\t\t3.89490981436958\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4870561787591408\n",
      "Utility Training Loss:\t\t4.046752903664682\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2452572765072765\n",
      "Utility Training Acc:\t\t0.07172557172557173\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5522880992869577\n",
      "Utility Training Coop Loss:\t3.911376763530184\n",
      "Privacy Training Coop Acc:\t0.17807952182952183\n",
      "Utility Training Coop Acc:\t0.2143775987556967\n",
      "Privacy Acc Adv:\t\t0.248245841995842\n",
      "Privacy Acc Coop:\t\t0.15910862785862787\n",
      "Utility Acc Adv:\t\t0.07308991683991684\n",
      "Utility Acc Coop:\t\t0.2329911642442622\n",
      "Val Privacy Acc Adv:\t\t0.2621742998180557\n",
      "Val Privacy Acc Coop:\t\t0.18127295684284908\n",
      "Val Utility Acc Adv:\t\t0.07330406337114405\n",
      "Val Utility Acc Coop:\t\t0.23041494492410627\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 122/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.18970756647864398\n",
      "Validation Loss:\t\t-0.2506538976430277\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6548013245675272\n",
      "End Effector Loss:\t\t0.005492768583435898\n",
      "Smoothing Loss:\t\t\t0.01076169045237348\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008473966231960764\n",
      "Privacy Loss Dyn:\t\t-3.4830881193620997\n",
      "Privacy Loss Stat:\t\t3.567827778893548\n",
      "Utility Loss:\t\t\t-1.5455620224411424\n",
      "Utility Loss Dyn:\t\t-4.046135991130202\n",
      "Utility Loss Stat:\t\t3.8915797863581574\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6108498658892537\n",
      "Val End Effector Loss:\t\t0.004931573297112626\n",
      "Val Smoothing Loss:\t\t0.009631446366436964\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.011802579068447932\n",
      "Val Privacy Loss Dyn:\t\t-3.466746547990594\n",
      "Val Privacy Loss Stat:\t\t3.5847723375667226\n",
      "Val Utility Loss:\t\t-1.517982120356284\n",
      "Val Utility Loss Dyn:\t\t-4.069138084068771\n",
      "Val Utility Loss Stat:\t\t3.9173398796191887\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.486048176234081\n",
      "Utility Training Loss:\t\t4.048039220227025\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24544568607688197\n",
      "Utility Training Acc:\t\t0.07195296257796258\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.551007162260662\n",
      "Utility Training Coop Loss:\t3.909353927366451\n",
      "Privacy Training Coop Acc:\t0.1804119022930982\n",
      "Utility Training Coop Acc:\t0.2152091995841996\n",
      "Privacy Acc Adv:\t\t0.24804443867563458\n",
      "Privacy Acc Coop:\t\t0.16186330561950152\n",
      "Utility Acc Adv:\t\t0.07227780665280666\n",
      "Utility Acc Coop:\t\t0.23414760914760915\n",
      "Val Privacy Acc Adv:\t\t0.2646852043295695\n",
      "Val Privacy Acc Coop:\t\t0.1418948002960071\n",
      "Val Utility Acc Adv:\t\t0.049005681818181816\n",
      "Val Utility Acc Coop:\t\t0.20806789485937802\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 123/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.21532406201373142\n",
      "Validation Loss:\t\t-0.1802365702792448\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6516218012249148\n",
      "End Effector Loss:\t\t0.005367507573832872\n",
      "Smoothing Loss:\t\t\t0.010747445742415726\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008625909593149926\n",
      "Privacy Loss Dyn:\t\t-3.481779884399842\n",
      "Privacy Loss Stat:\t\t3.5680389773573054\n",
      "Utility Loss:\t\t\t-1.5648034188950632\n",
      "Utility Loss Dyn:\t\t-4.04827450318049\n",
      "Utility Loss Stat:\t\t3.891794152418442\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6351339450675594\n",
      "Val End Effector Loss:\t\t0.005161729481067385\n",
      "Val Smoothing Loss:\t\t0.009702382286941279\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.004771247506141663\n",
      "Val Privacy Loss Dyn:\t\t-3.4933830140050777\n",
      "Val Privacy Loss Stat:\t\t3.5410954912831962\n",
      "Val Utility Loss:\t\t-1.489544584731425\n",
      "Val Utility Loss Dyn:\t\t-4.064520778242222\n",
      "Val Utility Loss Stat:\t\t3.9155663296210865\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4858171330172407\n",
      "Utility Training Loss:\t\t4.049708518069896\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2464397089428069\n",
      "Utility Training Acc:\t\t0.06863955301455302\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.549982276131358\n",
      "Utility Training Coop Loss:\t3.910490271455285\n",
      "Privacy Training Coop Acc:\t0.1822180353461333\n",
      "Utility Training Coop Acc:\t0.2160018191299171\n",
      "Privacy Acc Adv:\t\t0.24988305613615408\n",
      "Privacy Acc Coop:\t\t0.16113565488875284\n",
      "Utility Acc Adv:\t\t0.07019880457380458\n",
      "Utility Acc Coop:\t\t0.23377079002388798\n",
      "Val Privacy Acc Adv:\t\t0.23714416898971746\n",
      "Val Privacy Acc Coop:\t\t0.1897167699827143\n",
      "Val Utility Acc Adv:\t\t0.05165289256198347\n",
      "Val Utility Acc Coop:\t\t0.20814680899993693\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 124/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.2632571162884424\n",
      "Validation Loss:\t\t-0.18162077672641017\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6526831691143666\n",
      "End Effector Loss:\t\t0.005422668593012091\n",
      "Smoothing Loss:\t\t\t0.010770267164605727\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008617153503542878\n",
      "Privacy Loss Dyn:\t\t-3.4789358583160843\n",
      "Privacy Loss Stat:\t\t3.5651073859783815\n",
      "Utility Loss:\t\t\t-1.614974075444275\n",
      "Utility Loss Dyn:\t\t-4.051752484018243\n",
      "Utility Loss Stat:\t\t3.8902550772173243\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6227388587002912\n",
      "Val End Effector Loss:\t\t0.005074260642844414\n",
      "Val Smoothing Loss:\t\t0.009707903951283329\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0055643698154402175\n",
      "Val Privacy Loss Dyn:\t\t-3.53933890890484\n",
      "Val Privacy Loss Stat:\t\t3.5949826018869384\n",
      "Val Utility Loss:\t\t-1.4668608342320466\n",
      "Val Utility Loss Dyn:\t\t-4.048494118796892\n",
      "Val Utility Loss Stat:\t\t3.9018080416789727\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.482475961072529\n",
      "Utility Training Loss:\t\t4.053282918652477\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24876559251559252\n",
      "Utility Training Acc:\t\t0.06617073804573805\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.549992649817913\n",
      "Utility Training Coop Loss:\t3.9085574705238897\n",
      "Privacy Training Coop Acc:\t0.1809511434542414\n",
      "Utility Training Coop Acc:\t0.2169113825394805\n",
      "Privacy Acc Adv:\t\t0.25370322245322247\n",
      "Privacy Acc Coop:\t\t0.16476091476091476\n",
      "Utility Acc Adv:\t\t0.06571595634095634\n",
      "Utility Acc Coop:\t\t0.23425805613615408\n",
      "Val Privacy Acc Adv:\t\t0.18953741965276644\n",
      "Val Privacy Acc Coop:\t\t0.13247532139663115\n",
      "Val Utility Acc Adv:\t\t0.06937987833045238\n",
      "Val Utility Acc Coop:\t\t0.2241520317009658\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 125/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.28654904468778886\n",
      "Validation Loss:\t\t-0.3135828778940476\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6502732039117516\n",
      "End Effector Loss:\t\t0.0053673445633389905\n",
      "Smoothing Loss:\t\t\t0.01074479481064\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008159567561318125\n",
      "Privacy Loss Dyn:\t\t-3.485595661240655\n",
      "Privacy Loss Stat:\t\t3.567191331897109\n",
      "Utility Loss:\t\t\t-1.632856749695205\n",
      "Utility Loss Dyn:\t\t-4.053026123750731\n",
      "Utility Loss Stat:\t\t3.88974044278357\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6340362020144777\n",
      "Val End Effector Loss:\t\t0.005334876673507758\n",
      "Val Smoothing Loss:\t\t0.00977263515545748\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.013605510954521904\n",
      "Val Privacy Loss Dyn:\t\t-3.472371315167955\n",
      "Val Privacy Loss Stat:\t\t3.6084264250826243\n",
      "Val Utility Loss:\t\t-1.6299135744079085\n",
      "Val Utility Loss Dyn:\t\t-4.0585239854725925\n",
      "Val Utility Loss Stat:\t\t3.8955326395586503\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.487952061353751\n",
      "Utility Training Loss:\t\t4.054619354666395\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24416580041889838\n",
      "Utility Training Acc:\t\t0.06529365904365904\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.550038643537589\n",
      "Utility Training Coop Loss:\t3.908353312099798\n",
      "Privacy Training Coop Acc:\t0.18166580041889838\n",
      "Utility Training Coop Acc:\t0.21629417879727675\n",
      "Privacy Acc Adv:\t\t0.2446660602972562\n",
      "Privacy Acc Coop:\t\t0.16154495841995842\n",
      "Utility Acc Adv:\t\t0.06483887733887733\n",
      "Utility Acc Coop:\t\t0.23668788983767344\n",
      "Val Privacy Acc Adv:\t\t0.2571883608918052\n",
      "Val Privacy Acc Coop:\t\t0.11969123048754024\n",
      "Val Utility Acc Adv:\t\t0.057011880165289255\n",
      "Val Utility Acc Coop:\t\t0.22884383609841677\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 126/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.3077906549902412\n",
      "Validation Loss:\t\t0.0648954126075649\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6522590006215656\n",
      "End Effector Loss:\t\t0.005414753098751413\n",
      "Smoothing Loss:\t\t\t0.010755724148735745\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008250782401794703\n",
      "Privacy Loss Dyn:\t\t-3.4849362700496047\n",
      "Privacy Loss Stat:\t\t3.5674440954926108\n",
      "Utility Loss:\t\t\t-1.658241363176437\n",
      "Utility Loss Dyn:\t\t-4.055010615664064\n",
      "Utility Loss Stat:\t\t3.8891864767193547\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6126546784619654\n",
      "Val End Effector Loss:\t\t0.004992893172528072\n",
      "Val Smoothing Loss:\t\t0.009703974957262312\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0001355187952025863\n",
      "Val Privacy Loss Dyn:\t\t-3.534313237864124\n",
      "Val Privacy Loss Stat:\t\t3.5356684253235495\n",
      "Val Utility Loss:\t\t-1.1946542834447436\n",
      "Val Utility Loss Dyn:\t\t-4.0535174775714715\n",
      "Val Utility Loss Stat:\t\t3.934052046172875\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4873746113073305\n",
      "Utility Training Loss:\t\t4.05630698868242\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2434511434542414\n",
      "Utility Training Acc:\t\t0.06191528066528067\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.552517720666596\n",
      "Utility Training Coop Loss:\t3.9070775261044255\n",
      "Privacy Training Coop Acc:\t0.17945036385014745\n",
      "Utility Training Coop Acc:\t0.21933471933471935\n",
      "Privacy Acc Adv:\t\t0.24538071726191316\n",
      "Privacy Acc Coop:\t\t0.16229859669838032\n",
      "Utility Acc Adv:\t\t0.06266242203742203\n",
      "Utility Acc Coop:\t\t0.23677884615384615\n",
      "Val Privacy Acc Adv:\t\t0.193741391205098\n",
      "Val Privacy Acc Coop:\t\t0.19522641186625506\n",
      "Val Utility Acc Adv:\t\t0.06429350321481297\n",
      "Val Utility Acc Coop:\t\t0.189006542709987\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 127/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.3447061810127446\n",
      "Validation Loss:\t\t-0.15348431360253617\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6431452073079384\n",
      "End Effector Loss:\t\t0.005323428948644138\n",
      "Smoothing Loss:\t\t\t0.010752787039539701\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008248274545659642\n",
      "Privacy Loss Dyn:\t\t-3.48703038717258\n",
      "Privacy Loss Stat:\t\t3.56951313306289\n",
      "Utility Loss:\t\t\t-1.6768266594583427\n",
      "Utility Loss Dyn:\t\t-4.055123272408071\n",
      "Utility Loss Stat:\t\t3.8874406125590113\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6016737761453164\n",
      "Val End Effector Loss:\t\t0.0048683773166276825\n",
      "Val Smoothing Loss:\t\t0.009701688125467867\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.004819651526853073\n",
      "Val Privacy Loss Dyn:\t\t-3.5050986217073175\n",
      "Val Privacy Loss Stat:\t\t3.5532951286016417\n",
      "Val Utility Loss:\t\t-1.3956249568087995\n",
      "Val Utility Loss Dyn:\t\t-4.047759720116607\n",
      "Val Utility Loss Stat:\t\t3.908197213302959\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.487989207563182\n",
      "Utility Training Loss:\t\t4.056276228720334\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24470504158004158\n",
      "Utility Training Acc:\t\t0.06201273388773389\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.551940829986842\n",
      "Utility Training Coop Loss:\t3.9044756557242537\n",
      "Privacy Training Coop Acc:\t0.17908653846153846\n",
      "Utility Training Coop Acc:\t0.2222258316008316\n",
      "Privacy Acc Adv:\t\t0.24441268191268192\n",
      "Privacy Acc Coop:\t\t0.15956340956340956\n",
      "Utility Acc Adv:\t\t0.06448154885654886\n",
      "Utility Acc Coop:\t\t0.23783134095943892\n",
      "Val Privacy Acc Adv:\t\t0.22349919651227057\n",
      "Val Privacy Acc Coop:\t\t0.17542613636363635\n",
      "Val Utility Acc Adv:\t\t0.07134555785123967\n",
      "Val Utility Acc Coop:\t\t0.21613865932218793\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 128/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.3509234012164594\n",
      "Validation Loss:\t\t-0.2025511463226612\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6408512126383316\n",
      "End Effector Loss:\t\t0.005329011997794674\n",
      "Smoothing Loss:\t\t\t0.010764189330249127\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.00838942066795365\n",
      "Privacy Loss Dyn:\t\t-3.4857581385455854\n",
      "Privacy Loss Stat:\t\t3.5696523385335404\n",
      "Utility Loss:\t\t\t-1.6786368284800444\n",
      "Utility Loss Dyn:\t\t-4.054665837615047\n",
      "Utility Loss Stat:\t\t3.886802166514486\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.620498518128533\n",
      "Val End Effector Loss:\t\t0.004855423194475564\n",
      "Val Smoothing Loss:\t\t0.00968574742547983\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.007256075185685118\n",
      "Val Privacy Loss Dyn:\t\t-3.49913138397469\n",
      "Val Privacy Loss Stat:\t\t3.571692131767588\n",
      "Val Utility Loss:\t\t-1.4847169198280523\n",
      "Val Utility Loss Dyn:\t\t-4.057123606855219\n",
      "Val Utility Loss Stat:\t\t3.908651916941335\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4891192085281975\n",
      "Utility Training Loss:\t\t4.056338462908897\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2438734407515387\n",
      "Utility Training Acc:\t\t0.06201273388773389\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5513826365778205\n",
      "Utility Training Coop Loss:\t3.90553481068284\n",
      "Privacy Training Coop Acc:\t0.18077572765072766\n",
      "Utility Training Coop Acc:\t0.22023778586898177\n",
      "Privacy Acc Adv:\t\t0.24580301455921047\n",
      "Privacy Acc Coop:\t\t0.15996621621931417\n",
      "Utility Acc Adv:\t\t0.06387733888043683\n",
      "Utility Acc Coop:\t\t0.23800675676295266\n",
      "Val Privacy Acc Adv:\t\t0.2307449494958047\n",
      "Val Privacy Acc Coop:\t\t0.15647956841309701\n",
      "Val Utility Acc Adv:\t\t0.052657254363510236\n",
      "Val Utility Acc Coop:\t\t0.21525625576657698\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 129/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.4080967029940004\n",
      "Validation Loss:\t\t-0.41489851250013043\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6397786179785917\n",
      "End Effector Loss:\t\t0.005289525797555762\n",
      "Smoothing Loss:\t\t\t0.010747206362502615\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008939001422662001\n",
      "Privacy Loss Dyn:\t\t-3.4829057103135233\n",
      "Privacy Loss Stat:\t\t3.5722957197692935\n",
      "Utility Loss:\t\t\t-1.7341240865029317\n",
      "Utility Loss Dyn:\t\t-4.057847313722305\n",
      "Utility Loss Stat:\t\t3.8844349029901863\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6158337476086025\n",
      "Val End Effector Loss:\t\t0.004867360553384782\n",
      "Val Smoothing Loss:\t\t0.00966964654666795\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.014460215637506532\n",
      "Val Privacy Loss Dyn:\t\t-3.473255726916731\n",
      "Val Privacy Loss Stat:\t\t3.617857881813995\n",
      "Val Utility Loss:\t\t-1.6949025225048222\n",
      "Val Utility Loss Dyn:\t\t-4.052285397840926\n",
      "Val Utility Loss Stat:\t\t3.8827951555409705\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.485666507742757\n",
      "Utility Training Loss:\t\t4.0582115424645915\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24774558213297393\n",
      "Utility Training Acc:\t\t0.061005717255717254\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5508302286608058\n",
      "Utility Training Coop Loss:\t3.902798765662306\n",
      "Privacy Training Coop Acc:\t0.1820945946069864\n",
      "Utility Training Coop Acc:\t0.22203092515592515\n",
      "Privacy Acc Adv:\t\t0.24820036383775565\n",
      "Privacy Acc Coop:\t\t0.15675025987835783\n",
      "Utility Acc Adv:\t\t0.0586018711018711\n",
      "Utility Acc Coop:\t\t0.24106678794178793\n",
      "Val Privacy Acc Adv:\t\t0.2568798783304524\n",
      "Val Privacy Acc Coop:\t\t0.11265352387597\n",
      "Val Utility Acc Adv:\t\t0.06818181818181818\n",
      "Val Utility Acc Coop:\t\t0.24227358816453248\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 130/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.42794532947079617\n",
      "Validation Loss:\t\t-0.28197959538795486\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.641834876114762\n",
      "End Effector Loss:\t\t0.005384354643270048\n",
      "Smoothing Loss:\t\t\t0.010765630243106004\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.00897324766785588\n",
      "Privacy Loss Dyn:\t\t-3.4833004373026983\n",
      "Privacy Loss Stat:\t\t3.5730329129899117\n",
      "Utility Loss:\t\t\t-1.7582695736954466\n",
      "Utility Loss Dyn:\t\t-4.059375081637297\n",
      "Utility Loss Stat:\t\t3.883548131108036\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6046444502743807\n",
      "Val End Effector Loss:\t\t0.005143261283216613\n",
      "Val Smoothing Loss:\t\t0.009736575315175347\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.007476612063478832\n",
      "Val Privacy Loss Dyn:\t\t-3.4691703856483964\n",
      "Val Privacy Loss Stat:\t\t3.5439365141647907\n",
      "Val Utility Loss:\t\t-1.5330980947195005\n",
      "Val Utility Loss Dyn:\t\t-4.065972416361501\n",
      "Val Utility Loss Stat:\t\t3.9126626031457885\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.487342762104439\n",
      "Utility Training Loss:\t\t4.060422533762926\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24520530145839942\n",
      "Utility Training Acc:\t\t0.05869932432432432\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5555299575016552\n",
      "Utility Training Coop Loss:\t3.902715847298906\n",
      "Privacy Training Coop Acc:\t0.1756691788003747\n",
      "Utility Training Coop Acc:\t0.22193347193347193\n",
      "Privacy Acc Adv:\t\t0.24905145530765121\n",
      "Privacy Acc Coop:\t\t0.15682822245941835\n",
      "Utility Acc Adv:\t\t0.05824454261954262\n",
      "Utility Acc Coop:\t\t0.24168399168399168\n",
      "Val Privacy Acc Adv:\t\t0.2622101698840453\n",
      "Val Privacy Acc Coop:\t\t0.18700499312321017\n",
      "Val Utility Acc Adv:\t\t0.046035640495867766\n",
      "Val Utility Acc Coop:\t\t0.20973226585048288\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 131/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.4422157644458781\n",
      "Validation Loss:\t\t0.28903962063703165\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6375222093040384\n",
      "End Effector Loss:\t\t0.0052907830750445785\n",
      "Smoothing Loss:\t\t\t0.01074679928498726\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.009076697167140779\n",
      "Privacy Loss Dyn:\t\t-3.483607126124931\n",
      "Privacy Loss Stat:\t\t3.574374101761721\n",
      "Utility Loss:\t\t\t-1.763868062263219\n",
      "Utility Loss Dyn:\t\t-4.059506940990377\n",
      "Utility Loss Stat:\t\t3.8831201296090585\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.598752271045338\n",
      "Val End Effector Loss:\t\t0.004789144034528227\n",
      "Val Smoothing Loss:\t\t0.009673071906840322\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.005722529755150976\n",
      "Val Privacy Loss Dyn:\t\t-3.5248205947481894\n",
      "Val Privacy Loss Stat:\t\t3.5820458955016017\n",
      "Val Utility Loss:\t\t-0.9479958163805244\n",
      "Val Utility Loss Dyn:\t\t-4.063880755881633\n",
      "Val Utility Loss Stat:\t\t3.9690811757213815\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4860831129823553\n",
      "Utility Training Loss:\t\t4.060124189095289\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24751169438979234\n",
      "Utility Training Acc:\t\t0.05869932432432432\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5554829404656454\n",
      "Utility Training Coop Loss:\t3.900522973829892\n",
      "Privacy Training Coop Acc:\t0.17453872141372143\n",
      "Utility Training Coop Acc:\t0.2247596153846154\n",
      "Privacy Acc Adv:\t\t0.24754417879727675\n",
      "Privacy Acc Coop:\t\t0.15504807692307693\n",
      "Utility Acc Adv:\t\t0.05853690228690229\n",
      "Utility Acc Coop:\t\t0.24228170478480274\n",
      "Val Privacy Acc Adv:\t\t0.20442349633032625\n",
      "Val Privacy Acc Coop:\t\t0.14530963039656808\n",
      "Val Utility Acc Adv:\t\t0.049522210743801656\n",
      "Val Utility Acc Coop:\t\t0.15181646006535893\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 132/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.46357451352579304\n",
      "Validation Loss:\t\t-0.30251529303664143\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6312797980348187\n",
      "End Effector Loss:\t\t0.0052248178526232494\n",
      "Smoothing Loss:\t\t\t0.01071942262370875\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008515252764656242\n",
      "Privacy Loss Dyn:\t\t-3.484751034179497\n",
      "Privacy Loss Stat:\t\t3.569903554638805\n",
      "Utility Loss:\t\t\t-1.772032450241755\n",
      "Utility Loss Dyn:\t\t-4.059114988033588\n",
      "Utility Loss Stat:\t\t3.8819117481644088\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6004049816776899\n",
      "Val End Effector Loss:\t\t0.0047487178134293226\n",
      "Val Smoothing Loss:\t\t0.009652604236390657\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.012840834530917082\n",
      "Val Privacy Loss Dyn:\t\t-3.4698538474800174\n",
      "Val Privacy Loss Stat:\t\t3.5982621908187866\n",
      "Val Utility Loss:\t\t-1.5498726190614307\n",
      "Val Utility Loss Dyn:\t\t-4.066836900454907\n",
      "Val Utility Loss Stat:\t\t3.911849644558489\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.488036719280568\n",
      "Utility Training Loss:\t\t4.060869081104619\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24438019750519752\n",
      "Utility Training Acc:\t\t0.05837448024948025\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.548333418592346\n",
      "Utility Training Coop Loss:\t3.89945298420912\n",
      "Privacy Training Coop Acc:\t0.18301715176715178\n",
      "Utility Training Coop Acc:\t0.22376559251869046\n",
      "Privacy Acc Adv:\t\t0.24681652806652807\n",
      "Privacy Acc Coop:\t\t0.15943347193347193\n",
      "Utility Acc Adv:\t\t0.05853690228690229\n",
      "Utility Acc Coop:\t\t0.24317177755297345\n",
      "Val Privacy Acc Adv:\t\t0.26155016072525467\n",
      "Val Privacy Acc Coop:\t\t0.12937614784291215\n",
      "Val Utility Acc Adv:\t\t0.052219639578449335\n",
      "Val Utility Acc Coop:\t\t0.21077967171888212\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 133/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.480925313185459\n",
      "Validation Loss:\t\t-0.6717254016740817\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6289127684370643\n",
      "End Effector Loss:\t\t0.005213930903258201\n",
      "Smoothing Loss:\t\t\t0.010717965162934237\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008740438307149495\n",
      "Privacy Loss Dyn:\t\t-3.484131626676373\n",
      "Privacy Loss Stat:\t\t3.5715360106152954\n",
      "Utility Loss:\t\t\t-1.7848591160129856\n",
      "Utility Loss Dyn:\t\t-4.059987955430441\n",
      "Utility Loss Stat:\t\t3.8815020469023134\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5973567827797133\n",
      "Val End Effector Loss:\t\t0.0047596451756159565\n",
      "Val Smoothing Loss:\t\t0.00964387360294465\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0005761919435390756\n",
      "Val Privacy Loss Dyn:\t\t-3.5416069641586176\n",
      "Val Privacy Loss Stat:\t\t3.547368889505213\n",
      "Val Utility Loss:\t\t-1.900706425186031\n",
      "Val Utility Loss Dyn:\t\t-4.064002433099037\n",
      "Val Utility Loss Stat:\t\t3.873931789201153\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4862098136215844\n",
      "Utility Training Loss:\t\t4.0605353052551685\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2464202183014142\n",
      "Utility Training Acc:\t\t0.05682822245632041\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5513331508438206\n",
      "Utility Training Coop Loss:\t3.8993606017186093\n",
      "Privacy Training Coop Acc:\t0.1795543139324119\n",
      "Utility Training Coop Acc:\t0.22506496881806676\n",
      "Privacy Acc Adv:\t\t0.2473167879448859\n",
      "Privacy Acc Coop:\t\t0.15808212058521853\n",
      "Utility Acc Adv:\t\t0.05666580041889837\n",
      "Utility Acc Coop:\t\t0.24332120582430378\n",
      "Val Privacy Acc Adv:\t\t0.18752152204883\n",
      "Val Privacy Acc Coop:\t\t0.18287276171825148\n",
      "Val Utility Acc Adv:\t\t0.05268595041322314\n",
      "Val Utility Acc Coop:\t\t0.25013630624768163\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 134/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.48442890781622666\n",
      "Validation Loss:\t\t-0.41252163388527746\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6270116937197667\n",
      "End Effector Loss:\t\t0.005207336351871801\n",
      "Smoothing Loss:\t\t\t0.010723676322910958\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008265745057385577\n",
      "Privacy Loss Dyn:\t\t-3.4859943270931124\n",
      "Privacy Loss Stat:\t\t3.5686517728341594\n",
      "Utility Loss:\t\t\t-1.7840964025866217\n",
      "Utility Loss Dyn:\t\t-4.060053279394915\n",
      "Utility Loss Stat:\t\t3.881643636806591\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5843413179694128\n",
      "Val End Effector Loss:\t\t0.004736393772369667\n",
      "Val Smoothing Loss:\t\t0.00964634888613027\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.007167783157884582\n",
      "Val Privacy Loss Dyn:\t\t-3.4778276598157962\n",
      "Val Privacy Loss Stat:\t\t3.549505486468638\n",
      "Val Utility Loss:\t\t-1.6220474952508595\n",
      "Val Utility Loss Dyn:\t\t-4.057946027310426\n",
      "Val Utility Loss Stat:\t\t3.895741274041578\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4862216525167042\n",
      "Utility Training Loss:\t\t4.061419886759562\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2472518191299171\n",
      "Utility Training Acc:\t\t0.05668529106029106\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.549840493658228\n",
      "Utility Training Coop Loss:\t3.8990828725751374\n",
      "Privacy Training Coop Acc:\t0.18166580041889838\n",
      "Utility Training Coop Acc:\t0.22672167359977155\n",
      "Privacy Acc Adv:\t\t0.24653716216526012\n",
      "Privacy Acc Coop:\t\t0.16126559251869046\n",
      "Utility Acc Adv:\t\t0.058212058212058215\n",
      "Utility Acc Coop:\t\t0.24320426196045786\n",
      "Val Privacy Acc Adv:\t\t0.2534004821141889\n",
      "Val Privacy Acc Coop:\t\t0.18080664601577215\n",
      "Val Utility Acc Adv:\t\t0.06018279385098741\n",
      "Val Utility Acc Coop:\t\t0.22738033748608977\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 135/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.5296502021700918\n",
      "Validation Loss:\t\t-0.4838670093358364\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6230947688500748\n",
      "End Effector Loss:\t\t0.005149556277174572\n",
      "Smoothing Loss:\t\t\t0.010688435430047945\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008615691826645898\n",
      "Privacy Loss Dyn:\t\t-3.483442893395057\n",
      "Privacy Loss Stat:\t\t3.5695998076341753\n",
      "Utility Loss:\t\t\t-1.821670294303656\n",
      "Utility Loss Dyn:\t\t-4.060137455775683\n",
      "Utility Loss Stat:\t\t3.8779704310542087\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5849951883116045\n",
      "Val End Effector Loss:\t\t0.004701116032348099\n",
      "Val Smoothing Loss:\t\t0.009650871783979853\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.009042395848380633\n",
      "Val Privacy Loss Dyn:\t\t-3.4735786003514755\n",
      "Val Privacy Loss Stat:\t\t3.5640025670863382\n",
      "Val Utility Loss:\t\t-1.6965535140234578\n",
      "Val Utility Loss Dyn:\t\t-4.061433341877519\n",
      "Val Utility Loss Stat:\t\t3.8917779883077324\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.486730762677976\n",
      "Utility Training Loss:\t\t4.062385309758652\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24462058212368007\n",
      "Utility Training Acc:\t\t0.05515852390852391\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.552385688323737\n",
      "Utility Training Coop Loss:\t3.898486042716647\n",
      "Privacy Training Coop Acc:\t0.17971673596983392\n",
      "Utility Training Coop Acc:\t0.22707900208210002\n",
      "Privacy Acc Adv:\t\t0.2486486486517466\n",
      "Privacy Acc Coop:\t\t0.1600961538492518\n",
      "Utility Acc Adv:\t\t0.05843944906444906\n",
      "Utility Acc Coop:\t\t0.2481613825394805\n",
      "Val Privacy Acc Adv:\t\t0.2570448806278469\n",
      "Val Privacy Acc Coop:\t\t0.165569042709987\n",
      "Val Utility Acc Adv:\t\t0.05430010330578512\n",
      "Val Utility Acc Coop:\t\t0.2326245408905439\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 136/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.5322962690245461\n",
      "Validation Loss:\t\t-0.4808313305420447\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6210562027603573\n",
      "End Effector Loss:\t\t0.005101736912817506\n",
      "Smoothing Loss:\t\t\t0.010690168399661934\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008831306796311836\n",
      "Privacy Loss Dyn:\t\t-3.4834307598225043\n",
      "Privacy Loss Stat:\t\t3.5717438288389274\n",
      "Utility Loss:\t\t\t-1.820412229351591\n",
      "Utility Loss Dyn:\t\t-4.060222276283153\n",
      "Utility Loss Stat:\t\t3.8781810530505902\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5961487766139764\n",
      "Val End Effector Loss:\t\t0.004767734660817049\n",
      "Val Smoothing Loss:\t\t0.009619926608529342\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.012209115626890798\n",
      "Val Privacy Loss Dyn:\t\t-3.4818262989855997\n",
      "Val Privacy Loss Stat:\t\t3.6039174647370644\n",
      "Val Utility Loss:\t\t-1.718965514632296\n",
      "Val Utility Loss Dyn:\t\t-4.072880614394984\n",
      "Val Utility Loss Stat:\t\t3.9009840621435936\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4850554676908465\n",
      "Utility Training Loss:\t\t4.060855722476935\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24845374220684016\n",
      "Utility Training Acc:\t\t0.057380457383555336\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.550174724535238\n",
      "Utility Training Coop Loss:\t3.895588604427425\n",
      "Privacy Training Coop Acc:\t0.18019100831600832\n",
      "Utility Training Coop Acc:\t0.2277546777794614\n",
      "Privacy Acc Adv:\t\t0.2486161642442622\n",
      "Privacy Acc Coop:\t\t0.15733497921307715\n",
      "Utility Acc Adv:\t\t0.05749740124740125\n",
      "Utility Acc Coop:\t\t0.24736226611846202\n",
      "Val Privacy Acc Adv:\t\t0.24944042700750768\n",
      "Val Privacy Acc Coop:\t\t0.12553805097444984\n",
      "Val Utility Acc Adv:\t\t0.04492366850406917\n",
      "Val Utility Acc Coop:\t\t0.2244892103120315\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 137/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.5519636614643145\n",
      "Validation Loss:\t\t-0.6487182243034428\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6196460078573028\n",
      "End Effector Loss:\t\t0.00511029470647083\n",
      "Smoothing Loss:\t\t\t0.010683126224828362\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.00841919854748026\n",
      "Privacy Loss Dyn:\t\t-3.483978627377389\n",
      "Privacy Loss Stat:\t\t3.5681706030006963\n",
      "Utility Loss:\t\t\t-1.8368345486646878\n",
      "Utility Loss Dyn:\t\t-4.062476246867507\n",
      "Utility Loss Stat:\t\t3.878792794727238\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.582367099021092\n",
      "Val End Effector Loss:\t\t0.004619605706481279\n",
      "Val Smoothing Loss:\t\t0.009627460458793115\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.011043571551476629\n",
      "Val Privacy Loss Dyn:\t\t-3.496201072350021\n",
      "Val Privacy Loss Stat:\t\t3.606636789712039\n",
      "Val Utility Loss:\t\t-1.8579979809847744\n",
      "Val Utility Loss Dyn:\t\t-4.056964326495967\n",
      "Val Utility Loss Stat:\t\t3.8711645391361773\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.486124067445307\n",
      "Utility Training Loss:\t\t4.0633800074365185\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24494542619852416\n",
      "Utility Training Acc:\t\t0.05626299376299376\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5508504176585935\n",
      "Utility Training Coop Loss:\t3.8965042090961193\n",
      "Privacy Training Coop Acc:\t0.18156834719644516\n",
      "Utility Training Coop Acc:\t0.2294828482359462\n",
      "Privacy Acc Adv:\t\t0.2481288981319961\n",
      "Privacy Acc Coop:\t\t0.1610252079002079\n",
      "Utility Acc Adv:\t\t0.05522349272349272\n",
      "Utility Acc Coop:\t\t0.2451078482359462\n",
      "Val Privacy Acc Adv:\t\t0.23420999771799922\n",
      "Val Privacy Acc Coop:\t\t0.12290518824780776\n",
      "Val Utility Acc Adv:\t\t0.06540547520661157\n",
      "Val Utility Acc Coop:\t\t0.2530704775040061\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 138/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.5403885867392447\n",
      "Validation Loss:\t\t-0.5360478133940685\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6163993629311325\n",
      "End Effector Loss:\t\t0.005068361786534921\n",
      "Smoothing Loss:\t\t\t0.01069636125332461\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008502923277460364\n",
      "Privacy Loss Dyn:\t\t-3.4842284647689787\n",
      "Privacy Loss Stat:\t\t3.569257691843346\n",
      "Utility Loss:\t\t\t-1.8188476800422906\n",
      "Utility Loss Dyn:\t\t-4.062561458956427\n",
      "Utility Loss Stat:\t\t3.880676696801136\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5864803323075791\n",
      "Val End Effector Loss:\t\t0.004693735580437255\n",
      "Val Smoothing Loss:\t\t0.009609524378060433\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.005277864142390322\n",
      "Val Privacy Loss Dyn:\t\t-3.557031950182166\n",
      "Val Privacy Loss Stat:\t\t3.6098105946848213\n",
      "Val Utility Loss:\t\t-1.7478086534610464\n",
      "Val Utility Loss Dyn:\t\t-4.067132612397848\n",
      "Val Utility Loss Stat:\t\t3.8923517470517432\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.487878476755535\n",
      "Utility Training Loss:\t\t4.062888949923605\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2442437629999589\n",
      "Utility Training Acc:\t\t0.05556133056442852\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.550094528654261\n",
      "Utility Training Coop Loss:\t3.8975105496305438\n",
      "Privacy Training Coop Acc:\t0.1809316528128487\n",
      "Utility Training Coop Acc:\t0.22705951144070735\n",
      "Privacy Acc Adv:\t\t0.24838227653206013\n",
      "Privacy Acc Coop:\t\t0.16025857588667383\n",
      "Utility Acc Adv:\t\t0.05565878378688174\n",
      "Utility Acc Coop:\t\t0.24440618503738093\n",
      "Val Privacy Acc Adv:\t\t0.17003845271061768\n",
      "Val Privacy Acc Coop:\t\t0.11767533287590692\n",
      "Val Utility Acc Adv:\t\t0.05338182966109396\n",
      "Val Utility Acc Coop:\t\t0.23063733930553287\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 139/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.5419847077695874\n",
      "Validation Loss:\t\t-0.7197290935807608\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6197042958404319\n",
      "End Effector Loss:\t\t0.005134818031599749\n",
      "Smoothing Loss:\t\t\t0.010696485555844997\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008633644039318615\n",
      "Privacy Loss Dyn:\t\t-3.4853507124212824\n",
      "Privacy Loss Stat:\t\t3.571687145441337\n",
      "Utility Loss:\t\t\t-1.8272512162301744\n",
      "Utility Loss Dyn:\t\t-4.063287003868087\n",
      "Utility Loss Stat:\t\t3.8805618878461714\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5796241260880282\n",
      "Val End Effector Loss:\t\t0.004612678194356974\n",
      "Val Smoothing Loss:\t\t0.009618105332190093\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.013616820258542526\n",
      "Val Privacy Loss Dyn:\t\t-3.4730454969012046\n",
      "Val Privacy Loss Stat:\t\t3.6092137108164386\n",
      "Val Utility Loss:\t\t-1.9260611573526683\n",
      "Val Utility Loss Dyn:\t\t-4.063220377303352\n",
      "Val Utility Loss Stat:\t\t3.870614262651806\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.487664698810934\n",
      "Utility Training Loss:\t\t4.064096141258049\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24629028067147657\n",
      "Utility Training Acc:\t\t0.05431392931392932\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5508258132082013\n",
      "Utility Training Coop Loss:\t3.8970409693688217\n",
      "Privacy Training Coop Acc:\t0.1778976091507071\n",
      "Utility Training Coop Acc:\t0.22754677755297345\n",
      "Privacy Acc Adv:\t\t0.24736226611846202\n",
      "Privacy Acc Coop:\t\t0.15751689189189189\n",
      "Utility Acc Adv:\t\t0.05496361746361746\n",
      "Utility Acc Coop:\t\t0.2442762474074433\n",
      "Val Privacy Acc Adv:\t\t0.2595055670408178\n",
      "Val Privacy Acc Coop:\t\t0.11853621444426292\n",
      "Val Utility Acc Adv:\t\t0.05303030304056554\n",
      "Val Utility Acc Coop:\t\t0.25383809689155296\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 140/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.5654756154907623\n",
      "Validation Loss:\t\t-0.2684953316568959\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6148679759547021\n",
      "End Effector Loss:\t\t0.005061185664861326\n",
      "Smoothing Loss:\t\t\t0.010694563659895483\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.007871868549662172\n",
      "Privacy Loss Dyn:\t\t-3.4872227686606423\n",
      "Privacy Loss Stat:\t\t3.565941456697587\n",
      "Utility Loss:\t\t\t-1.8402283127243455\n",
      "Utility Loss Dyn:\t\t-4.06321934355024\n",
      "Utility Loss Stat:\t\t3.879196514954438\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5738199746066873\n",
      "Val End Effector Loss:\t\t0.004660327645588266\n",
      "Val Smoothing Loss:\t\t0.00959946446828852\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0076716842114432785\n",
      "Val Privacy Loss Dyn:\t\t-3.4744695582665686\n",
      "Val Privacy Loss Stat:\t\t3.5511864019819526\n",
      "Val Utility Loss:\t\t-1.4572656883681117\n",
      "Val Utility Loss Dyn:\t\t-4.066925490690657\n",
      "Val Utility Loss Stat:\t\t3.921198912888519\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.489029670207763\n",
      "Utility Training Loss:\t\t4.06383672870866\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24403586278896075\n",
      "Utility Training Acc:\t\t0.0537941787941788\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5508619888904436\n",
      "Utility Training Coop Loss:\t3.8947973246386045\n",
      "Privacy Training Coop Acc:\t0.18094464659443021\n",
      "Utility Training Coop Acc:\t0.22920348233467824\n",
      "Privacy Acc Adv:\t\t0.2455561330809167\n",
      "Privacy Acc Coop:\t\t0.1640202702950539\n",
      "Utility Acc Adv:\t\t0.05522349272349272\n",
      "Utility Acc Coop:\t\t0.24608238046047842\n",
      "Val Privacy Acc Adv:\t\t0.2594051308745195\n",
      "Val Privacy Acc Coop:\t\t0.1777218204792127\n",
      "Val Utility Acc Adv:\t\t0.05446510560317966\n",
      "Val Utility Acc Coop:\t\t0.20146780304056555\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 141/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.5983114143264269\n",
      "Validation Loss:\t\t-0.7660568635487421\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6184966864680054\n",
      "End Effector Loss:\t\t0.005178693805147435\n",
      "Smoothing Loss:\t\t\t0.010705799179484684\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008092253408907853\n",
      "Privacy Loss Dyn:\t\t-3.4885054100575914\n",
      "Privacy Loss Stat:\t\t3.569427940800879\n",
      "Utility Loss:\t\t\t-1.8806931342999305\n",
      "Utility Loss Dyn:\t\t-4.066712551454001\n",
      "Utility Loss Stat:\t\t3.8786432336620877\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.586673172544842\n",
      "Val End Effector Loss:\t\t0.004989772900354025\n",
      "Val Smoothing Loss:\t\t0.009659616413241453\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0057549065917976636\n",
      "Val Privacy Loss Dyn:\t\t-3.4696772556659603\n",
      "Val Privacy Loss Stat:\t\t3.5272263219533873\n",
      "Val Utility Loss:\t\t-1.9791267410782742\n",
      "Val Utility Loss Dyn:\t\t-4.072311401859788\n",
      "Val Utility Loss Stat:\t\t3.8743987250919183\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.490143256970602\n",
      "Utility Training Loss:\t\t4.06633745260893\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24302884615694412\n",
      "Utility Training Acc:\t\t0.05223492723492724\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.549444962935735\n",
      "Utility Training Coop Loss:\t3.895686543904818\n",
      "Privacy Training Coop Acc:\t0.1814254158004158\n",
      "Utility Training Coop Acc:\t0.2294828482359462\n",
      "Privacy Acc Adv:\t\t0.24325623700933496\n",
      "Privacy Acc Coop:\t\t0.16022609147918943\n",
      "Utility Acc Adv:\t\t0.05109797297297297\n",
      "Utility Acc Coop:\t\t0.24582250520060314\n",
      "Val Privacy Acc Adv:\t\t0.26196625345378866\n",
      "Val Privacy Acc Coop:\t\t0.20495437328849941\n",
      "Val Utility Acc Adv:\t\t0.04409865702479339\n",
      "Val Utility Acc Coop:\t\t0.2498565197437386\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 142/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.6213941099722395\n",
      "Validation Loss:\t\t-0.5047184119408965\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6147056847129195\n",
      "End Effector Loss:\t\t0.005166886337082097\n",
      "Smoothing Loss:\t\t\t0.01078450068126659\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008157616903281262\n",
      "Privacy Loss Dyn:\t\t-3.487917144928058\n",
      "Privacy Loss Stat:\t\t3.5694933113585887\n",
      "Utility Loss:\t\t\t-1.8964834867544829\n",
      "Utility Loss Dyn:\t\t-4.065604731347605\n",
      "Utility Loss Stat:\t\t3.8759563821764846\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.599053060466593\n",
      "Val End Effector Loss:\t\t0.0053543409198899715\n",
      "Val Smoothing Loss:\t\t0.009695438141857604\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.010893338721645765\n",
      "Val Privacy Loss Dyn:\t\t-3.4693491567264902\n",
      "Val Privacy Loss Stat:\t\t3.578282539509545\n",
      "Val Utility Loss:\t\t-1.7481585258294727\n",
      "Val Utility Loss Dyn:\t\t-4.08263514554205\n",
      "Val Utility Loss Stat:\t\t3.907819286358258\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4893579497902407\n",
      "Utility Training Loss:\t\t4.066445212354283\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24418529106029105\n",
      "Utility Training Acc:\t\t0.05268970893970894\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5512410858316876\n",
      "Utility Training Coop Loss:\t3.893994688987732\n",
      "Privacy Training Coop Acc:\t0.1805808212058212\n",
      "Utility Training Coop Acc:\t0.2307822245353225\n",
      "Privacy Acc Adv:\t\t0.24382796257796258\n",
      "Privacy Acc Coop:\t\t0.15962837837837837\n",
      "Utility Acc Adv:\t\t0.05137084199893995\n",
      "Utility Acc Coop:\t\t0.24946725572964754\n",
      "Val Privacy Acc Adv:\t\t0.2612129821141889\n",
      "Val Privacy Acc Coop:\t\t0.1503314394042019\n",
      "Val Utility Acc Adv:\t\t0.03777117768595041\n",
      "Val Utility Acc Coop:\t\t0.21509125345378868\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 143/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.6311159171125311\n",
      "Validation Loss:\t\t-0.20156384248686723\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6149216729241449\n",
      "End Effector Loss:\t\t0.005146210193208064\n",
      "Smoothing Loss:\t\t\t0.010716518897876887\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008438644996551862\n",
      "Privacy Loss Dyn:\t\t-3.4837442423350597\n",
      "Privacy Loss Stat:\t\t3.5681306889547875\n",
      "Utility Loss:\t\t\t-1.9066936707050537\n",
      "Utility Loss Dyn:\t\t-4.065967548166144\n",
      "Utility Loss Stat:\t\t3.875298180599966\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6018955027145788\n",
      "Val End Effector Loss:\t\t0.004720309203248163\n",
      "Val Smoothing Loss:\t\t0.009643255082567123\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.008500002570881331\n",
      "Val Privacy Loss Dyn:\t\t-3.4707870158282192\n",
      "Val Privacy Loss Stat:\t\t3.5557870465861865\n",
      "Val Utility Loss:\t\t-1.4475049263189648\n",
      "Val Utility Loss Dyn:\t\t-4.066048184702219\n",
      "Val Utility Loss Stat:\t\t3.9212976797553134\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.488144608892175\n",
      "Utility Training Loss:\t\t4.066865267723861\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24603690228690228\n",
      "Utility Training Acc:\t\t0.05005847193347193\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5468099635257047\n",
      "Utility Training Coop Loss:\t3.892519781842301\n",
      "Privacy Training Coop Acc:\t0.18431652806652807\n",
      "Utility Training Coop Acc:\t0.23013253638563433\n",
      "Privacy Acc Adv:\t\t0.2486486486517466\n",
      "Privacy Acc Coop:\t\t0.16172037422347219\n",
      "Utility Acc Adv:\t\t0.052117983371081325\n",
      "Utility Acc Coop:\t\t0.2499155405436385\n",
      "Val Privacy Acc Adv:\t\t0.260825585419974\n",
      "Val Privacy Acc Coop:\t\t0.17300849403293173\n",
      "Val Utility Acc Adv:\t\t0.05165289256198347\n",
      "Val Utility Acc Coop:\t\t0.2012238865949152\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 144/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.6226142877306239\n",
      "Validation Loss:\t\t-0.4983554850524861\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6100361003635331\n",
      "End Effector Loss:\t\t0.005063538328481145\n",
      "Smoothing Loss:\t\t\t0.010672203469885951\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.00869867673410943\n",
      "Privacy Loss Dyn:\t\t-3.487581605475063\n",
      "Privacy Loss Stat:\t\t3.57456837126718\n",
      "Utility Loss:\t\t\t-1.8884653142980627\n",
      "Utility Loss Dyn:\t\t-4.065116511065351\n",
      "Utility Loss Stat:\t\t3.876269974728384\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.580716459526996\n",
      "Val End Effector Loss:\t\t0.004667527140464541\n",
      "Val Smoothing Loss:\t\t0.009629930868891091\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.009524937442018966\n",
      "Val Privacy Loss Dyn:\t\t-3.4866991683471302\n",
      "Val Privacy Loss Stat:\t\t3.5819485399348676\n",
      "Val Utility Loss:\t\t-1.7028706605769386\n",
      "Val Utility Loss Dyn:\t\t-4.077884294769981\n",
      "Val Utility Loss Stat:\t\t3.9075972132446353\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4900350937476525\n",
      "Utility Training Loss:\t\t4.0649697998705125\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24282094594594594\n",
      "Utility Training Acc:\t\t0.05473622661122661\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5486966364101162\n",
      "Utility Training Coop Loss:\t3.890888937793502\n",
      "Privacy Training Coop Acc:\t0.18168529106029105\n",
      "Utility Training Coop Acc:\t0.23161382536382535\n",
      "Privacy Acc Adv:\t\t0.24334069646569648\n",
      "Privacy Acc Coop:\t\t0.1546257796257796\n",
      "Utility Acc Adv:\t\t0.05320945945945946\n",
      "Utility Acc Coop:\t\t0.24710888773388773\n",
      "Val Privacy Acc Adv:\t\t0.24324925391634633\n",
      "Val Privacy Acc Coop:\t\t0.14563246097508048\n",
      "Val Utility Acc Adv:\t\t0.04163079660324272\n",
      "Val Utility Acc Coop:\t\t0.21559343434685518\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 145/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.6561826693141938\n",
      "Validation Loss:\t\t-0.5426484172786624\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6106181623658122\n",
      "End Effector Loss:\t\t0.005078961374238133\n",
      "Smoothing Loss:\t\t\t0.010722982718971347\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.008257223637832673\n",
      "Privacy Loss Dyn:\t\t-3.484744560693753\n",
      "Privacy Loss Stat:\t\t3.567316794841552\n",
      "Utility Loss:\t\t\t-1.922924125021064\n",
      "Utility Loss Dyn:\t\t-4.066165991979428\n",
      "Utility Loss Stat:\t\t3.8738735802703985\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5890823564499863\n",
      "Val End Effector Loss:\t\t0.0047216683708916395\n",
      "Val Smoothing Loss:\t\t0.009599043734656447\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0073547427935048565\n",
      "Val Privacy Loss Dyn:\t\t-3.476590906292939\n",
      "Val Privacy Loss Stat:\t\t3.550138331149235\n",
      "Val Utility Loss:\t\t-1.7616866718639026\n",
      "Val Utility Loss Dyn:\t\t-4.069682219304329\n",
      "Val Utility Loss Stat:\t\t3.8935135450244935\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4858827035788935\n",
      "Utility Training Loss:\t\t4.065583828581098\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24715436590746387\n",
      "Utility Training Acc:\t\t0.05275467775467776\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5491516857781678\n",
      "Utility Training Coop Loss:\t3.8932745290645197\n",
      "Privacy Training Coop Acc:\t0.18065878378688174\n",
      "Utility Training Coop Acc:\t0.2322310291060291\n",
      "Privacy Acc Adv:\t\t0.24793399168708963\n",
      "Privacy Acc Coop:\t\t0.16217515592825388\n",
      "Utility Acc Adv:\t\t0.0516502079002079\n",
      "Utility Acc Coop:\t\t0.2512474012504992\n",
      "Val Privacy Acc Adv:\t\t0.2558683425434365\n",
      "Val Privacy Acc Coop:\t\t0.1798883723633841\n",
      "Val Utility Acc Adv:\t\t0.048618285123966945\n",
      "Val Utility Acc Coop:\t\t0.23113952022938689\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 146/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.6599406065620683\n",
      "Validation Loss:\t\t-0.8020286911575139\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.61249002876252\n",
      "End Effector Loss:\t\t0.005106529857229496\n",
      "Smoothing Loss:\t\t\t0.010681088595107012\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.007854677101678512\n",
      "Privacy Loss Dyn:\t\t-3.487077723917495\n",
      "Privacy Loss Stat:\t\t3.5656244910928168\n",
      "Utility Loss:\t\t\t-1.9299251373988924\n",
      "Utility Loss Dyn:\t\t-4.0658082840596315\n",
      "Utility Loss Stat:\t\t3.8728157656108517\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5880739504763902\n",
      "Val End Effector Loss:\t\t0.0047310897522444325\n",
      "Val Smoothing Loss:\t\t0.00964292363563845\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.008439631932530521\n",
      "Val Privacy Loss Dyn:\t\t-3.490764986877599\n",
      "Val Privacy Loss Stat:\t\t3.575161308789056\n",
      "Val Utility Loss:\t\t-2.020276085404325\n",
      "Val Utility Loss Dyn:\t\t-4.068733367052945\n",
      "Val Utility Loss Stat:\t\t3.866705750630907\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4891697351749125\n",
      "Utility Training Loss:\t\t4.065846625335995\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24447765072765074\n",
      "Utility Training Acc:\t\t0.052995062373160325\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.545127152157425\n",
      "Utility Training Coop Loss:\t3.8908952199495754\n",
      "Privacy Training Coop Acc:\t0.1869802494802495\n",
      "Utility Training Coop Acc:\t0.23451793139602936\n",
      "Privacy Acc Adv:\t\t0.24548466735966737\n",
      "Privacy Acc Coop:\t\t0.1645010395010395\n",
      "Utility Acc Adv:\t\t0.05228040540850336\n",
      "Utility Acc Coop:\t\t0.2522219334750314\n",
      "Val Privacy Acc Adv:\t\t0.24009268824780775\n",
      "Val Privacy Acc Coop:\t\t0.15376779155359288\n",
      "Val Utility Acc Adv:\t\t0.05008895776026751\n",
      "Val Utility Acc Coop:\t\t0.2588886019488997\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 147/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.7127516647944083\n",
      "Validation Loss:\t\t-0.6297851770015602\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6088505511534189\n",
      "End Effector Loss:\t\t0.005053917372264278\n",
      "Smoothing Loss:\t\t\t0.010687926984556685\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.007592743374949433\n",
      "Privacy Loss Dyn:\t\t-3.4870637692433633\n",
      "Privacy Loss Stat:\t\t3.5629912096844394\n",
      "Utility Loss:\t\t\t-1.9751632119414713\n",
      "Utility Loss Dyn:\t\t-4.067810901980886\n",
      "Utility Loss Stat:\t\t3.870294584801688\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5659336704483702\n",
      "Val End Effector Loss:\t\t0.004587656940999325\n",
      "Val Smoothing Loss:\t\t0.009573706027412834\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.010842681054241401\n",
      "Val Privacy Loss Dyn:\t\t-3.4993588412103573\n",
      "Val Privacy Loss Stat:\t\t3.607785644610066\n",
      "Val Utility Loss:\t\t-1.8058039767683045\n",
      "Val Utility Loss Dyn:\t\t-4.075259833296468\n",
      "Val Utility Loss Stat:\t\t3.894679450299129\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4860806869122194\n",
      "Utility Training Loss:\t\t4.067900308948049\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24801195426815018\n",
      "Utility Training Acc:\t\t0.05087058212058212\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.543244109580026\n",
      "Utility Training Coop Loss:\t3.8874835093155227\n",
      "Privacy Training Coop Acc:\t0.18850051975671567\n",
      "Utility Training Coop Acc:\t0.23622661122661123\n",
      "Privacy Acc Adv:\t\t0.24469854470474062\n",
      "Privacy Acc Coop:\t\t0.16656055093864888\n",
      "Utility Acc Adv:\t\t0.04953872141372141\n",
      "Utility Acc Coop:\t\t0.25519750519750517\n",
      "Val Privacy Acc Adv:\t\t0.23154843894164423\n",
      "Val Privacy Acc Coop:\t\t0.1207960284938497\n",
      "Val Utility Acc Adv:\t\t0.041774276859504134\n",
      "Val Utility Acc Coop:\t\t0.2282340450227753\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 148/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.7216444806313905\n",
      "Validation Loss:\t\t-0.03720137665109817\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.609379737732812\n",
      "End Effector Loss:\t\t0.005067630011681274\n",
      "Smoothing Loss:\t\t\t0.010662703762768058\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0076194617146018145\n",
      "Privacy Loss Dyn:\t\t-3.486154546113123\n",
      "Privacy Loss Stat:\t\t3.5623491618340823\n",
      "Utility Loss:\t\t\t-1.9850791605991038\n",
      "Utility Loss Dyn:\t\t-4.067962554289249\n",
      "Utility Loss Stat:\t\t3.869454631438622\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5766553454532111\n",
      "Val End Effector Loss:\t\t0.004568345186181274\n",
      "Val Smoothing Loss:\t\t0.009594003757469603\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.010258099880100282\n",
      "Val Privacy Loss Dyn:\t\t-3.4729542860314866\n",
      "Val Privacy Loss Stat:\t\t3.5755352904973936\n",
      "Val Utility Loss:\t\t-1.234120526589638\n",
      "Val Utility Loss Dyn:\t\t-4.070640878243879\n",
      "Val Utility Loss Stat:\t\t3.9472288435155694\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4878725385963296\n",
      "Utility Training Loss:\t\t4.067656437225501\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24535472972972974\n",
      "Utility Training Acc:\t\t0.05103300415800416\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5435030430617305\n",
      "Utility Training Coop Loss:\t3.888914612871198\n",
      "Privacy Training Coop Acc:\t0.18824714137214138\n",
      "Utility Training Coop Acc:\t0.23749350311850312\n",
      "Privacy Acc Adv:\t\t0.24587448024948025\n",
      "Privacy Acc Coop:\t\t0.16696985446985446\n",
      "Utility Acc Adv:\t\t0.04957120582120582\n",
      "Utility Acc Coop:\t\t0.25580821206440796\n",
      "Val Privacy Acc Adv:\t\t0.25783402204883\n",
      "Val Privacy Acc Coop:\t\t0.15410497015696173\n",
      "Val Utility Acc Adv:\t\t0.0446510560164028\n",
      "Val Utility Acc Coop:\t\t0.17486656337114406\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 149/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.7322056192048901\n",
      "Validation Loss:\t\t-0.6718300492310327\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6076440194354483\n",
      "End Effector Loss:\t\t0.005037603007722453\n",
      "Smoothing Loss:\t\t\t0.010682683984561205\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.007904481863033747\n",
      "Privacy Loss Dyn:\t\t-3.4843704697991607\n",
      "Privacy Loss Stat:\t\t3.5634152914035346\n",
      "Utility Loss:\t\t\t-1.9924837933260784\n",
      "Utility Loss Dyn:\t\t-4.068651644207088\n",
      "Utility Loss Stat:\t\t3.8694032581828983\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5774145585076869\n",
      "Val End Effector Loss:\t\t0.0046165151101121415\n",
      "Val Smoothing Loss:\t\t0.009608386344207097\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0029027536511421204\n",
      "Val Privacy Loss Dyn:\t\t-3.497763751952116\n",
      "Val Privacy Loss Stat:\t\t3.52679129178859\n",
      "Val Utility Loss:\t\t-1.8630035967866252\n",
      "Val Utility Loss Dyn:\t\t-4.066433639565775\n",
      "Val Utility Loss Stat:\t\t3.880133277621151\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.486924872328982\n",
      "Utility Training Loss:\t\t4.068344869633474\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24546517671827467\n",
      "Utility Training Acc:\t\t0.049863565488565485\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5420287470807654\n",
      "Utility Training Coop Loss:\t3.886852765281582\n",
      "Privacy Training Coop Acc:\t0.1875324844074844\n",
      "Utility Training Coop Acc:\t0.23833809771309772\n",
      "Privacy Acc Adv:\t\t0.24708939709249506\n",
      "Privacy Acc Coop:\t\t0.1657679313929314\n",
      "Utility Acc Adv:\t\t0.04895400207900208\n",
      "Utility Acc Coop:\t\t0.25573024948334744\n",
      "Val Privacy Acc Adv:\t\t0.23078081956949115\n",
      "Val Privacy Acc Coop:\t\t0.20416523186751634\n",
      "Val Utility Acc Adv:\t\t0.050490702479338845\n",
      "Val Utility Acc Coop:\t\t0.2441962236030535\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 150/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.7055615677271743\n",
      "Validation Loss:\t\t-1.0238543535921385\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6117978159206573\n",
      "End Effector Loss:\t\t0.005073724978936453\n",
      "Smoothing Loss:\t\t\t0.010678924655971618\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0072541700951027025\n",
      "Privacy Loss Dyn:\t\t-3.486350181692603\n",
      "Privacy Loss Stat:\t\t3.5588918802891847\n",
      "Utility Loss:\t\t\t-1.973521869048755\n",
      "Utility Loss Dyn:\t\t-4.069674100548711\n",
      "Utility Loss Stat:\t\t3.8723219008554786\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5742492321724734\n",
      "Val End Effector Loss:\t\t0.004654805860020344\n",
      "Val Smoothing Loss:\t\t0.009591718733480031\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.013000527011954095\n",
      "Val Privacy Loss Dyn:\t\t-3.4910057802830847\n",
      "Val Privacy Loss Stat:\t\t3.6210110571758807\n",
      "Val Utility Loss:\t\t-2.218783307666621\n",
      "Val Utility Loss Dyn:\t\t-4.0818877254635835\n",
      "Val Utility Loss Stat:\t\t3.8600093993273648\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.488132869875109\n",
      "Utility Training Loss:\t\t4.069051949992745\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2451078482359462\n",
      "Utility Training Acc:\t\t0.048466735966735966\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5406265776767056\n",
      "Utility Training Coop Loss:\t3.8898672742803972\n",
      "Privacy Training Coop Acc:\t0.19064449065068656\n",
      "Utility Training Coop Acc:\t0.2357068607068607\n",
      "Privacy Acc Adv:\t\t0.24573804574424166\n",
      "Privacy Acc Coop:\t\t0.1718555093586073\n",
      "Utility Acc Adv:\t\t0.04732978170478171\n",
      "Utility Acc Coop:\t\t0.2530210498960499\n",
      "Val Privacy Acc Adv:\t\t0.23820592287527628\n",
      "Val Privacy Acc Coop:\t\t0.10915260560317966\n",
      "Val Utility Acc Adv:\t\t0.037319214876033055\n",
      "Val Utility Acc Coop:\t\t0.2646923783304524\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 151/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.7349999877885603\n",
      "Validation Loss:\t\t-0.7962341609310882\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6120166350117344\n",
      "End Effector Loss:\t\t0.005070359890229164\n",
      "Smoothing Loss:\t\t\t0.010658174749316645\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.007163691638413189\n",
      "Privacy Loss Dyn:\t\t-3.4901482241069455\n",
      "Privacy Loss Stat:\t\t3.5617851403052\n",
      "Utility Loss:\t\t\t-2.0032418383877886\n",
      "Utility Loss Dyn:\t\t-4.0710210425938\n",
      "Utility Loss Stat:\t\t3.870696872534722\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6027675498246161\n",
      "Val End Effector Loss:\t\t0.005171257222248318\n",
      "Val Smoothing Loss:\t\t0.009631229822393044\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0015539477679355086\n",
      "Val Privacy Loss Dyn:\t\t-3.519369615010979\n",
      "Val Privacy Loss Stat:\t\t3.534909090227332\n",
      "Val Utility Loss:\t\t-2.0373881552830215\n",
      "Val Utility Loss Dyn:\t\t-4.078578037171324\n",
      "Val Utility Loss Stat:\t\t3.8748392231208233\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.488216722829426\n",
      "Utility Training Loss:\t\t4.069420268282821\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24458809771619566\n",
      "Utility Training Acc:\t\t0.04877208940018735\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.541340392741245\n",
      "Utility Training Coop Loss:\t3.887274153019435\n",
      "Privacy Training Coop Acc:\t0.18887084202062562\n",
      "Utility Training Coop Acc:\t0.23799376299686095\n",
      "Privacy Acc Adv:\t\t0.24150207900517695\n",
      "Privacy Acc Coop:\t\t0.16764553015172606\n",
      "Utility Acc Adv:\t\t0.046010914764012714\n",
      "Utility Acc Coop:\t\t0.25439838877648674\n",
      "Val Privacy Acc Adv:\t\t0.20965335170222707\n",
      "Val Privacy Acc Coop:\t\t0.1967903466756679\n",
      "Val Utility Acc Adv:\t\t0.03769226354539148\n",
      "Val Utility Acc Coop:\t\t0.25132001837915624\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 152/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.7566303620366631\n",
      "Validation Loss:\t\t-1.1492187198913417\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6071891351573928\n",
      "End Effector Loss:\t\t0.00506746280152281\n",
      "Smoothing Loss:\t\t\t0.01068956871844224\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.007639750001832007\n",
      "Privacy Loss Dyn:\t\t-3.4862979127562714\n",
      "Privacy Loss Stat:\t\t3.5626954117832463\n",
      "Utility Loss:\t\t\t-2.015784551101018\n",
      "Utility Loss Dyn:\t\t-4.0701425620771\n",
      "Utility Loss Stat:\t\t3.8685641177230963\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5786468661890543\n",
      "Val End Effector Loss:\t\t0.00473837752312745\n",
      "Val Smoothing Loss:\t\t0.009605443968114344\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t-0.0005495215127290773\n",
      "Val Privacy Loss Dyn:\t\t-3.5519279753866275\n",
      "Val Privacy Loss Stat:\t\t3.546432767525192\n",
      "Val Utility Loss:\t\t-2.3395176406734244\n",
      "Val Utility Loss Dyn:\t\t-4.084989944765391\n",
      "Val Utility Loss Stat:\t\t3.8510381973479406\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.488150680883015\n",
      "Utility Training Loss:\t\t4.071018825201879\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24554963617463618\n",
      "Utility Training Acc:\t\t0.04609537422037422\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5409695470159614\n",
      "Utility Training Coop Loss:\t3.8853589668095485\n",
      "Privacy Training Coop Acc:\t0.1896764553014553\n",
      "Utility Training Coop Acc:\t0.23953352391471983\n",
      "Privacy Acc Adv:\t\t0.24603690228690228\n",
      "Privacy Acc Coop:\t\t0.16654755717255718\n",
      "Utility Acc Adv:\t\t0.047849532224532226\n",
      "Utility Acc Coop:\t\t0.25655535343654934\n",
      "Val Privacy Acc Adv:\t\t0.17702594123134188\n",
      "Val Privacy Acc Coop:\t\t0.18392016758665072\n",
      "Val Utility Acc Adv:\t\t0.0331224173553719\n",
      "Val Utility Acc Coop:\t\t0.2745207759420857\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 153/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.7585731547658879\n",
      "Validation Loss:\t\t-0.7461477586583904\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6043938742543952\n",
      "End Effector Loss:\t\t0.005045320422402167\n",
      "Smoothing Loss:\t\t\t0.010665958310649759\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.007545946820362194\n",
      "Privacy Loss Dyn:\t\t-3.4856742350326506\n",
      "Privacy Loss Stat:\t\t3.561133704165659\n",
      "Utility Loss:\t\t\t-2.0119500467534372\n",
      "Utility Loss Dyn:\t\t-4.069627612891168\n",
      "Utility Loss Stat:\t\t3.868432606580104\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5842686347232378\n",
      "Val End Effector Loss:\t\t0.0047538390032916275\n",
      "Val Smoothing Loss:\t\t0.009636635611157032\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0014293829887366493\n",
      "Val Privacy Loss Dyn:\t\t-3.5157780755649912\n",
      "Val Privacy Loss Stat:\t\t3.5300719063144084\n",
      "Val Utility Loss:\t\t-1.9497781548618285\n",
      "Val Utility Loss Dyn:\t\t-4.069822296623356\n",
      "Val Utility Loss Stat:\t\t3.874844478181571\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4879163394598853\n",
      "Utility Training Loss:\t\t4.06796261823103\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24597193347193347\n",
      "Utility Training Acc:\t\t0.04970114345114345\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5396058827080994\n",
      "Utility Training Coop Loss:\t3.8868532339401405\n",
      "Privacy Training Coop Acc:\t0.19241813929623724\n",
      "Utility Training Coop Acc:\t0.23902027027027026\n",
      "Privacy Acc Adv:\t\t0.24629677754677753\n",
      "Privacy Acc Coop:\t\t0.16843165280665282\n",
      "Utility Acc Adv:\t\t0.04625779625779626\n",
      "Utility Acc Coop:\t\t0.25665930353430355\n",
      "Val Privacy Acc Adv:\t\t0.21354166667692917\n",
      "Val Privacy Acc Coop:\t\t0.20007604453712702\n",
      "Val Utility Acc Adv:\t\t0.05023243801652893\n",
      "Val Utility Acc Coop:\t\t0.24912477044527195\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 154/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.728943196181479\n",
      "Validation Loss:\t\t-0.8437624177741548\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6125802021946084\n",
      "End Effector Loss:\t\t0.005158282813263705\n",
      "Smoothing Loss:\t\t\t0.010681009217767575\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.007246145153739596\n",
      "Privacy Loss Dyn:\t\t-3.4893163635924056\n",
      "Privacy Loss Stat:\t\t3.561777814758047\n",
      "Utility Loss:\t\t\t-1.9985510574309098\n",
      "Utility Loss Dyn:\t\t-4.071434669336013\n",
      "Utility Loss Stat:\t\t3.87157955982581\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5873037659801728\n",
      "Val End Effector Loss:\t\t0.0048691618866248685\n",
      "Val Smoothing Loss:\t\t0.00966071075767525\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0051143344891958\n",
      "Val Privacy Loss Dyn:\t\t-3.480656366702939\n",
      "Val Privacy Loss Stat:\t\t3.531799719353353\n",
      "Val Utility Loss:\t\t-2.057335577720453\n",
      "Val Utility Loss Dyn:\t\t-4.070858893315654\n",
      "Val Utility Loss Stat:\t\t3.865125344804496\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4911443537833042\n",
      "Utility Training Loss:\t\t4.070332166806576\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24145660083160084\n",
      "Utility Training Acc:\t\t0.04840176715176715\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5410886871591676\n",
      "Utility Training Coop Loss:\t3.888346315173746\n",
      "Privacy Training Coop Acc:\t0.18957900207900208\n",
      "Utility Training Coop Acc:\t0.23698674636484432\n",
      "Privacy Acc Adv:\t\t0.24233367983367984\n",
      "Privacy Acc Coop:\t\t0.16765202702702703\n",
      "Utility Acc Adv:\t\t0.045965436590436594\n",
      "Utility Acc Coop:\t\t0.2534238565519545\n",
      "Val Privacy Acc Adv:\t\t0.2501865243616183\n",
      "Val Privacy Acc Coop:\t\t0.19887081037991303\n",
      "Val Utility Acc Adv:\t\t0.04757087924787082\n",
      "Val Utility Acc Coop:\t\t0.25995035583445847\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 155/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.769752573450396\n",
      "Validation Loss:\t\t-0.9180885512566517\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6030559757581124\n",
      "End Effector Loss:\t\t0.005008089957563226\n",
      "Smoothing Loss:\t\t\t0.010681547251144683\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006692396658869643\n",
      "Privacy Loss Dyn:\t\t-3.490278878975311\n",
      "Privacy Loss Stat:\t\t3.55720284674123\n",
      "Utility Loss:\t\t\t-2.019609653528416\n",
      "Utility Loss Dyn:\t\t-4.069759187975941\n",
      "Utility Loss Stat:\t\t3.8677982248040594\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5713614591143348\n",
      "Val End Effector Loss:\t\t0.004634692143140869\n",
      "Val Smoothing Loss:\t\t0.009593218065652042\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.010936042124574835\n",
      "Val Privacy Loss Dyn:\t\t-3.4689658875307763\n",
      "Val Privacy Loss Stat:\t\t3.5783263144414286\n",
      "Val Utility Loss:\t\t-2.1051618560286594\n",
      "Val Utility Loss Dyn:\t\t-4.080397977809276\n",
      "Val Utility Loss Stat:\t\t3.8698817831425627\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4905374037748564\n",
      "Utility Training Loss:\t\t4.069462831451591\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24213877338877338\n",
      "Utility Training Acc:\t\t0.0485966735966736\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.539876334136836\n",
      "Utility Training Coop Loss:\t3.8862223439305836\n",
      "Privacy Training Coop Acc:\t0.1922752079002079\n",
      "Utility Training Coop Acc:\t0.23615514553634143\n",
      "Privacy Acc Adv:\t\t0.24139163201663202\n",
      "Privacy Acc Coop:\t\t0.17294698544698545\n",
      "Utility Acc Adv:\t\t0.047004937629937626\n",
      "Utility Acc Coop:\t\t0.2579002079249915\n",
      "Val Privacy Acc Adv:\t\t0.2640180211237147\n",
      "Val Privacy Acc Coop:\t\t0.15135014922288823\n",
      "Val Utility Acc Adv:\t\t0.03777117768595041\n",
      "Val Utility Acc Coop:\t\t0.254318755766577\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 156/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.7522578976153863\n",
      "Validation Loss:\t\t-0.6562690595549739\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6049511130287345\n",
      "End Effector Loss:\t\t0.005056166818574567\n",
      "Smoothing Loss:\t\t\t0.01069286221438891\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006708380059492067\n",
      "Privacy Loss Dyn:\t\t-3.488813293203247\n",
      "Privacy Loss Stat:\t\t3.5558970963384904\n",
      "Utility Loss:\t\t\t-2.0060032549122515\n",
      "Utility Loss Dyn:\t\t-4.070545799271232\n",
      "Utility Loss Stat:\t\t3.8699454800254838\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5620722209742247\n",
      "Val End Effector Loss:\t\t0.004578050644972077\n",
      "Val Smoothing Loss:\t\t0.009583391086583234\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t-0.0025156441429429804\n",
      "Val Privacy Loss Dyn:\t\t-3.561709270496999\n",
      "Val Privacy Loss Stat:\t\t3.536552836579725\n",
      "Val Utility Loss:\t\t-1.8112260802718234\n",
      "Val Utility Loss Dyn:\t\t-4.064832574572445\n",
      "Val Utility Loss Stat:\t\t3.8837099641807806\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4911465669620063\n",
      "Utility Training Loss:\t\t4.069833922782707\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24244412682222477\n",
      "Utility Training Acc:\t\t0.04771959459459459\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5353455365075885\n",
      "Utility Training Coop Loss:\t3.8859995675433945\n",
      "Privacy Training Coop Acc:\t0.19630977133455493\n",
      "Utility Training Coop Acc:\t0.2382211538492518\n",
      "Privacy Acc Adv:\t\t0.2429963617494597\n",
      "Privacy Acc Coop:\t\t0.1744347713159672\n",
      "Utility Acc Adv:\t\t0.04651767151767152\n",
      "Utility Acc Coop:\t\t0.25446335759145555\n",
      "Val Privacy Acc Adv:\t\t0.165152949981453\n",
      "Val Privacy Acc Coop:\t\t0.19375573923765135\n",
      "Val Utility Acc Adv:\t\t0.05104310147094825\n",
      "Val Utility Acc Coop:\t\t0.24046573692486306\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 157/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.7472982747720365\n",
      "Validation Loss:\t\t-0.8193177957942109\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6024887864468251\n",
      "End Effector Loss:\t\t0.005018728597887372\n",
      "Smoothing Loss:\t\t\t0.010668203073966155\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006571170105260028\n",
      "Privacy Loss Dyn:\t\t-3.4901493029386237\n",
      "Privacy Loss Stat:\t\t3.5558609999638833\n",
      "Utility Loss:\t\t\t-1.9958703562524363\n",
      "Utility Loss Dyn:\t\t-4.070287605828902\n",
      "Utility Loss Stat:\t\t3.870700568518371\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5643691198269197\n",
      "Val End Effector Loss:\t\t0.004564688108045577\n",
      "Val Smoothing Loss:\t\t0.009583589998997501\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.003093899035256756\n",
      "Val Privacy Loss Dyn:\t\t-3.4798246498935477\n",
      "Val Privacy Loss Stat:\t\t3.510763635812712\n",
      "Val Utility Loss:\t\t-1.9844653941383046\n",
      "Val Utility Loss Dyn:\t\t-4.064741968123381\n",
      "Val Utility Loss Stat:\t\t3.866295425852468\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4904661723828863\n",
      "Utility Training Loss:\t\t4.068812936110705\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24324324324324326\n",
      "Utility Training Acc:\t\t0.04983108108108108\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.53539112327996\n",
      "Utility Training Coop Loss:\t3.8860622456068805\n",
      "Privacy Training Coop Acc:\t0.19643321205821207\n",
      "Utility Training Coop Acc:\t0.23971543659353456\n",
      "Privacy Acc Adv:\t\t0.24161902286902287\n",
      "Privacy Acc Coop:\t\t0.17375909563409564\n",
      "Utility Acc Adv:\t\t0.046745062370062374\n",
      "Utility Acc Coop:\t\t0.25394360707170505\n",
      "Val Privacy Acc Adv:\t\t0.25100436180152674\n",
      "Val Privacy Acc Coop:\t\t0.22070850551990437\n",
      "Val Utility Acc Adv:\t\t0.05661013544621793\n",
      "Val Utility Acc Coop:\t\t0.26038797064261004\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 158/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.7672948711116075\n",
      "Validation Loss:\t\t-0.7401115373931517\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6056816898549668\n",
      "End Effector Loss:\t\t0.005035992979949143\n",
      "Smoothing Loss:\t\t\t0.010665425900544142\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0065781483717123335\n",
      "Privacy Loss Dyn:\t\t-3.4915936213768943\n",
      "Privacy Loss Stat:\t\t3.5573751098648674\n",
      "Utility Loss:\t\t\t-2.0222686680339725\n",
      "Utility Loss Dyn:\t\t-4.0711485402747645\n",
      "Utility Loss Stat:\t\t3.8689216695059856\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5810548213025755\n",
      "Val End Effector Loss:\t\t0.004623367224073361\n",
      "Val Smoothing Loss:\t\t0.009610119388315611\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.011118327721583941\n",
      "Val Privacy Loss Dyn:\t\t-3.465600295500322\n",
      "Val Privacy Loss Stat:\t\t3.576783575302313\n",
      "Val Utility Loss:\t\t-1.9467932330675362\n",
      "Val Utility Loss Dyn:\t\t-4.083893701557286\n",
      "Val Utility Loss Stat:\t\t3.889214374802329\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4902070577328024\n",
      "Utility Training Loss:\t\t4.069565097160498\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24284693347812938\n",
      "Utility Training Acc:\t\t0.048564189189189186\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.537247487264463\n",
      "Utility Training Coop Loss:\t3.8863455932006516\n",
      "Privacy Training Coop Acc:\t0.19376949064449064\n",
      "Utility Training Coop Acc:\t0.24132016632636222\n",
      "Privacy Acc Adv:\t\t0.23971543659353456\n",
      "Privacy Acc Coop:\t\t0.17297946985446985\n",
      "Utility Acc Adv:\t\t0.04655015592515593\n",
      "Utility Acc Coop:\t\t0.2559381496943456\n",
      "Val Privacy Acc Adv:\t\t0.26791351011469344\n",
      "Val Privacy Acc Coop:\t\t0.15244777318983038\n",
      "Val Utility Acc Adv:\t\t0.03614267676853198\n",
      "Val Utility Acc Coop:\t\t0.23375803490808186\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 159/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.7876272268744337\n",
      "Validation Loss:\t\t-1.0114089707528386\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6032612156781239\n",
      "End Effector Loss:\t\t0.0050114379412051204\n",
      "Smoothing Loss:\t\t\t0.010665436259813591\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006886575735036648\n",
      "Privacy Loss Dyn:\t\t-3.4878969556824333\n",
      "Privacy Loss Stat:\t\t3.556762711174027\n",
      "Utility Loss:\t\t\t-2.03804397979546\n",
      "Utility Loss Dyn:\t\t-4.073153946602915\n",
      "Utility Loss Stat:\t\t3.8693495488216376\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6054854986588817\n",
      "Val End Effector Loss:\t\t0.004824329865615322\n",
      "Val Smoothing Loss:\t\t0.009653101005583755\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.014729442736826652\n",
      "Val Privacy Loss Dyn:\t\t-3.4668086397746376\n",
      "Val Privacy Loss Stat:\t\t3.614103068990156\n",
      "Val Utility Loss:\t\t-2.2708930417525868\n",
      "Val Utility Loss Dyn:\t\t-4.081740758635781\n",
      "Val Utility Loss Stat:\t\t3.8546514550516426\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4900513285163037\n",
      "Utility Training Loss:\t\t4.0704281354892276\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24106029106648696\n",
      "Utility Training Acc:\t\t0.04681003118503119\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.536259636066064\n",
      "Utility Training Coop Loss:\t3.8863182583370723\n",
      "Privacy Training Coop Acc:\t0.19465306655285017\n",
      "Utility Training Coop Acc:\t0.23805223495201858\n",
      "Privacy Acc Adv:\t\t0.24510135137613498\n",
      "Privacy Acc Coop:\t\t0.17315488565798362\n",
      "Utility Acc Adv:\t\t0.04421127858627859\n",
      "Utility Acc Coop:\t\t0.2555288461786298\n",
      "Val Privacy Acc Adv:\t\t0.2640969352719705\n",
      "Val Privacy Acc Coop:\t\t0.11608987603305786\n",
      "Val Utility Acc Adv:\t\t0.036322027090782964\n",
      "Val Utility Acc Coop:\t\t0.2694487488589996\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 160/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.7983758488027166\n",
      "Validation Loss:\t\t-0.8762150940462208\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6031060753827779\n",
      "End Effector Loss:\t\t0.0050517704757511335\n",
      "Smoothing Loss:\t\t\t0.010673551014266335\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0068715225572149865\n",
      "Privacy Loss Dyn:\t\t-3.4885723806468465\n",
      "Privacy Loss Stat:\t\t3.557287606776628\n",
      "Utility Loss:\t\t\t-2.0485319427046114\n",
      "Utility Loss Dyn:\t\t-4.0722677093037944\n",
      "Utility Loss Stat:\t\t3.8674145163716496\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5580434029506258\n",
      "Val End Effector Loss:\t\t0.004580053200652776\n",
      "Val Smoothing Loss:\t\t0.009556099828255693\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.008978178616890237\n",
      "Val Privacy Loss Dyn:\t\t-3.50751548463648\n",
      "Val Privacy Loss Stat:\t\t3.597297266002529\n",
      "Val Utility Loss:\t\t-2.03452843279878\n",
      "Val Utility Loss Dyn:\t\t-4.07619951086596\n",
      "Val Utility Loss Stat:\t\t3.8727466666008814\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.491338044095188\n",
      "Utility Training Loss:\t\t4.071872173128901\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24083939708939708\n",
      "Utility Training Acc:\t\t0.04583549896049896\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.537135392861158\n",
      "Utility Training Coop Loss:\t3.884032783042368\n",
      "Privacy Training Coop Acc:\t0.19330821206440796\n",
      "Utility Training Coop Acc:\t0.24114475052284848\n",
      "Privacy Acc Adv:\t\t0.24267151767461562\n",
      "Privacy Acc Coop:\t\t0.17198544698854493\n",
      "Utility Acc Adv:\t\t0.04443866943866944\n",
      "Utility Acc Coop:\t\t0.25845893971203765\n",
      "Val Privacy Acc Adv:\t\t0.22434573004807323\n",
      "Val Privacy Acc Coop:\t\t0.13220270890896477\n",
      "Val Utility Acc Adv:\t\t0.042871900826446284\n",
      "Val Utility Acc Coop:\t\t0.2502797865116399\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 161/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.8275395571070253\n",
      "Validation Loss:\t\t-0.9806755899898092\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5983362183005795\n",
      "End Effector Loss:\t\t0.004985781981156686\n",
      "Smoothing Loss:\t\t\t0.010655742576210266\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006008722523146013\n",
      "Privacy Loss Dyn:\t\t-3.4932855273482706\n",
      "Privacy Loss Stat:\t\t3.5533727538808715\n",
      "Utility Loss:\t\t\t-2.0671737258498735\n",
      "Utility Loss Dyn:\t\t-4.072011387769497\n",
      "Utility Loss Stat:\t\t3.8652940145897023\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5574601266748649\n",
      "Val End Effector Loss:\t\t0.0045195663740381226\n",
      "Val Smoothing Loss:\t\t0.009596094806593928\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.008646331173329315\n",
      "Val Privacy Loss Dyn:\t\t-3.481971857961544\n",
      "Val Privacy Loss Stat:\t\t3.568435165015134\n",
      "Val Utility Loss:\t\t-2.1375500229764577\n",
      "Val Utility Loss Dyn:\t\t-4.072966571189156\n",
      "Val Utility Loss Stat:\t\t3.859211564556626\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.492028004662163\n",
      "Utility Training Loss:\t\t4.072386808306165\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24184641372141372\n",
      "Utility Training Acc:\t\t0.044925935550935554\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.538156578793595\n",
      "Utility Training Coop Loss:\t3.8815037232674583\n",
      "Privacy Training Coop Acc:\t0.19253508316008316\n",
      "Utility Training Coop Acc:\t0.24364604989914784\n",
      "Privacy Acc Adv:\t\t0.23900077962887759\n",
      "Privacy Acc Coop:\t\t0.17678014553014554\n",
      "Utility Acc Adv:\t\t0.04525077962577963\n",
      "Utility Acc Coop:\t\t0.26008316008625804\n",
      "Val Privacy Acc Adv:\t\t0.25104023186751634\n",
      "Val Privacy Acc Coop:\t\t0.16080549816516312\n",
      "Val Utility Acc Adv:\t\t0.042649506429625936\n",
      "Val Utility Acc Coop:\t\t0.2677915518687776\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 162/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.8430691633543886\n",
      "Validation Loss:\t\t-0.8871437090195038\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5963917409617787\n",
      "End Effector Loss:\t\t0.0049570503827618155\n",
      "Smoothing Loss:\t\t\t0.01062457689874091\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006642902839208591\n",
      "Privacy Loss Dyn:\t\t-3.4907464138435476\n",
      "Privacy Loss Stat:\t\t3.557175448927215\n",
      "Utility Loss:\t\t\t-2.0793263243042754\n",
      "Utility Loss Dyn:\t\t-4.071930189638277\n",
      "Utility Loss Stat:\t\t3.863997561024529\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.567863154571411\n",
      "Val End Effector Loss:\t\t0.0044943930384941586\n",
      "Val Smoothing Loss:\t\t0.009561975739611513\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.004109019275046577\n",
      "Val Privacy Loss Dyn:\t\t-3.4714331341183877\n",
      "Val Privacy Loss Stat:\t\t3.512523321080799\n",
      "Val Utility Loss:\t\t-2.0601593600816965\n",
      "Val Utility Loss Dyn:\t\t-4.067751582989023\n",
      "Val Utility Loss Stat:\t\t3.861735648360134\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.489880564306977\n",
      "Utility Training Loss:\t\t4.071976963051144\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2437240124802084\n",
      "Utility Training Acc:\t\t0.04551065488565489\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5365167102793893\n",
      "Utility Training Coop Loss:\t3.8822294228290075\n",
      "Privacy Training Coop Acc:\t0.19420478170787966\n",
      "Utility Training Coop Acc:\t0.24527027027336823\n",
      "Privacy Acc Adv:\t\t0.24063799376918968\n",
      "Privacy Acc Coop:\t\t0.17292749480559275\n",
      "Utility Acc Adv:\t\t0.04421127858627859\n",
      "Utility Acc Coop:\t\t0.26045348233467824\n",
      "Val Privacy Acc Adv:\t\t0.2606964531885691\n",
      "Val Privacy Acc Coop:\t\t0.21862804178487172\n",
      "Val Utility Acc Adv:\t\t0.048639807172796944\n",
      "Val Utility Acc Coop:\t\t0.2628199609750805\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 163/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.8418646655287477\n",
      "Validation Loss:\t\t-0.7325015076020471\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5954933595260811\n",
      "End Effector Loss:\t\t0.004955162670804099\n",
      "Smoothing Loss:\t\t\t0.010664041524873021\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0065868734198151905\n",
      "Privacy Loss Dyn:\t\t-3.4902259644252593\n",
      "Privacy Loss Stat:\t\t3.5560946972603116\n",
      "Utility Loss:\t\t\t-2.076385545631456\n",
      "Utility Loss Dyn:\t\t-4.0717750175579175\n",
      "Utility Loss Stat:\t\t3.8641364700828915\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5579440462564634\n",
      "Val End Effector Loss:\t\t0.004551227922716817\n",
      "Val Smoothing Loss:\t\t0.00958832703561576\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t-0.003837403618107157\n",
      "Val Privacy Loss Dyn:\t\t-3.553511335830058\n",
      "Val Privacy Loss Stat:\t\t3.5151373010036373\n",
      "Val Utility Loss:\t\t-1.8778684080139665\n",
      "Val Utility Loss Dyn:\t\t-4.073087053358062\n",
      "Val Utility Loss Stat:\t\t3.88530020477358\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4916494866666574\n",
      "Utility Training Loss:\t\t4.072048895820015\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24228170478480274\n",
      "Utility Training Acc:\t\t0.045283264033264034\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5357697718852275\n",
      "Utility Training Coop Loss:\t3.8814475409949893\n",
      "Privacy Training Coop Acc:\t0.19616683992303582\n",
      "Utility Training Coop Acc:\t0.244295738048836\n",
      "Privacy Acc Adv:\t\t0.2416969854500834\n",
      "Privacy Acc Coop:\t\t0.17389553017031378\n",
      "Utility Acc Adv:\t\t0.04499090436590437\n",
      "Utility Acc Coop:\t\t0.2608303014583994\n",
      "Val Privacy Acc Adv:\t\t0.17206869834710745\n",
      "Val Privacy Acc Coop:\t\t0.21555756428086562\n",
      "Val Utility Acc Adv:\t\t0.04506714876033058\n",
      "Val Utility Acc Coop:\t\t0.23888745411368442\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 164/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.8664668987634865\n",
      "Validation Loss:\t\t-1.050639879766636\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5956735442123393\n",
      "End Effector Loss:\t\t0.004967477712576934\n",
      "Smoothing Loss:\t\t\t0.010676639624087143\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006581005924952501\n",
      "Privacy Loss Dyn:\t\t-3.489975848217764\n",
      "Privacy Loss Stat:\t\t3.5557859097597753\n",
      "Utility Loss:\t\t\t-2.1013923890873203\n",
      "Utility Loss Dyn:\t\t-4.0722556619782955\n",
      "Utility Loss Stat:\t\t3.862116413899618\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.565125480909978\n",
      "Val End Effector Loss:\t\t0.004547758351661234\n",
      "Val Smoothing Loss:\t\t0.009593939586650302\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.007218881210019765\n",
      "Val Privacy Loss Dyn:\t\t-3.4781226451731913\n",
      "Val Privacy Loss Stat:\t\t3.5503114639234936\n",
      "Val Utility Loss:\t\t-2.2214392985194182\n",
      "Val Utility Loss Dyn:\t\t-4.074186617677862\n",
      "Val Utility Loss Stat:\t\t3.852042692751924\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4921870895829863\n",
      "Utility Training Loss:\t\t4.071876221288019\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24067047817667409\n",
      "Utility Training Acc:\t\t0.04603040540540541\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.538129119268326\n",
      "Utility Training Coop Loss:\t3.8807148048634836\n",
      "Privacy Training Coop Acc:\t0.1929833679895639\n",
      "Utility Training Coop Acc:\t0.24419828482638278\n",
      "Privacy Acc Adv:\t\t0.24139812892291254\n",
      "Privacy Acc Coop:\t\t0.17397998961118552\n",
      "Utility Acc Adv:\t\t0.04505587318087318\n",
      "Utility Acc Coop:\t\t0.2640267671579631\n",
      "Val Privacy Acc Adv:\t\t0.2540748393055329\n",
      "Val Privacy Acc Coop:\t\t0.17886966254469777\n",
      "Val Utility Acc Adv:\t\t0.04027490817349066\n",
      "Val Utility Acc Coop:\t\t0.27351641414825584\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 165/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.90778370239344\n",
      "Validation Loss:\t\t-1.063664882170606\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5959584900408426\n",
      "End Effector Loss:\t\t0.005001839964791916\n",
      "Smoothing Loss:\t\t\t0.010667029272071754\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006925252581832315\n",
      "Privacy Loss Dyn:\t\t-3.486809648000277\n",
      "Privacy Loss Stat:\t\t3.5560621788992455\n",
      "Utility Loss:\t\t\t-2.1436288639314456\n",
      "Utility Loss Dyn:\t\t-4.073526823595011\n",
      "Utility Loss Stat:\t\t3.859163947264023\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5692462194557032\n",
      "Val End Effector Loss:\t\t0.00471072928779874\n",
      "Val Smoothing Loss:\t\t0.009601906753022008\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.005956773792416596\n",
      "Val Privacy Loss Dyn:\t\t-3.4887047656311476\n",
      "Val Privacy Loss Stat:\t\t3.548272505279415\n",
      "Val Utility Loss:\t\t-2.2416305463176127\n",
      "Val Utility Loss Dyn:\t\t-4.079330072915258\n",
      "Val Utility Loss Stat:\t\t3.855167011091532\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.490023303180623\n",
      "Utility Training Loss:\t\t4.072890893585221\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24397089397399194\n",
      "Utility Training Acc:\t\t0.04516632016941812\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.536953242553743\n",
      "Utility Training Coop Loss:\t3.8773508188382504\n",
      "Privacy Training Coop Acc:\t0.19418529106648696\n",
      "Utility Training Coop Acc:\t0.2481938669469649\n",
      "Privacy Acc Adv:\t\t0.24565358630336992\n",
      "Privacy Acc Coop:\t\t0.17373960499270294\n",
      "Utility Acc Adv:\t\t0.04308731809041604\n",
      "Utility Acc Coop:\t\t0.26532614345733935\n",
      "Val Privacy Acc Adv:\t\t0.24358643252741208\n",
      "Val Privacy Acc Coop:\t\t0.18172491965276644\n",
      "Val Utility Acc Adv:\t\t0.037512913223140494\n",
      "Val Utility Acc Coop:\t\t0.2691546143455939\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 166/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.9057238430051974\n",
      "Validation Loss:\t\t-0.5614115809829336\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.592587428225549\n",
      "End Effector Loss:\t\t0.004969142130992362\n",
      "Smoothing Loss:\t\t\t0.010665150914968547\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006216713240885189\n",
      "Privacy Loss Dyn:\t\t-3.4909625172367216\n",
      "Privacy Loss Stat:\t\t3.553129659620987\n",
      "Utility Loss:\t\t\t-2.1340800065260668\n",
      "Utility Loss Dyn:\t\t-4.073062891028279\n",
      "Utility Loss Stat:\t\t3.859654897711629\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5513229325783154\n",
      "Val End Effector Loss:\t\t0.004491777181402157\n",
      "Val Smoothing Loss:\t\t0.009521986149089827\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0032242459575991984\n",
      "Val Privacy Loss Dyn:\t\t-3.4942046990079327\n",
      "Val Privacy Loss Stat:\t\t3.5264471577218743\n",
      "Val Utility Loss:\t\t-1.7003394276642603\n",
      "Val Utility Loss Dyn:\t\t-4.070830327420195\n",
      "Val Utility Loss Stat:\t\t3.9007963794322054\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4890607726796996\n",
      "Utility Training Loss:\t\t4.0727233703319845\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2442112785924745\n",
      "Utility Training Acc:\t\t0.0446985446985447\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5354538511585547\n",
      "Utility Training Coop Loss:\t3.877440727674044\n",
      "Privacy Training Coop Acc:\t0.19448414760914762\n",
      "Utility Training Coop Acc:\t0.24495841996461587\n",
      "Privacy Acc Adv:\t\t0.24067697505197505\n",
      "Privacy Acc Coop:\t\t0.17718295218605012\n",
      "Utility Acc Adv:\t\t0.04421127858627859\n",
      "Utility Acc Coop:\t\t0.26487136175255765\n",
      "Val Privacy Acc Adv:\t\t0.2352430555692389\n",
      "Val Privacy Acc Coop:\t\t0.20350522270872573\n",
      "Val Utility Acc Adv:\t\t0.047520661157024795\n",
      "Val Utility Acc Coop:\t\t0.2239081152707092\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 167/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.9223360351137739\n",
      "Validation Loss:\t\t-0.6929642343893647\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5909384670599582\n",
      "End Effector Loss:\t\t0.004952503666678626\n",
      "Smoothing Loss:\t\t\t0.01065403233928966\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.00630426998569663\n",
      "Privacy Loss Dyn:\t\t-3.4914540674483208\n",
      "Privacy Loss Stat:\t\t3.554496767862919\n",
      "Utility Loss:\t\t\t-2.14743183952855\n",
      "Utility Loss Dyn:\t\t-4.074433351752663\n",
      "Utility Loss Stat:\t\t3.859690169286827\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5726703697245968\n",
      "Val End Effector Loss:\t\t0.004488834302606877\n",
      "Val Smoothing Loss:\t\t0.009544755309081275\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.005160288069366424\n",
      "Val Privacy Loss Dyn:\t\t-3.4850261492177474\n",
      "Val Privacy Loss Stat:\t\t3.5366290324975638\n",
      "Val Utility Loss:\t\t-1.8765883642779895\n",
      "Val Utility Loss Dyn:\t\t-4.0704008769397895\n",
      "Val Utility Loss Stat:\t\t3.8827420433690727\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4924557109880348\n",
      "Utility Training Loss:\t\t4.072276805393909\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24055353432831794\n",
      "Utility Training Acc:\t\t0.045231288984386935\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5358635893482675\n",
      "Utility Training Coop Loss:\t3.8762287503716357\n",
      "Privacy Training Coop Acc:\t0.1956275987773824\n",
      "Utility Training Coop Acc:\t0.24744672557482353\n",
      "Privacy Acc Adv:\t\t0.24097583162561523\n",
      "Privacy Acc Coop:\t\t0.17597453224931586\n",
      "Utility Acc Adv:\t\t0.04250259875569671\n",
      "Utility Acc Coop:\t\t0.26544308732118527\n",
      "Val Privacy Acc Adv:\t\t0.24610451103980877\n",
      "Val Privacy Acc Coop:\t\t0.19309573004807323\n",
      "Val Utility Acc Adv:\t\t0.045440197429689\n",
      "Val Utility Acc Coop:\t\t0.24169249312321017\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 168/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.942175864108418\n",
      "Validation Loss:\t\t-1.0282225593470407\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5915896589567656\n",
      "End Effector Loss:\t\t0.004958486560830874\n",
      "Smoothing Loss:\t\t\t0.010652506793219899\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006895250751174166\n",
      "Privacy Loss Dyn:\t\t-3.489305454083639\n",
      "Privacy Loss Stat:\t\t3.5582579614714622\n",
      "Utility Loss:\t\t\t-2.1691664380491895\n",
      "Utility Loss Dyn:\t\t-4.0744144730657155\n",
      "Utility Loss Stat:\t\t3.857497818009026\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.561103307942221\n",
      "Val End Effector Loss:\t\t0.004483331939155497\n",
      "Val Smoothing Loss:\t\t0.00957526495845696\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t-0.0004865580723305379\n",
      "Val Privacy Loss Dyn:\t\t-3.5340939543463965\n",
      "Val Privacy Loss Stat:\t\t3.5292283754703426\n",
      "Val Utility Loss:\t\t-2.1831517416583606\n",
      "Val Utility Loss Dyn:\t\t-4.079481612552296\n",
      "Val Utility Loss Stat:\t\t3.8611664432139436\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.490995687407416\n",
      "Utility Training Loss:\t\t4.0733970683726355\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24323674636794226\n",
      "Utility Training Acc:\t\t0.0438539501039501\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5368550800236247\n",
      "Utility Training Coop Loss:\t3.87621334808532\n",
      "Privacy Training Coop Acc:\t0.1947700104012063\n",
      "Utility Training Coop Acc:\t0.2478235446985447\n",
      "Privacy Acc Adv:\t\t0.24325623700933496\n",
      "Privacy Acc Coop:\t\t0.1717385654947614\n",
      "Utility Acc Adv:\t\t0.04281444906444906\n",
      "Utility Acc Coop:\t\t0.26786642411642414\n",
      "Val Privacy Acc Adv:\t\t0.19481749312321017\n",
      "Val Privacy Acc Coop:\t\t0.19976756198347106\n",
      "Val Utility Acc Adv:\t\t0.037319214876033055\n",
      "Val Utility Acc Coop:\t\t0.2614210284938497\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 169/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.9460471551710442\n",
      "Validation Loss:\t\t-0.6896197789787384\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5898878952941379\n",
      "End Effector Loss:\t\t0.0049671528724423005\n",
      "Smoothing Loss:\t\t\t0.010640007682849426\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006156024188113064\n",
      "Privacy Loss Dyn:\t\t-3.4906642459286474\n",
      "Privacy Loss Stat:\t\t3.55222448291501\n",
      "Utility Loss:\t\t\t-2.168866147618284\n",
      "Utility Loss Dyn:\t\t-4.074289183606725\n",
      "Utility Loss Stat:\t\t3.857402564086438\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5492341819504076\n",
      "Val End Effector Loss:\t\t0.0044513020192057445\n",
      "Val Smoothing Loss:\t\t0.009592530601427021\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0017326601034353588\n",
      "Val Privacy Loss Dyn:\t\t-3.497238184794907\n",
      "Val Privacy Loss Stat:\t\t3.514564786568161\n",
      "Val Utility Loss:\t\t-1.8230496950385984\n",
      "Val Utility Loss Dyn:\t\t-4.068945202453078\n",
      "Val Utility Loss Stat:\t\t3.886640228023214\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.490809659700136\n",
      "Utility Training Loss:\t\t4.0737556920477855\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24065748441058235\n",
      "Utility Training Acc:\t\t0.04324974012783808\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5340844424995215\n",
      "Utility Training Coop Loss:\t3.874619696095679\n",
      "Privacy Training Coop Acc:\t0.19599142411952208\n",
      "Utility Training Coop Acc:\t0.25145530146149736\n",
      "Privacy Acc Adv:\t\t0.24098232848542644\n",
      "Privacy Acc Coop:\t\t0.17718295218605012\n",
      "Utility Acc Adv:\t\t0.04193737006237006\n",
      "Utility Acc Coop:\t\t0.26706730769540565\n",
      "Val Privacy Acc Adv:\t\t0.23400912535461513\n",
      "Val Privacy Acc Coop:\t\t0.21586604684221844\n",
      "Val Utility Acc Adv:\t\t0.04970156106605264\n",
      "Val Utility Acc Coop:\t\t0.2370939508757808\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 170/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.974031724333918\n",
      "Validation Loss:\t\t-1.284171727662983\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5866277243578013\n",
      "End Effector Loss:\t\t0.004950262186951982\n",
      "Smoothing Loss:\t\t\t0.010642750184351808\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0059734609233614315\n",
      "Privacy Loss Dyn:\t\t-3.49397929790362\n",
      "Privacy Loss Stat:\t\t3.5537139065796026\n",
      "Utility Loss:\t\t\t-2.1901391439774924\n",
      "Utility Loss Dyn:\t\t-4.074765673050513\n",
      "Utility Loss Stat:\t\t3.855751751614212\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5688287338688354\n",
      "Val End Effector Loss:\t\t0.004791154594964941\n",
      "Val Smoothing Loss:\t\t0.009624756559006069\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.009430350227789446\n",
      "Val Privacy Loss Dyn:\t\t-3.4786105052498746\n",
      "Val Privacy Loss Stat:\t\t3.5729140146704745\n",
      "Val Utility Loss:\t\t-2.464924969949013\n",
      "Val Utility Loss Dyn:\t\t-4.083363356176487\n",
      "Val Utility Loss Stat:\t\t3.8368708644031493\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.493103947807994\n",
      "Utility Training Loss:\t\t4.073442859114332\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2390787422099381\n",
      "Utility Training Acc:\t\t0.04532874220684016\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.533128166892672\n",
      "Utility Training Coop Loss:\t3.872063869498128\n",
      "Privacy Training Coop Acc:\t0.19764812890122685\n",
      "Utility Training Coop Acc:\t0.25307952183571775\n",
      "Privacy Acc Adv:\t\t0.2377468815030774\n",
      "Privacy Acc Coop:\t\t0.1762928794178794\n",
      "Utility Acc Adv:\t\t0.0420997920997921\n",
      "Utility Acc Coop:\t\t0.26926975054453417\n",
      "Val Privacy Acc Adv:\t\t0.2510115358331972\n",
      "Val Privacy Acc Coop:\t\t0.15651543847908658\n",
      "Val Utility Acc Adv:\t\t0.03551136363636364\n",
      "Val Utility Acc Coop:\t\t0.2889907598988084\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 171/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.9655130322685701\n",
      "Validation Loss:\t\t-1.2044255777323727\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.590303260763321\n",
      "End Effector Loss:\t\t0.004986583593344072\n",
      "Smoothing Loss:\t\t\t0.010666597314593296\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006605936713872977\n",
      "Privacy Loss Dyn:\t\t-3.4896196235985864\n",
      "Privacy Loss Stat:\t\t3.5556789901796844\n",
      "Utility Loss:\t\t\t-2.189711866160688\n",
      "Utility Loss Dyn:\t\t-4.074604315965934\n",
      "Utility Loss Stat:\t\t3.8556331257314542\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5747082064097578\n",
      "Val End Effector Loss:\t\t0.004629470850052389\n",
      "Val Smoothing Loss:\t\t0.00956141218843231\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.006605075348999874\n",
      "Val Privacy Loss Dyn:\t\t-3.4716908158349598\n",
      "Val Privacy Loss Stat:\t\t3.537741568462908\n",
      "Val Utility Loss:\t\t-2.393760767850009\n",
      "Val Utility Loss Dyn:\t\t-4.098532743197827\n",
      "Val Utility Loss Stat:\t\t3.859156661782383\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4911483915332946\n",
      "Utility Training Loss:\t\t4.073043245783467\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24062500000309794\n",
      "Utility Training Acc:\t\t0.04295738046047841\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5317666426517857\n",
      "Utility Training Coop Loss:\t3.874348446386024\n",
      "Privacy Training Coop Acc:\t0.1987525987556967\n",
      "Utility Training Coop Acc:\t0.25012344075463666\n",
      "Privacy Acc Adv:\t\t0.2428989085270065\n",
      "Privacy Acc Coop:\t\t0.17447375259875259\n",
      "Utility Acc Adv:\t\t0.04272998960808756\n",
      "Utility Acc Coop:\t\t0.26944516633255816\n",
      "Val Privacy Acc Adv:\t\t0.26172951103980874\n",
      "Val Privacy Acc Coop:\t\t0.19285181361781664\n",
      "Val Utility Acc Adv:\t\t0.021952479338842975\n",
      "Val Utility Acc Coop:\t\t0.2654528237017226\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 172/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.9496761036653405\n",
      "Validation Loss:\t\t-1.070689777885987\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5896972243106786\n",
      "End Effector Loss:\t\t0.004943437787671254\n",
      "Smoothing Loss:\t\t\t0.010684748868053302\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006073655154006149\n",
      "Privacy Loss Dyn:\t\t-3.4924782722754686\n",
      "Privacy Loss Stat:\t\t3.553214822390471\n",
      "Utility Loss:\t\t\t-2.1721418939856134\n",
      "Utility Loss Dyn:\t\t-4.074384585735456\n",
      "Utility Loss Stat:\t\t3.857170405853811\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5769755460999229\n",
      "Val End Effector Loss:\t\t0.004525940925410125\n",
      "Val Smoothing Loss:\t\t0.00958777964596198\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.002499600579915953\n",
      "Val Privacy Loss Dyn:\t\t-3.490366241656059\n",
      "Val Privacy Loss Stat:\t\t3.5153622509034212\n",
      "Val Utility Loss:\t\t-2.260429752759697\n",
      "Val Utility Loss Dyn:\t\t-4.073849839612472\n",
      "Val Utility Loss Stat:\t\t3.8478068694595464\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.492208084048947\n",
      "Utility Training Loss:\t\t4.074419507861386\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24047557173176765\n",
      "Utility Training Acc:\t\t0.04359407484407484\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.534911081101939\n",
      "Utility Training Coop Loss:\t3.875004188682334\n",
      "Privacy Training Coop Acc:\t0.1966086278617258\n",
      "Utility Training Coop Acc:\t0.24885654886274478\n",
      "Privacy Acc Adv:\t\t0.24062500000309794\n",
      "Privacy Acc Coop:\t\t0.17666320166629962\n",
      "Utility Acc Adv:\t\t0.042327182952182955\n",
      "Utility Acc Coop:\t\t0.26708030146149736\n",
      "Val Privacy Acc Adv:\t\t0.2387870179165986\n",
      "Val Privacy Acc Coop:\t\t0.21518451561150717\n",
      "Val Utility Acc Adv:\t\t0.04396952479338843\n",
      "Val Utility Acc Coop:\t\t0.27871039946956083\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 173/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-0.9986216086611586\n",
      "Validation Loss:\t\t-0.5236024390174892\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.582604420872835\n",
      "End Effector Loss:\t\t0.004921103613460804\n",
      "Smoothing Loss:\t\t\t0.010643004971748051\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.005856819249488212\n",
      "Privacy Loss Dyn:\t\t-3.493917447365743\n",
      "Privacy Loss Stat:\t\t3.5524856380018526\n",
      "Utility Loss:\t\t\t-2.2065373854924637\n",
      "Utility Loss Dyn:\t\t-4.075343876271634\n",
      "Utility Loss Stat:\t\t3.8546901438191625\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5607630132643644\n",
      "Val End Effector Loss:\t\t0.004432752956963368\n",
      "Val Smoothing Loss:\t\t0.009566645172601643\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.004056131790492161\n",
      "Val Privacy Loss Dyn:\t\t-3.4731856042688545\n",
      "Val Privacy Loss Stat:\t\t3.513746923651577\n",
      "Val Utility Loss:\t\t-1.682317284513111\n",
      "Val Utility Loss Dyn:\t\t-4.074989918834907\n",
      "Val Utility Loss Stat:\t\t3.906758189201355\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4922525984333856\n",
      "Utility Training Loss:\t\t4.074577122616916\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2412941787941788\n",
      "Utility Training Acc:\t\t0.04224272349582145\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.533378984477069\n",
      "Utility Training Coop Loss:\t3.8730564610625997\n",
      "Privacy Training Coop Acc:\t0.19773258835758836\n",
      "Utility Training Coop Acc:\t0.2512149168430148\n",
      "Privacy Acc Adv:\t\t0.23762344074844075\n",
      "Privacy Acc Coop:\t\t0.1778846153846154\n",
      "Utility Acc Adv:\t\t0.042483108114304016\n",
      "Utility Acc Coop:\t\t0.2697765072827032\n",
      "Val Privacy Acc Adv:\t\t0.25945534895766864\n",
      "Val Privacy Acc Coop:\t\t0.21723628328913006\n",
      "Val Utility Acc Adv:\t\t0.04103535353706395\n",
      "Val Utility Acc Coop:\t\t0.21672692839518065\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 174/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.02982128016155\n",
      "Validation Loss:\t\t-0.9679783825562451\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5833146246827814\n",
      "End Effector Loss:\t\t0.00494924603270177\n",
      "Smoothing Loss:\t\t\t0.010653180220278596\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006644816941382236\n",
      "Privacy Loss Dyn:\t\t-3.4898788708411232\n",
      "Privacy Loss Stat:\t\t3.5563270428572276\n",
      "Utility Loss:\t\t\t-2.240004133038114\n",
      "Utility Loss Dyn:\t\t-4.075216382308215\n",
      "Utility Loss Stat:\t\t3.851215973217621\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5550832997176273\n",
      "Val End Effector Loss:\t\t0.004573819783616288\n",
      "Val Smoothing Loss:\t\t0.009588197355682015\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.008912014813462564\n",
      "Val Privacy Loss Dyn:\t\t-3.4887394121855744\n",
      "Val Privacy Loss Stat:\t\t3.5778595603202\n",
      "Val Utility Loss:\t\t-2.120395408189001\n",
      "Val Utility Loss Dyn:\t\t-4.0796311349908185\n",
      "Val Utility Loss Stat:\t\t3.867591600280163\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4905238947105013\n",
      "Utility Training Loss:\t\t4.0736147983158455\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24146959459769254\n",
      "Utility Training Acc:\t\t0.043724012474012475\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5345481525092017\n",
      "Utility Training Coop Loss:\t3.8692591049071408\n",
      "Privacy Training Coop Acc:\t0.19565358627858628\n",
      "Utility Training Coop Acc:\t0.25456081081390874\n",
      "Privacy Acc Adv:\t\t0.24187889812889812\n",
      "Privacy Acc Coop:\t\t0.1734797297328277\n",
      "Utility Acc Adv:\t\t0.04041060291060291\n",
      "Utility Acc Coop:\t\t0.2741164241195221\n",
      "Val Privacy Acc Adv:\t\t0.24380882690883865\n",
      "Val Privacy Acc Coop:\t\t0.15094123048754024\n",
      "Val Utility Acc Adv:\t\t0.03538223140495868\n",
      "Val Utility Acc Coop:\t\t0.2567220500493345\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 175/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.0422692914239737\n",
      "Validation Loss:\t\t-1.0033176241457955\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5810604587414161\n",
      "End Effector Loss:\t\t0.0049381576855560445\n",
      "Smoothing Loss:\t\t\t0.010632212493053624\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006353001398752732\n",
      "Privacy Loss Dyn:\t\t-3.4885420831474097\n",
      "Privacy Loss Stat:\t\t3.552072093789146\n",
      "Utility Loss:\t\t\t-2.247578004293779\n",
      "Utility Loss Dyn:\t\t-4.0749218813346975\n",
      "Utility Loss Stat:\t\t3.8501640825906067\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5461714772030342\n",
      "Val End Effector Loss:\t\t0.004537367704035791\n",
      "Val Smoothing Loss:\t\t0.009534821382816111\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.003864746571572359\n",
      "Val Privacy Loss Dyn:\t\t-3.555236243019419\n",
      "Val Privacy Loss Stat:\t\t3.5938837055332407\n",
      "Val Utility Loss:\t\t-2.1326671553052163\n",
      "Val Utility Loss Dyn:\t\t-4.0695231601226425\n",
      "Val Utility Loss Stat:\t\t3.8562564391735172\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4918443011642744\n",
      "Utility Training Loss:\t\t4.074152866916696\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24067697505197505\n",
      "Utility Training Acc:\t\t0.04245712058212058\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.533971654154407\n",
      "Utility Training Coop Loss:\t3.8679957536054994\n",
      "Privacy Training Coop Acc:\t0.1970504158004158\n",
      "Utility Training Coop Acc:\t0.25571075884195477\n",
      "Privacy Acc Adv:\t\t0.24288591476091476\n",
      "Privacy Acc Coop:\t\t0.17739734927234926\n",
      "Utility Acc Adv:\t\t0.04245712058212058\n",
      "Utility Acc Coop:\t\t0.27357718295837885\n",
      "Val Privacy Acc Adv:\t\t0.17262109733871683\n",
      "Val Privacy Acc Coop:\t\t0.1357681932974576\n",
      "Val Utility Acc Adv:\t\t0.045841942148760334\n",
      "Val Utility Acc Coop:\t\t0.26665088386575053\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 176/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.0572356781718977\n",
      "Validation Loss:\t\t-1.0459069790249336\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5781975504390415\n",
      "End Effector Loss:\t\t0.004922529744960197\n",
      "Smoothing Loss:\t\t\t0.010643559435901393\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006221991164025051\n",
      "Privacy Loss Dyn:\t\t-3.4932085709363654\n",
      "Privacy Loss Stat:\t\t3.555428477186175\n",
      "Utility Loss:\t\t\t-2.2567059760777717\n",
      "Utility Loss Dyn:\t\t-4.07431661413514\n",
      "Utility Loss Stat:\t\t3.8486460130080857\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5483445046731263\n",
      "Val End Effector Loss:\t\t0.004438117645827145\n",
      "Val Smoothing Loss:\t\t0.009562650191297463\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0036751261550532887\n",
      "Val Privacy Loss Dyn:\t\t-3.488423964208808\n",
      "Val Privacy Loss Stat:\t\t3.525175228591793\n",
      "Val Utility Loss:\t\t-2.1793971810459105\n",
      "Val Utility Loss Dyn:\t\t-4.073579379349701\n",
      "Val Utility Loss Stat:\t\t3.855639656220586\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4921900504839893\n",
      "Utility Training Loss:\t\t4.074476814319587\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2394035862847822\n",
      "Utility Training Acc:\t\t0.04239215176715177\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5348358682188326\n",
      "Utility Training Coop Loss:\t3.8681832120720907\n",
      "Privacy Training Coop Acc:\t0.1955821205883165\n",
      "Utility Training Coop Acc:\t0.2580821205883165\n",
      "Privacy Acc Adv:\t\t0.2386239605051564\n",
      "Privacy Acc Coop:\t\t0.17482458420578012\n",
      "Utility Acc Adv:\t\t0.042327182952182955\n",
      "Utility Acc Coop:\t\t0.2754287941849901\n",
      "Val Privacy Acc Adv:\t\t0.24257489669421486\n",
      "Val Privacy Acc Coop:\t\t0.20523415980013934\n",
      "Val Utility Acc Adv:\t\t0.04635847107438017\n",
      "Val Utility Acc Coop:\t\t0.2703239784214245\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 177/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.0502330055440972\n",
      "Validation Loss:\t\t-1.1635956388151596\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5794617409455801\n",
      "End Effector Loss:\t\t0.0049423551958503505\n",
      "Smoothing Loss:\t\t\t0.010651336801809543\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006561427533998311\n",
      "Privacy Loss Dyn:\t\t-3.4910492012257883\n",
      "Privacy Loss Stat:\t\t3.556663478238667\n",
      "Utility Loss:\t\t\t-2.2526142810337757\n",
      "Utility Loss Dyn:\t\t-4.074091593589704\n",
      "Utility Loss Stat:\t\t3.8488301650897876\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5469029452189926\n",
      "Val End Effector Loss:\t\t0.004499357685827735\n",
      "Val Smoothing Loss:\t\t0.009568240401173427\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t-0.0036926978875782865\n",
      "Val Privacy Loss Dyn:\t\t-3.567925787169086\n",
      "Val Privacy Loss Stat:\t\t3.5309988043525\n",
      "Val Utility Loss:\t\t-2.2869129102092143\n",
      "Val Utility Loss Dyn:\t\t-4.069431152225526\n",
      "Val Utility Loss Stat:\t\t3.8407398541111593\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4920033982290795\n",
      "Utility Training Loss:\t\t4.073388897951328\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24106029106648696\n",
      "Utility Training Acc:\t\t0.043366683991683995\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5356624054561783\n",
      "Utility Training Coop Loss:\t3.8680706314138464\n",
      "Privacy Training Coop Acc:\t0.19584199584819176\n",
      "Utility Training Coop Acc:\t0.2550805613336593\n",
      "Privacy Acc Adv:\t\t0.24167749480869072\n",
      "Privacy Acc Coop:\t\t0.17334979210289006\n",
      "Utility Acc Adv:\t\t0.043724012474012475\n",
      "Utility Acc Coop:\t\t0.27711798337417926\n",
      "Val Privacy Acc Adv:\t\t0.16079115014800355\n",
      "Val Privacy Acc Coop:\t\t0.1992366850329948\n",
      "Val Utility Acc Adv:\t\t0.0506198347107438\n",
      "Val Utility Acc Coop:\t\t0.28395460287401497\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 178/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.0377297530322493\n",
      "Validation Loss:\t\t-0.6763039348331427\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5787945965967158\n",
      "End Effector Loss:\t\t0.00494640893854681\n",
      "Smoothing Loss:\t\t\t0.010616647196244331\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.006476429203939537\n",
      "Privacy Loss Dyn:\t\t-3.4929372627373296\n",
      "Privacy Loss Stat:\t\t3.5577015544669295\n",
      "Utility Loss:\t\t\t-2.2385917274966807\n",
      "Utility Loss Dyn:\t\t-4.073746915170903\n",
      "Utility Loss Stat:\t\t3.8498877324086465\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5505169048782222\n",
      "Val End Effector Loss:\t\t0.004643553336370306\n",
      "Val Smoothing Loss:\t\t0.009534583994656924\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0021980318648756043\n",
      "Val Privacy Loss Dyn:\t\t-3.5169795524975487\n",
      "Val Privacy Loss Stat:\t\t3.538959870653704\n",
      "Val Utility Loss:\t\t-1.8127830836398542\n",
      "Val Utility Loss Dyn:\t\t-4.0778021580916795\n",
      "Val Utility Loss Stat:\t\t3.896523865293865\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4950735212115887\n",
      "Utility Training Loss:\t\t4.073284877560987\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.23809121621931417\n",
      "Utility Training Acc:\t\t0.0442762474012474\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.535624990839968\n",
      "Utility Training Coop Loss:\t3.8686548977036983\n",
      "Privacy Training Coop Acc:\t0.19647869023178818\n",
      "Utility Training Coop Acc:\t0.2568022349303329\n",
      "Privacy Acc Adv:\t\t0.24004028066837862\n",
      "Privacy Acc Coop:\t\t0.17205041580351377\n",
      "Utility Acc Adv:\t\t0.04317177754677755\n",
      "Utility Acc Coop:\t\t0.2752208939739919\n",
      "Val Privacy Acc Adv:\t\t0.21155446510731188\n",
      "Val Privacy Acc Coop:\t\t0.19044134527260115\n",
      "Val Utility Acc Adv:\t\t0.03730486685117661\n",
      "Val Utility Acc Coop:\t\t0.2249196510577251\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 179/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.080638059596928\n",
      "Validation Loss:\t\t-0.7846435094406167\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5761386139353198\n",
      "End Effector Loss:\t\t0.004895460999061561\n",
      "Smoothing Loss:\t\t\t0.01063818863898965\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.005944841338046623\n",
      "Privacy Loss Dyn:\t\t-3.4903859199952185\n",
      "Privacy Loss Stat:\t\t3.549834331454953\n",
      "Utility Loss:\t\t\t-2.275670156657324\n",
      "Utility Loss Dyn:\t\t-4.075008705599145\n",
      "Utility Loss Stat:\t\t3.847441697814608\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5439385573479755\n",
      "Val End Effector Loss:\t\t0.004608899424206619\n",
      "Val Smoothing Loss:\t\t0.009555585242707805\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t-0.0020409621729338464\n",
      "Val Privacy Loss Dyn:\t\t-3.557831687868134\n",
      "Val Privacy Loss Stat:\t\t3.5374220722963003\n",
      "Val Utility Loss:\t\t-1.903755314093976\n",
      "Val Utility Loss Dyn:\t\t-4.0779312725894705\n",
      "Val Utility Loss Stat:\t\t3.8875557469927573\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.490900288004885\n",
      "Utility Training Loss:\t\t4.0749102669793205\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.24155405405405406\n",
      "Utility Training Acc:\t\t0.042164760914760915\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5322455626267653\n",
      "Utility Training Coop Loss:\t3.8659487157254606\n",
      "Privacy Training Coop Acc:\t0.2000194906475886\n",
      "Utility Training Coop Acc:\t0.25975831601141397\n",
      "Privacy Acc Adv:\t\t0.2417814449064449\n",
      "Privacy Acc Coop:\t\t0.18034693347812938\n",
      "Utility Acc Adv:\t\t0.042781964656964655\n",
      "Utility Acc Coop:\t\t0.27775467775777574\n",
      "Val Privacy Acc Adv:\t\t0.16945735766929537\n",
      "Val Privacy Acc Coop:\t\t0.19268681130502835\n",
      "Val Utility Acc Adv:\t\t0.03698203627266421\n",
      "Val Utility Acc Coop:\t\t0.23382977502466726\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 180/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.0805315795681767\n",
      "Validation Loss:\t\t-1.2487239040865385\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5746317865818801\n",
      "End Effector Loss:\t\t0.004903616817143365\n",
      "Smoothing Loss:\t\t\t0.010613906931077863\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.005845370077045941\n",
      "Privacy Loss Dyn:\t\t-3.492313332468457\n",
      "Privacy Loss Stat:\t\t3.550767039063071\n",
      "Utility Loss:\t\t\t-2.272385860926892\n",
      "Utility Loss Dyn:\t\t-4.0743077725729675\n",
      "Utility Loss Stat:\t\t3.8470691834071076\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5327044506826677\n",
      "Val End Effector Loss:\t\t0.00443068132466398\n",
      "Val Smoothing Loss:\t\t0.009495286176689276\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.001944655229237454\n",
      "Val Privacy Loss Dyn:\t\t-3.5189598123889323\n",
      "Val Privacy Loss Stat:\t\t3.5384063632035057\n",
      "Val Utility Loss:\t\t-2.3489940028545284\n",
      "Val Utility Loss Dyn:\t\t-4.081271507523277\n",
      "Val Utility Loss Stat:\t\t3.8463721147253493\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.494994661168596\n",
      "Utility Training Loss:\t\t4.074979970955799\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.23729859667359668\n",
      "Utility Training Acc:\t\t0.04369152806652807\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5331420442418597\n",
      "Utility Training Coop Loss:\t3.8659657076341944\n",
      "Privacy Training Coop Acc:\t0.198739604989605\n",
      "Utility Training Coop Acc:\t0.2598232848263828\n",
      "Privacy Acc Adv:\t\t0.24004028066837862\n",
      "Privacy Acc Coop:\t\t0.17864475052284848\n",
      "Utility Acc Adv:\t\t0.041482588357588356\n",
      "Utility Acc Coop:\t\t0.277137474015572\n",
      "Val Privacy Acc Adv:\t\t0.2106577135191476\n",
      "Val Privacy Acc Coop:\t\t0.19133092287527628\n",
      "Val Utility Acc Adv:\t\t0.04003099173553719\n",
      "Val Utility Acc Coop:\t\t0.2787319214876033\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 181/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.0749552307181882\n",
      "Validation Loss:\t\t-0.985435648644266\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5707744420380205\n",
      "End Effector Loss:\t\t0.004895011242382275\n",
      "Smoothing Loss:\t\t\t0.01064532562623695\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.005142479143618546\n",
      "Privacy Loss Dyn:\t\t-3.497969088336286\n",
      "Privacy Loss Stat:\t\t3.5493938774180265\n",
      "Utility Loss:\t\t\t-2.258477581761731\n",
      "Utility Loss Dyn:\t\t-4.073390576547\n",
      "Utility Loss Stat:\t\t3.847542821493565\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5424642993891535\n",
      "Val End Effector Loss:\t\t0.004494595232184915\n",
      "Val Smoothing Loss:\t\t0.00952123484116294\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0009587150959929159\n",
      "Val Privacy Loss Dyn:\t\t-3.5038540757392065\n",
      "Val Privacy Loss Stat:\t\t3.5134412331029403\n",
      "Val Utility Loss:\t\t-2.104381261778272\n",
      "Val Utility Loss Dyn:\t\t-4.07625752342634\n",
      "Val Utility Loss Stat:\t\t3.865819411336883\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4960506512568545\n",
      "Utility Training Loss:\t\t4.0730885485353685\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.23640202703012497\n",
      "Utility Training Acc:\t\t0.04443866943866944\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.530031082288143\n",
      "Utility Training Coop Loss:\t3.867646705583822\n",
      "Privacy Training Coop Acc:\t0.1999675155987115\n",
      "Utility Training Coop Acc:\t0.25769880457380456\n",
      "Privacy Acc Adv:\t\t0.23364085239395035\n",
      "Privacy Acc Coop:\t\t0.18112655925775517\n",
      "Utility Acc Adv:\t\t0.04430873180873181\n",
      "Utility Acc Coop:\t\t0.27722193347193347\n",
      "Val Privacy Acc Adv:\t\t0.22734446740470643\n",
      "Val Privacy Acc Coop:\t\t0.21696367080916057\n",
      "Val Utility Acc Adv:\t\t0.041874713041196186\n",
      "Val Utility Acc Coop:\t\t0.2576188016528926\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 182/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.1160807862370556\n",
      "Validation Loss:\t\t-1.3775064562070223\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5700510002037592\n",
      "End Effector Loss:\t\t0.004864910932832829\n",
      "Smoothing Loss:\t\t\t0.01062245383808339\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0050588646388599135\n",
      "Privacy Loss Dyn:\t\t-3.5014615492612555\n",
      "Privacy Loss Stat:\t\t3.5520501865418685\n",
      "Utility Loss:\t\t\t-2.297973926250751\n",
      "Utility Loss Dyn:\t\t-4.074487206346032\n",
      "Utility Loss Stat:\t\t3.8446898182811458\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5279100717099245\n",
      "Val End Effector Loss:\t\t0.0044106154414932895\n",
      "Val Smoothing Loss:\t\t0.009541043512376933\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.013462025641409818\n",
      "Val Privacy Loss Dyn:\t\t-3.486559701852562\n",
      "Val Privacy Loss Stat:\t\t3.6211799530943565\n",
      "Val Utility Loss:\t\t-2.4798223716168364\n",
      "Val Utility Loss Dyn:\t\t-4.085436814580082\n",
      "Val Utility Loss Stat:\t\t3.837454571704234\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4977411728143197\n",
      "Utility Training Loss:\t\t4.073009327146963\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.23508965696465697\n",
      "Utility Training Acc:\t\t0.04480899168708964\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.532631809894855\n",
      "Utility Training Coop Loss:\t3.865209940069678\n",
      "Privacy Training Coop Acc:\t0.19851221413721415\n",
      "Utility Training Coop Acc:\t0.25925805613305614\n",
      "Privacy Acc Adv:\t\t0.23076923076923078\n",
      "Privacy Acc Coop:\t\t0.17765722453222454\n",
      "Utility Acc Adv:\t\t0.04182042619852415\n",
      "Utility Acc Coop:\t\t0.27997661123280715\n",
      "Val Privacy Acc Adv:\t\t0.24480601469408875\n",
      "Val Privacy Acc Coop:\t\t0.10908803948747718\n",
      "Val Utility Acc Adv:\t\t0.03278523875200305\n",
      "Val Utility Acc Coop:\t\t0.2873909550080122\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 183/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.0872041854364585\n",
      "Validation Loss:\t\t-0.743991631271764\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5696177525666548\n",
      "End Effector Loss:\t\t0.004898274266073895\n",
      "Smoothing Loss:\t\t\t0.010639402817880537\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.004831765180070286\n",
      "Privacy Loss Dyn:\t\t-3.5007183596398876\n",
      "Privacy Loss Stat:\t\t3.5490360116264674\n",
      "Utility Loss:\t\t\t-2.2680879343076454\n",
      "Utility Loss Dyn:\t\t-4.073012878642013\n",
      "Utility Loss Stat:\t\t3.8462040892757647\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5407832356647027\n",
      "Val End Effector Loss:\t\t0.00453100940077912\n",
      "Val Smoothing Loss:\t\t0.009510806545207261\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0006617268254934264\n",
      "Val Privacy Loss Dyn:\t\t-3.5128586972055356\n",
      "Val Privacy Loss Stat:\t\t3.519475962997468\n",
      "Val Utility Loss:\t\t-1.8592832581070828\n",
      "Val Utility Loss Dyn:\t\t-4.077215345437861\n",
      "Val Utility Loss Stat:\t\t3.891287020415314\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.4979035549500876\n",
      "Utility Training Loss:\t\t4.071869428836878\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.23664241164860755\n",
      "Utility Training Acc:\t\t0.04583549896049896\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.530186318062447\n",
      "Utility Training Coop Loss:\t3.8639474881661906\n",
      "Privacy Training Coop Acc:\t0.20084459460079052\n",
      "Utility Training Coop Acc:\t0.26066787942097736\n",
      "Privacy Acc Adv:\t\t0.22930093555713146\n",
      "Privacy Acc Coop:\t\t0.1817762474074433\n",
      "Utility Acc Adv:\t\t0.043886434511434515\n",
      "Utility Acc Coop:\t\t0.27878118503118504\n",
      "Val Privacy Acc Adv:\t\t0.21669105831379734\n",
      "Val Privacy Acc Coop:\t\t0.21076532370172257\n",
      "Val Utility Acc Adv:\t\t0.043309515611507185\n",
      "Val Utility Acc Coop:\t\t0.231734963272475\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 184/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.0673778868433312\n",
      "Validation Loss:\t\t-1.0806890984358313\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5681454708757123\n",
      "End Effector Loss:\t\t0.004884648039257406\n",
      "Smoothing Loss:\t\t\t0.010628315153010886\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.00472277065200766\n",
      "Privacy Loss Dyn:\t\t-3.5059669491159196\n",
      "Privacy Loss Stat:\t\t3.5531946522282465\n",
      "Utility Loss:\t\t\t-2.245161191341535\n",
      "Utility Loss Dyn:\t\t-4.073651346248302\n",
      "Utility Loss Stat:\t\t3.8491352261228027\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5439396770286166\n",
      "Val End Effector Loss:\t\t0.004615760819162896\n",
      "Val Smoothing Loss:\t\t0.009563761711320725\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.004786277359182184\n",
      "Val Privacy Loss Dyn:\t\t-3.4965424355396553\n",
      "Val Privacy Loss Stat:\t\t3.544405202235072\n",
      "Val Utility Loss:\t\t-2.206661776077649\n",
      "Val Utility Loss Dyn:\t\t-4.070497183267736\n",
      "Val Utility Loss Stat:\t\t3.849831001325087\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.501110864032579\n",
      "Utility Training Loss:\t\t4.073718694540171\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.2322115384646364\n",
      "Utility Training Acc:\t\t0.04343165280665281\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5298286406265227\n",
      "Utility Training Coop Loss:\t3.86625697384753\n",
      "Privacy Training Coop Acc:\t0.20183861746671541\n",
      "Utility Training Coop Acc:\t0.25940098752908547\n",
      "Privacy Acc Adv:\t\t0.22366813929623724\n",
      "Privacy Acc Coop:\t\t0.17691008316008316\n",
      "Utility Acc Adv:\t\t0.04313929313929314\n",
      "Utility Acc Coop:\t\t0.274941528072724\n",
      "Val Privacy Acc Adv:\t\t0.23287563131398653\n",
      "Val Privacy Acc Coop:\t\t0.18459452479338842\n",
      "Val Utility Acc Adv:\t\t0.05060548668588735\n",
      "Val Utility Acc Coop:\t\t0.27431990360179226\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 185/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.0920704139160329\n",
      "Validation Loss:\t\t-1.2772274999917785\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5717385044464698\n",
      "End Effector Loss:\t\t0.004916897223170328\n",
      "Smoothing Loss:\t\t\t0.010616985410587424\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.004231048101199144\n",
      "Privacy Loss Dyn:\t\t-3.505901399868194\n",
      "Privacy Loss Stat:\t\t3.548211880632349\n",
      "Utility Loss:\t\t\t-2.2765463196562132\n",
      "Utility Loss Dyn:\t\t-4.073022809940663\n",
      "Utility Loss Stat:\t\t3.845368180354271\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5374250891041165\n",
      "Val End Effector Loss:\t\t0.004391231523607357\n",
      "Val Smoothing Loss:\t\t0.009528498694469983\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t-0.0010526549717611517\n",
      "Val Privacy Loss Dyn:\t\t-3.5715484298950386\n",
      "Val Privacy Loss Stat:\t\t3.561021881655228\n",
      "Val Utility Loss:\t\t-2.3840017555173763\n",
      "Val Utility Loss Dyn:\t\t-4.075196927244013\n",
      "Val Utility Loss Stat:\t\t3.8367967640072846\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.5006718454638537\n",
      "Utility Training Loss:\t\t4.073553974068338\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.23149688149997946\n",
      "Utility Training Acc:\t\t0.04430873180873181\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.530944885434331\n",
      "Utility Training Coop Loss:\t3.8659901534693155\n",
      "Privacy Training Coop Acc:\t0.1995517151767152\n",
      "Utility Training Coop Acc:\t0.25830951144070735\n",
      "Privacy Acc Adv:\t\t0.22433731808731808\n",
      "Privacy Acc Coop:\t\t0.18194516632016633\n",
      "Utility Acc Adv:\t\t0.04437370062370062\n",
      "Utility Acc Coop:\t\t0.27922946986066577\n",
      "Val Privacy Acc Adv:\t\t0.1565943526273424\n",
      "Val Privacy Acc Coop:\t\t0.1684745179165986\n",
      "Val Utility Acc Adv:\t\t0.039514462809917356\n",
      "Val Utility Acc Coop:\t\t0.2882805326260811\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 186/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.124754961212156\n",
      "Validation Loss:\t\t-1.0785847193415254\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5682616256130956\n",
      "End Effector Loss:\t\t0.0048863099120255256\n",
      "Smoothing Loss:\t\t\t0.010631917207647045\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.003841835811827138\n",
      "Privacy Loss Dyn:\t\t-3.512424463046068\n",
      "Privacy Loss Stat:\t\t3.550842816765244\n",
      "Utility Loss:\t\t\t-2.3019021127427193\n",
      "Utility Loss Dyn:\t\t-4.074479671129318\n",
      "Utility Loss Stat:\t\t3.844289459458508\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5261668322130668\n",
      "Val End Effector Loss:\t\t0.004483391240735592\n",
      "Val Smoothing Loss:\t\t0.009539798740105134\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t-1.1587130629326686e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.514179868639008\n",
      "Val Privacy Loss Stat:\t\t3.514064000165167\n",
      "Val Utility Loss:\t\t-2.1640095828978483\n",
      "Val Utility Loss Dyn:\t\t-4.079818140376698\n",
      "Val Utility Loss Stat:\t\t3.863417182086913\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.5023143108074484\n",
      "Utility Training Loss:\t\t4.073531565695939\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.23042489605299402\n",
      "Utility Training Acc:\t\t0.044406185031185035\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5292183076517496\n",
      "Utility Training Coop Loss:\t3.862339231427643\n",
      "Privacy Training Coop Acc:\t0.20151377339187135\n",
      "Utility Training Coop Acc:\t0.2612980769292728\n",
      "Privacy Acc Adv:\t\t0.2152221933502913\n",
      "Privacy Acc Coop:\t\t0.17896959459769254\n",
      "Utility Acc Adv:\t\t0.04203482328482328\n",
      "Utility Acc Coop:\t\t0.2803534303565283\n",
      "Val Privacy Acc Adv:\t\t0.21237947659428455\n",
      "Val Privacy Acc Coop:\t\t0.21589474288423446\n",
      "Val Utility Acc Adv:\t\t0.03551136363636364\n",
      "Val Utility Acc Coop:\t\t0.26038797064261004\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 187/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.140542717267161\n",
      "Validation Loss:\t\t-1.2720055560358177\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.567438793591303\n",
      "End Effector Loss:\t\t0.0048909484737469444\n",
      "Smoothing Loss:\t\t\t0.010598625123729298\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0029273149934974877\n",
      "Privacy Loss Dyn:\t\t-3.521651734433402\n",
      "Privacy Loss Stat:\t\t3.550924881084545\n",
      "Utility Loss:\t\t\t-2.3150344420371582\n",
      "Utility Loss Dyn:\t\t-4.073859481206803\n",
      "Utility Loss Stat:\t\t3.8423560339794833\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5340747711949112\n",
      "Val End Effector Loss:\t\t0.0044389744823190485\n",
      "Val Smoothing Loss:\t\t0.009543639862686703\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0018806322054429488\n",
      "Val Privacy Loss Dyn:\t\t-3.582998839291659\n",
      "Val Privacy Loss Stat:\t\t3.6018051633164903\n",
      "Val Utility Loss:\t\t-2.3751056214009436\n",
      "Val Utility Loss Dyn:\t\t-4.08892976597321\n",
      "Val Utility Loss Stat:\t\t3.851419191715146\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.505667033661428\n",
      "Utility Training Loss:\t\t4.072816395214343\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.22643581082320263\n",
      "Utility Training Acc:\t\t0.044341216216216214\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.530549231041494\n",
      "Utility Training Coop Loss:\t3.861271425493046\n",
      "Privacy Training Coop Acc:\t0.2021894490892327\n",
      "Utility Training Coop Acc:\t0.2643711018741998\n",
      "Privacy Acc Adv:\t\t0.20421647610386792\n",
      "Privacy Acc Coop:\t\t0.1787746881527861\n",
      "Utility Acc Adv:\t\t0.0425545738045738\n",
      "Utility Acc Coop:\t\t0.28262084202062565\n",
      "Val Privacy Acc Adv:\t\t0.1473900941239039\n",
      "Val Privacy Acc Coop:\t\t0.1279556932974576\n",
      "Val Utility Acc Adv:\t\t0.02815082644628099\n",
      "Val Utility Acc Coop:\t\t0.2718592171734276\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 188/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.1515665859886273\n",
      "Validation Loss:\t\t-1.1979026003232733\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.569483696546971\n",
      "End Effector Loss:\t\t0.004915841666327135\n",
      "Smoothing Loss:\t\t\t0.010622034624331242\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.002486930598588099\n",
      "Privacy Loss Dyn:\t\t-3.5264547656826566\n",
      "Privacy Loss Stat:\t\t3.5513240750762876\n",
      "Utility Loss:\t\t\t-2.329802856128082\n",
      "Utility Loss Dyn:\t\t-4.075185337334314\n",
      "Utility Loss Stat:\t\t3.842205052564149\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.545972586170701\n",
      "Val End Effector Loss:\t\t0.004590508548739128\n",
      "Val Smoothing Loss:\t\t0.009534580172193507\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t-0.0006923285767066578\n",
      "Val Privacy Loss Dyn:\t\t-3.523579289105313\n",
      "Val Privacy Loss Stat:\t\t3.516656004200297\n",
      "Val Utility Loss:\t\t-2.322349698090356\n",
      "Val Utility Loss Dyn:\t\t-4.070273300340353\n",
      "Val Utility Loss Stat:\t\t3.8380383356543613\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.505035079442538\n",
      "Utility Training Loss:\t\t4.074732852576924\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.22529235967045763\n",
      "Utility Training Acc:\t\t0.04313929313929314\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.531103962424391\n",
      "Utility Training Coop Loss:\t3.8612015467919334\n",
      "Privacy Training Coop Acc:\t0.19968165280665282\n",
      "Utility Training Coop Acc:\t0.2628898128960088\n",
      "Privacy Acc Adv:\t\t0.1983822765072765\n",
      "Privacy Acc Coop:\t\t0.17820945945945946\n",
      "Utility Acc Adv:\t\t0.04183991683991684\n",
      "Utility Acc Coop:\t\t0.2829002079064038\n",
      "Val Privacy Acc Adv:\t\t0.20265151517204016\n",
      "Val Privacy Acc Coop:\t\t0.2139218893548674\n",
      "Val Utility Acc Adv:\t\t0.050684400826446284\n",
      "Val Utility Acc Coop:\t\t0.2862502869741976\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 189/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.160227802913179\n",
      "Validation Loss:\t\t-1.1378281925543219\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5668024685303535\n",
      "End Effector Loss:\t\t0.0049115834312838755\n",
      "Smoothing Loss:\t\t\t0.01058046611581625\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0017872929511099991\n",
      "Privacy Loss Dyn:\t\t-3.529409081177503\n",
      "Privacy Loss Stat:\t\t3.547282011246235\n",
      "Utility Loss:\t\t\t-2.332273015361318\n",
      "Utility Loss Dyn:\t\t-4.074868503330651\n",
      "Utility Loss Stat:\t\t3.84164120650341\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5310515460273451\n",
      "Val End Effector Loss:\t\t0.004381405230041994\n",
      "Val Smoothing Loss:\t\t0.009512802968879254\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t-0.002739796091702359\n",
      "Val Privacy Loss Dyn:\t\t-3.583933201210558\n",
      "Val Privacy Loss Stat:\t\t3.556535237091632\n",
      "Val Utility Loss:\t\t-2.230111303408284\n",
      "Val Utility Loss Dyn:\t\t-4.080745811797371\n",
      "Val Utility Loss Stat:\t\t3.857734684116584\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.505050300312637\n",
      "Utility Training Loss:\t\t4.073763967303873\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.22831340956650753\n",
      "Utility Training Acc:\t\t0.045543139293139294\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.529751108738588\n",
      "Utility Training Coop Loss:\t3.8609267230341193\n",
      "Privacy Training Coop Acc:\t0.2017411642442622\n",
      "Utility Training Coop Acc:\t0.26424766113505294\n",
      "Privacy Acc Adv:\t\t0.1948544698575678\n",
      "Privacy Acc Coop:\t\t0.18280275468085264\n",
      "Utility Acc Adv:\t\t0.041645010395010396\n",
      "Utility Acc Coop:\t\t0.2821790540664459\n",
      "Val Privacy Acc Adv:\t\t0.1476985766775598\n",
      "Val Privacy Acc Coop:\t\t0.17378328742136148\n",
      "Val Utility Acc Adv:\t\t0.03498048668588735\n",
      "Val Utility Acc Coop:\t\t0.2657828282965116\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 190/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.1521098845272388\n",
      "Validation Loss:\t\t-0.21973612378082\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.566206430570995\n",
      "End Effector Loss:\t\t0.0049120832165401125\n",
      "Smoothing Loss:\t\t\t0.01063477873110954\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0010732176274123161\n",
      "Privacy Loss Dyn:\t\t-3.531929592828493\n",
      "Privacy Loss Stat:\t\t3.5426617741832613\n",
      "Utility Loss:\t\t\t-2.322412383779419\n",
      "Utility Loss Dyn:\t\t-4.074345092515688\n",
      "Utility Loss Stat:\t\t3.842103849825393\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5389051012510111\n",
      "Val End Effector Loss:\t\t0.00457468493610682\n",
      "Val Smoothing Loss:\t\t0.009535419872061404\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t-0.0002544937917023651\n",
      "Val Privacy Loss Dyn:\t\t-3.525752153770983\n",
      "Val Privacy Loss Stat:\t\t3.523207214253008\n",
      "Val Utility Loss:\t\t-1.330472780653268\n",
      "Val Utility Loss Dyn:\t\t-4.073047619220639\n",
      "Val Utility Loss Stat:\t\t3.940000347362077\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.5051102898472806\n",
      "Utility Training Loss:\t\t4.0728311005848115\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.22790410603530195\n",
      "Utility Training Acc:\t\t0.04456860706860707\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.527088282757638\n",
      "Utility Training Coop Loss:\t3.8604620008607418\n",
      "Privacy Training Coop Acc:\t0.20396309771929363\n",
      "Utility Training Coop Acc:\t0.2633965696496676\n",
      "Privacy Acc Adv:\t\t0.19236616424736014\n",
      "Privacy Acc Coop:\t\t0.18746101871721463\n",
      "Utility Acc Adv:\t\t0.04265202702702703\n",
      "Utility Acc Coop:\t\t0.2823154885716845\n",
      "Val Privacy Acc Adv:\t\t0.19575728882442822\n",
      "Val Privacy Acc Coop:\t\t0.2070133149747021\n",
      "Val Utility Acc Adv:\t\t0.044988234619771646\n",
      "Val Utility Acc Coop:\t\t0.18113665061056122\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 191/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.1764866802008849\n",
      "Validation Loss:\t\t-1.1470879674889147\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5629420025185091\n",
      "End Effector Loss:\t\t0.0049195651707032275\n",
      "Smoothing Loss:\t\t\t0.010608000631430603\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0009341734672534491\n",
      "Privacy Loss Dyn:\t\t-3.535622884726574\n",
      "Privacy Loss Stat:\t\t3.544964615619604\n",
      "Utility Loss:\t\t\t-2.3400484271455952\n",
      "Utility Loss Dyn:\t\t-4.0766261783806055\n",
      "Utility Loss Stat:\t\t3.8426213356164785\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5270491260881266\n",
      "Val End Effector Loss:\t\t0.004445172426356234\n",
      "Val Smoothing Loss:\t\t0.00949971919998619\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.005982317276730025\n",
      "Val Privacy Loss Dyn:\t\t-3.5367225408554077\n",
      "Val Privacy Loss Stat:\t\t3.5965457026623495\n",
      "Val Utility Loss:\t\t-2.2401128721631265\n",
      "Val Utility Loss Dyn:\t\t-4.0806264458609025\n",
      "Val Utility Loss Stat:\t\t3.856615158151989\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.5036919040144605\n",
      "Utility Training Loss:\t\t4.075218184326394\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.22769620582430378\n",
      "Utility Training Acc:\t\t0.04191787942097737\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.527980083487386\n",
      "Utility Training Coop Loss:\t3.8608866778827755\n",
      "Privacy Training Coop Acc:\t0.20297557172866967\n",
      "Utility Training Coop Acc:\t0.2652481808762788\n",
      "Privacy Acc Adv:\t\t0.1888318607068607\n",
      "Privacy Acc Coop:\t\t0.18538851351351351\n",
      "Utility Acc Adv:\t\t0.0395010395010395\n",
      "Utility Acc Coop:\t\t0.2816528066559046\n",
      "Val Privacy Acc Adv:\t\t0.19077852387597\n",
      "Val Privacy Acc Coop:\t\t0.1331353305785124\n",
      "Val Utility Acc Adv:\t\t0.03460743801652893\n",
      "Val Utility Acc Coop:\t\t0.2658258723633841\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 192/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.211549782052853\n",
      "Validation Loss:\t\t-1.1797507607478126\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5660202198055826\n",
      "End Effector Loss:\t\t0.0049618418965480925\n",
      "Smoothing Loss:\t\t\t0.01063213095150253\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.001022768088784882\n",
      "Privacy Loss Dyn:\t\t-3.5366301645608056\n",
      "Privacy Loss Stat:\t\t3.546857838075523\n",
      "Utility Loss:\t\t\t-2.381471221511428\n",
      "Utility Loss Dyn:\t\t-4.07603653428956\n",
      "Utility Loss Stat:\t\t3.837889410353996\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5519374602220275\n",
      "Val End Effector Loss:\t\t0.004485414291285594\n",
      "Val Smoothing Loss:\t\t0.009551440584011498\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.005123109179587404\n",
      "Val Privacy Loss Dyn:\t\t-3.538045018172461\n",
      "Val Privacy Loss Stat:\t\t3.589276108367384\n",
      "Val Utility Loss:\t\t-2.3218885295647236\n",
      "Val Utility Loss Dyn:\t\t-4.080922148444436\n",
      "Val Utility Loss Stat:\t\t3.8487332965716843\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.503580951145434\n",
      "Utility Training Loss:\t\t4.074715530054485\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.22846283783783783\n",
      "Utility Training Acc:\t\t0.04307432432432432\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.530562460546434\n",
      "Utility Training Coop Loss:\t3.856975964349917\n",
      "Privacy Training Coop Acc:\t0.20049376299376298\n",
      "Utility Training Coop Acc:\t0.26646959459459457\n",
      "Privacy Acc Adv:\t\t0.18870192307692307\n",
      "Privacy Acc Coop:\t\t0.1831795738045738\n",
      "Utility Acc Adv:\t\t0.04002079002079002\n",
      "Utility Acc Coop:\t\t0.28673986486486486\n",
      "Val Privacy Acc Adv:\t\t0.1899248163469813\n",
      "Val Privacy Acc Coop:\t\t0.1400439049586777\n",
      "Val Utility Acc Adv:\t\t0.0349948347107438\n",
      "Val Utility Acc Coop:\t\t0.2750086088256895\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 193/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.2122465737721653\n",
      "Validation Loss:\t\t-1.1262443723149351\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5594155954471992\n",
      "End Effector Loss:\t\t0.004871620769271716\n",
      "Smoothing Loss:\t\t\t0.010605848059367986\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0011308818064211807\n",
      "Privacy Loss Dyn:\t\t-3.5382233399611254\n",
      "Privacy Loss Stat:\t\t3.549532160937414\n",
      "Utility Loss:\t\t\t-2.368897812777894\n",
      "Utility Loss Dyn:\t\t-4.075626062256383\n",
      "Utility Loss Stat:\t\t3.838736281325564\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5294819522864562\n",
      "Val End Effector Loss:\t\t0.004413703883216862\n",
      "Val Smoothing Loss:\t\t0.009504983264160119\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t-0.003007578825162462\n",
      "Val Privacy Loss Dyn:\t\t-3.544864938278829\n",
      "Val Privacy Loss Stat:\t\t3.514789152736506\n",
      "Val Utility Loss:\t\t-2.215129355753749\n",
      "Val Utility Loss Dyn:\t\t-4.079504921909206\n",
      "Val Utility Loss Stat:\t\t3.8579919855456706\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.501849988641957\n",
      "Utility Training Loss:\t\t4.074911077156385\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.22943737006237006\n",
      "Utility Training Acc:\t\t0.04295738046047841\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5311684742291107\n",
      "Utility Training Coop Loss:\t3.8554903645525354\n",
      "Privacy Training Coop Acc:\t0.2000389812889813\n",
      "Utility Training Coop Acc:\t0.2675675675737635\n",
      "Privacy Acc Adv:\t\t0.18824714137214138\n",
      "Privacy Acc Coop:\t\t0.17999610187110188\n",
      "Utility Acc Adv:\t\t0.04057302494802495\n",
      "Utility Acc Coop:\t\t0.28527156965276557\n",
      "Val Privacy Acc Adv:\t\t0.185491276427734\n",
      "Val Privacy Acc Coop:\t\t0.21543560608113108\n",
      "Val Utility Acc Adv:\t\t0.03583419421487603\n",
      "Val Utility Acc Coop:\t\t0.26398932508939554\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 194/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.215860561283766\n",
      "Validation Loss:\t\t-1.3208134597636882\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5577029563842841\n",
      "End Effector Loss:\t\t0.004887686536759681\n",
      "Smoothing Loss:\t\t\t0.010620489211660072\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0010469953322361017\n",
      "Privacy Loss Dyn:\t\t-3.5396245792353227\n",
      "Privacy Loss Stat:\t\t3.5500945355936793\n",
      "Utility Loss:\t\t\t-2.3690626219751434\n",
      "Utility Loss Dyn:\t\t-4.074769024045948\n",
      "Utility Loss Stat:\t\t3.8378627605101174\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5249648189002817\n",
      "Val End Effector Loss:\t\t0.004419208849176057\n",
      "Val Smoothing Loss:\t\t0.009527882395604672\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0022367652782723925\n",
      "Val Privacy Loss Dyn:\t\t-3.5452740970721917\n",
      "Val Privacy Loss Stat:\t\t3.5676417404955085\n",
      "Val Utility Loss:\t\t-2.4059827189800167\n",
      "Val Utility Loss Dyn:\t\t-4.072814090685411\n",
      "Val Utility Loss Stat:\t\t3.8322158248956537\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.5037190056640246\n",
      "Utility Training Loss:\t\t4.074843128109176\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.22663721414341004\n",
      "Utility Training Acc:\t\t0.043301715176715175\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.529578250312012\n",
      "Utility Training Coop Loss:\t3.854999760332326\n",
      "Privacy Training Coop Acc:\t0.20043529108507468\n",
      "Utility Training Coop Acc:\t0.2676195426226406\n",
      "Privacy Acc Adv:\t\t0.18701923079401442\n",
      "Privacy Acc Coop:\t\t0.18067177755297345\n",
      "Utility Acc Adv:\t\t0.042846933471933475\n",
      "Utility Acc Coop:\t\t0.28756496881806676\n",
      "Val Privacy Acc Adv:\t\t0.1837551652892562\n",
      "Val Privacy Acc Coop:\t\t0.16178833792555677\n",
      "Val Utility Acc Adv:\t\t0.04059773875200305\n",
      "Val Utility Acc Coop:\t\t0.2916236226100567\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 195/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t-1.2394591259195038\n",
      "Validation Loss:\t\t-1.0641736457978705\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5555108801119045\n",
      "End Effector Loss:\t\t0.004887549615399273\n",
      "Smoothing Loss:\t\t\t0.010596481193023543\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0008417578286291904\n",
      "Privacy Loss Dyn:\t\t-3.5389414138456887\n",
      "Privacy Loss Stat:\t\t3.547358983023994\n",
      "Utility Loss:\t\t\t-2.3879996357241686\n",
      "Utility Loss Dyn:\t\t-4.074192209699794\n",
      "Utility Loss Stat:\t\t3.8353922434011767\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5124255601655353\n",
      "Val End Effector Loss:\t\t0.004371435898606288\n",
      "Val Smoothing Loss:\t\t0.00951510606803123\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t-0.00031421918514346287\n",
      "Val Privacy Loss Dyn:\t\t-3.53990095114905\n",
      "Val Privacy Loss Stat:\t\t3.536758770627424\n",
      "Val Utility Loss:\t\t-2.1216273031944084\n",
      "Val Utility Loss Dyn:\t\t-4.0727261639823595\n",
      "Val Utility Loss Stat:\t\t3.8605634491305705\n",
      "\n",
      "Adversary Losses\n",
      "Privacy Training Loss:\t\t3.502387073828128\n",
      "Utility Training Loss:\t\t4.073748812606082\n",
      "Discriminator Training Loss:\t0.0\n",
      "Privacy Training Acc:\t\t0.23042489605299402\n",
      "Utility Training Acc:\t\t0.044341216216216214\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Training Coop Loss:\t3.5283962374169713\n",
      "Utility Training Coop Loss:\t3.8542726069626836\n",
      "Privacy Training Coop Acc:\t0.20330041580351377\n",
      "Utility Training Coop Acc:\t0.27044568607378405\n",
      "Privacy Acc Adv:\t\t0.1882601351382331\n",
      "Privacy Acc Coop:\t\t0.18304963617463618\n",
      "Utility Acc Adv:\t\t0.042684511434511435\n",
      "Utility Acc Coop:\t\t0.29006626819436615\n",
      "Val Privacy Acc Adv:\t\t0.1888343664117096\n",
      "Val Privacy Acc Coop:\t\t0.1933826905452023\n",
      "Val Utility Acc Adv:\t\t0.04516758494202263\n",
      "Val Utility Acc Coop:\t\t0.2633293158998174\n",
      "\n",
      "\n",
      "\n",
      "Moving to new stage\n",
      "{'epochs': 100, 'paired': True, 'ae': True, 'ee': True, 'cross': True, 'triplet': True, 'train_emb_adv': True, 'train_discrim_adv': False, 'emb_adv': True, 'discrim_adv': False, 'eval': True, 'sgn_eval': False, 'save': True} \n",
      "\n",
      "--------------------\n",
      "Epoch 196/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t7.000632082889726\n",
      "Validation Loss:\t\t3.501907458730564\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.730051052242384\n",
      "Cross Reconstruction Loss:\t3.5509143031261248\n",
      "End Effector Loss:\t\t0.011041664414737024\n",
      "Smoothing Loss:\t\t\t0.010712130188879987\n",
      "Triplet Loss:\t\t\t4.7069292426948275\n",
      "Latent Consistency Loss:\t0.2846919181193592\n",
      "Privacy Loss:\t\t\t0.004429849709598055\n",
      "Privacy Loss Dyn:\t\t-3.543105714685705\n",
      "Privacy Loss Stat:\t\t3.587404212658785\n",
      "Utility Loss:\t\t\t-2.416017794715847\n",
      "Utility Loss Dyn:\t\t-4.089801527488254\n",
      "Utility Loss Stat:\t\t3.8481997465828024\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.6631312645544671\n",
      "Val Cross Reconstruction Loss:\t3.2321136757067053\n",
      "Val End Effector Loss:\t\t0.008761087509619582\n",
      "Val Smoothing Loss:\t\t0.009354223547633857\n",
      "Val Triplet Loss:\t\t3.9258946370167336\n",
      "Val Latent Consistency Loss:\t0.05957231642144501\n",
      "Val Privacy Loss:\t\t0.004866361618041992\n",
      "Val Privacy Loss Dyn:\t\t-3.533130384554529\n",
      "Val Privacy Loss Stat:\t\t3.581793979474693\n",
      "Val Utility Loss:\t\t-2.710874375264356\n",
      "Val Utility Loss Dyn:\t\t-4.088961094048373\n",
      "Val Utility Loss Stat:\t\t3.8178736540921934\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5094311820034485\n",
      "Adv Utility Training Loss:\t\t4.090238328019701\n",
      "Coop Privacy Training Loss:\t3.590649814691135\n",
      "Coop Utility Training Loss:\t3.850396607064011\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.2217440419065899\n",
      "Adv Utility Training Acc:\t\t0.0287657949456174\n",
      "Coop Privacy Training Acc:\t\t0.13929042706333974\n",
      "Coop Utility Training Acc:\t\t0.273162587971849\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.1860104766474728\n",
      "Privacy Acc Coop:\t\t0.1431641874600128\n",
      "Utility Acc Adv:\t\t0.028550863723608447\n",
      "Utility Acc Coop:\t\t0.27547184900831734\n",
      "Val Privacy Acc Adv:\t\t0.1959593949044586\n",
      "Val Privacy Acc Coop:\t\t0.14918391719745222\n",
      "Val Utility Acc Adv:\t\t0.031747611464968156\n",
      "Val Utility Acc Coop:\t\t0.30712579617834396\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 197/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t3.5350822876144967\n",
      "Validation Loss:\t\t3.4704265412251663\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6700248512333963\n",
      "Cross Reconstruction Loss:\t3.1096819520988146\n",
      "End Effector Loss:\t\t0.009876547650012807\n",
      "Smoothing Loss:\t\t\t0.010647316098627912\n",
      "Triplet Loss:\t\t\t3.797640532007297\n",
      "Latent Consistency Loss:\t0.05318586378860611\n",
      "Privacy Loss:\t\t\t0.003874575241360997\n",
      "Privacy Loss Dyn:\t\t-3.5444022251563583\n",
      "Privacy Loss Stat:\t\t3.583147977760642\n",
      "Utility Loss:\t\t\t-2.491127861057118\n",
      "Utility Loss Dyn:\t\t-4.091247410325766\n",
      "Utility Loss Stat:\t\t3.8421346258064606\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.598232610590139\n",
      "Val Cross Reconstruction Loss:\t2.9982705769265534\n",
      "Val End Effector Loss:\t\t0.008269088277533936\n",
      "Val Smoothing Loss:\t\t0.00929889260275159\n",
      "Val Triplet Loss:\t\t3.6375016133496714\n",
      "Val Latent Consistency Loss:\t0.03949757553874307\n",
      "Val Privacy Loss:\t\t0.003433897806580659\n",
      "Val Privacy Loss Dyn:\t\t-3.533846466404617\n",
      "Val Privacy Loss Stat:\t\t3.568185435738533\n",
      "Val Utility Loss:\t\t-2.0979427653513136\n",
      "Val Utility Loss Dyn:\t\t-4.095987332095007\n",
      "Val Utility Loss Stat:\t\t3.8861930582933364\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.508925131323699\n",
      "Adv Utility Training Loss:\t\t4.088330647461855\n",
      "Coop Privacy Training Loss:\t3.5866749844944636\n",
      "Coop Utility Training Loss:\t3.845403969783624\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.22208393314139474\n",
      "Adv Utility Training Acc:\t\t0.03156989763275752\n",
      "Coop Privacy Training Acc:\t\t0.14362404030710174\n",
      "Coop Utility Training Acc:\t\t0.27853586852207296\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.18480086372360843\n",
      "Privacy Acc Coop:\t\t0.14761276391554704\n",
      "Utility Acc Adv:\t\t0.029080694177863083\n",
      "Utility Acc Coop:\t\t0.2820497440818938\n",
      "Val Privacy Acc Adv:\t\t0.19615843949044587\n",
      "Val Privacy Acc Coop:\t\t0.16650079617834396\n",
      "Val Utility Acc Adv:\t\t0.02428343949044586\n",
      "Val Utility Acc Coop:\t\t0.2372611464968153\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 198/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t2.9489272181337944\n",
      "Validation Loss:\t\t2.6037120412869057\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.6226265833534953\n",
      "Cross Reconstruction Loss:\t2.942420470127294\n",
      "End Effector Loss:\t\t0.009531778378158292\n",
      "Smoothing Loss:\t\t\t0.010598123457904856\n",
      "Triplet Loss:\t\t\t3.5560134936812897\n",
      "Latent Consistency Loss:\t0.03953516964162494\n",
      "Privacy Loss:\t\t\t0.003094584741275126\n",
      "Privacy Loss Dyn:\t\t-3.544937287548453\n",
      "Privacy Loss Stat:\t\t3.5758831375925038\n",
      "Utility Loss:\t\t\t-2.5863539365645183\n",
      "Utility Loss Dyn:\t\t-4.097109884004599\n",
      "Utility Loss Stat:\t\t3.8384744858634985\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5686917126558388\n",
      "Val Cross Reconstruction Loss:\t2.893261765218844\n",
      "Val End Effector Loss:\t\t0.008046957207428422\n",
      "Val Smoothing Loss:\t\t0.00927910750589458\n",
      "Val Triplet Loss:\t\t3.423718898918978\n",
      "Val Latent Consistency Loss:\t0.0341604288287793\n",
      "Val Privacy Loss:\t\t0.0031741789192151113\n",
      "Val Privacy Loss Dyn:\t\t-3.533525056899733\n",
      "Val Privacy Loss Stat:\t\t3.5652668369803457\n",
      "Val Utility Loss:\t\t-2.627379204816879\n",
      "Val Utility Loss Dyn:\t\t-4.098805403253834\n",
      "Val Utility Loss Stat:\t\t3.8360674791275318\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5082942420522603\n",
      "Adv Utility Training Loss:\t\t4.088741767734422\n",
      "Coop Privacy Training Loss:\t3.575586934617446\n",
      "Coop Utility Training Loss:\t3.8419582369383987\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.22293865962891873\n",
      "Adv Utility Training Acc:\t\t0.03223968330134357\n",
      "Coop Privacy Training Acc:\t\t0.15698476487523993\n",
      "Coop Utility Training Acc:\t\t0.2815599008317338\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.18468090211132437\n",
      "Privacy Acc Coop:\t\t0.1570097568777991\n",
      "Utility Acc Adv:\t\t0.022802703134996802\n",
      "Utility Acc Coop:\t\t0.2851587492002559\n",
      "Val Privacy Acc Adv:\t\t0.19715366242038215\n",
      "Val Privacy Acc Coop:\t\t0.16620222929936307\n",
      "Val Utility Acc Adv:\t\t0.01930732484076433\n",
      "Val Utility Acc Coop:\t\t0.28791799363057324\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 199/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t2.728444245139224\n",
      "Validation Loss:\t\t2.2944306013690436\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5891161971151715\n",
      "Cross Reconstruction Loss:\t2.8658296846840066\n",
      "End Effector Loss:\t\t0.009417981693493732\n",
      "Smoothing Loss:\t\t\t0.01057671799109349\n",
      "Triplet Loss:\t\t\t3.430861974326907\n",
      "Latent Consistency Loss:\t0.04176787731743591\n",
      "Privacy Loss:\t\t\t0.0025398804259773103\n",
      "Privacy Loss Dyn:\t\t-3.545642393488039\n",
      "Privacy Loss Stat:\t\t3.57104119229454\n",
      "Utility Loss:\t\t\t-2.6285998783123774\n",
      "Utility Loss Dyn:\t\t-4.101654487775826\n",
      "Utility Loss Stat:\t\t3.8387945004937287\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5363405420901669\n",
      "Val Cross Reconstruction Loss:\t2.8311965754077693\n",
      "Val End Effector Loss:\t\t0.007958323662139617\n",
      "Val Smoothing Loss:\t\t0.009228892897249787\n",
      "Val Triplet Loss:\t\t3.3423678115674647\n",
      "Val Latent Consistency Loss:\t0.040777171445879966\n",
      "Val Privacy Loss:\t\t0.001852497743193511\n",
      "Val Privacy Loss Dyn:\t\t-3.53764782437853\n",
      "Val Privacy Loss Stat:\t\t3.5561727839670363\n",
      "Val Utility Loss:\t\t-2.8490071630781624\n",
      "Val Utility Loss Dyn:\t\t-4.103301172803162\n",
      "Val Utility Loss Stat:\t\t3.8184004604436788\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.50650471917956\n",
      "Adv Utility Training Loss:\t\t4.090171399973785\n",
      "Coop Privacy Training Loss:\t3.570651759265404\n",
      "Coop Utility Training Loss:\t3.8431880840184363\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.2239933221369162\n",
      "Adv Utility Training Acc:\t\t0.030120361484325016\n",
      "Coop Privacy Training Acc:\t\t0.16136336372360843\n",
      "Coop Utility Training Acc:\t\t0.2804952415227127\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.184021113243762\n",
      "Privacy Acc Coop:\t\t0.1605686180422265\n",
      "Utility Acc Adv:\t\t0.017224488163787587\n",
      "Utility Acc Coop:\t\t0.2852387236084453\n",
      "Val Privacy Acc Adv:\t\t0.1923765923566879\n",
      "Val Privacy Acc Coop:\t\t0.17436305732484075\n",
      "Val Utility Acc Adv:\t\t0.016421178343949044\n",
      "Val Utility Acc Coop:\t\t0.30692675159235666\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 200/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t2.573424577179126\n",
      "Validation Loss:\t\t2.1789953306222416\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5605789333181509\n",
      "Cross Reconstruction Loss:\t2.8251828181766503\n",
      "End Effector Loss:\t\t0.009354446533476304\n",
      "Smoothing Loss:\t\t\t0.010554152985370968\n",
      "Triplet Loss:\t\t\t3.368678751010126\n",
      "Latent Consistency Loss:\t0.04487258993608785\n",
      "Privacy Loss:\t\t\t0.0018729787374717336\n",
      "Privacy Loss Dyn:\t\t-3.5463906263435643\n",
      "Privacy Loss Stat:\t\t3.5651204119259474\n",
      "Utility Loss:\t\t\t-2.690546112646297\n",
      "Utility Loss Dyn:\t\t-4.105495774738314\n",
      "Utility Loss Stat:\t\t3.8364411645109504\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.5154507238014489\n",
      "Val Cross Reconstruction Loss:\t2.7983581154209793\n",
      "Val End Effector Loss:\t\t0.007908714890693593\n",
      "Val Smoothing Loss:\t\t0.009213367423671445\n",
      "Val Triplet Loss:\t\t3.287648465223373\n",
      "Val Latent Consistency Loss:\t0.03971120203803679\n",
      "Val Privacy Loss:\t\t0.001139416246657159\n",
      "Val Privacy Loss Dyn:\t\t-3.541578253363348\n",
      "Val Privacy Loss Stat:\t\t3.5529724200060415\n",
      "Val Utility Loss:\t\t-2.8531906225119426\n",
      "Val Utility Loss Dyn:\t\t-4.109729417570078\n",
      "Val Utility Loss Stat:\t\t3.824410342866448\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5075287469594203\n",
      "Adv Utility Training Loss:\t\t4.09651483943351\n",
      "Coop Privacy Training Loss:\t3.5657153843460523\n",
      "Coop Utility Training Loss:\t3.8407195288633127\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.2242332453614843\n",
      "Adv Utility Training Acc:\t\t0.023577455214331414\n",
      "Coop Privacy Training Acc:\t\t0.16572196896992963\n",
      "Coop Utility Training Acc:\t\t0.28286948176583493\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.183441298784389\n",
      "Privacy Acc Coop:\t\t0.16638675623800384\n",
      "Utility Acc Adv:\t\t0.014525351887396034\n",
      "Utility Acc Coop:\t\t0.28746801023672425\n",
      "Val Privacy Acc Adv:\t\t0.18869426751592358\n",
      "Val Privacy Acc Coop:\t\t0.1816281847133758\n",
      "Val Utility Acc Adv:\t\t0.011146496815286623\n",
      "Val Utility Acc Coop:\t\t0.29956210191082805\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 201/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t2.4505879178843433\n",
      "Validation Loss:\t\t1.9569008267087162\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5406779830873737\n",
      "Cross Reconstruction Loss:\t2.7977276386851617\n",
      "End Effector Loss:\t\t0.009323335544969493\n",
      "Smoothing Loss:\t\t\t0.010548481653055376\n",
      "Triplet Loss:\t\t\t3.352632968454733\n",
      "Latent Consistency Loss:\t0.04698917381131756\n",
      "Privacy Loss:\t\t\t0.0010883602780252409\n",
      "Privacy Loss Dyn:\t\t-3.5474831287630537\n",
      "Privacy Loss Stat:\t\t3.55836673005605\n",
      "Utility Loss:\t\t\t-2.775122656550685\n",
      "Utility Loss Dyn:\t\t-4.110927428637875\n",
      "Utility Loss Stat:\t\t3.833415165362416\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.4999782691715629\n",
      "Val Cross Reconstruction Loss:\t2.7712838141022216\n",
      "Val End Effector Loss:\t\t0.007890275824862491\n",
      "Val Smoothing Loss:\t\t0.00923243823170567\n",
      "Val Triplet Loss:\t\t3.2810851980926126\n",
      "Val Latent Consistency Loss:\t0.041627194779883525\n",
      "Val Privacy Loss:\t\t0.002521972557541671\n",
      "Val Privacy Loss Dyn:\t\t-3.5368867892368585\n",
      "Val Privacy Loss Stat:\t\t3.5621065091175637\n",
      "Val Utility Loss:\t\t-3.055650820398027\n",
      "Val Utility Loss Dyn:\t\t-4.116035786403972\n",
      "Val Utility Loss Stat:\t\t3.8104706706514784\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.506718279685413\n",
      "Adv Utility Training Loss:\t\t4.104203488379812\n",
      "Coop Privacy Training Loss:\t3.559422637588003\n",
      "Coop Utility Training Loss:\t3.838027212609104\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.22401831413947537\n",
      "Adv Utility Training Acc:\t\t0.01652471209213052\n",
      "Coop Privacy Training Acc:\t\t0.17240483045425464\n",
      "Coop Utility Training Acc:\t\t0.28548364523352526\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.18250159948816377\n",
      "Privacy Acc Coop:\t\t0.17340451055662187\n",
      "Utility Acc Adv:\t\t0.010036788227767114\n",
      "Utility Acc Coop:\t\t0.2899572136916187\n",
      "Val Privacy Acc Adv:\t\t0.1933718152866242\n",
      "Val Privacy Acc Coop:\t\t0.1664012738853503\n",
      "Val Utility Acc Adv:\t\t0.004976114649681528\n",
      "Val Utility Acc Coop:\t\t0.3130971337579618\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 202/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t2.3047178951655147\n",
      "Validation Loss:\t\t1.9657214735723605\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5262493711210411\n",
      "Cross Reconstruction Loss:\t2.7755165626357474\n",
      "End Effector Loss:\t\t0.00929606025168578\n",
      "Smoothing Loss:\t\t\t0.01052939437743293\n",
      "Triplet Loss:\t\t\t3.3321810371206118\n",
      "Latent Consistency Loss:\t0.04428012932812222\n",
      "Privacy Loss:\t\t\t0.0005330463021669491\n",
      "Privacy Loss Dyn:\t\t-3.5498840290235543\n",
      "Privacy Loss Stat:\t\t3.555214491396933\n",
      "Utility Loss:\t\t\t-2.8417321252121197\n",
      "Utility Loss Dyn:\t\t-4.115005208831221\n",
      "Utility Loss Stat:\t\t3.8308319996658686\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.4881778617573392\n",
      "Val Cross Reconstruction Loss:\t2.753749543694174\n",
      "Val End Effector Loss:\t\t0.007867068461599243\n",
      "Val Smoothing Loss:\t\t0.0091983261102941\n",
      "Val Triplet Loss:\t\t3.2657630124669166\n",
      "Val Latent Consistency Loss:\t0.040878573088509264\n",
      "Val Privacy Loss:\t\t0.001066356138059288\n",
      "Val Privacy Loss Dyn:\t\t-3.535617568690306\n",
      "Val Privacy Loss Stat:\t\t3.546281105393817\n",
      "Val Utility Loss:\t\t-2.9970863488069766\n",
      "Val Utility Loss Dyn:\t\t-4.1142158538672575\n",
      "Val Utility Loss Stat:\t\t3.8145072156456625\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5079407431113743\n",
      "Adv Utility Training Loss:\t\t4.107933004163277\n",
      "Coop Privacy Training Loss:\t3.55708112323124\n",
      "Coop Utility Training Loss:\t3.835837095728\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.22368342130518235\n",
      "Adv Utility Training Acc:\t\t0.012810900511836212\n",
      "Coop Privacy Training Acc:\t\t0.1755188339731286\n",
      "Coop Utility Training Acc:\t\t0.28767294465770954\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.1800323896353167\n",
      "Privacy Acc Coop:\t\t0.17769313819577734\n",
      "Utility Acc Adv:\t\t0.0061680262316058864\n",
      "Utility Acc Coop:\t\t0.2927763115802943\n",
      "Val Privacy Acc Adv:\t\t0.1949641719745223\n",
      "Val Privacy Acc Coop:\t\t0.18401671974522293\n",
      "Val Utility Acc Adv:\t\t0.006369426751592357\n",
      "Val Utility Acc Coop:\t\t0.3104100318471338\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 203/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t2.192932062399212\n",
      "Validation Loss:\t\t1.7247024033289806\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5174050200504137\n",
      "Cross Reconstruction Loss:\t2.7583287257989553\n",
      "End Effector Loss:\t\t0.009283523429518832\n",
      "Smoothing Loss:\t\t\t0.010521439386749794\n",
      "Triplet Loss:\t\t\t3.30948251329472\n",
      "Latent Consistency Loss:\t0.04078060585197469\n",
      "Privacy Loss:\t\t\t0.0006775845340330937\n",
      "Privacy Loss Dyn:\t\t-3.5498209075903326\n",
      "Privacy Loss Stat:\t\t3.5565967449986315\n",
      "Utility Loss:\t\t\t-2.8765248489623945\n",
      "Utility Loss Dyn:\t\t-4.1172432441857865\n",
      "Utility Loss Stat:\t\t3.8295907544082963\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.48216994837590843\n",
      "Val Cross Reconstruction Loss:\t2.7545938932212297\n",
      "Val End Effector Loss:\t\t0.007839401578827268\n",
      "Val Smoothing Loss:\t\t0.00921689433336353\n",
      "Val Triplet Loss:\t\t3.2274954774577145\n",
      "Val Latent Consistency Loss:\t0.033369430311166556\n",
      "Val Privacy Loss:\t\t0.0007067246801534277\n",
      "Val Privacy Loss Dyn:\t\t-3.536578761544197\n",
      "Val Privacy Loss Stat:\t\t3.5436460121422058\n",
      "Val Utility Loss:\t\t-3.1124834437279185\n",
      "Val Utility Loss Dyn:\t\t-4.1184397199351315\n",
      "Val Utility Loss Stat:\t\t3.8071913719177246\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.50622678886067\n",
      "Adv Utility Training Loss:\t\t4.103947316082486\n",
      "Coop Privacy Training Loss:\t3.5582099567981995\n",
      "Coop Utility Training Loss:\t3.834785693437719\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.2240632997440819\n",
      "Adv Utility Training Acc:\t\t0.01658469289827255\n",
      "Coop Privacy Training Acc:\t\t0.1736694257837492\n",
      "Coop Utility Training Acc:\t\t0.28898752399232247\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.18024232245681382\n",
      "Privacy Acc Coop:\t\t0.17611364363403711\n",
      "Utility Acc Adv:\t\t0.003418905950095969\n",
      "Utility Acc Coop:\t\t0.29414587332053743\n",
      "Val Privacy Acc Adv:\t\t0.1936703821656051\n",
      "Val Privacy Acc Coop:\t\t0.1900875796178344\n",
      "Val Utility Acc Adv:\t\t0.001890923566878981\n",
      "Val Utility Acc Coop:\t\t0.3176751592356688\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 204/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t2.0798107982873537\n",
      "Validation Loss:\t\t1.63042580678015\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.509988701236759\n",
      "Cross Reconstruction Loss:\t2.7527009411187637\n",
      "End Effector Loss:\t\t0.009280806918278747\n",
      "Smoothing Loss:\t\t\t0.010527691132343128\n",
      "Triplet Loss:\t\t\t3.274488758140852\n",
      "Latent Consistency Loss:\t0.035969657195411425\n",
      "Privacy Loss:\t\t\t-0.0002500596751178295\n",
      "Privacy Loss Dyn:\t\t-3.550746669085912\n",
      "Privacy Loss Stat:\t\t3.5482460735550463\n",
      "Utility Loss:\t\t\t-2.8902358471851506\n",
      "Utility Loss Dyn:\t\t-4.118282340691018\n",
      "Utility Loss Stat:\t\t3.8292587584436357\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.4740808604249529\n",
      "Val Cross Reconstruction Loss:\t2.739202440164651\n",
      "Val End Effector Loss:\t\t0.007844870497775117\n",
      "Val Smoothing Loss:\t\t0.009194675583843213\n",
      "Val Triplet Loss:\t\t3.190344430838421\n",
      "Val Latent Consistency Loss:\t0.03135740065318384\n",
      "Val Privacy Loss:\t\t-0.0012005840896800826\n",
      "Val Privacy Loss Dyn:\t\t-3.536236093302441\n",
      "Val Privacy Loss Stat:\t\t3.5242302569614092\n",
      "Val Utility Loss:\t\t-3.1298029225343353\n",
      "Val Utility Loss Dyn:\t\t-4.119126729904466\n",
      "Val Utility Loss Stat:\t\t3.806146418213085\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5077838899230467\n",
      "Adv Utility Training Loss:\t\t4.103486786877125\n",
      "Coop Privacy Training Loss:\t3.5511532037287132\n",
      "Coop Utility Training Loss:\t3.83481966831405\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.22245881317978247\n",
      "Adv Utility Training Acc:\t\t0.015879918426103645\n",
      "Coop Privacy Training Acc:\t\t0.18259157069737683\n",
      "Coop Utility Training Acc:\t\t0.28870761356365965\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.17915267114523353\n",
      "Privacy Acc Coop:\t\t0.1865902911068458\n",
      "Utility Acc Adv:\t\t0.00201935380678183\n",
      "Utility Acc Coop:\t\t0.29456573896353166\n",
      "Val Privacy Acc Adv:\t\t0.19386942675159236\n",
      "Val Privacy Acc Coop:\t\t0.2115843949044586\n",
      "Val Utility Acc Adv:\t\t0.0005971337579617834\n",
      "Val Utility Acc Coop:\t\t0.31787420382165604\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 205/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.9112609340853974\n",
      "Validation Loss:\t\t1.6388200483504374\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.5028115751952296\n",
      "Cross Reconstruction Loss:\t2.745577805940722\n",
      "End Effector Loss:\t\t0.009286058626315834\n",
      "Smoothing Loss:\t\t\t0.01051851608435923\n",
      "Triplet Loss:\t\t\t3.23135266850106\n",
      "Latent Consistency Loss:\t0.03266469443065573\n",
      "Privacy Loss:\t\t\t-0.0012155424991785832\n",
      "Privacy Loss Dyn:\t\t-3.5494238000150986\n",
      "Privacy Loss Stat:\t\t3.537268373497922\n",
      "Utility Loss:\t\t\t-2.966545693171154\n",
      "Utility Loss Dyn:\t\t-4.119718229473209\n",
      "Utility Loss Stat:\t\t3.8230636653729304\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.46832245075778595\n",
      "Val Cross Reconstruction Loss:\t2.7327791034795674\n",
      "Val End Effector Loss:\t\t0.007873400861907538\n",
      "Val Smoothing Loss:\t\t0.00921331016512908\n",
      "Val Triplet Loss:\t\t3.157955528064898\n",
      "Val Latent Consistency Loss:\t0.028744199508979062\n",
      "Val Privacy Loss:\t\t-0.001961132333536816\n",
      "Val Privacy Loss Dyn:\t\t-3.5396756639905798\n",
      "Val Privacy Loss Stat:\t\t3.520064344831333\n",
      "Val Utility Loss:\t\t-3.050052497037657\n",
      "Val Utility Loss Dyn:\t\t-4.1204858464040575\n",
      "Val Utility Loss Stat:\t\t3.815480596700292\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.50634855806103\n",
      "Adv Utility Training Loss:\t\t4.104232514125753\n",
      "Coop Privacy Training Loss:\t3.5399580581479553\n",
      "Coop Utility Training Loss:\t3.829014632157309\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.2236084452975048\n",
      "Adv Utility Training Acc:\t\t0.015135156749840051\n",
      "Coop Privacy Training Acc:\t\t0.19521753039027512\n",
      "Coop Utility Training Acc:\t\t0.29459572936660267\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.180542226487524\n",
      "Privacy Acc Coop:\t\t0.19889635316698656\n",
      "Utility Acc Adv:\t\t0.0005698176583493282\n",
      "Utility Acc Coop:\t\t0.3005738163787588\n",
      "Val Privacy Acc Adv:\t\t0.19018710191082802\n",
      "Val Privacy Acc Coop:\t\t0.21805334394904458\n",
      "Val Utility Acc Adv:\t\t0.0003980891719745223\n",
      "Val Utility Acc Coop:\t\t0.3073248407643312\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 206/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.8493276020262917\n",
      "Validation Loss:\t\t1.4569633925796315\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.49063960558622216\n",
      "Cross Reconstruction Loss:\t2.7359643200613792\n",
      "End Effector Loss:\t\t0.009282342497597825\n",
      "Smoothing Loss:\t\t\t0.01051360213597587\n",
      "Triplet Loss:\t\t\t3.207026301479767\n",
      "Latent Consistency Loss:\t0.03198185990196882\n",
      "Privacy Loss:\t\t\t-0.0018188282990409866\n",
      "Privacy Loss Dyn:\t\t-3.550002926218151\n",
      "Privacy Loss Stat:\t\t3.531814648261531\n",
      "Utility Loss:\t\t\t-2.971397272989831\n",
      "Utility Loss Dyn:\t\t-4.120382860541268\n",
      "Utility Loss Stat:\t\t3.823243130801659\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.45466197600030595\n",
      "Val Cross Reconstruction Loss:\t2.7163522516845897\n",
      "Val End Effector Loss:\t\t0.007840938287769343\n",
      "Val Smoothing Loss:\t\t0.009175830950758829\n",
      "Val Triplet Loss:\t\t3.1439804317085605\n",
      "Val Latent Consistency Loss:\t0.028375457224857275\n",
      "Val Privacy Loss:\t\t-0.002438352745809373\n",
      "Val Privacy Loss Dyn:\t\t-3.538926886904771\n",
      "Val Privacy Loss Stat:\t\t3.514543366280331\n",
      "Val Utility Loss:\t\t-3.1846608690395475\n",
      "Val Utility Loss Dyn:\t\t-4.1211577464061175\n",
      "Val Utility Loss Stat:\t\t3.8026916555538297\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5070647354394446\n",
      "Adv Utility Training Loss:\t\t4.104751156143706\n",
      "Coop Privacy Training Loss:\t3.534461820880648\n",
      "Coop Utility Training Loss:\t3.82862725642272\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.22444817658349328\n",
      "Adv Utility Training Acc:\t\t0.015395073576455535\n",
      "Coop Privacy Training Acc:\t\t0.20046085252719129\n",
      "Coop Utility Training Acc:\t\t0.2945707373640435\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.18004238643634038\n",
      "Privacy Acc Coop:\t\t0.2038447696737044\n",
      "Utility Acc Adv:\t\t0.0010496641074856047\n",
      "Utility Acc Coop:\t\t0.3003638835572617\n",
      "Val Privacy Acc Adv:\t\t0.1913813694267516\n",
      "Val Privacy Acc Coop:\t\t0.22064092356687898\n",
      "Val Utility Acc Adv:\t\t0.0005971337579617834\n",
      "Val Utility Acc Coop:\t\t0.31986464968152867\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 207/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.7770153866438476\n",
      "Validation Loss:\t\t1.6463964841548044\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.48152786150088467\n",
      "Cross Reconstruction Loss:\t2.725570285007577\n",
      "End Effector Loss:\t\t0.009287380762648503\n",
      "Smoothing Loss:\t\t\t0.01050670555585987\n",
      "Triplet Loss:\t\t\t3.1899599569849073\n",
      "Latent Consistency Loss:\t0.030531783158618597\n",
      "Privacy Loss:\t\t\t-0.0020793969060698917\n",
      "Privacy Loss Dyn:\t\t-3.5511904670424896\n",
      "Privacy Loss Stat:\t\t3.5303964970284216\n",
      "Utility Loss:\t\t\t-2.9926032653925745\n",
      "Utility Loss Dyn:\t\t-4.120774792007964\n",
      "Utility Loss Stat:\t\t3.8215144603433933\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.44645771725921873\n",
      "Val Cross Reconstruction Loss:\t2.711700879844131\n",
      "Val End Effector Loss:\t\t0.007860138193721984\n",
      "Val Smoothing Loss:\t\t0.009180898063335639\n",
      "Val Triplet Loss:\t\t3.1209744070745575\n",
      "Val Latent Consistency Loss:\t0.02721504449464713\n",
      "Val Privacy Loss:\t\t-0.003086509028817438\n",
      "Val Privacy Loss Dyn:\t\t-3.5444705926688616\n",
      "Val Privacy Loss Stat:\t\t3.5136054852965533\n",
      "Val Utility Loss:\t\t-2.9431302258922796\n",
      "Val Utility Loss Dyn:\t\t-4.121563252370069\n",
      "Val Utility Loss Stat:\t\t3.8272502452704558\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5070618632811428\n",
      "Adv Utility Training Loss:\t\t4.102161228084747\n",
      "Coop Privacy Training Loss:\t3.5330830381531326\n",
      "Coop Utility Training Loss:\t3.8274167523655613\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.22254878438899553\n",
      "Adv Utility Training Acc:\t\t0.018139195457453614\n",
      "Coop Privacy Training Acc:\t\t0.20116062859884837\n",
      "Coop Utility Training Acc:\t\t0.2961852207293666\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.17882277671145233\n",
      "Privacy Acc Coop:\t\t0.20440459053103008\n",
      "Utility Acc Adv:\t\t0.0005898112603966731\n",
      "Utility Acc Coop:\t\t0.30214331413947537\n",
      "Val Privacy Acc Adv:\t\t0.18560907643312102\n",
      "Val Privacy Acc Coop:\t\t0.2197452229299363\n",
      "Val Utility Acc Adv:\t\t0.0002985668789808917\n",
      "Val Utility Acc Coop:\t\t0.29568073248407645\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 208/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.6871631305810166\n",
      "Validation Loss:\t\t1.520510922571656\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.47371758422406146\n",
      "Cross Reconstruction Loss:\t2.7181602754580694\n",
      "End Effector Loss:\t\t0.009287518938325265\n",
      "Smoothing Loss:\t\t\t0.010493074064408157\n",
      "Triplet Loss:\t\t\t3.170930474062265\n",
      "Latent Consistency Loss:\t0.029546867267145838\n",
      "Privacy Loss:\t\t\t-0.0022752107867657642\n",
      "Privacy Loss Dyn:\t\t-3.552874747256171\n",
      "Privacy Loss Stat:\t\t3.5301226369097534\n",
      "Utility Loss:\t\t\t-3.036978738092873\n",
      "Utility Loss Dyn:\t\t-4.121238968727761\n",
      "Utility Loss Stat:\t\t3.817541090860934\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.44015769821823025\n",
      "Val Cross Reconstruction Loss:\t2.7028547229280897\n",
      "Val End Effector Loss:\t\t0.007856222308555226\n",
      "Val Smoothing Loss:\t\t0.009189914051846713\n",
      "Val Triplet Loss:\t\t3.102574410711884\n",
      "Val Latent Consistency Loss:\t0.02672687130179375\n",
      "Val Privacy Loss:\t\t-0.002504683414082618\n",
      "Val Privacy Loss Dyn:\t\t-3.5401930854578687\n",
      "Val Privacy Loss Stat:\t\t3.5151462403072675\n",
      "Val Utility Loss:\t\t-3.0328543839181306\n",
      "Val Utility Loss Dyn:\t\t-4.12120284851949\n",
      "Val Utility Loss Stat:\t\t3.8179173864376774\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5086266654314175\n",
      "Adv Utility Training Loss:\t\t4.100122667472483\n",
      "Coop Privacy Training Loss:\t3.5332327569362376\n",
      "Coop Utility Training Loss:\t3.8240521309548132\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.22230886116442738\n",
      "Adv Utility Training Acc:\t\t0.01966370761356366\n",
      "Coop Privacy Training Acc:\t\t0.20011096449136276\n",
      "Coop Utility Training Acc:\t\t0.2994141874600128\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.17707333653230967\n",
      "Privacy Acc Coop:\t\t0.2038147792706334\n",
      "Utility Acc Adv:\t\t0.00028990722968650034\n",
      "Utility Acc Coop:\t\t0.30645193538067816\n",
      "Val Privacy Acc Adv:\t\t0.18949044585987262\n",
      "Val Privacy Acc Coop:\t\t0.21815286624203822\n",
      "Val Utility Acc Adv:\t\t0.0003980891719745223\n",
      "Val Utility Acc Coop:\t\t0.3063296178343949\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 209/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.6406643343940426\n",
      "Validation Loss:\t\t1.3768121363345984\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.4669142807437606\n",
      "Cross Reconstruction Loss:\t2.711388100207958\n",
      "End Effector Loss:\t\t0.00929201890816358\n",
      "Smoothing Loss:\t\t\t0.010503829563821898\n",
      "Triplet Loss:\t\t\t3.1551024646844454\n",
      "Latent Consistency Loss:\t0.028882699972703832\n",
      "Privacy Loss:\t\t\t-0.0027283201481543974\n",
      "Privacy Loss Dyn:\t\t-3.5541146227128215\n",
      "Privacy Loss Stat:\t\t3.5268314192864043\n",
      "Utility Loss:\t\t\t-3.046307698626283\n",
      "Utility Loss Dyn:\t\t-4.1214005405599305\n",
      "Utility Loss Stat:\t\t3.816769768317693\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.43249117359993566\n",
      "Val Cross Reconstruction Loss:\t2.691600388022745\n",
      "Val End Effector Loss:\t\t0.007854379514813613\n",
      "Val Smoothing Loss:\t\t0.009145680230680355\n",
      "Val Triplet Loss:\t\t3.090383590406673\n",
      "Val Latent Consistency Loss:\t0.025785568188045435\n",
      "Val Privacy Loss:\t\t-0.003417730141597189\n",
      "Val Privacy Loss Dyn:\t\t-3.5483081052257757\n",
      "Val Privacy Loss Stat:\t\t3.5141308034301564\n",
      "Val Utility Loss:\t\t-3.137443202316381\n",
      "Val Utility Loss Dyn:\t\t-4.121384386803694\n",
      "Val Utility Loss Stat:\t\t3.8076400999810285\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5086967688833224\n",
      "Adv Utility Training Loss:\t\t4.099348171353721\n",
      "Coop Privacy Training Loss:\t3.5301165702780772\n",
      "Coop Utility Training Loss:\t3.8234506249809144\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.2220339491362764\n",
      "Adv Utility Training Acc:\t\t0.02079834452975048\n",
      "Coop Privacy Training Acc:\t\t0.20301003678822777\n",
      "Coop Utility Training Acc:\t\t0.3004688499680102\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.17592370441458732\n",
      "Privacy Acc Coop:\t\t0.2070037587971849\n",
      "Utility Acc Adv:\t\t0.0002499200255918106\n",
      "Utility Acc Coop:\t\t0.30714171465131157\n",
      "Val Privacy Acc Adv:\t\t0.18172770700636942\n",
      "Val Privacy Acc Coop:\t\t0.21954617834394904\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.31598328025477707\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 210/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.6014680070665523\n",
      "Validation Loss:\t\t1.3170551958547276\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.4606644367836106\n",
      "Cross Reconstruction Loss:\t2.7059488406336927\n",
      "End Effector Loss:\t\t0.009292485710216765\n",
      "Smoothing Loss:\t\t\t0.01050640301545337\n",
      "Triplet Loss:\t\t\t3.1425239194758947\n",
      "Latent Consistency Loss:\t0.028111111880378393\n",
      "Privacy Loss:\t\t\t-0.0029333411541339\n",
      "Privacy Loss Dyn:\t\t-3.5560027556928855\n",
      "Privacy Loss Stat:\t\t3.526669350634457\n",
      "Utility Loss:\t\t\t-3.0519691462403906\n",
      "Utility Loss Dyn:\t\t-4.12158510887844\n",
      "Utility Loss Stat:\t\t3.8163881939493227\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.427047196657035\n",
      "Val Cross Reconstruction Loss:\t2.687953365836174\n",
      "Val End Effector Loss:\t\t0.007850762925282785\n",
      "Val Smoothing Loss:\t\t0.009152534755931538\n",
      "Val Triplet Loss:\t\t3.0768707421175234\n",
      "Val Latent Consistency Loss:\t0.025535319095394415\n",
      "Val Privacy Loss:\t\t-0.003322101702356035\n",
      "Val Privacy Loss Dyn:\t\t-3.545287106447159\n",
      "Val Privacy Loss Stat:\t\t3.512066080312061\n",
      "Val Utility Loss:\t\t-3.1700446985329793\n",
      "Val Utility Loss Dyn:\t\t-4.121042288033066\n",
      "Val Utility Loss Stat:\t\t3.8040378124091276\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5103323909615525\n",
      "Adv Utility Training Loss:\t\t4.099557745403307\n",
      "Coop Privacy Training Loss:\t3.5298454288633985\n",
      "Coop Utility Training Loss:\t3.823215559363289\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.21962472008957135\n",
      "Adv Utility Training Acc:\t\t0.020513435700575816\n",
      "Coop Privacy Training Acc:\t\t0.20305002399232247\n",
      "Coop Utility Training Acc:\t\t0.3003089011516315\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.17410428662827895\n",
      "Privacy Acc Coop:\t\t0.2072536788227767\n",
      "Utility Acc Adv:\t\t0.00022992642354446578\n",
      "Utility Acc Coop:\t\t0.30731166026871404\n",
      "Val Privacy Acc Adv:\t\t0.1849124203821656\n",
      "Val Privacy Acc Coop:\t\t0.2203423566878981\n",
      "Val Utility Acc Adv:\t\t0.0005971337579617834\n",
      "Val Utility Acc Coop:\t\t0.31727707006369427\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 211/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.5362950372327921\n",
      "Validation Loss:\t\t1.2904044968212487\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.4549477116198244\n",
      "Cross Reconstruction Loss:\t2.7005919547547763\n",
      "End Effector Loss:\t\t0.009295479228847582\n",
      "Smoothing Loss:\t\t\t0.010496086538998708\n",
      "Triplet Loss:\t\t\t3.128395544590282\n",
      "Latent Consistency Loss:\t0.027676260761406585\n",
      "Privacy Loss:\t\t\t-0.0031701822312916995\n",
      "Privacy Loss Dyn:\t\t-3.5574939351621837\n",
      "Privacy Loss Stat:\t\t3.5257921109043933\n",
      "Utility Loss:\t\t\t-3.0864312921818144\n",
      "Utility Loss Dyn:\t\t-4.121708826002828\n",
      "Utility Loss Stat:\t\t3.813065700628631\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.4218937538232014\n",
      "Val Cross Reconstruction Loss:\t2.68225481707579\n",
      "Val End Effector Loss:\t\t0.007852451941057754\n",
      "Val Smoothing Loss:\t\t0.009158231940856026\n",
      "Val Triplet Loss:\t\t3.069109953133164\n",
      "Val Latent Consistency Loss:\t0.02460182248169829\n",
      "Val Privacy Loss:\t\t-0.0039411843961970824\n",
      "Val Privacy Loss Dyn:\t\t-3.5489241712412256\n",
      "Val Privacy Loss Stat:\t\t3.509512336390793\n",
      "Val Utility Loss:\t\t-3.16812262565467\n",
      "Val Utility Loss Dyn:\t\t-4.121620806918782\n",
      "Val Utility Loss Stat:\t\t3.8048085285599824\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.511243225288025\n",
      "Adv Utility Training Loss:\t\t4.099849070026107\n",
      "Coop Privacy Training Loss:\t3.5296417074331625\n",
      "Coop Utility Training Loss:\t3.8198113029611775\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.2184600927703135\n",
      "Adv Utility Training Acc:\t\t0.02095829334612924\n",
      "Coop Privacy Training Acc:\t\t0.202545185540627\n",
      "Coop Utility Training Acc:\t\t0.3040327095329495\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.172454814459373\n",
      "Privacy Acc Coop:\t\t0.20736364363403711\n",
      "Utility Acc Adv:\t\t0.00016994561740243122\n",
      "Utility Acc Coop:\t\t0.31136036468330136\n",
      "Val Privacy Acc Adv:\t\t0.18113057324840764\n",
      "Val Privacy Acc Coop:\t\t0.22541799363057324\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.3176751592356688\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 212/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.4970202751681734\n",
      "Validation Loss:\t\t1.319264301828518\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.44951911940837014\n",
      "Cross Reconstruction Loss:\t2.696259831588999\n",
      "End Effector Loss:\t\t0.00929733074847573\n",
      "Smoothing Loss:\t\t\t0.010504590481476797\n",
      "Triplet Loss:\t\t\t3.1166268536011836\n",
      "Latent Consistency Loss:\t0.027185108395852267\n",
      "Privacy Loss:\t\t\t-0.003191279262895395\n",
      "Privacy Loss Dyn:\t\t-3.558967000310877\n",
      "Privacy Loss Stat:\t\t3.5270542058133194\n",
      "Utility Loss:\t\t\t-3.0977417036118755\n",
      "Utility Loss Dyn:\t\t-4.121725717265104\n",
      "Utility Loss Stat:\t\t3.8119515472700103\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.4163959891932785\n",
      "Val Cross Reconstruction Loss:\t2.6794592908992887\n",
      "Val End Effector Loss:\t\t0.00784153625321616\n",
      "Val Smoothing Loss:\t\t0.009144249728103732\n",
      "Val Triplet Loss:\t\t3.0536223050135716\n",
      "Val Latent Consistency Loss:\t0.024683132554125634\n",
      "Val Privacy Loss:\t\t-0.003822429354783076\n",
      "Val Privacy Loss Dyn:\t\t-3.5477374055583004\n",
      "Val Privacy Loss Stat:\t\t3.509513104797169\n",
      "Val Utility Loss:\t\t-3.1133790957699916\n",
      "Val Utility Loss Dyn:\t\t-4.121788583743345\n",
      "Val Utility Loss Stat:\t\t3.810450652602372\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5137018974362775\n",
      "Adv Utility Training Loss:\t\t4.099886089429898\n",
      "Coop Privacy Training Loss:\t3.5299958729698195\n",
      "Coop Utility Training Loss:\t3.819417330063999\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.21699056301983366\n",
      "Adv Utility Training Acc:\t\t0.020898312539987203\n",
      "Coop Privacy Training Acc:\t\t0.2017304462571977\n",
      "Coop Utility Training Acc:\t\t0.30433261356365965\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.1710352687140115\n",
      "Privacy Acc Coop:\t\t0.20516434740882916\n",
      "Utility Acc Adv:\t\t0.00017994241842610365\n",
      "Utility Acc Coop:\t\t0.31183021433141395\n",
      "Val Privacy Acc Adv:\t\t0.18252388535031847\n",
      "Val Privacy Acc Coop:\t\t0.22223328025477707\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.31359474522292996\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 213/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.4641440576365454\n",
      "Validation Loss:\t\t1.4550308968610823\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.44444711564522255\n",
      "Cross Reconstruction Loss:\t2.691655507090758\n",
      "End Effector Loss:\t\t0.009293770422635841\n",
      "Smoothing Loss:\t\t\t0.010495524128609393\n",
      "Triplet Loss:\t\t\t3.1045419515437676\n",
      "Latent Consistency Loss:\t0.02688934823935488\n",
      "Privacy Loss:\t\t\t-0.0035208203780368896\n",
      "Privacy Loss Dyn:\t\t-3.5594834331053615\n",
      "Privacy Loss Stat:\t\t3.524275228447893\n",
      "Utility Loss:\t\t\t-3.1046106822965087\n",
      "Utility Loss Dyn:\t\t-4.121735981314592\n",
      "Utility Loss Stat:\t\t3.8112749144272855\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.4118090613632445\n",
      "Val Cross Reconstruction Loss:\t2.6749855955694892\n",
      "Val End Effector Loss:\t\t0.007849795144691968\n",
      "Val Smoothing Loss:\t\t0.00917972248213686\n",
      "Val Triplet Loss:\t\t3.0379965168655296\n",
      "Val Latent Consistency Loss:\t0.024727432864012234\n",
      "Val Privacy Loss:\t\t-0.0045601993229738465\n",
      "Val Privacy Loss Dyn:\t\t-3.55307046774846\n",
      "Val Privacy Loss Stat:\t\t3.50746849236215\n",
      "Val Utility Loss:\t\t-2.952185418195785\n",
      "Val Utility Loss Dyn:\t\t-4.121919370760583\n",
      "Val Utility Loss Stat:\t\t3.826700839267415\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.514590151097938\n",
      "Adv Utility Training Loss:\t\t4.099635534841742\n",
      "Coop Privacy Training Loss:\t3.528004701978033\n",
      "Coop Utility Training Loss:\t3.8182565212554835\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.21471129238643635\n",
      "Adv Utility Training Acc:\t\t0.020568418106206014\n",
      "Coop Privacy Training Acc:\t\t0.20377979046705055\n",
      "Coop Utility Training Acc:\t\t0.3054472568777991\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.17050543825975686\n",
      "Privacy Acc Coop:\t\t0.20771353166986564\n",
      "Utility Acc Adv:\t\t0.00014995201535508636\n",
      "Utility Acc Coop:\t\t0.31269993602047347\n",
      "Val Privacy Acc Adv:\t\t0.17724920382165604\n",
      "Val Privacy Acc Coop:\t\t0.22581608280254778\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.296875\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 214/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.436365914994032\n",
      "Validation Loss:\t\t1.174149653666718\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.4400623312991015\n",
      "Cross Reconstruction Loss:\t2.6880080721276127\n",
      "End Effector Loss:\t\t0.009291145227782748\n",
      "Smoothing Loss:\t\t\t0.010500929453925624\n",
      "Triplet Loss:\t\t\t3.0934633866991663\n",
      "Latent Consistency Loss:\t0.026728936719516875\n",
      "Privacy Loss:\t\t\t-0.0037741881872092923\n",
      "Privacy Loss Dyn:\t\t-3.5606601030797584\n",
      "Privacy Loss Stat:\t\t3.5229182254024902\n",
      "Utility Loss:\t\t\t-3.1103320521417523\n",
      "Utility Loss Dyn:\t\t-4.121695523985059\n",
      "Utility Loss Stat:\t\t3.8106623211504935\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.4095796065725339\n",
      "Val Cross Reconstruction Loss:\t2.676138674377636\n",
      "Val End Effector Loss:\t\t0.007871352275536888\n",
      "Val Smoothing Loss:\t\t0.009203696350572974\n",
      "Val Triplet Loss:\t\t3.027244065217911\n",
      "Val Latent Consistency Loss:\t0.024577114553113653\n",
      "Val Privacy Loss:\t\t-0.004333849165849625\n",
      "Val Privacy Loss Dyn:\t\t-3.5516301932608245\n",
      "Val Privacy Loss Stat:\t\t3.5082917091952766\n",
      "Val Utility Loss:\t\t-3.2167872289183794\n",
      "Val Utility Loss Dyn:\t\t-4.122010829342399\n",
      "Val Utility Loss Stat:\t\t3.8003321255847906\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5199132746637285\n",
      "Adv Utility Training Loss:\t\t4.097992102915251\n",
      "Coop Privacy Training Loss:\t3.5264329321477477\n",
      "Coop Utility Training Loss:\t3.8182346826932863\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.2100977687140115\n",
      "Adv Utility Training Acc:\t\t0.022557781509916826\n",
      "Coop Privacy Training Acc:\t\t0.20522932661548304\n",
      "Coop Utility Training Acc:\t\t0.30525231925783747\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.1694757677543186\n",
      "Privacy Acc Coop:\t\t0.20895313499680102\n",
      "Utility Acc Adv:\t\t0.0001999360204734485\n",
      "Utility Acc Coop:\t\t0.3128099008317338\n",
      "Val Privacy Acc Adv:\t\t0.1786425159235669\n",
      "Val Privacy Acc Coop:\t\t0.22283041401273884\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.32414410828025475\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 215/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.3885948338074536\n",
      "Validation Loss:\t\t1.5240519697878772\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.43591894086400285\n",
      "Cross Reconstruction Loss:\t2.684219307191694\n",
      "End Effector Loss:\t\t0.009293510648585803\n",
      "Smoothing Loss:\t\t\t0.01049990589823991\n",
      "Triplet Loss:\t\t\t3.082624282123031\n",
      "Latent Consistency Loss:\t0.026380483343510848\n",
      "Privacy Loss:\t\t\t-0.005600796646592866\n",
      "Privacy Loss Dyn:\t\t-3.5839702642200395\n",
      "Privacy Loss Stat:\t\t3.527962298554941\n",
      "Utility Loss:\t\t\t-3.133286532879791\n",
      "Utility Loss Dyn:\t\t-4.12178077471996\n",
      "Utility Loss Stat:\t\t3.808452124177685\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.4056721787164166\n",
      "Val Cross Reconstruction Loss:\t2.6716295275718545\n",
      "Val End Effector Loss:\t\t0.007850939078719183\n",
      "Val Smoothing Loss:\t\t0.009157324805974391\n",
      "Val Triplet Loss:\t\t3.0212053402214294\n",
      "Val Latent Consistency Loss:\t0.023960941951650723\n",
      "Val Privacy Loss:\t\t-0.011159480946838477\n",
      "Val Privacy Loss Dyn:\t\t-3.6169989169782895\n",
      "Val Privacy Loss Stat:\t\t3.5054040927036554\n",
      "Val Utility Loss:\t\t-2.839433487813184\n",
      "Val Utility Loss Dyn:\t\t-4.121341255819722\n",
      "Val Utility Loss Stat:\t\t3.8373979018751982\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.54654250096146\n",
      "Adv Utility Training Loss:\t\t4.097922764141744\n",
      "Coop Privacy Training Loss:\t3.531815466633685\n",
      "Coop Utility Training Loss:\t3.815404241083527\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1826665467050544\n",
      "Adv Utility Training Acc:\t\t0.022712731925783748\n",
      "Coop Privacy Training Acc:\t\t0.19996101247600767\n",
      "Coop Utility Training Acc:\t\t0.3080414267434421\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.14640315099168266\n",
      "Privacy Acc Coop:\t\t0.2044645713371721\n",
      "Utility Acc Adv:\t\t0.00014995201535508636\n",
      "Utility Acc Coop:\t\t0.31559900831733845\n",
      "Val Privacy Acc Adv:\t\t0.11335589171974522\n",
      "Val Privacy Acc Coop:\t\t0.22740843949044587\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.28682324840764334\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 216/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.3357765091677278\n",
      "Validation Loss:\t\t1.1799932728005442\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.4317387488699844\n",
      "Cross Reconstruction Loss:\t2.681310405200365\n",
      "End Effector Loss:\t\t0.00929554578832095\n",
      "Smoothing Loss:\t\t\t0.01048837612744752\n",
      "Triplet Loss:\t\t\t3.0715947264063\n",
      "Latent Consistency Loss:\t0.02609369424138974\n",
      "Privacy Loss:\t\t\t-0.009410920199566901\n",
      "Privacy Loss Dyn:\t\t-3.6226302347958126\n",
      "Privacy Loss Stat:\t\t3.528521040808445\n",
      "Utility Loss:\t\t\t-3.1597134498015325\n",
      "Utility Loss Dyn:\t\t-4.121777476825092\n",
      "Utility Loss Stat:\t\t3.8058061271772425\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.401144966578028\n",
      "Val Cross Reconstruction Loss:\t2.666402271598767\n",
      "Val End Effector Loss:\t\t0.00786401452437328\n",
      "Val Smoothing Loss:\t\t0.009189324592874878\n",
      "Val Triplet Loss:\t\t3.01015057229692\n",
      "Val Latent Consistency Loss:\t0.024018997041757698\n",
      "Val Privacy Loss:\t\t-0.00846136755244747\n",
      "Val Privacy Loss Dyn:\t\t-3.619323997740533\n",
      "Val Privacy Loss Stat:\t\t3.534710323734648\n",
      "Val Utility Loss:\t\t-3.16624805426142\n",
      "Val Utility Loss Dyn:\t\t-4.122013741997397\n",
      "Val Utility Loss Stat:\t\t3.8053889289783065\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5796709707434635\n",
      "Adv Utility Training Loss:\t\t4.097176961538811\n",
      "Coop Privacy Training Loss:\t3.533086309506202\n",
      "Coop Utility Training Loss:\t3.8134179646131403\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.15168646033269353\n",
      "Adv Utility Training Acc:\t\t0.023312539987204093\n",
      "Coop Privacy Training Acc:\t\t0.19845649392194498\n",
      "Coop Utility Training Acc:\t\t0.3103107005758157\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.10772552783109406\n",
      "Privacy Acc Coop:\t\t0.2034848848368522\n",
      "Utility Acc Adv:\t\t8.997120921305183e-05\n",
      "Utility Acc Coop:\t\t0.318358125399872\n",
      "Val Privacy Acc Adv:\t\t0.11136544585987261\n",
      "Val Privacy Acc Coop:\t\t0.19546178343949044\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.3184713375796178\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 217/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.3132422801598154\n",
      "Validation Loss:\t\t1.0578885881147186\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.4279443806779743\n",
      "Cross Reconstruction Loss:\t2.6791228342727447\n",
      "End Effector Loss:\t\t0.009298815787308066\n",
      "Smoothing Loss:\t\t\t0.01048137148352422\n",
      "Triplet Loss:\t\t\t3.062998391997715\n",
      "Latent Consistency Loss:\t0.025863342778429495\n",
      "Privacy Loss:\t\t\t-0.009804502787379522\n",
      "Privacy Loss Dyn:\t\t-3.623944486629025\n",
      "Privacy Loss Stat:\t\t3.5258994596704643\n",
      "Utility Loss:\t\t\t-3.163129007213785\n",
      "Utility Loss Dyn:\t\t-4.121793580070491\n",
      "Utility Loss Stat:\t\t3.8054806766644242\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.39714194065446307\n",
      "Val Cross Reconstruction Loss:\t2.659210410087731\n",
      "Val End Effector Loss:\t\t0.007850054156177552\n",
      "Val Smoothing Loss:\t\t0.009148690072451808\n",
      "Val Triplet Loss:\t\t3.003559575718679\n",
      "Val Latent Consistency Loss:\t0.023567159749140407\n",
      "Val Privacy Loss:\t\t-0.011279199533401781\n",
      "Val Privacy Loss Dyn:\t\t-3.623427029627903\n",
      "Val Privacy Loss Stat:\t\t3.510635032775296\n",
      "Val Utility Loss:\t\t-3.2655644021975765\n",
      "Val Utility Loss Dyn:\t\t-4.122027503457039\n",
      "Val Utility Loss Stat:\t\t3.795471074474845\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.575513844755469\n",
      "Adv Utility Training Loss:\t\t4.096820892924615\n",
      "Coop Privacy Training Loss:\t3.529912269809501\n",
      "Coop Utility Training Loss:\t3.8136783102271044\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.15428562859884837\n",
      "Adv Utility Training Acc:\t\t0.024142274472168906\n",
      "Coop Privacy Training Acc:\t\t0.20176043666026872\n",
      "Coop Utility Training Acc:\t\t0.3105106365962892\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.10637595969289827\n",
      "Privacy Acc Coop:\t\t0.20637396033269353\n",
      "Utility Acc Adv:\t\t0.00013995521433141396\n",
      "Utility Acc Coop:\t\t0.31868801983365325\n",
      "Val Privacy Acc Adv:\t\t0.10728503184713375\n",
      "Val Privacy Acc Coop:\t\t0.2226313694267516\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.3271297770700637\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 218/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.2757405209881196\n",
      "Validation Loss:\t\t1.0759413295846647\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.4241744655679604\n",
      "Cross Reconstruction Loss:\t2.676336835533552\n",
      "End Effector Loss:\t\t0.00930247567707264\n",
      "Smoothing Loss:\t\t\t0.010496009724251616\n",
      "Triplet Loss:\t\t\t3.0545089607885534\n",
      "Latent Consistency Loss:\t0.025617657537957604\n",
      "Privacy Loss:\t\t\t-0.010473695994186157\n",
      "Privacy Loss Dyn:\t\t-3.628779256641293\n",
      "Privacy Loss Stat:\t\t3.524042298072283\n",
      "Utility Loss:\t\t\t-3.181244443184431\n",
      "Utility Loss Dyn:\t\t-4.121802422760849\n",
      "Utility Loss Stat:\t\t3.8036779718222102\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3942188506673096\n",
      "Val Cross Reconstruction Loss:\t2.6624754614131465\n",
      "Val End Effector Loss:\t\t0.00786004169209368\n",
      "Val Smoothing Loss:\t\t0.009176821652562565\n",
      "Val Triplet Loss:\t\t3.002215941240833\n",
      "Val Latent Consistency Loss:\t0.023124440673999727\n",
      "Val Privacy Loss:\t\t-0.010913826287931697\n",
      "Val Privacy Loss Dyn:\t\t-3.625017102356929\n",
      "Val Privacy Loss Stat:\t\t3.5158788580803355\n",
      "Val Utility Loss:\t\t-3.236680948050918\n",
      "Val Utility Loss Dyn:\t\t-4.121410503508939\n",
      "Val Utility Loss Stat:\t\t3.7977424275343585\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5767869990526373\n",
      "Adv Utility Training Loss:\t\t4.096154129055167\n",
      "Coop Privacy Training Loss:\t3.528326480722702\n",
      "Coop Utility Training Loss:\t3.81150173179934\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.15294605726167626\n",
      "Adv Utility Training Acc:\t\t0.02529690499040307\n",
      "Coop Privacy Training Acc:\t\t0.20308001439539347\n",
      "Coop Utility Training Acc:\t\t0.3121551103646833\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.10170745361484325\n",
      "Privacy Acc Coop:\t\t0.20789347408829176\n",
      "Utility Acc Adv:\t\t0.0001199616122840691\n",
      "Utility Acc Coop:\t\t0.32026751439539347\n",
      "Val Privacy Acc Adv:\t\t0.10559315286624203\n",
      "Val Privacy Acc Coop:\t\t0.21725716560509553\n",
      "Val Utility Acc Adv:\t\t0.0003980891719745223\n",
      "Val Utility Acc Coop:\t\t0.32434315286624205\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 219/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.2488925252324274\n",
      "Validation Loss:\t\t1.3793803610999114\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.4209803395254522\n",
      "Cross Reconstruction Loss:\t2.674711418929805\n",
      "End Effector Loss:\t\t0.00930250192451948\n",
      "Smoothing Loss:\t\t\t0.010481138424667805\n",
      "Triplet Loss:\t\t\t3.0474106665993834\n",
      "Latent Consistency Loss:\t0.025313502404021287\n",
      "Privacy Loss:\t\t\t-0.007380162323428818\n",
      "Privacy Loss Dyn:\t\t-3.6307797058225058\n",
      "Privacy Loss Stat:\t\t3.5569780852195167\n",
      "Utility Loss:\t\t\t-3.194450761596133\n",
      "Utility Loss Dyn:\t\t-4.121816916413896\n",
      "Utility Loss Stat:\t\t3.8023718399492044\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3925173609120071\n",
      "Val Cross Reconstruction Loss:\t2.6633325670934784\n",
      "Val End Effector Loss:\t\t0.007856097374894436\n",
      "Val Smoothing Loss:\t\t0.009159255986380729\n",
      "Val Triplet Loss:\t\t2.9929828431196275\n",
      "Val Latent Consistency Loss:\t0.023177331349082814\n",
      "Val Privacy Loss:\t\t3.5259184563995166e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.625690349348032\n",
      "Val Privacy Loss Stat:\t\t3.626042956759216\n",
      "Val Utility Loss:\t\t-2.932112894240458\n",
      "Val Utility Loss Dyn:\t\t-4.121679795016149\n",
      "Val Utility Loss Stat:\t\t3.828468520170564\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5775928953406297\n",
      "Adv Utility Training Loss:\t\t4.095211253590257\n",
      "Coop Privacy Training Loss:\t3.560377448168002\n",
      "Coop Utility Training Loss:\t3.810564838917074\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.15146653071017274\n",
      "Adv Utility Training Acc:\t\t0.025726767434420986\n",
      "Coop Privacy Training Acc:\t\t0.17112523992322456\n",
      "Coop Utility Training Acc:\t\t0.31320977287268076\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.0997680742162508\n",
      "Privacy Acc Coop:\t\t0.17510396673064618\n",
      "Utility Acc Adv:\t\t8.997120921305183e-05\n",
      "Utility Acc Coop:\t\t0.3214071497120921\n",
      "Val Privacy Acc Adv:\t\t0.10499601910828026\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.29209792993630573\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 220/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.225758209539743\n",
      "Validation Loss:\t\t1.2252980433167167\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.4173525233949062\n",
      "Cross Reconstruction Loss:\t2.672871875290068\n",
      "End Effector Loss:\t\t0.009302638003081846\n",
      "Smoothing Loss:\t\t\t0.01048855463660162\n",
      "Triplet Loss:\t\t\t3.040076996528103\n",
      "Latent Consistency Loss:\t0.025151815656298485\n",
      "Privacy Loss:\t\t\t7.604542101947298e-05\n",
      "Privacy Loss Dyn:\t\t-3.6308507904057614\n",
      "Privacy Loss Stat:\t\t3.6316112440820696\n",
      "Utility Loss:\t\t\t-3.208673534527545\n",
      "Utility Loss Dyn:\t\t-4.121872655718432\n",
      "Utility Loss Stat:\t\t3.8010053073299748\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.389932058799039\n",
      "Val Cross Reconstruction Loss:\t2.657174620658729\n",
      "Val End Effector Loss:\t\t0.007883673726586968\n",
      "Val Smoothing Loss:\t\t0.009170655573415717\n",
      "Val Triplet Loss:\t\t2.9816999891001705\n",
      "Val Latent Consistency Loss:\t0.023102839305332513\n",
      "Val Privacy Loss:\t\t-6.689767169344956e-06\n",
      "Val Privacy Loss Dyn:\t\t-3.6258113019785303\n",
      "Val Privacy Loss Stat:\t\t3.625744398991773\n",
      "Val Utility Loss:\t\t-3.06840087501866\n",
      "Val Utility Loss Dyn:\t\t-4.121940679610915\n",
      "Val Utility Loss Stat:\t\t3.8151005954499455\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.579150703726712\n",
      "Adv Utility Training Loss:\t\t4.094719390417625\n",
      "Coop Privacy Training Loss:\t3.6316112445396866\n",
      "Coop Utility Training Loss:\t3.8091663830721143\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.15218630038387715\n",
      "Adv Utility Training Acc:\t\t0.02710632597568778\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.31480926103646834\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09970809341010876\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t9.996801023672424e-05\n",
      "Utility Acc Coop:\t\t0.3233265355086372\n",
      "Val Privacy Acc Adv:\t\t0.10489649681528662\n",
      "Val Privacy Acc Coop:\t\t0.10519506369426751\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.31001194267515925\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 221/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.1969299497224644\n",
      "Validation Loss:\t\t1.1839027890022014\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.4137829386951522\n",
      "Cross Reconstruction Loss:\t2.670338386156127\n",
      "End Effector Loss:\t\t0.009301703394362638\n",
      "Smoothing Loss:\t\t\t0.010482033125946557\n",
      "Triplet Loss:\t\t\t3.0321135382124496\n",
      "Latent Consistency Loss:\t0.02502069180629914\n",
      "Privacy Loss:\t\t\t9.501624854802323e-05\n",
      "Privacy Loss Dyn:\t\t-3.6306510854819916\n",
      "Privacy Loss Stat:\t\t3.6316012448404207\n",
      "Utility Loss:\t\t\t-3.220833046803929\n",
      "Utility Loss Dyn:\t\t-4.121925085230051\n",
      "Utility Loss Stat:\t\t3.799841776156532\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3854361058800084\n",
      "Val Cross Reconstruction Loss:\t2.6497377901320247\n",
      "Val End Effector Loss:\t\t0.007866643968328929\n",
      "Val Smoothing Loss:\t\t0.009178849915932319\n",
      "Val Triplet Loss:\t\t2.9768797880525044\n",
      "Val Latent Consistency Loss:\t0.022903581013440328\n",
      "Val Privacy Loss:\t\t2.3199114829871305e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.625810937517008\n",
      "Val Privacy Loss Stat:\t\t3.6260429491662673\n",
      "Val Utility Loss:\t\t-3.0932852143694642\n",
      "Val Utility Loss Dyn:\t\t-4.121892020960522\n",
      "Val Utility Loss Stat:\t\t3.8125635013458834\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5791381287101895\n",
      "Adv Utility Training Loss:\t\t4.093759136785701\n",
      "Coop Privacy Training Loss:\t3.631601245145499\n",
      "Coop Utility Training Loss:\t3.8083788071850213\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.15072176903390916\n",
      "Adv Utility Training Acc:\t\t0.027246281190019195\n",
      "Coop Privacy Training Acc:\t\t0.09933821177223288\n",
      "Coop Utility Training Acc:\t\t0.3157539587332054\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09990802943058222\n",
      "Privacy Acc Coop:\t\t0.09933821177223288\n",
      "Utility Acc Adv:\t\t0.00010996481126039668\n",
      "Utility Acc Coop:\t\t0.32477607165706973\n",
      "Val Privacy Acc Adv:\t\t0.10489649681528662\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.31011146496815284\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 222/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.1562493369698297\n",
      "Validation Loss:\t\t1.0657611415264712\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.4104227527013133\n",
      "Cross Reconstruction Loss:\t2.668694605220226\n",
      "End Effector Loss:\t\t0.009303342326951194\n",
      "Smoothing Loss:\t\t\t0.010493901442028511\n",
      "Triplet Loss:\t\t\t3.024061453929713\n",
      "Latent Consistency Loss:\t0.024949548740991017\n",
      "Privacy Loss:\t\t\t7.075303956933e-05\n",
      "Privacy Loss Dyn:\t\t-3.6309237036274857\n",
      "Privacy Loss Stat:\t\t3.6316312366163435\n",
      "Utility Loss:\t\t\t-3.2458783916685725\n",
      "Utility Loss Dyn:\t\t-4.121997476920667\n",
      "Utility Loss Stat:\t\t3.797409638485997\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3821248987298103\n",
      "Val Cross Reconstruction Loss:\t2.6447997472848104\n",
      "Val End Effector Loss:\t\t0.007875571979482653\n",
      "Val Smoothing Loss:\t\t0.00919022182429767\n",
      "Val Triplet Loss:\t\t2.97298517500519\n",
      "Val Latent Consistency Loss:\t0.022648645131878413\n",
      "Val Privacy Loss:\t\t2.173101826078573e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6261242438273826\n",
      "Val Privacy Loss Stat:\t\t3.6263415418612728\n",
      "Val Utility Loss:\t\t-3.197908194961062\n",
      "Val Utility Loss Dyn:\t\t-4.121921101952814\n",
      "Val Utility Loss Stat:\t\t3.802130292175682\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5780617399087564\n",
      "Adv Utility Training Loss:\t\t4.093869481114188\n",
      "Coop Privacy Training Loss:\t3.6316312367688823\n",
      "Coop Utility Training Loss:\t3.805851781970785\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.15065678982725528\n",
      "Adv Utility Training Acc:\t\t0.02714631317978247\n",
      "Coop Privacy Training Acc:\t\t0.09930822136916187\n",
      "Coop Utility Training Acc:\t\t0.3180482245681382\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09970809341010876\n",
      "Privacy Acc Coop:\t\t0.09930822136916187\n",
      "Utility Acc Adv:\t\t7.99744081893794e-05\n",
      "Utility Acc Coop:\t\t0.3268853966730646\n",
      "Val Privacy Acc Adv:\t\t0.10459792993630573\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.32076035031847133\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 223/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.1256606741769624\n",
      "Validation Loss:\t\t1.1685632278869866\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.40790422730772297\n",
      "Cross Reconstruction Loss:\t2.667813802939993\n",
      "End Effector Loss:\t\t0.009299293531954612\n",
      "Smoothing Loss:\t\t\t0.01047599653821255\n",
      "Triplet Loss:\t\t\t3.0158309054847567\n",
      "Latent Consistency Loss:\t0.025127559854998774\n",
      "Privacy Loss:\t\t\t5.336661637782746e-05\n",
      "Privacy Loss Dyn:\t\t-3.63110756782561\n",
      "Privacy Loss Stat:\t\t3.6316412341800626\n",
      "Utility Loss:\t\t\t-3.2648163134671906\n",
      "Utility Loss Dyn:\t\t-4.121794697876855\n",
      "Utility Loss Stat:\t\t3.7953130646691595\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.37978384904800705\n",
      "Val Cross Reconstruction Loss:\t2.663374807424606\n",
      "Val End Effector Loss:\t\t0.007863592448389264\n",
      "Val Smoothing Loss:\t\t0.009158599264563838\n",
      "Val Triplet Loss:\t\t2.95750051395149\n",
      "Val Latent Consistency Loss:\t0.023914683183097536\n",
      "Val Privacy Loss:\t\t1.2827147344115434e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6253175386198007\n",
      "Val Privacy Loss Stat:\t\t3.625445819964075\n",
      "Val Utility Loss:\t\t-3.0893414977249827\n",
      "Val Utility Loss Dyn:\t\t-4.121861570200343\n",
      "Val Utility Loss Stat:\t\t3.8129274252873318\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5776694849066755\n",
      "Adv Utility Training Loss:\t\t4.095159471454486\n",
      "Coop Privacy Training Loss:\t3.6316412347902185\n",
      "Coop Utility Training Loss:\t3.804440959630223\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.15163647632757518\n",
      "Adv Utility Training Acc:\t\t0.026391554702495202\n",
      "Coop Privacy Training Acc:\t\t0.0992982245681382\n",
      "Coop Utility Training Acc:\t\t0.3193927943058221\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09952815099168266\n",
      "Privacy Acc Coop:\t\t0.0992982245681382\n",
      "Utility Acc Adv:\t\t0.0002499200255918106\n",
      "Utility Acc Coop:\t\t0.3288147792706334\n",
      "Val Privacy Acc Adv:\t\t0.10549363057324841\n",
      "Val Privacy Acc Coop:\t\t0.10549363057324841\n",
      "Val Utility Acc Adv:\t\t0.0003980891719745223\n",
      "Val Utility Acc Coop:\t\t0.3088176751592357\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 224/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.1106439578327245\n",
      "Validation Loss:\t\t1.0040008209076277\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.40578691479264356\n",
      "Cross Reconstruction Loss:\t2.6674883008689663\n",
      "End Effector Loss:\t\t0.00929943405589898\n",
      "Smoothing Loss:\t\t\t0.010481734016477603\n",
      "Triplet Loss:\t\t\t3.0092622310933743\n",
      "Latent Consistency Loss:\t0.025523240708401014\n",
      "Privacy Loss:\t\t\t5.3096526872631225e-05\n",
      "Privacy Loss Dyn:\t\t-3.631080284991176\n",
      "Privacy Loss Stat:\t\t3.6316112477430074\n",
      "Utility Loss:\t\t\t-3.2729710818709887\n",
      "Utility Loss Dyn:\t\t-4.121690426129068\n",
      "Utility Loss Stat:\t\t3.7943933216029073\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3781293767273046\n",
      "Val Cross Reconstruction Loss:\t2.653452575586404\n",
      "Val End Effector Loss:\t\t0.007870365773582725\n",
      "Val Smoothing Loss:\t\t0.009158140282698308\n",
      "Val Triplet Loss:\t\t2.955009299478713\n",
      "Val Latent Consistency Loss:\t0.023738804386015153\n",
      "Val Privacy Loss:\t\t-1.6102745274829258e-06\n",
      "Val Privacy Loss Dyn:\t\t-3.626059056846959\n",
      "Val Privacy Loss Stat:\t\t3.6260429461290884\n",
      "Val Utility Loss:\t\t-3.2453437124847606\n",
      "Val Utility Loss Dyn:\t\t-4.121509111610947\n",
      "Val Utility Loss Stat:\t\t3.796974760711573\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5778039749509163\n",
      "Adv Utility Training Loss:\t\t4.09555797888084\n",
      "Coop Privacy Training Loss:\t3.6316112478955467\n",
      "Coop Utility Training Loss:\t3.803448465338748\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.15156649872040948\n",
      "Adv Utility Training Acc:\t\t0.02520693378119002\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.3205824136276392\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09959812859884837\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t0.0002799104286628279\n",
      "Utility Acc Coop:\t\t0.32995441458733205\n",
      "Val Privacy Acc Adv:\t\t0.10479697452229299\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.0004976114649681529\n",
      "Val Utility Acc Coop:\t\t0.32563694267515925\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 225/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.0806363341759029\n",
      "Validation Loss:\t\t0.9019204515750241\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.4030686785643938\n",
      "Cross Reconstruction Loss:\t2.666012819501275\n",
      "End Effector Loss:\t\t0.00930439706347163\n",
      "Smoothing Loss:\t\t\t0.010482629145580801\n",
      "Triplet Loss:\t\t\t3.00251014051114\n",
      "Latent Consistency Loss:\t0.025717056720438326\n",
      "Privacy Loss:\t\t\t4.9277310636816924e-05\n",
      "Privacy Loss Dyn:\t\t-3.6311384623277974\n",
      "Privacy Loss Stat:\t\t3.631631234480796\n",
      "Utility Loss:\t\t\t-3.2925845760606607\n",
      "Utility Loss Dyn:\t\t-4.12163391619711\n",
      "Utility Loss Stat:\t\t3.7923754661874898\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.37598284205813315\n",
      "Val Cross Reconstruction Loss:\t2.6481862280778823\n",
      "Val End Effector Loss:\t\t0.007871498680038816\n",
      "Val Smoothing Loss:\t\t0.009146969314593419\n",
      "Val Triplet Loss:\t\t2.9482738045370502\n",
      "Val Latent Consistency Loss:\t0.024348565573050717\n",
      "Val Privacy Loss:\t\t4.0082605021774386e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6259406979676263\n",
      "Val Privacy Loss Stat:\t\t3.626341523638197\n",
      "Val Utility Loss:\t\t-3.341975825607397\n",
      "Val Utility Loss Dyn:\t\t-4.121821306313679\n",
      "Val Utility Loss Stat:\t\t3.7876237167674267\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.577571817338276\n",
      "Adv Utility Training Loss:\t\t4.095287111883962\n",
      "Coop Privacy Training Loss:\t3.6316312349384137\n",
      "Coop Utility Training Loss:\t3.8015415990345005\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.15284608925143953\n",
      "Adv Utility Training Acc:\t\t0.025951695457453614\n",
      "Coop Privacy Training Acc:\t\t0.09930822136916187\n",
      "Coop Utility Training Acc:\t\t0.3226067658349328\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09960812539987204\n",
      "Privacy Acc Coop:\t\t0.09930822136916187\n",
      "Utility Acc Adv:\t\t0.0002799104286628279\n",
      "Utility Acc Coop:\t\t0.33212372040946897\n",
      "Val Privacy Acc Adv:\t\t0.10499601910828026\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.0004976114649681529\n",
      "Val Utility Acc Coop:\t\t0.3346934713375796\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 226/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.078586475937958\n",
      "Validation Loss:\t\t0.9549923580922898\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.40047054424624523\n",
      "Cross Reconstruction Loss:\t2.663492267359089\n",
      "End Effector Loss:\t\t0.009308908387639644\n",
      "Smoothing Loss:\t\t\t0.01048706553760804\n",
      "Triplet Loss:\t\t\t2.9966951911447905\n",
      "Latent Consistency Loss:\t0.02567109380749198\n",
      "Privacy Loss:\t\t\t3.578991975375497e-05\n",
      "Privacy Loss Dyn:\t\t-3.631223346663833\n",
      "Privacy Loss Stat:\t\t3.631581247119818\n",
      "Utility Loss:\t\t\t-3.2829158658487096\n",
      "Utility Loss Dyn:\t\t-4.121662558459809\n",
      "Utility Loss Stat:\t\t3.793370974803688\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3730518538860758\n",
      "Val Cross Reconstruction Loss:\t2.643640332920536\n",
      "Val End Effector Loss:\t\t0.007859318021827252\n",
      "Val Smoothing Loss:\t\t0.009108080095641173\n",
      "Val Triplet Loss:\t\t2.94181031026658\n",
      "Val Latent Consistency Loss:\t0.023731092667313897\n",
      "Val Privacy Loss:\t\t-6.499184165031287e-06\n",
      "Val Privacy Loss Dyn:\t\t-3.6264065192763213\n",
      "Val Privacy Loss Stat:\t\t3.626341523638197\n",
      "Val Utility Loss:\t\t-3.269773689804563\n",
      "Val Utility Loss Dyn:\t\t-4.121659154345275\n",
      "Val Utility Loss Stat:\t\t3.7946817981209726\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5763158255178658\n",
      "Adv Utility Training Loss:\t\t4.0950316202160035\n",
      "Coop Privacy Training Loss:\t3.6315812474248963\n",
      "Coop Utility Training Loss:\t3.8020190040956914\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.15487543985924504\n",
      "Adv Utility Training Acc:\t\t0.026436540307101727\n",
      "Coop Privacy Training Acc:\t\t0.09935820537428024\n",
      "Coop Utility Training Acc:\t\t0.3218520073576456\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09949816058861165\n",
      "Privacy Acc Coop:\t\t0.09935820537428024\n",
      "Utility Acc Adv:\t\t0.00030990083173384515\n",
      "Utility Acc Coop:\t\t0.33105406269993604\n",
      "Val Privacy Acc Adv:\t\t0.1044984076433121\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.0002985668789808917\n",
      "Val Utility Acc Coop:\t\t0.32961783439490444\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 227/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.059530736606804\n",
      "Validation Loss:\t\t0.8761444266909247\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3978234659916151\n",
      "Cross Reconstruction Loss:\t2.661054062980608\n",
      "End Effector Loss:\t\t0.009311138619195077\n",
      "Smoothing Loss:\t\t\t0.010488444271003464\n",
      "Triplet Loss:\t\t\t2.991304783964493\n",
      "Latent Consistency Loss:\t0.025403248558508534\n",
      "Privacy Loss:\t\t\t3.0773939113165425e-05\n",
      "Privacy Loss Dyn:\t\t-3.631333499860855\n",
      "Privacy Loss Stat:\t\t3.631641235552914\n",
      "Utility Loss:\t\t\t-3.28836611151619\n",
      "Utility Loss Dyn:\t\t-4.1217794335963855\n",
      "Utility Loss Stat:\t\t3.792942823085431\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.37102433014067876\n",
      "Val Cross Reconstruction Loss:\t2.6391403234688338\n",
      "Val End Effector Loss:\t\t0.00787336381365824\n",
      "Val Smoothing Loss:\t\t0.009182323194494482\n",
      "Val Triplet Loss:\t\t2.9394661681667253\n",
      "Val Latent Consistency Loss:\t0.023391073545927454\n",
      "Val Privacy Loss:\t\t-2.1781511367506283e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626260780225134\n",
      "Val Privacy Loss Stat:\t\t3.626042974982292\n",
      "Val Utility Loss:\t\t-3.338593695573746\n",
      "Val Utility Loss Dyn:\t\t-4.121142059374767\n",
      "Val Utility Loss Stat:\t\t3.7872827068255965\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5770497230559073\n",
      "Adv Utility Training Loss:\t\t4.0940401235301\n",
      "Coop Privacy Training Loss:\t3.6316412360105312\n",
      "Coop Utility Training Loss:\t3.801644658401694\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.15427063339731287\n",
      "Adv Utility Training Acc:\t\t0.02709632917466411\n",
      "Coop Privacy Training Acc:\t\t0.0992982245681382\n",
      "Coop Utility Training Acc:\t\t0.3220369481765835\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09941818618042227\n",
      "Privacy Acc Coop:\t\t0.0992982245681382\n",
      "Utility Acc Adv:\t\t0.00020993282149712092\n",
      "Utility Acc Coop:\t\t0.33105406269993604\n",
      "Val Privacy Acc Adv:\t\t0.10459792993630573\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.000696656050955414\n",
      "Val Utility Acc Coop:\t\t0.3369824840764331\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 228/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t1.0097279277864322\n",
      "Validation Loss:\t\t1.0223970048034647\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3954800901051446\n",
      "Cross Reconstruction Loss:\t2.659851421092614\n",
      "End Effector Loss:\t\t0.00931465734536411\n",
      "Smoothing Loss:\t\t\t0.010489584802413361\n",
      "Triplet Loss:\t\t\t2.9860496879462928\n",
      "Latent Consistency Loss:\t0.025139775115255353\n",
      "Privacy Loss:\t\t\t2.9700750429052158e-05\n",
      "Privacy Loss Dyn:\t\t-3.6313242297559998\n",
      "Privacy Loss Stat:\t\t3.6316212372221552\n",
      "Utility Loss:\t\t\t-3.325477946666442\n",
      "Utility Loss Dyn:\t\t-4.121825504974151\n",
      "Utility Loss Stat:\t\t3.7892777097583656\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3690949161151412\n",
      "Val Cross Reconstruction Loss:\t2.6315488314173026\n",
      "Val End Effector Loss:\t\t0.007866764034791167\n",
      "Val Smoothing Loss:\t\t0.009132246172447114\n",
      "Val Triplet Loss:\t\t2.934902497917224\n",
      "Val Latent Consistency Loss:\t0.02342674680718571\n",
      "Val Privacy Loss:\t\t-3.293061711985594e-06\n",
      "Val Privacy Loss Dyn:\t\t-3.6260758828205666\n",
      "Val Privacy Loss Stat:\t\t3.626042950684857\n",
      "Val Utility Loss:\t\t-3.1833778672916875\n",
      "Val Utility Loss Dyn:\t\t-4.121726440016631\n",
      "Val Utility Loss Stat:\t\t3.803388669991949\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5744106591091045\n",
      "Adv Utility Training Loss:\t\t4.093358203682927\n",
      "Coop Privacy Training Loss:\t3.6316212373746946\n",
      "Coop Utility Training Loss:\t3.798682016054179\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.15450555822136916\n",
      "Adv Utility Training Acc:\t\t0.028940738963531668\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.3251559500959693\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09946817018554063\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t0.00020993282149712092\n",
      "Utility Acc Coop:\t\t0.3347728726807422\n",
      "Val Privacy Acc Adv:\t\t0.10479697452229299\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.0003980891719745223\n",
      "Val Utility Acc Coop:\t\t0.3195660828025478\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 229/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.9882452306817319\n",
      "Validation Loss:\t\t0.8215307657173865\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.39337930905079127\n",
      "Cross Reconstruction Loss:\t2.657928612090347\n",
      "End Effector Loss:\t\t0.0093188932572473\n",
      "Smoothing Loss:\t\t\t0.010491116629330702\n",
      "Triplet Loss:\t\t\t2.9819053642580466\n",
      "Latent Consistency Loss:\t0.024733569834116783\n",
      "Privacy Loss:\t\t\t2.5793538212547377e-05\n",
      "Privacy Loss Dyn:\t\t-3.6313533059923753\n",
      "Privacy Loss Stat:\t\t3.631611241336366\n",
      "Utility Loss:\t\t\t-3.3343653566015123\n",
      "Utility Loss Dyn:\t\t-4.121895740372358\n",
      "Utility Loss Stat:\t\t3.7884592163356845\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.36673790672022827\n",
      "Val Cross Reconstruction Loss:\t2.6427285701605925\n",
      "Val End Effector Loss:\t\t0.007880565161656613\n",
      "Val Smoothing Loss:\t\t0.009196257488624116\n",
      "Val Triplet Loss:\t\t2.9301195129467423\n",
      "Val Latent Consistency Loss:\t0.022790685236738745\n",
      "Val Privacy Loss:\t\t-2.2367117511239022e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626565189118598\n",
      "Val Privacy Loss Stat:\t\t3.626341522119607\n",
      "Val Utility Loss:\t\t-3.369691229170295\n",
      "Val Utility Loss Dyn:\t\t-4.121461081656681\n",
      "Val Utility Loss Stat:\t\t3.7844919581322154\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.572604540594861\n",
      "Adv Utility Training Loss:\t\t4.092110641477052\n",
      "Coop Privacy Training Loss:\t3.631611241336366\n",
      "Coop Utility Training Loss:\t3.797774000954948\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1567298464491363\n",
      "Adv Utility Training Acc:\t\t0.028355926103646834\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.32602067338451696\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09940818937939859\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t0.0001999360204734485\n",
      "Utility Acc Coop:\t\t0.33568258157389635\n",
      "Val Privacy Acc Adv:\t\t0.10429936305732485\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.0004976114649681529\n",
      "Val Utility Acc Coop:\t\t0.33867436305732485\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 230/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.957125318348074\n",
      "Validation Loss:\t\t0.9022425201240998\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.39102200041653173\n",
      "Cross Reconstruction Loss:\t2.6572062134819006\n",
      "End Effector Loss:\t\t0.009319727477377433\n",
      "Smoothing Loss:\t\t\t0.010474089178556406\n",
      "Triplet Loss:\t\t\t2.9764700535391664\n",
      "Latent Consistency Loss:\t0.024537972853264593\n",
      "Privacy Loss:\t\t\t2.4682710510907994e-05\n",
      "Privacy Loss Dyn:\t\t-3.631374405502739\n",
      "Privacy Loss Stat:\t\t3.631621241188171\n",
      "Utility Loss:\t\t\t-3.3532557569858894\n",
      "Utility Loss Dyn:\t\t-4.121996019257236\n",
      "Utility Loss Stat:\t\t3.786670446853491\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3645977302911175\n",
      "Val Cross Reconstruction Loss:\t2.636419926479364\n",
      "Val End Effector Loss:\t\t0.007862778831344501\n",
      "Val Smoothing Loss:\t\t0.009194784824422021\n",
      "Val Triplet Loss:\t\t2.926896385326507\n",
      "Val Latent Consistency Loss:\t0.022672309783423782\n",
      "Val Privacy Loss:\t\t-2.098577037738387e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6259542544176626\n",
      "Val Privacy Loss Stat:\t\t3.6257444005103627\n",
      "Val Utility Loss:\t\t-3.2796405622154285\n",
      "Val Utility Loss Dyn:\t\t-4.122218071275456\n",
      "Val Utility Loss Stat:\t\t3.794254028113784\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.57212344073212\n",
      "Adv Utility Training Loss:\t\t4.092272156869763\n",
      "Coop Privacy Training Loss:\t3.6316212414932494\n",
      "Coop Utility Training Loss:\t3.796430974912735\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1575195937300064\n",
      "Adv Utility Training Acc:\t\t0.028815778950735765\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.3276101647472809\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09940818937939859\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t0.0001599488163787588\n",
      "Utility Acc Coop:\t\t0.33815179142674345\n",
      "Val Privacy Acc Adv:\t\t0.10489649681528662\n",
      "Val Privacy Acc Coop:\t\t0.10519506369426751\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.3287221337579618\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 231/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.9345865699195053\n",
      "Validation Loss:\t\t0.776112433926315\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3888056082216044\n",
      "Cross Reconstruction Loss:\t2.6564819763962153\n",
      "End Effector Loss:\t\t0.009319567403405123\n",
      "Smoothing Loss:\t\t\t0.010476798407247223\n",
      "Triplet Loss:\t\t\t2.9721274429304203\n",
      "Latent Consistency Loss:\t0.024396247815004695\n",
      "Privacy Loss:\t\t\t2.435555232311012e-05\n",
      "Privacy Loss Dyn:\t\t-3.6313676924104503\n",
      "Privacy Loss Stat:\t\t3.6316112462176164\n",
      "Utility Loss:\t\t\t-3.365537080868497\n",
      "Utility Loss Dyn:\t\t-4.121986300382413\n",
      "Utility Loss Stat:\t\t3.7854325955904073\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3623453559009892\n",
      "Val Cross Reconstruction Loss:\t2.631255497598344\n",
      "Val End Effector Loss:\t\t0.007881887574460665\n",
      "Val Smoothing Loss:\t\t0.009125096465395704\n",
      "Val Triplet Loss:\t\t2.923043413526693\n",
      "Val Latent Consistency Loss:\t0.022606974716778774\n",
      "Val Privacy Loss:\t\t-2.2693424467827865e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6268670164096126\n",
      "Val Privacy Loss Stat:\t\t3.6266400920357675\n",
      "Val Utility Loss:\t\t-3.3960514676039386\n",
      "Val Utility Loss Dyn:\t\t-4.1219764393606\n",
      "Val Utility Loss Stat:\t\t3.782371308393539\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5708565063684015\n",
      "Adv Utility Training Loss:\t\t4.0916242010686465\n",
      "Coop Privacy Training Loss:\t3.6316112463701558\n",
      "Coop Utility Training Loss:\t3.7949468310033367\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.15937899872040948\n",
      "Adv Utility Training Acc:\t\t0.029210652591170824\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.3288797584772873\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09942818298144594\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t0.0001599488163787588\n",
      "Utility Acc Coop:\t\t0.33898152591170827\n",
      "Val Privacy Acc Adv:\t\t0.10400079617834394\n",
      "Val Privacy Acc Coop:\t\t0.10429936305732485\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.3403662420382166\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 232/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.9473775896927198\n",
      "Validation Loss:\t\t1.0039583132098056\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3867419568186606\n",
      "Cross Reconstruction Loss:\t2.6560842841386947\n",
      "End Effector Loss:\t\t0.009321070430825345\n",
      "Smoothing Loss:\t\t\t0.010480768865383136\n",
      "Triplet Loss:\t\t\t2.967405680426404\n",
      "Latent Consistency Loss:\t0.024354910800353846\n",
      "Privacy Loss:\t\t\t2.6592576038509473e-05\n",
      "Privacy Loss Dyn:\t\t-3.631375307466308\n",
      "Privacy Loss Stat:\t\t3.63164123295975\n",
      "Utility Loss:\t\t\t-3.343459502139003\n",
      "Utility Loss Dyn:\t\t-4.122037925708011\n",
      "Utility Loss Stat:\t\t3.787691971924697\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3622067403641476\n",
      "Val Cross Reconstruction Loss:\t2.6358095005059696\n",
      "Val End Effector Loss:\t\t0.007890244257772804\n",
      "Val Smoothing Loss:\t\t0.009152495530641572\n",
      "Val Triplet Loss:\t\t2.9198759346251277\n",
      "Val Latent Consistency Loss:\t0.0223992029620204\n",
      "Val Privacy Loss:\t\t2.06964790441428e-06\n",
      "Val Privacy Loss Dyn:\t\t-3.6263208450025814\n",
      "Val Privacy Loss Stat:\t\t3.6263415373055037\n",
      "Val Utility Loss:\t\t-3.163253857071992\n",
      "Val Utility Loss Dyn:\t\t-4.1220451099857405\n",
      "Val Utility Loss Stat:\t\t3.805719724885977\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5703118957927114\n",
      "Adv Utility Training Loss:\t\t4.091027459652852\n",
      "Coop Privacy Training Loss:\t3.6316412331122887\n",
      "Coop Utility Training Loss:\t3.7969675297471706\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.15885416666666666\n",
      "Adv Utility Training Acc:\t\t0.030820137555982084\n",
      "Coop Privacy Training Acc:\t\t0.0992982245681382\n",
      "Coop Utility Training Acc:\t\t0.3269903630838132\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09940818937939859\n",
      "Privacy Acc Coop:\t\t0.0992982245681382\n",
      "Utility Acc Adv:\t\t0.00012995841330774152\n",
      "Utility Acc Coop:\t\t0.33634237044145876\n",
      "Val Privacy Acc Adv:\t\t0.10459792993630573\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.31916799363057324\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 233/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.8862085394866369\n",
      "Validation Loss:\t\t1.0344884881903982\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3846895947756862\n",
      "Cross Reconstruction Loss:\t2.6549097393387338\n",
      "End Effector Loss:\t\t0.009321004731171858\n",
      "Smoothing Loss:\t\t\t0.010483203814213027\n",
      "Triplet Loss:\t\t\t2.963001447843575\n",
      "Latent Consistency Loss:\t0.024260992559670486\n",
      "Privacy Loss:\t\t\t2.6239676881278852e-05\n",
      "Privacy Loss Dyn:\t\t-3.631328850622293\n",
      "Privacy Loss Stat:\t\t3.6315912471241623\n",
      "Utility Loss:\t\t\t-3.3950698618239037\n",
      "Utility Loss Dyn:\t\t-4.122034641846738\n",
      "Utility Loss Stat:\t\t3.7825276596913793\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.35981795865639\n",
      "Val Cross Reconstruction Loss:\t2.6394633684947992\n",
      "Val End Effector Loss:\t\t0.007876115563402699\n",
      "Val Smoothing Loss:\t\t0.009156965849339772\n",
      "Val Triplet Loss:\t\t2.913484807227068\n",
      "Val Latent Consistency Loss:\t0.022584317168992035\n",
      "Val Privacy Loss:\t\t-9.815973840701352e-06\n",
      "Val Privacy Loss Dyn:\t\t-3.625245419277507\n",
      "Val Privacy Loss Stat:\t\t3.6251472728267595\n",
      "Val Utility Loss:\t\t-3.1237589356246267\n",
      "Val Utility Loss Dyn:\t\t-4.1219311580536475\n",
      "Val Utility Loss Stat:\t\t3.809555248090416\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.568840679112567\n",
      "Adv Utility Training Loss:\t\t4.090741343019257\n",
      "Coop Privacy Training Loss:\t3.6315912474292404\n",
      "Coop Utility Training Loss:\t3.7921026424193185\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1618532069737684\n",
      "Adv Utility Training Acc:\t\t0.030435260716570697\n",
      "Coop Privacy Training Acc:\t\t0.09934820857325656\n",
      "Coop Utility Training Acc:\t\t0.3319887635956494\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09948816378758797\n",
      "Privacy Acc Coop:\t\t0.09934820857325656\n",
      "Utility Acc Adv:\t\t0.00012995841330774152\n",
      "Utility Acc Coop:\t\t0.3417206493921945\n",
      "Val Privacy Acc Adv:\t\t0.10569267515923567\n",
      "Val Privacy Acc Coop:\t\t0.1057921974522293\n",
      "Val Utility Acc Adv:\t\t0.0003980891719745223\n",
      "Val Utility Acc Coop:\t\t0.3140923566878981\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 234/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.8891143155029796\n",
      "Validation Loss:\t\t0.7778616344117245\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.38254094261125504\n",
      "Cross Reconstruction Loss:\t2.6540385101059654\n",
      "End Effector Loss:\t\t0.00932287603470134\n",
      "Smoothing Loss:\t\t\t0.010484584770746343\n",
      "Triplet Loss:\t\t\t2.958233365933253\n",
      "Latent Consistency Loss:\t0.0241448706968122\n",
      "Privacy Loss:\t\t\t2.2804306168168764e-05\n",
      "Privacy Loss Dyn:\t\t-3.63139320380857\n",
      "Privacy Loss Stat:\t\t3.6316212491202036\n",
      "Utility Loss:\t\t\t-3.3818529266923645\n",
      "Utility Loss Dyn:\t\t-4.122098333013416\n",
      "Utility Loss Stat:\t\t3.78391304690336\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.35785193940636456\n",
      "Val Cross Reconstruction Loss:\t2.6357174527113605\n",
      "Val End Effector Loss:\t\t0.00787618158052966\n",
      "Val Smoothing Loss:\t\t0.009170232041127933\n",
      "Val Triplet Loss:\t\t2.9054990680354416\n",
      "Val Latent Consistency Loss:\t0.02274745062088511\n",
      "Val Privacy Loss:\t\t-1.954614736471966e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6265369782781907\n",
      "Val Privacy Loss Stat:\t\t3.6263415145266586\n",
      "Val Utility Loss:\t\t-3.369754888449505\n",
      "Val Utility Loss Dyn:\t\t-4.121846721430493\n",
      "Val Utility Loss Stat:\t\t3.7848712243851583\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5679469750771062\n",
      "Adv Utility Training Loss:\t\t4.090133426285522\n",
      "Coop Privacy Training Loss:\t3.6316212495778206\n",
      "Coop Utility Training Loss:\t3.793225738381394\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.16166826615483046\n",
      "Adv Utility Training Acc:\t\t0.030860124760076775\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.3309990802943058\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09938819577735125\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t9.996801023672424e-05\n",
      "Utility Acc Coop:\t\t0.3404910428662828\n",
      "Val Privacy Acc Adv:\t\t0.10429936305732485\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.0003980891719745223\n",
      "Val Utility Acc Coop:\t\t0.3377786624203822\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 235/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.8526435849755545\n",
      "Validation Loss:\t\t0.7283899731293415\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3805708791381338\n",
      "Cross Reconstruction Loss:\t2.6530290136563037\n",
      "End Effector Loss:\t\t0.009322586766088421\n",
      "Smoothing Loss:\t\t\t0.010479793595465917\n",
      "Triplet Loss:\t\t\t2.954367646786622\n",
      "Latent Consistency Loss:\t0.0240469862881545\n",
      "Privacy Loss:\t\t\t2.2380114059301804e-05\n",
      "Privacy Loss Dyn:\t\t-3.631427436018326\n",
      "Privacy Loss Stat:\t\t3.631651232506477\n",
      "Utility Loss:\t\t\t-3.4094229421780344\n",
      "Utility Loss Dyn:\t\t-4.122130195070976\n",
      "Utility Loss Stat:\t\t3.781187902103993\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.354983760482946\n",
      "Val Cross Reconstruction Loss:\t2.630347054475432\n",
      "Val End Effector Loss:\t\t0.007887069488857772\n",
      "Val Smoothing Loss:\t\t0.009182342090851562\n",
      "Val Triplet Loss:\t\t2.905335110463914\n",
      "Val Latent Consistency Loss:\t0.022323004806497293\n",
      "Val Privacy Loss:\t\t-2.228017825229912e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626265770310809\n",
      "Val Privacy Loss Stat:\t\t3.626042970426523\n",
      "Val Utility Loss:\t\t-3.408589211239177\n",
      "Val Utility Loss Dyn:\t\t-4.121787538953647\n",
      "Val Utility Loss Stat:\t\t3.7809286208669093\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5674838380636653\n",
      "Adv Utility Training Loss:\t\t4.090104839089431\n",
      "Coop Privacy Training Loss:\t3.631651232659016\n",
      "Coop Utility Training Loss:\t3.791073797455371\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.16255298304542545\n",
      "Adv Utility Training Acc:\t\t0.03102507197696737\n",
      "Coop Privacy Training Acc:\t\t0.09928822776711452\n",
      "Coop Utility Training Acc:\t\t0.3329884436980166\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.0993682021753039\n",
      "Privacy Acc Coop:\t\t0.09928822776711452\n",
      "Utility Acc Adv:\t\t9.996801023672424e-05\n",
      "Utility Acc Coop:\t\t0.3430302303262956\n",
      "Val Privacy Acc Adv:\t\t0.10459792993630573\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.0003980891719745223\n",
      "Val Utility Acc Coop:\t\t0.34285429936305734\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 236/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.8417178758682823\n",
      "Validation Loss:\t\t0.7372457709898994\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.37850030373855803\n",
      "Cross Reconstruction Loss:\t2.6524268384172\n",
      "End Effector Loss:\t\t0.0093220993596405\n",
      "Smoothing Loss:\t\t\t0.01047281316950469\n",
      "Triplet Loss:\t\t\t2.9501003898723113\n",
      "Latent Consistency Loss:\t0.023912325315534954\n",
      "Privacy Loss:\t\t\t1.8955688025046828e-05\n",
      "Privacy Loss Dyn:\t\t-3.631441667151619\n",
      "Privacy Loss Stat:\t\t3.6316312312774754\n",
      "Utility Loss:\t\t\t-3.410508554254826\n",
      "Utility Loss Dyn:\t\t-4.122206964328056\n",
      "Utility Loss Stat:\t\t3.7811561012146035\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3541249408843411\n",
      "Val Cross Reconstruction Loss:\t2.6295236022609054\n",
      "Val End Effector Loss:\t\t0.007877160566651328\n",
      "Val Smoothing Loss:\t\t0.009164407496358369\n",
      "Val Triplet Loss:\t\t2.903881783698015\n",
      "Val Latent Consistency Loss:\t0.022062284266872772\n",
      "Val Privacy Loss:\t\t-1.749965795286142e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6253222659894617\n",
      "Val Privacy Loss Stat:\t\t3.6251472652338115\n",
      "Val Utility Loss:\t\t-3.3938139654268884\n",
      "Val Utility Loss Dyn:\t\t-4.121388915238107\n",
      "Val Utility Loss Stat:\t\t3.782007515050803\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5656883765395757\n",
      "Adv Utility Training Loss:\t\t4.089631633123982\n",
      "Coop Privacy Training Loss:\t3.6316312315825536\n",
      "Coop Utility Training Loss:\t3.790672025540206\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.16347768714011515\n",
      "Adv Utility Training Acc:\t\t0.032019753678822774\n",
      "Coop Privacy Training Acc:\t\t0.09930822136916187\n",
      "Coop Utility Training Acc:\t\t0.33336332373640437\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09938819577735125\n",
      "Privacy Acc Coop:\t\t0.09930822136916187\n",
      "Utility Acc Adv:\t\t8.997120921305183e-05\n",
      "Utility Acc Coop:\t\t0.3429502559181062\n",
      "Val Privacy Acc Adv:\t\t0.10549363057324841\n",
      "Val Privacy Acc Coop:\t\t0.1057921974522293\n",
      "Val Utility Acc Adv:\t\t0.0005971337579617834\n",
      "Val Utility Acc Coop:\t\t0.34106289808917195\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 237/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.8180332700003914\n",
      "Validation Loss:\t\t0.6840680419900425\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.37671712387927586\n",
      "Cross Reconstruction Loss:\t2.652347253670085\n",
      "End Effector Loss:\t\t0.009324285465394523\n",
      "Smoothing Loss:\t\t\t0.010479182550136622\n",
      "Triplet Loss:\t\t\t2.9459037576359353\n",
      "Latent Consistency Loss:\t0.023833860861887095\n",
      "Privacy Loss:\t\t\t2.218617968885699e-05\n",
      "Privacy Loss Dyn:\t\t-3.631359383454326\n",
      "Privacy Loss Stat:\t\t3.6315812474248963\n",
      "Utility Loss:\t\t\t-3.425662088912798\n",
      "Utility Loss Dyn:\t\t-4.122208442431723\n",
      "Utility Loss Stat:\t\t3.779642241472475\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3519338830641121\n",
      "Val Cross Reconstruction Loss:\t2.6356924992458075\n",
      "Val End Effector Loss:\t\t0.007879035538477693\n",
      "Val Smoothing Loss:\t\t0.009152212008169501\n",
      "Val Triplet Loss:\t\t2.8978523433588115\n",
      "Val Latent Consistency Loss:\t0.022545819141113074\n",
      "Val Privacy Loss:\t\t-2.1308850330911624e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626256031595218\n",
      "Val Privacy Loss Stat:\t\t3.6260429446104987\n",
      "Val Utility Loss:\t\t-3.441993859163515\n",
      "Val Utility Loss Dyn:\t\t-4.121817172712581\n",
      "Val Utility Loss Stat:\t\t3.7776177886185374\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5659600413158317\n",
      "Adv Utility Training Loss:\t\t4.089454491017952\n",
      "Coop Privacy Training Loss:\t3.631581247577435\n",
      "Coop Utility Training Loss:\t3.789256672789024\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1656220009596929\n",
      "Adv Utility Training Acc:\t\t0.03263955534229047\n",
      "Coop Privacy Training Acc:\t\t0.09935820537428024\n",
      "Coop Utility Training Acc:\t\t0.3348428502879079\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09948816378758797\n",
      "Privacy Acc Coop:\t\t0.09935820537428024\n",
      "Utility Acc Adv:\t\t9.996801023672424e-05\n",
      "Utility Acc Coop:\t\t0.3445697376839411\n",
      "Val Privacy Acc Adv:\t\t0.10459792993630573\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.0004976114649681529\n",
      "Val Utility Acc Coop:\t\t0.34643710191082805\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 238/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.7985913817790442\n",
      "Validation Loss:\t\t0.8381483862591776\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3749877320065074\n",
      "Cross Reconstruction Loss:\t2.651297766431661\n",
      "End Effector Loss:\t\t0.009324302839655107\n",
      "Smoothing Loss:\t\t\t0.010475933999276016\n",
      "Triplet Loss:\t\t\t2.9420092075357664\n",
      "Latent Consistency Loss:\t0.023766756573154503\n",
      "Privacy Loss:\t\t\t1.7906028493733568e-05\n",
      "Privacy Loss Dyn:\t\t-3.6314721677979063\n",
      "Privacy Loss Stat:\t\t3.6316512318963206\n",
      "Utility Loss:\t\t\t-3.436960651107271\n",
      "Utility Loss Dyn:\t\t-4.122171592956465\n",
      "Utility Loss Stat:\t\t3.778475523147534\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.34968128496674217\n",
      "Val Cross Reconstruction Loss:\t2.63028949385236\n",
      "Val End Effector Loss:\t\t0.007885957480805695\n",
      "Val Smoothing Loss:\t\t0.009205867924911392\n",
      "Val Triplet Loss:\t\t2.8953108210472545\n",
      "Val Latent Consistency Loss:\t0.021990170583698402\n",
      "Val Privacy Loss:\t\t-2.079025195662383e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6268479975925128\n",
      "Val Privacy Loss Stat:\t\t3.6266401057030744\n",
      "Val Utility Loss:\t\t-3.274938425440697\n",
      "Val Utility Loss Dyn:\t\t-4.122106588570175\n",
      "Val Utility Loss Stat:\t\t3.7946127281067477\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.563698409843811\n",
      "Adv Utility Training Loss:\t\t4.088231898238853\n",
      "Coop Privacy Training Loss:\t3.6316512318963206\n",
      "Coop Utility Training Loss:\t3.7886799579237183\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.16629178662827895\n",
      "Adv Utility Training Acc:\t\t0.03318937939859245\n",
      "Coop Privacy Training Acc:\t\t0.09928822776711452\n",
      "Coop Utility Training Acc:\t\t0.33548764395393477\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.0993682021753039\n",
      "Privacy Acc Coop:\t\t0.09928822776711452\n",
      "Utility Acc Adv:\t\t8.997120921305183e-05\n",
      "Utility Acc Coop:\t\t0.34585932501599487\n",
      "Val Privacy Acc Adv:\t\t0.10410031847133758\n",
      "Val Privacy Acc Coop:\t\t0.10429936305732485\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.32991640127388533\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 239/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.7899685252579411\n",
      "Validation Loss:\t\t0.7091407083259647\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.37382230789937504\n",
      "Cross Reconstruction Loss:\t2.6514732428872274\n",
      "End Effector Loss:\t\t0.009328478816193567\n",
      "Smoothing Loss:\t\t\t0.01047802810191927\n",
      "Triplet Loss:\t\t\t2.9389367973049407\n",
      "Latent Consistency Loss:\t0.023730617902591414\n",
      "Privacy Loss:\t\t\t1.8373598902940904e-05\n",
      "Privacy Loss Dyn:\t\t-3.63142750649138\n",
      "Privacy Loss Stat:\t\t3.6316112433193743\n",
      "Utility Loss:\t\t\t-3.4398473201466158\n",
      "Utility Loss Dyn:\t\t-4.122084755204995\n",
      "Utility Loss Stat:\t\t3.778100025020802\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3500215949336435\n",
      "Val Cross Reconstruction Loss:\t2.6316336279462096\n",
      "Val End Effector Loss:\t\t0.007884982377172086\n",
      "Val Smoothing Loss:\t\t0.009241260659352988\n",
      "Val Triplet Loss:\t\t2.8918430380001188\n",
      "Val Latent Consistency Loss:\t0.022238837887242343\n",
      "Val Privacy Loss:\t\t1.570145795299749e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6261845136144357\n",
      "Val Privacy Loss Stat:\t\t3.6263415251567865\n",
      "Val Utility Loss:\t\t-3.4039217469039236\n",
      "Val Utility Loss Dyn:\t\t-4.121902635902356\n",
      "Val Utility Loss Stat:\t\t3.781510470019784\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5641265612569897\n",
      "Adv Utility Training Loss:\t\t4.088235260810291\n",
      "Coop Privacy Training Loss:\t3.6316112443871478\n",
      "Coop Utility Training Loss:\t3.7884363334909588\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1653470889315419\n",
      "Adv Utility Training Acc:\t\t0.033814179462571974\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.3355976087651951\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09941818618042227\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t0.00017994241842610365\n",
      "Utility Acc Coop:\t\t0.3463991522712732\n",
      "Val Privacy Acc Adv:\t\t0.10459792993630573\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.34295382165605093\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 240/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.794584448084054\n",
      "Validation Loss:\t\t0.7781570909105858\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3725039784487287\n",
      "Cross Reconstruction Loss:\t2.6513018225220177\n",
      "End Effector Loss:\t\t0.009323144427209292\n",
      "Smoothing Loss:\t\t\t0.010472420483567798\n",
      "Triplet Loss:\t\t\t2.935603668959722\n",
      "Latent Consistency Loss:\t0.02377998752380058\n",
      "Privacy Loss:\t\t\t1.4042881003420702e-05\n",
      "Privacy Loss Dyn:\t\t-3.6314808109671506\n",
      "Privacy Loss Stat:\t\t3.6316212378323116\n",
      "Utility Loss:\t\t\t-3.4297116768337257\n",
      "Utility Loss Dyn:\t\t-4.122085973076994\n",
      "Utility Loss Stat:\t\t3.779114802525887\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3475611659751576\n",
      "Val Cross Reconstruction Loss:\t2.628806700372392\n",
      "Val End Effector Loss:\t\t0.007877458053030027\n",
      "Val Smoothing Loss:\t\t0.00912935394722565\n",
      "Val Triplet Loss:\t\t2.8926414517080707\n",
      "Val Latent Consistency Loss:\t0.021777142355349034\n",
      "Val Privacy Loss:\t\t-3.910368415200786e-08\n",
      "Val Privacy Loss Dyn:\t\t-3.6266404899062623\n",
      "Val Privacy Loss Stat:\t\t3.6266400935543572\n",
      "Val Utility Loss:\t\t-3.325524275469932\n",
      "Val Utility Loss Dyn:\t\t-4.12176729007891\n",
      "Val Utility Loss Stat:\t\t3.789214881362429\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.562551578191024\n",
      "Adv Utility Training Loss:\t\t4.088640846965104\n",
      "Coop Privacy Training Loss:\t3.631621238442468\n",
      "Coop Utility Training Loss:\t3.78905252074097\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.16707653550863724\n",
      "Adv Utility Training Acc:\t\t0.03297944657709533\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.3347428822776711\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.0993682021753039\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t0.0001199616122840691\n",
      "Utility Acc Coop:\t\t0.3450595809341011\n",
      "Val Privacy Acc Adv:\t\t0.10429936305732485\n",
      "Val Privacy Acc Coop:\t\t0.10429936305732485\n",
      "Val Utility Acc Adv:\t\t0.0002985668789808917\n",
      "Val Utility Acc Coop:\t\t0.334593949044586\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 241/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.7790400649046124\n",
      "Validation Loss:\t\t0.7667359458935109\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3715093686690486\n",
      "Cross Reconstruction Loss:\t2.6507571857858756\n",
      "End Effector Loss:\t\t0.009325009924124257\n",
      "Smoothing Loss:\t\t\t0.010479952418736956\n",
      "Triplet Loss:\t\t\t2.9337908097436163\n",
      "Latent Consistency Loss:\t0.02361898164557423\n",
      "Privacy Loss:\t\t\t1.7994977843662295e-05\n",
      "Privacy Loss Dyn:\t\t-3.631451295570769\n",
      "Privacy Loss Stat:\t\t3.6316312405823594\n",
      "Utility Loss:\t\t\t-3.4398178837654765\n",
      "Utility Loss Dyn:\t\t-4.1220508436323815\n",
      "Utility Loss Stat:\t\t3.7780690524186067\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.34691698156344664\n",
      "Val Cross Reconstruction Loss:\t2.6288279606278535\n",
      "Val End Effector Loss:\t\t0.007885961941662868\n",
      "Val Smoothing Loss:\t\t0.009175994839803999\n",
      "Val Triplet Loss:\t\t2.8887023120928723\n",
      "Val Latent Consistency Loss:\t0.022322026241546982\n",
      "Val Privacy Loss:\t\t-1.876730068474059e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.625932067822499\n",
      "Val Privacy Loss Stat:\t\t3.625744394436004\n",
      "Val Utility Loss:\t\t-3.337298569405914\n",
      "Val Utility Loss Dyn:\t\t-4.121671476181905\n",
      "Val Utility Loss Stat:\t\t3.787941603144263\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5611199113854366\n",
      "Adv Utility Training Loss:\t\t4.087865311139986\n",
      "Coop Privacy Training Loss:\t3.6316312408874376\n",
      "Coop Utility Training Loss:\t3.788118883805327\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.16826615483045426\n",
      "Adv Utility Training Acc:\t\t0.03414407389635317\n",
      "Coop Privacy Training Acc:\t\t0.09930822136916187\n",
      "Coop Utility Training Acc:\t\t0.33570757357645553\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09938819577735125\n",
      "Privacy Acc Coop:\t\t0.09930822136916187\n",
      "Utility Acc Adv:\t\t0.00013995521433141396\n",
      "Utility Acc Coop:\t\t0.3458793186180422\n",
      "Val Privacy Acc Adv:\t\t0.10489649681528662\n",
      "Val Privacy Acc Coop:\t\t0.10519506369426751\n",
      "Val Utility Acc Adv:\t\t0.0005971337579617834\n",
      "Val Utility Acc Coop:\t\t0.3342953821656051\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 242/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.7485038988215947\n",
      "Validation Loss:\t\t0.6780521267206426\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.37023930757837425\n",
      "Cross Reconstruction Loss:\t2.650338009848323\n",
      "End Effector Loss:\t\t0.00932460473534566\n",
      "Smoothing Loss:\t\t\t0.010470852025522972\n",
      "Triplet Loss:\t\t\t2.9313169228900953\n",
      "Latent Consistency Loss:\t0.023577366803635105\n",
      "Privacy Loss:\t\t\t1.3676291463928809e-05\n",
      "Privacy Loss Dyn:\t\t-3.6314744845614246\n",
      "Privacy Loss Stat:\t\t3.6316112460650776\n",
      "Utility Loss:\t\t\t-3.46484995162876\n",
      "Utility Loss Dyn:\t\t-4.122053698553768\n",
      "Utility Loss Stat:\t\t3.7755686972893283\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3459917500520208\n",
      "Val Cross Reconstruction Loss:\t2.6345211639525785\n",
      "Val End Effector Loss:\t\t0.00787420404458027\n",
      "Val Smoothing Loss:\t\t0.009165105365430283\n",
      "Val Triplet Loss:\t\t2.8831059188599797\n",
      "Val Latent Consistency Loss:\t0.02261489621440696\n",
      "Val Privacy Loss:\t\t-1.5947089833059128e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6259038660936294\n",
      "Val Privacy Loss Stat:\t\t3.625744386843056\n",
      "Val Utility Loss:\t\t-3.4219919435537545\n",
      "Val Utility Loss Dyn:\t\t-4.121833980463113\n",
      "Val Utility Loss Stat:\t\t3.779634797649019\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.561170808489477\n",
      "Adv Utility Training Loss:\t\t4.087824476428773\n",
      "Coop Privacy Training Loss:\t3.6316112460650776\n",
      "Coop Utility Training Loss:\t3.7863578395208943\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.17086032469609724\n",
      "Adv Utility Training Acc:\t\t0.033944137875879715\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.3377169305822137\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09937819897632758\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t0.00012995841330774152\n",
      "Utility Acc Coop:\t\t0.34855846129238643\n",
      "Val Privacy Acc Adv:\t\t0.10489649681528662\n",
      "Val Privacy Acc Coop:\t\t0.10519506369426751\n",
      "Val Utility Acc Adv:\t\t0.0002985668789808917\n",
      "Val Utility Acc Coop:\t\t0.3447452229299363\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 243/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.7387862665100846\n",
      "Validation Loss:\t\t0.7333639632364747\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.36893823445415314\n",
      "Cross Reconstruction Loss:\t2.649756159373605\n",
      "End Effector Loss:\t\t0.009323722196377037\n",
      "Smoothing Loss:\t\t\t0.010467389383384873\n",
      "Triplet Loss:\t\t\t2.92826475886603\n",
      "Latent Consistency Loss:\t0.023650329358642176\n",
      "Privacy Loss:\t\t\t1.3851997414538286e-05\n",
      "Privacy Loss Dyn:\t\t-3.6314727326501126\n",
      "Privacy Loss Stat:\t\t3.6316112462176164\n",
      "Utility Loss:\t\t\t-3.4695736060749622\n",
      "Utility Loss Dyn:\t\t-4.122047095137075\n",
      "Utility Loss Stat:\t\t3.775089729312743\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3451202555446868\n",
      "Val Cross Reconstruction Loss:\t2.632386692010673\n",
      "Val End Effector Loss:\t\t0.007889247552794257\n",
      "Val Smoothing Loss:\t\t0.009240534826875871\n",
      "Val Triplet Loss:\t\t2.8801229774572286\n",
      "Val Latent Consistency Loss:\t0.02235284827317402\n",
      "Val Privacy Loss:\t\t-1.4073719644242791e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6261837102804972\n",
      "Val Privacy Loss Stat:\t\t3.6260429734637025\n",
      "Val Utility Loss:\t\t-3.3593634587184638\n",
      "Val Utility Loss Dyn:\t\t-4.121890408218286\n",
      "Val Utility Loss Stat:\t\t3.7859540517163124\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.560516061038446\n",
      "Adv Utility Training Loss:\t\t4.087357980199754\n",
      "Coop Privacy Training Loss:\t3.6316112462176164\n",
      "Coop Utility Training Loss:\t3.7857440465242527\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.16941078854766475\n",
      "Adv Utility Training Acc:\t\t0.034478966730646196\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.33824676103646834\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09938819577735125\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t9.996801023672424e-05\n",
      "Utility Acc Coop:\t\t0.34913827575175943\n",
      "Val Privacy Acc Adv:\t\t0.10479697452229299\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.3362858280254777\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 244/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.6923577393919363\n",
      "Validation Loss:\t\t0.6870614498568948\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.36734599853202615\n",
      "Cross Reconstruction Loss:\t2.6494496556634104\n",
      "End Effector Loss:\t\t0.009324737496183075\n",
      "Smoothing Loss:\t\t\t0.010474092854390675\n",
      "Triplet Loss:\t\t\t2.9244794587790013\n",
      "Latent Consistency Loss:\t0.023601297219417946\n",
      "Privacy Loss:\t\t\t1.5469216720766543e-05\n",
      "Privacy Loss Dyn:\t\t-3.6314965330173936\n",
      "Privacy Loss Stat:\t\t3.6316512257947573\n",
      "Utility Loss:\t\t\t-3.5085341440738964\n",
      "Utility Loss Dyn:\t\t-4.122066582614462\n",
      "Utility Loss Stat:\t\t3.771213171196838\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.34305976872231553\n",
      "Val Cross Reconstruction Loss:\t2.6300410055051184\n",
      "Val End Effector Loss:\t\t0.007880650374706194\n",
      "Val Smoothing Loss:\t\t0.00913366662326512\n",
      "Val Triplet Loss:\t\t2.883337140842608\n",
      "Val Latent Consistency Loss:\t0.022049510115935544\n",
      "Val Privacy Loss:\t\t-2.2076307588322146e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6265623113911625\n",
      "Val Privacy Loss Stat:\t\t3.626341540342683\n",
      "Val Utility Loss:\t\t-3.4011540018069515\n",
      "Val Utility Loss Dyn:\t\t-4.121927240092283\n",
      "Val Utility Loss Stat:\t\t3.7818118386967168\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.560569382446055\n",
      "Adv Utility Training Loss:\t\t4.086422105668373\n",
      "Coop Privacy Training Loss:\t3.6316512260998355\n",
      "Coop Utility Training Loss:\t3.782131504112532\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.17012056142034548\n",
      "Adv Utility Training Acc:\t\t0.03413907549584133\n",
      "Coop Privacy Training Acc:\t\t0.09928822776711452\n",
      "Coop Utility Training Acc:\t\t0.34240043186180424\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.0993682021753039\n",
      "Privacy Acc Coop:\t\t0.09928822776711452\n",
      "Utility Acc Adv:\t\t0.00013995521433141396\n",
      "Utility Acc Coop:\t\t0.3536568298144594\n",
      "Val Privacy Acc Adv:\t\t0.10429936305732485\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.34255573248407645\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 245/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.6900966540372245\n",
      "Validation Loss:\t\t0.7444096584537416\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.36578368074758194\n",
      "Cross Reconstruction Loss:\t2.6490443077746373\n",
      "End Effector Loss:\t\t0.009325772924593013\n",
      "Smoothing Loss:\t\t\t0.010474789189621664\n",
      "Triplet Loss:\t\t\t2.921825095315202\n",
      "Latent Consistency Loss:\t0.023523066991312108\n",
      "Privacy Loss:\t\t\t1.1749112750960709e-05\n",
      "Privacy Loss Dyn:\t\t-3.6315237450736957\n",
      "Privacy Loss Stat:\t\t3.6316412346376796\n",
      "Utility Loss:\t\t\t-3.504192794048092\n",
      "Utility Loss Dyn:\t\t-4.122149717022194\n",
      "Utility Loss Stat:\t\t3.7717304357869152\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.34184840188664234\n",
      "Val Cross Reconstruction Loss:\t2.626939457692918\n",
      "Val End Effector Loss:\t\t0.007878268570609533\n",
      "Val Smoothing Loss:\t\t0.009133260495438698\n",
      "Val Triplet Loss:\t\t2.8787092296940506\n",
      "Val Latent Consistency Loss:\t0.02186403675657359\n",
      "Val Privacy Loss:\t\t-1.7456757794519897e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6262175338283464\n",
      "Val Privacy Loss Stat:\t\t3.6260429582778055\n",
      "Val Utility Loss:\t\t-3.334591252029322\n",
      "Val Utility Loss Dyn:\t\t-4.122020350899666\n",
      "Val Utility Loss Stat:\t\t3.7885612120294265\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.559791099087062\n",
      "Adv Utility Training Loss:\t\t4.0869378305289965\n",
      "Coop Privacy Training Loss:\t3.6316412347902185\n",
      "Coop Utility Training Loss:\t3.7824798074198775\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.16996561100447857\n",
      "Adv Utility Training Acc:\t\t0.03455394273832374\n",
      "Coop Privacy Training Acc:\t\t0.0992982245681382\n",
      "Coop Utility Training Acc:\t\t0.34153570857325655\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09933821177223288\n",
      "Privacy Acc Coop:\t\t0.0992982245681382\n",
      "Utility Acc Adv:\t\t6.997760716570698e-05\n",
      "Utility Acc Coop:\t\t0.35256717850287905\n",
      "Val Privacy Acc Adv:\t\t0.10459792993630573\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.3352906050955414\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 246/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.6861977172265888\n",
      "Validation Loss:\t\t0.7931898493604486\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.36424157296093473\n",
      "Cross Reconstruction Loss:\t2.6476877263472467\n",
      "End Effector Loss:\t\t0.009325209714863175\n",
      "Smoothing Loss:\t\t\t0.010470974429195326\n",
      "Triplet Loss:\t\t\t2.9181899833740217\n",
      "Latent Consistency Loss:\t0.02341836626192773\n",
      "Privacy Loss:\t\t\t1.520738339317356e-05\n",
      "Privacy Loss Dyn:\t\t-3.631469165981388\n",
      "Privacy Loss Stat:\t\t3.631621238595007\n",
      "Utility Loss:\t\t\t-3.500181189577929\n",
      "Utility Loss Dyn:\t\t-4.1221965767219135\n",
      "Utility Loss Stat:\t\t3.772178458770879\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.34037541659774295\n",
      "Val Cross Reconstruction Loss:\t2.628783762075339\n",
      "Val End Effector Loss:\t\t0.007877174589877866\n",
      "Val Smoothing Loss:\t\t0.009142588002452995\n",
      "Val Triplet Loss:\t\t2.8765356753282485\n",
      "Val Latent Consistency Loss:\t0.021821506190926408\n",
      "Val Privacy Loss:\t\t-2.0312845327292277e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6265446334887463\n",
      "Val Privacy Loss Stat:\t\t3.6263415114894793\n",
      "Val Utility Loss:\t\t-3.2804746931525552\n",
      "Val Utility Loss Dyn:\t\t-4.122082619150733\n",
      "Val Utility Loss Stat:\t\t3.7940351355607342\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5582990277217736\n",
      "Adv Utility Training Loss:\t\t4.086606144676281\n",
      "Coop Privacy Training Loss:\t3.631621239205163\n",
      "Coop Utility Training Loss:\t3.782803928402091\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.17215990882917467\n",
      "Adv Utility Training Acc:\t\t0.03433401311580294\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.3411408349328215\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09938819577735125\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t5.998080614203455e-05\n",
      "Utility Acc Coop:\t\t0.3521673064619322\n",
      "Val Privacy Acc Adv:\t\t0.10439888535031847\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.32902070063694266\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 247/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.6537890178130574\n",
      "Validation Loss:\t\t0.6004595989064806\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.36264294588024315\n",
      "Cross Reconstruction Loss:\t2.6471692079622167\n",
      "End Effector Loss:\t\t0.009324895473338916\n",
      "Smoothing Loss:\t\t\t0.010470481454475199\n",
      "Triplet Loss:\t\t\t2.9153427080092182\n",
      "Latent Consistency Loss:\t0.023226148256423072\n",
      "Privacy Loss:\t\t\t1.2612522067889447e-05\n",
      "Privacy Loss Dyn:\t\t-3.631485117908021\n",
      "Privacy Loss Stat:\t\t3.6316112402685925\n",
      "Utility Loss:\t\t\t-3.5245669286219035\n",
      "Utility Loss Dyn:\t\t-4.122228527252139\n",
      "Utility Loss Stat:\t\t3.769771827007057\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3389615311174636\n",
      "Val Cross Reconstruction Loss:\t2.621595164013516\n",
      "Val End Effector Loss:\t\t0.007876492838025283\n",
      "Val Smoothing Loss:\t\t0.009125857854226403\n",
      "Val Triplet Loss:\t\t2.874230908740098\n",
      "Val Latent Consistency Loss:\t0.02162306945011684\n",
      "Val Privacy Loss:\t\t-1.3145291881196818e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6258758450769317\n",
      "Val Privacy Loss Stat:\t\t3.6257444005103627\n",
      "Val Utility Loss:\t\t-3.465325495240035\n",
      "Val Utility Loss Dyn:\t\t-4.121909961578952\n",
      "Val Utility Loss Stat:\t\t3.775377420862769\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.561386736554361\n",
      "Adv Utility Training Loss:\t\t4.086165905914013\n",
      "Coop Privacy Training Loss:\t3.631611240421132\n",
      "Coop Utility Training Loss:\t3.781134132689112\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.16869601727447217\n",
      "Adv Utility Training Acc:\t\t0.03529870441458733\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.3431002079334613\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.0993682021753039\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t6.997760716570698e-05\n",
      "Utility Acc Coop:\t\t0.3548064619321817\n",
      "Val Privacy Acc Adv:\t\t0.10489649681528662\n",
      "Val Privacy Acc Coop:\t\t0.10519506369426751\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.3470342356687898\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 248/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.6379687714969032\n",
      "Validation Loss:\t\t0.6777651811338914\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.36113703729476365\n",
      "Cross Reconstruction Loss:\t2.646866404239901\n",
      "End Effector Loss:\t\t0.009322577689715344\n",
      "Smoothing Loss:\t\t\t0.010476309467662395\n",
      "Triplet Loss:\t\t\t2.912947482049885\n",
      "Latent Consistency Loss:\t0.02314353433824356\n",
      "Privacy Loss:\t\t\t1.8703693467992587e-05\n",
      "Privacy Loss Dyn:\t\t-3.6314342044823\n",
      "Privacy Loss Stat:\t\t3.631621241188171\n",
      "Utility Loss:\t\t\t-3.53414496960582\n",
      "Utility Loss Dyn:\t\t-4.122268267953083\n",
      "Utility Loss Stat:\t\t3.7688537740737904\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3378485836041201\n",
      "Val Cross Reconstruction Loss:\t2.622683507621668\n",
      "Val End Effector Loss:\t\t0.007873326516265322\n",
      "Val Smoothing Loss:\t\t0.009151946527847819\n",
      "Val Triplet Loss:\t\t2.8718554077634386\n",
      "Val Latent Consistency Loss:\t0.021880741189619538\n",
      "Val Privacy Loss:\t\t-1.5154386022288329e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626493060664766\n",
      "Val Privacy Loss Stat:\t\t3.6263415160452483\n",
      "Val Utility Loss:\t\t-3.3861771601780206\n",
      "Val Utility Loss Dyn:\t\t-4.12232044851704\n",
      "Val Utility Loss Stat:\t\t3.7837027303732125\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.560221113154923\n",
      "Adv Utility Training Loss:\t\t4.085974673163181\n",
      "Coop Privacy Training Loss:\t3.6316212414932494\n",
      "Coop Utility Training Loss:\t3.7794635678741004\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1704654510556622\n",
      "Adv Utility Training Acc:\t\t0.03587851887396033\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.3449246241202815\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09941818618042227\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t5.998080614203455e-05\n",
      "Utility Acc Coop:\t\t0.35554622520793344\n",
      "Val Privacy Acc Adv:\t\t0.10429936305732485\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.3403662420382166\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 249/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.6434902692629562\n",
      "Validation Loss:\t\t0.6465394378396546\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.35968587123768037\n",
      "Cross Reconstruction Loss:\t2.6457184583654176\n",
      "End Effector Loss:\t\t0.009321563428783848\n",
      "Smoothing Loss:\t\t\t0.010466909885134783\n",
      "Triplet Loss:\t\t\t2.909841311107594\n",
      "Latent Consistency Loss:\t0.023112078011393433\n",
      "Privacy Loss:\t\t\t9.686422134467752e-06\n",
      "Privacy Loss Dyn:\t\t-3.6314943858773296\n",
      "Privacy Loss Stat:\t\t3.6315912497173266\n",
      "Utility Loss:\t\t\t-3.5221473903741427\n",
      "Utility Loss Dyn:\t\t-4.122285528970085\n",
      "Utility Loss Stat:\t\t3.770070793074976\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.33724208223591945\n",
      "Val Cross Reconstruction Loss:\t2.6269634483726163\n",
      "Val End Effector Loss:\t\t0.007874566486259555\n",
      "Val Smoothing Loss:\t\t0.009118704466374626\n",
      "Val Triplet Loss:\t\t2.8712187025957046\n",
      "Val Latent Consistency Loss:\t0.021539084387907557\n",
      "Val Privacy Loss:\t\t-1.783109014960611e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626519840993699\n",
      "Val Privacy Loss Stat:\t\t3.6263415357869144\n",
      "Val Utility Loss:\t\t-3.4124634615175284\n",
      "Val Utility Loss Dyn:\t\t-4.1220224161816255\n",
      "Val Utility Loss Stat:\t\t3.7807760830897434\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.559490981196564\n",
      "Adv Utility Training Loss:\t\t4.085617445862148\n",
      "Coop Privacy Training Loss:\t3.6315912497173266\n",
      "Coop Utility Training Loss:\t3.781184556006775\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.17061540307101727\n",
      "Adv Utility Training Acc:\t\t0.03620841330774152\n",
      "Coop Privacy Training Acc:\t\t0.09934820857325656\n",
      "Coop Utility Training Acc:\t\t0.34275031989763277\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.0993682021753039\n",
      "Privacy Acc Coop:\t\t0.09934820857325656\n",
      "Utility Acc Adv:\t\t4.998400511836212e-05\n",
      "Utility Acc Coop:\t\t0.35397672744721687\n",
      "Val Privacy Acc Adv:\t\t0.10439888535031847\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.34106289808917195\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 250/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.6037988895770837\n",
      "Validation Loss:\t\t0.7440464139506695\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3584757033861835\n",
      "Cross Reconstruction Loss:\t2.645789561863519\n",
      "End Effector Loss:\t\t0.009319103161446268\n",
      "Smoothing Loss:\t\t\t0.010471788929478622\n",
      "Triplet Loss:\t\t\t2.9070002930483145\n",
      "Latent Consistency Loss:\t0.023023432788039276\n",
      "Privacy Loss:\t\t\t1.1141473333269681e-05\n",
      "Privacy Loss Dyn:\t\t-3.631529815366309\n",
      "Privacy Loss Stat:\t\t3.6316412305191244\n",
      "Utility Loss:\t\t\t-3.555711696183003\n",
      "Utility Loss Dyn:\t\t-4.122249107214403\n",
      "Utility Loss Stat:\t\t3.7666779426298915\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.33454147769007714\n",
      "Val Cross Reconstruction Loss:\t2.6207051930154206\n",
      "Val End Effector Loss:\t\t0.007876782010718706\n",
      "Val Smoothing Loss:\t\t0.009156260660191061\n",
      "Val Triplet Loss:\t\t2.867402079758371\n",
      "Val Latent Consistency Loss:\t0.0214406532609159\n",
      "Val Privacy Loss:\t\t3.07894056769693e-07\n",
      "Val Privacy Loss Dyn:\t\t-3.6251441581993347\n",
      "Val Privacy Loss Stat:\t\t3.625147253085094\n",
      "Val Utility Loss:\t\t-3.304261541670295\n",
      "Val Utility Loss Dyn:\t\t-4.122329848587134\n",
      "Val Utility Loss Stat:\t\t3.7919037053539495\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.557662801565608\n",
      "Adv Utility Training Loss:\t\t4.084231188719805\n",
      "Coop Privacy Training Loss:\t3.6316412306716637\n",
      "Coop Utility Training Loss:\t3.7776702103215154\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.17227987044145873\n",
      "Adv Utility Training Acc:\t\t0.03661828214971209\n",
      "Coop Privacy Training Acc:\t\t0.0992982245681382\n",
      "Coop Utility Training Acc:\t\t0.3466640674984005\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09932821497120921\n",
      "Privacy Acc Coop:\t\t0.0992982245681382\n",
      "Utility Acc Adv:\t\t7.99744081893794e-05\n",
      "Utility Acc Coop:\t\t0.3578254958413308\n",
      "Val Privacy Acc Adv:\t\t0.10569267515923567\n",
      "Val Privacy Acc Coop:\t\t0.1057921974522293\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.33061305732484075\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 251/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.5881021899991667\n",
      "Validation Loss:\t\t0.837267035250641\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3572918411084497\n",
      "Cross Reconstruction Loss:\t2.6456845268101854\n",
      "End Effector Loss:\t\t0.009318661046591578\n",
      "Smoothing Loss:\t\t\t0.010478317389003717\n",
      "Triplet Loss:\t\t\t2.9037521164614044\n",
      "Latent Consistency Loss:\t0.02302136200331795\n",
      "Privacy Loss:\t\t\t1.1715077469155183e-05\n",
      "Privacy Loss Dyn:\t\t-3.6315040861423857\n",
      "Privacy Loss Stat:\t\t3.6316212410356323\n",
      "Utility Loss:\t\t\t-3.5657810106234753\n",
      "Utility Loss Dyn:\t\t-4.122257436458224\n",
      "Utility Loss Stat:\t\t3.7656793307586884\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3348989057692753\n",
      "Val Cross Reconstruction Loss:\t2.6242865650517166\n",
      "Val End Effector Loss:\t\t0.007906738173358949\n",
      "Val Smoothing Loss:\t\t0.0092592648924536\n",
      "Val Triplet Loss:\t\t2.8652637232640745\n",
      "Val Latent Consistency Loss:\t0.021504363632363497\n",
      "Val Privacy Loss:\t\t-1.968149166957588e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6259411945464506\n",
      "Val Privacy Loss Stat:\t\t3.6257443913988245\n",
      "Val Utility Loss:\t\t-3.21093164431821\n",
      "Val Utility Loss Dyn:\t\t-4.122111621176361\n",
      "Val Utility Loss Stat:\t\t3.8010184370028743\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5544585495214776\n",
      "Adv Utility Training Loss:\t\t4.084909130652898\n",
      "Coop Privacy Training Loss:\t3.631621241188171\n",
      "Coop Utility Training Loss:\t3.777262604854386\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1738793586052463\n",
      "Adv Utility Training Acc:\t\t0.0367582373640435\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.34677903071017274\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09935820537428024\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t5.998080614203455e-05\n",
      "Utility Acc Coop:\t\t0.35884516954574536\n",
      "Val Privacy Acc Adv:\t\t0.10499601910828026\n",
      "Val Privacy Acc Coop:\t\t0.10519506369426751\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.32115843949044587\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 252/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.5925149905637755\n",
      "Validation Loss:\t\t0.6107803062434979\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.35591262023149967\n",
      "Cross Reconstruction Loss:\t2.6447702189400952\n",
      "End Effector Loss:\t\t0.009316345812336936\n",
      "Smoothing Loss:\t\t\t0.010474948073074137\n",
      "Triplet Loss:\t\t\t2.900785818209804\n",
      "Latent Consistency Loss:\t0.022995630074804856\n",
      "Privacy Loss:\t\t\t1.1846470817570799e-05\n",
      "Privacy Loss Dyn:\t\t-3.6315327647093847\n",
      "Privacy Loss Stat:\t\t3.6316512268625307\n",
      "Utility Loss:\t\t\t-3.5552824146077944\n",
      "Utility Loss Dyn:\t\t-4.122286359087748\n",
      "Utility Loss Stat:\t\t3.766758118084586\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3323426945194317\n",
      "Val Cross Reconstruction Loss:\t2.620063733143412\n",
      "Val End Effector Loss:\t\t0.007869402593250866\n",
      "Val Smoothing Loss:\t\t0.00914289851251776\n",
      "Val Triplet Loss:\t\t2.859259198425682\n",
      "Val Latent Consistency Loss:\t0.021575197933395955\n",
      "Val Privacy Loss:\t\t-2.1970575782144146e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626262681499408\n",
      "Val Privacy Loss Stat:\t\t3.6260429689079334\n",
      "Val Utility Loss:\t\t-3.42619875282239\n",
      "Val Utility Loss Dyn:\t\t-4.122194545284199\n",
      "Val Utility Loss Stat:\t\t3.7795746539049087\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.555333088852241\n",
      "Adv Utility Training Loss:\t\t4.084863502248616\n",
      "Coop Privacy Training Loss:\t3.6316512268625307\n",
      "Coop Utility Training Loss:\t3.7781305729542036\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.17511396353166986\n",
      "Adv Utility Training Acc:\t\t0.03704314619321817\n",
      "Coop Privacy Training Acc:\t\t0.09928822776711452\n",
      "Coop Utility Training Acc:\t\t0.34593430102367245\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09934820857325656\n",
      "Privacy Acc Coop:\t\t0.09928822776711452\n",
      "Utility Acc Adv:\t\t4.998400511836212e-05\n",
      "Utility Acc Coop:\t\t0.35767554382597566\n",
      "Val Privacy Acc Adv:\t\t0.10469745222929937\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.34265525477707004\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 253/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.5634968236234141\n",
      "Validation Loss:\t\t0.6229388211041119\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3546278229887792\n",
      "Cross Reconstruction Loss:\t2.6437584211333625\n",
      "End Effector Loss:\t\t0.009316437645032954\n",
      "Smoothing Loss:\t\t\t0.010463191700714353\n",
      "Triplet Loss:\t\t\t2.89888071342683\n",
      "Latent Consistency Loss:\t0.02289767391200315\n",
      "Privacy Loss:\t\t\t8.852090579305638e-06\n",
      "Privacy Loss Dyn:\t\t-3.63153271589688\n",
      "Privacy Loss Stat:\t\t3.6316212370696164\n",
      "Utility Loss:\t\t\t-3.578706971972094\n",
      "Utility Loss Dyn:\t\t-4.122305983240149\n",
      "Utility Loss Stat:\t\t3.7644352845785636\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3319872296919489\n",
      "Val Cross Reconstruction Loss:\t2.6214210425212885\n",
      "Val End Effector Loss:\t\t0.00787732770049553\n",
      "Val Smoothing Loss:\t\t0.009140721483713692\n",
      "Val Triplet Loss:\t\t2.8597775021935723\n",
      "Val Latent Consistency Loss:\t0.021581209472315326\n",
      "Val Privacy Loss:\t\t-1.7996806247978453e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6256257819521958\n",
      "Val Privacy Loss Stat:\t\t3.6254458214826646\n",
      "Val Utility Loss:\t\t-3.4140488205442003\n",
      "Val Utility Loss Dyn:\t\t-4.122262930414479\n",
      "Val Utility Loss Stat:\t\t3.78085807326493\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5545145591252596\n",
      "Adv Utility Training Loss:\t\t4.084404453587547\n",
      "Coop Privacy Training Loss:\t3.6316212373746946\n",
      "Coop Utility Training Loss:\t3.775851539519073\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.17611864203454894\n",
      "Adv Utility Training Acc:\t\t0.0371431142034549\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.34822356845809344\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09934820857325656\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t5.998080614203455e-05\n",
      "Utility Acc Coop:\t\t0.3598448496481126\n",
      "Val Privacy Acc Adv:\t\t0.10529458598726114\n",
      "Val Privacy Acc Coop:\t\t0.10549363057324841\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.3408638535031847\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 254/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.5728264550475245\n",
      "Validation Loss:\t\t0.5062749619554182\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.35337297737560286\n",
      "Cross Reconstruction Loss:\t2.6431919428605113\n",
      "End Effector Loss:\t\t0.009316422767110135\n",
      "Smoothing Loss:\t\t\t0.010463942257331127\n",
      "Triplet Loss:\t\t\t2.8958795754023265\n",
      "Latent Consistency Loss:\t0.022813103759395565\n",
      "Privacy Loss:\t\t\t8.518907097922025e-06\n",
      "Privacy Loss Dyn:\t\t-3.631516049019587\n",
      "Privacy Loss Stat:\t\t3.631601241484561\n",
      "Utility Loss:\t\t\t-3.562966076441476\n",
      "Utility Loss Dyn:\t\t-4.122340721574565\n",
      "Utility Loss Stat:\t\t3.766044119421824\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.33084064285466624\n",
      "Val Cross Reconstruction Loss:\t2.620721332586495\n",
      "Val End Effector Loss:\t\t0.007868065620375097\n",
      "Val Smoothing Loss:\t\t0.009109669625996405\n",
      "Val Triplet Loss:\t\t2.8582489490509033\n",
      "Val Latent Consistency Loss:\t0.02121355463483721\n",
      "Val Privacy Loss:\t\t-1.6059655292778258e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6262035552103806\n",
      "Val Privacy Loss Stat:\t\t3.6260429628335746\n",
      "Val Utility Loss:\t\t-3.52304397874577\n",
      "Val Utility Loss Dyn:\t\t-4.122259777822312\n",
      "Val Utility Loss Stat:\t\t3.7699553541317106\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5528810379677527\n",
      "Adv Utility Training Loss:\t\t4.083703254326291\n",
      "Coop Privacy Training Loss:\t3.6316012416371\n",
      "Coop Utility Training Loss:\t3.777291978084347\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.17645353486884197\n",
      "Adv Utility Training Acc:\t\t0.037572976647472806\n",
      "Coop Privacy Training Acc:\t\t0.09933821177223288\n",
      "Coop Utility Training Acc:\t\t0.3468390115163148\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.0993682021753039\n",
      "Privacy Acc Coop:\t\t0.09933821177223288\n",
      "Utility Acc Adv:\t\t5.998080614203455e-05\n",
      "Utility Acc Coop:\t\t0.3581753838771593\n",
      "Val Privacy Acc Adv:\t\t0.10459792993630573\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.35429936305732485\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 255/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.5276474460997569\n",
      "Validation Loss:\t\t0.5188108052061812\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.35197797858097274\n",
      "Cross Reconstruction Loss:\t2.642848373450916\n",
      "End Effector Loss:\t\t0.00931419833650859\n",
      "Smoothing Loss:\t\t\t0.010470933253773781\n",
      "Triplet Loss:\t\t\t2.893104419903502\n",
      "Latent Consistency Loss:\t0.022712971418094956\n",
      "Privacy Loss:\t\t\t8.448910728449709e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315367432336205\n",
      "Privacy Loss Stat:\t\t3.631621238442468\n",
      "Utility Loss:\t\t\t-3.6015629222281684\n",
      "Utility Loss Dyn:\t\t-4.122338239763764\n",
      "Utility Loss Stat:\t\t3.762181949707002\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.32962118136654994\n",
      "Val Cross Reconstruction Loss:\t2.620808930913354\n",
      "Val End Effector Loss:\t\t0.00787343996559169\n",
      "Val Smoothing Loss:\t\t0.009171663394945252\n",
      "Val Triplet Loss:\t\t2.8543794139934953\n",
      "Val Latent Consistency Loss:\t0.02138517844449183\n",
      "Val Privacy Loss:\t\t-1.9189278790905216e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.62623484878783\n",
      "Val Privacy Loss Stat:\t\t3.626042955240626\n",
      "Val Utility Loss:\t\t-3.5061128944348376\n",
      "Val Utility Loss Dyn:\t\t-4.122094950098901\n",
      "Val Utility Loss Stat:\t\t3.771483681004518\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5527401655359445\n",
      "Adv Utility Training Loss:\t\t4.084154044826749\n",
      "Coop Privacy Training Loss:\t3.631621238747546\n",
      "Coop Utility Training Loss:\t3.7736870972529024\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.17873280550223927\n",
      "Adv Utility Training Acc:\t\t0.0380828134996801\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.3507627559181062\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09934820857325656\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t5.998080614203455e-05\n",
      "Utility Acc Coop:\t\t0.3625939699296225\n",
      "Val Privacy Acc Adv:\t\t0.10469745222929937\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.3515127388535032\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 256/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.5465865527063379\n",
      "Validation Loss:\t\t0.5493975836119265\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.35073606169383953\n",
      "Cross Reconstruction Loss:\t2.642283306317076\n",
      "End Effector Loss:\t\t0.0093132771944278\n",
      "Smoothing Loss:\t\t\t0.010470794362176307\n",
      "Triplet Loss:\t\t\t2.8900425507331304\n",
      "Latent Consistency Loss:\t0.022739060645564312\n",
      "Privacy Loss:\t\t\t7.62870810539846e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315349531875385\n",
      "Privacy Loss Stat:\t\t3.6316112375228893\n",
      "Utility Loss:\t\t\t-3.577280338651007\n",
      "Utility Loss Dyn:\t\t-4.122340706930814\n",
      "Utility Loss Stat:\t\t3.7646126699844236\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3283843547105789\n",
      "Val Cross Reconstruction Loss:\t2.619543722480725\n",
      "Val End Effector Loss:\t\t0.007871108794003535\n",
      "Val Smoothing Loss:\t\t0.009155836709697916\n",
      "Val Triplet Loss:\t\t2.8509370126542013\n",
      "Val Latent Consistency Loss:\t0.021583834674897467\n",
      "Val Privacy Loss:\t\t1.3702804115927143e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.625607361459428\n",
      "Val Privacy Loss Stat:\t\t3.625744386843056\n",
      "Val Utility Loss:\t\t-3.4714531625152394\n",
      "Val Utility Loss Dyn:\t\t-4.121614905679301\n",
      "Val Utility Loss Stat:\t\t3.774469594287265\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.550021247229207\n",
      "Adv Utility Training Loss:\t\t4.083874323088926\n",
      "Coop Privacy Training Loss:\t3.6316112381330456\n",
      "Coop Utility Training Loss:\t3.776527099707\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.17903270953294945\n",
      "Adv Utility Training Acc:\t\t0.037797904670505436\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.3473438499680102\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09935820537428024\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t4.998400511836212e-05\n",
      "Utility Acc Coop:\t\t0.3596948976327575\n",
      "Val Privacy Acc Adv:\t\t0.10519506369426751\n",
      "Val Privacy Acc Coop:\t\t0.10519506369426751\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.3476313694267516\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 257/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.4919477125459368\n",
      "Validation Loss:\t\t0.62401202030385\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3495506064028444\n",
      "Cross Reconstruction Loss:\t2.6423548201452975\n",
      "End Effector Loss:\t\t0.009312153152134734\n",
      "Smoothing Loss:\t\t\t0.010468873640156506\n",
      "Triplet Loss:\t\t\t2.887050901249442\n",
      "Latent Consistency Loss:\t0.0227217682448388\n",
      "Privacy Loss:\t\t\t9.122103814962806e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315300226669165\n",
      "Privacy Loss Stat:\t\t3.6316212395102414\n",
      "Utility Loss:\t\t\t-3.6263854624137464\n",
      "Utility Loss Dyn:\t\t-4.122324210134593\n",
      "Utility Loss Stat:\t\t3.7596856585238427\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3273621207209909\n",
      "Val Cross Reconstruction Loss:\t2.6209286899323674\n",
      "Val End Effector Loss:\t\t0.007865418591032363\n",
      "Val Smoothing Loss:\t\t0.009155935664204466\n",
      "Val Triplet Loss:\t\t2.8457963284413528\n",
      "Val Latent Consistency Loss:\t0.02140999199217482\n",
      "Val Privacy Loss:\t\t-1.7737886708253507e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.625623218572823\n",
      "Val Privacy Loss Stat:\t\t3.6254458260384337\n",
      "Val Utility Loss:\t\t-3.388016840454879\n",
      "Val Utility Loss Dyn:\t\t-4.121771405456932\n",
      "Val Utility Loss Stat:\t\t3.782969729915546\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5499175517740573\n",
      "Adv Utility Training Loss:\t\t4.084152052666389\n",
      "Coop Privacy Training Loss:\t3.6316212401203978\n",
      "Coop Utility Training Loss:\t3.771475805354591\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.17967750319897632\n",
      "Adv Utility Training Acc:\t\t0.03696317178502879\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.35271713051823417\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.0993682021753039\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t4.998400511836212e-05\n",
      "Utility Acc Coop:\t\t0.3647532789507358\n",
      "Val Privacy Acc Adv:\t\t0.10529458598726114\n",
      "Val Privacy Acc Coop:\t\t0.10549363057324841\n",
      "Val Utility Acc Adv:\t\t0.0003980891719745223\n",
      "Val Utility Acc Coop:\t\t0.3404657643312102\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 258/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.49234704314346733\n",
      "Validation Loss:\t\t0.5967271654825111\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3488719098875329\n",
      "Cross Reconstruction Loss:\t2.6439343040293024\n",
      "End Effector Loss:\t\t0.009306126774389413\n",
      "Smoothing Loss:\t\t\t0.0104710782695769\n",
      "Triplet Loss:\t\t\t2.882405330184478\n",
      "Latent Consistency Loss:\t0.023025894703215997\n",
      "Privacy Loss:\t\t\t8.96367291495042e-06\n",
      "Privacy Loss Dyn:\t\t-3.631541594586461\n",
      "Privacy Loss Stat:\t\t3.6316312363112653\n",
      "Utility Loss:\t\t\t-3.6231828105045447\n",
      "Utility Loss Dyn:\t\t-4.122080930135072\n",
      "Utility Loss Stat:\t\t3.759762651250672\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3278343855955039\n",
      "Val Cross Reconstruction Loss:\t2.62250880071312\n",
      "Val End Effector Loss:\t\t0.00786345257500934\n",
      "Val Smoothing Loss:\t\t0.009204926405244382\n",
      "Val Triplet Loss:\t\t2.8414888776791325\n",
      "Val Latent Consistency Loss:\t0.022374331286758375\n",
      "Val Privacy Loss:\t\t-1.8655304696149886e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626528058082435\n",
      "Val Privacy Loss Stat:\t\t3.626341528193966\n",
      "Val Utility Loss:\t\t-3.4218842573226635\n",
      "Val Utility Loss Dyn:\t\t-4.122146655040182\n",
      "Val Utility Loss Stat:\t\t3.7799582056179166\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5504703074789017\n",
      "Adv Utility Training Loss:\t\t4.083351859204371\n",
      "Coop Privacy Training Loss:\t3.6316312367688823\n",
      "Coop Utility Training Loss:\t3.7718350933060307\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18145693378119002\n",
      "Adv Utility Training Acc:\t\t0.038162787907869485\n",
      "Coop Privacy Training Acc:\t\t0.09930822136916187\n",
      "Coop Utility Training Acc:\t\t0.3524522152911068\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09933821177223288\n",
      "Privacy Acc Coop:\t\t0.09930822136916187\n",
      "Utility Acc Adv:\t\t0.00012995841330774152\n",
      "Utility Acc Coop:\t\t0.36493322136916184\n",
      "Val Privacy Acc Adv:\t\t0.10439888535031847\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.3431528662420382\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 259/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.5034707758208631\n",
      "Validation Loss:\t\t0.6365815306046776\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3494358261712301\n",
      "Cross Reconstruction Loss:\t2.647128552789499\n",
      "End Effector Loss:\t\t0.009294996403338852\n",
      "Smoothing Loss:\t\t\t0.010467477059986869\n",
      "Triplet Loss:\t\t\t2.8788676814093317\n",
      "Latent Consistency Loss:\t0.023832036071455183\n",
      "Privacy Loss:\t\t\t1.4479352508076323e-05\n",
      "Privacy Loss Dyn:\t\t-3.6314764459088913\n",
      "Privacy Loss Stat:\t\t3.631621240272937\n",
      "Utility Loss:\t\t\t-3.6180136711721\n",
      "Utility Loss Dyn:\t\t-4.121815435259448\n",
      "Utility Loss Stat:\t\t3.7600140660066903\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3282314193476537\n",
      "Val Cross Reconstruction Loss:\t2.6389427367289353\n",
      "Val End Effector Loss:\t\t0.007830161393685326\n",
      "Val Smoothing Loss:\t\t0.009132830832438295\n",
      "Val Triplet Loss:\t\t2.8442050150245617\n",
      "Val Latent Consistency Loss:\t0.022958344572288975\n",
      "Val Privacy Loss:\t\t-1.3740579034112822e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6261803784947486\n",
      "Val Privacy Loss Stat:\t\t3.626042978019471\n",
      "Val Utility Loss:\t\t-3.3927789432987288\n",
      "Val Utility Loss Dyn:\t\t-4.12194533864404\n",
      "Val Utility Loss Stat:\t\t3.7826674166758347\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5490534589295195\n",
      "Adv Utility Training Loss:\t\t4.083193284460008\n",
      "Coop Privacy Training Loss:\t3.631621240730554\n",
      "Coop Utility Training Loss:\t3.771982847385809\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1810270713371721\n",
      "Adv Utility Training Acc:\t\t0.03814279430582214\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.3522072936660269\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09940818937939859\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t0.0003498880358285349\n",
      "Utility Acc Coop:\t\t0.36473328534868843\n",
      "Val Privacy Acc Adv:\t\t0.10479697452229299\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.3398686305732484\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 260/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.5096418104579604\n",
      "Validation Loss:\t\t0.5410434057947936\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.34951062226859864\n",
      "Cross Reconstruction Loss:\t2.648446978168158\n",
      "End Effector Loss:\t\t0.009293588294253773\n",
      "Smoothing Loss:\t\t\t0.010471937831453098\n",
      "Triplet Loss:\t\t\t2.8771239957669112\n",
      "Latent Consistency Loss:\t0.024344828334933125\n",
      "Privacy Loss:\t\t\t8.53494276850939e-06\n",
      "Privacy Loss Dyn:\t\t-3.631495899522602\n",
      "Privacy Loss Stat:\t\t3.631581254899311\n",
      "Utility Loss:\t\t\t-3.6155143415630437\n",
      "Utility Loss Dyn:\t\t-4.121839548636917\n",
      "Utility Loss Stat:\t\t3.7602881094773304\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.32745548323461204\n",
      "Val Cross Reconstruction Loss:\t2.6240764894303243\n",
      "Val End Effector Loss:\t\t0.007857841650130832\n",
      "Val Smoothing Loss:\t\t0.009136346753117195\n",
      "Val Triplet Loss:\t\t2.8376259090034823\n",
      "Val Latent Consistency Loss:\t0.023220306262373924\n",
      "Val Privacy Loss:\t\t-7.985313986517061e-06\n",
      "Val Privacy Loss Dyn:\t\t-3.6258242494741064\n",
      "Val Privacy Loss Stat:\t\t3.6257443959545936\n",
      "Val Utility Loss:\t\t-3.4813630656831585\n",
      "Val Utility Loss Dyn:\t\t-4.121340432744117\n",
      "Val Utility Loss Stat:\t\t3.7732041322501604\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5500939250831336\n",
      "Adv Utility Training Loss:\t\t4.082226666897745\n",
      "Coop Privacy Training Loss:\t3.6315812552043893\n",
      "Coop Utility Training Loss:\t3.7716833994469425\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18100707773512476\n",
      "Adv Utility Training Acc:\t\t0.03941738643634037\n",
      "Coop Privacy Training Acc:\t\t0.09935820537428024\n",
      "Coop Utility Training Acc:\t\t0.3525271912987844\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09939819257837491\n",
      "Privacy Acc Coop:\t\t0.09935820537428024\n",
      "Utility Acc Adv:\t\t0.00032989443378119\n",
      "Utility Acc Coop:\t\t0.36425343889955214\n",
      "Val Privacy Acc Adv:\t\t0.10509554140127389\n",
      "Val Privacy Acc Coop:\t\t0.10519506369426751\n",
      "Val Utility Acc Adv:\t\t0.0009952229299363057\n",
      "Val Utility Acc Coop:\t\t0.3497213375796178\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 261/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.49714205062025185\n",
      "Validation Loss:\t\t0.4854410306141255\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.34891760305418695\n",
      "Cross Reconstruction Loss:\t2.647978012026386\n",
      "End Effector Loss:\t\t0.00929672785058036\n",
      "Smoothing Loss:\t\t\t0.01046564924588483\n",
      "Triplet Loss:\t\t\t2.8744316322255883\n",
      "Latent Consistency Loss:\t0.02466594175062001\n",
      "Privacy Loss:\t\t\t7.6118906720357295e-06\n",
      "Privacy Loss Dyn:\t\t-3.631535124488923\n",
      "Privacy Loss Stat:\t\t3.631611241336366\n",
      "Utility Loss:\t\t\t-3.6272832879025585\n",
      "Utility Loss Dyn:\t\t-4.121858994623674\n",
      "Utility Loss Stat:\t\t3.7591306665961133\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3270926340750069\n",
      "Val Cross Reconstruction Loss:\t2.620182491411829\n",
      "Val End Effector Loss:\t\t0.007861499256412885\n",
      "Val Smoothing Loss:\t\t0.00910592885913363\n",
      "Val Triplet Loss:\t\t2.8371040942562615\n",
      "Val Latent Consistency Loss:\t0.023689879496006448\n",
      "Val Privacy Loss:\t\t-1.5277012138609673e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6264942816108654\n",
      "Val Privacy Loss Stat:\t\t3.6263415099708896\n",
      "Val Utility Loss:\t\t-3.5399293838792545\n",
      "Val Utility Loss Dyn:\t\t-4.12186640842705\n",
      "Val Utility Loss Stat:\t\t3.7678734481714335\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5478018205743984\n",
      "Adv Utility Training Loss:\t\t4.080233892720248\n",
      "Coop Privacy Training Loss:\t3.6316112422516005\n",
      "Coop Utility Training Loss:\t3.77033878318484\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1831813819577735\n",
      "Adv Utility Training Acc:\t\t0.04067198496481126\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.35394673704414586\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09935820537428024\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t0.00028990722968650034\n",
      "Utility Acc Coop:\t\t0.3653031030070377\n",
      "Val Privacy Acc Adv:\t\t0.10429936305732485\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.35459792993630573\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 262/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.4889783329537147\n",
      "Validation Loss:\t\t0.4673633494645737\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.34771620540838555\n",
      "Cross Reconstruction Loss:\t2.646536547178194\n",
      "End Effector Loss:\t\t0.009300308534130693\n",
      "Smoothing Loss:\t\t\t0.010464304360672498\n",
      "Triplet Loss:\t\t\t2.872706472454205\n",
      "Latent Consistency Loss:\t0.024568265567337634\n",
      "Privacy Loss:\t\t\t6.826276284948192e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315729709595956\n",
      "Privacy Loss Stat:\t\t3.6316412341800626\n",
      "Utility Loss:\t\t\t-3.630196903885288\n",
      "Utility Loss Dyn:\t\t-4.121910036944916\n",
      "Utility Loss Stat:\t\t3.758890344939473\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3251182381894178\n",
      "Val Cross Reconstruction Loss:\t2.6222008155409697\n",
      "Val End Effector Loss:\t\t0.007858397124726682\n",
      "Val Smoothing Loss:\t\t0.009150340530285789\n",
      "Val Triplet Loss:\t\t2.835631710708521\n",
      "Val Latent Consistency Loss:\t0.022661029711175874\n",
      "Val Privacy Loss:\t\t-2.1476085018959774e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6259591533879565\n",
      "Val Privacy Loss Stat:\t\t3.625744386843056\n",
      "Val Utility Loss:\t\t-3.5426231432872215\n",
      "Val Utility Loss Dyn:\t\t-4.121052043453144\n",
      "Val Utility Loss Stat:\t\t3.7667897172794222\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.547880303455482\n",
      "Adv Utility Training Loss:\t\t4.078659538572901\n",
      "Coop Privacy Training Loss:\t3.6316412343326014\n",
      "Coop Utility Training Loss:\t3.7704801217760706\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18199176263595648\n",
      "Adv Utility Training Acc:\t\t0.042486404350607805\n",
      "Coop Privacy Training Acc:\t\t0.0992982245681382\n",
      "Coop Utility Training Acc:\t\t0.3535868522072937\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09931821817018555\n",
      "Privacy Acc Coop:\t\t0.0992982245681382\n",
      "Utility Acc Adv:\t\t0.0002699136276391555\n",
      "Utility Acc Coop:\t\t0.36525311900191937\n",
      "Val Privacy Acc Adv:\t\t0.10499601910828026\n",
      "Val Privacy Acc Coop:\t\t0.10519506369426751\n",
      "Val Utility Acc Adv:\t\t0.0007961783439490446\n",
      "Val Utility Acc Coop:\t\t0.35628980891719747\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 263/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.467934174768231\n",
      "Validation Loss:\t\t0.5033705999991697\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.34640877300626716\n",
      "Cross Reconstruction Loss:\t2.6452413973561177\n",
      "End Effector Loss:\t\t0.009303336394909038\n",
      "Smoothing Loss:\t\t\t0.010469296348882422\n",
      "Triplet Loss:\t\t\t2.870995759201294\n",
      "Latent Consistency Loss:\t0.024343001137243886\n",
      "Privacy Loss:\t\t\t7.58412855981789e-06\n",
      "Privacy Loss Dyn:\t\t-3.631525401953162\n",
      "Privacy Loss Stat:\t\t3.6316012430099516\n",
      "Utility Loss:\t\t\t-3.644552083177133\n",
      "Utility Loss Dyn:\t\t-4.121967258014057\n",
      "Utility Loss Stat:\t\t3.7575120462184524\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.32403273889972906\n",
      "Val Cross Reconstruction Loss:\t2.6214289999311897\n",
      "Val End Effector Loss:\t\t0.007864497127426658\n",
      "Val Smoothing Loss:\t\t0.009133108645369103\n",
      "Val Triplet Loss:\t\t2.83427807328048\n",
      "Val Latent Consistency Loss:\t0.022747700084831304\n",
      "Val Privacy Loss:\t\t-2.0441355978607373e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6262473771526555\n",
      "Val Privacy Loss Stat:\t\t3.626042956759216\n",
      "Val Utility Loss:\t\t-3.5038362247928694\n",
      "Val Utility Loss Dyn:\t\t-4.1215752370797905\n",
      "Val Utility Loss Stat:\t\t3.7711916182451186\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5485636658647164\n",
      "Adv Utility Training Loss:\t\t4.076729063948072\n",
      "Coop Privacy Training Loss:\t3.6316012430099516\n",
      "Coop Utility Training Loss:\t3.769562453546359\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.182311660268714\n",
      "Adv Utility Training Acc:\t\t0.044230846129238645\n",
      "Coop Privacy Training Acc:\t\t0.09933821177223288\n",
      "Coop Utility Training Acc:\t\t0.35477147312859886\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.0993682021753039\n",
      "Privacy Acc Coop:\t\t0.09933821177223288\n",
      "Utility Acc Adv:\t\t0.0002499200255918106\n",
      "Utility Acc Coop:\t\t0.3671325175943698\n",
      "Val Privacy Acc Adv:\t\t0.10459792993630573\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.000696656050955414\n",
      "Val Utility Acc Coop:\t\t0.3535031847133758\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 264/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.4532438801626555\n",
      "Validation Loss:\t\t0.5409322916322453\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.34562346417402046\n",
      "Cross Reconstruction Loss:\t2.644831723154011\n",
      "End Effector Loss:\t\t0.00930368472861933\n",
      "Smoothing Loss:\t\t\t0.010458744877040082\n",
      "Triplet Loss:\t\t\t2.869275045791499\n",
      "Latent Consistency Loss:\t0.024209298977600942\n",
      "Privacy Loss:\t\t\t6.64067436164568e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315548343682855\n",
      "Privacy Loss Stat:\t\t3.6316212410356323\n",
      "Utility Loss:\t\t\t-3.6545408130531043\n",
      "Utility Loss Dyn:\t\t-4.121954534424472\n",
      "Utility Loss Stat:\t\t3.756500457542795\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3234249125620362\n",
      "Val Cross Reconstruction Loss:\t2.6151477007349584\n",
      "Val End Effector Loss:\t\t0.007867404084747575\n",
      "Val Smoothing Loss:\t\t0.009125536156426759\n",
      "Val Triplet Loss:\t\t2.8328224078864808\n",
      "Val Latent Consistency Loss:\t0.022628332007747547\n",
      "Val Privacy Loss:\t\t-2.3110846804965074e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6259755101173545\n",
      "Val Privacy Loss Stat:\t\t3.6257443974731833\n",
      "Val Utility Loss:\t\t-3.46175892337872\n",
      "Val Utility Loss Dyn:\t\t-4.121783353720501\n",
      "Val Utility Loss Stat:\t\t3.7756074264550663\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.546546368742325\n",
      "Adv Utility Training Loss:\t\t4.075312005657457\n",
      "Coop Privacy Training Loss:\t3.6316212413407105\n",
      "Coop Utility Training Loss:\t3.7685492028049072\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1827915067178503\n",
      "Adv Utility Training Acc:\t\t0.04588531669865643\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.35556122040946897\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09932821497120921\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t0.00025991682661548305\n",
      "Utility Acc Coop:\t\t0.36792226487523993\n",
      "Val Privacy Acc Adv:\t\t0.10489649681528662\n",
      "Val Privacy Acc Coop:\t\t0.10519506369426751\n",
      "Val Utility Acc Adv:\t\t0.0004976114649681529\n",
      "Val Utility Acc Coop:\t\t0.34783041401273884\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 265/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.44439421122582656\n",
      "Validation Loss:\t\t0.4800517850668187\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.34493516915628564\n",
      "Cross Reconstruction Loss:\t2.644392049549027\n",
      "End Effector Loss:\t\t0.009300864495572969\n",
      "Smoothing Loss:\t\t\t0.010460863523578518\n",
      "Triplet Loss:\t\t\t2.8669668122582608\n",
      "Latent Consistency Loss:\t0.024163887490442716\n",
      "Privacy Loss:\t\t\t7.074762443205674e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315504920383486\n",
      "Privacy Loss Stat:\t\t3.6316212393577025\n",
      "Utility Loss:\t\t\t-3.659211542540762\n",
      "Utility Loss Dyn:\t\t-4.121949650428269\n",
      "Utility Loss Stat:\t\t3.756028497974154\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3224353292945084\n",
      "Val Cross Reconstruction Loss:\t2.6203884486180202\n",
      "Val End Effector Loss:\t\t0.007852771963069962\n",
      "Val Smoothing Loss:\t\t0.00915030298078326\n",
      "Val Triplet Loss:\t\t2.8282946127994806\n",
      "Val Latent Consistency Loss:\t0.02309208587523858\n",
      "Val Privacy Loss:\t\t-2.0272792524592893e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6265442659900446\n",
      "Val Privacy Loss Stat:\t\t3.6263415312311453\n",
      "Val Utility Loss:\t\t-3.521356594790319\n",
      "Val Utility Loss Dyn:\t\t-4.121735879570056\n",
      "Val Utility Loss Stat:\t\t3.769600197008461\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.546666293287613\n",
      "Adv Utility Training Loss:\t\t4.073898369886138\n",
      "Coop Privacy Training Loss:\t3.6316212398153196\n",
      "Coop Utility Training Loss:\t3.7679096050774983\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1832913467690339\n",
      "Adv Utility Training Acc:\t\t0.04728486884197057\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.3563509676903391\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09934820857325656\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t0.0002399232245681382\n",
      "Utility Acc Coop:\t\t0.36854206653870764\n",
      "Val Privacy Acc Adv:\t\t0.10439888535031847\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.0005971337579617834\n",
      "Val Utility Acc Coop:\t\t0.35539410828025475\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 266/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.4353077377807003\n",
      "Validation Loss:\t\t0.5756565603860624\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3441783263373665\n",
      "Cross Reconstruction Loss:\t2.644172136705805\n",
      "End Effector Loss:\t\t0.009301029896495895\n",
      "Smoothing Loss:\t\t\t0.010460010547398263\n",
      "Triplet Loss:\t\t\t2.8651733918595754\n",
      "Latent Consistency Loss:\t0.02395893483090805\n",
      "Privacy Loss:\t\t\t7.405371827646012e-06\n",
      "Privacy Loss Dyn:\t\t-3.631557180114229\n",
      "Privacy Loss Stat:\t\t3.6316312358536478\n",
      "Utility Loss:\t\t\t-3.6629173269046094\n",
      "Utility Loss Dyn:\t\t-4.121992147510356\n",
      "Utility Loss Stat:\t\t3.755700407925128\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3219299112345762\n",
      "Val Cross Reconstruction Loss:\t2.6200090593593135\n",
      "Val End Effector Loss:\t\t0.007857581903078373\n",
      "Val Smoothing Loss:\t\t0.009144692598681921\n",
      "Val Triplet Loss:\t\t2.8293411139469997\n",
      "Val Latent Consistency Loss:\t0.022738934168295494\n",
      "Val Privacy Loss:\t\t-2.3382484533224894e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626873924474048\n",
      "Val Privacy Loss Stat:\t\t3.626640107221664\n",
      "Val Utility Loss:\t\t-3.4222028695853655\n",
      "Val Utility Loss Dyn:\t\t-4.1219123488019225\n",
      "Val Utility Loss Stat:\t\t3.7796920560727454\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5472377557748414\n",
      "Adv Utility Training Loss:\t\t4.072442836358771\n",
      "Coop Privacy Training Loss:\t3.631631236158726\n",
      "Coop Utility Training Loss:\t3.7677676969053495\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18334632917466412\n",
      "Adv Utility Training Acc:\t\t0.0480896113243762\n",
      "Coop Privacy Training Acc:\t\t0.09930822136916187\n",
      "Coop Utility Training Acc:\t\t0.3563609644913628\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09933821177223288\n",
      "Privacy Acc Coop:\t\t0.09930822136916187\n",
      "Utility Acc Adv:\t\t0.00022992642354446578\n",
      "Utility Acc Coop:\t\t0.368592050543826\n",
      "Val Privacy Acc Adv:\t\t0.10400079617834394\n",
      "Val Privacy Acc Coop:\t\t0.10429936305732485\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.34484474522292996\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 267/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.4207185328492963\n",
      "Validation Loss:\t\t0.6235790892628728\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.343334769952854\n",
      "Cross Reconstruction Loss:\t2.643690903981527\n",
      "End Effector Loss:\t\t0.009301417151505339\n",
      "Smoothing Loss:\t\t\t0.010463260187483224\n",
      "Triplet Loss:\t\t\t2.8624548815948723\n",
      "Latent Consistency Loss:\t0.023887581874211857\n",
      "Privacy Loss:\t\t\t7.840203537211842e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315228426525095\n",
      "Privacy Loss Stat:\t\t3.6316012457556552\n",
      "Utility Loss:\t\t\t-3.6723498285236222\n",
      "Utility Loss Dyn:\t\t-4.121981971628454\n",
      "Utility Loss Stat:\t\t3.7547469924675374\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.321645938571851\n",
      "Val Cross Reconstruction Loss:\t2.614561325425555\n",
      "Val End Effector Loss:\t\t0.007853792832013528\n",
      "Val Smoothing Loss:\t\t0.009149560114594212\n",
      "Val Triplet Loss:\t\t2.827848079098258\n",
      "Val Latent Consistency Loss:\t0.022856890550179847\n",
      "Val Privacy Loss:\t\t-1.6518079551162234e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626805278146343\n",
      "Val Privacy Loss Stat:\t\t3.626640088998588\n",
      "Val Utility Loss:\t\t-3.3728718848744776\n",
      "Val Utility Loss Dyn:\t\t-4.121792802385464\n",
      "Val Utility Loss Stat:\t\t3.7845056087348112\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5464810826270456\n",
      "Adv Utility Training Loss:\t\t4.071121386511541\n",
      "Coop Privacy Training Loss:\t3.6316012460607334\n",
      "Coop Utility Training Loss:\t3.766939173580665\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18317138515674983\n",
      "Adv Utility Training Acc:\t\t0.0494141874600128\n",
      "Coop Privacy Training Acc:\t\t0.09933821177223288\n",
      "Coop Utility Training Acc:\t\t0.35724068298144596\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.0993682021753039\n",
      "Privacy Acc Coop:\t\t0.09933821177223288\n",
      "Utility Acc Adv:\t\t0.00020993282149712092\n",
      "Utility Acc Coop:\t\t0.36983165387076133\n",
      "Val Privacy Acc Adv:\t\t0.10410031847133758\n",
      "Val Privacy Acc Coop:\t\t0.10429936305732485\n",
      "Val Utility Acc Adv:\t\t0.0005971337579617834\n",
      "Val Utility Acc Coop:\t\t0.33996815286624205\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 268/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.3989931218461947\n",
      "Validation Loss:\t\t0.5989590111502986\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.34255850374202884\n",
      "Cross Reconstruction Loss:\t2.6433666849929556\n",
      "End Effector Loss:\t\t0.009299268232812236\n",
      "Smoothing Loss:\t\t\t0.010465415400796721\n",
      "Triplet Loss:\t\t\t2.8606750194796065\n",
      "Latent Consistency Loss:\t0.02374772706277006\n",
      "Privacy Loss:\t\t\t7.767194520946656e-06\n",
      "Privacy Loss Dyn:\t\t-3.631533566454779\n",
      "Privacy Loss Stat:\t\t3.631611243471913\n",
      "Utility Loss:\t\t\t-3.6893161205015956\n",
      "Utility Loss Dyn:\t\t-4.122013547217625\n",
      "Utility Loss Stat:\t\t3.753081939347036\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3211295859069581\n",
      "Val Cross Reconstruction Loss:\t2.617279313931799\n",
      "Val End Effector Loss:\t\t0.007867339651462189\n",
      "Val Smoothing Loss:\t\t0.009130229968814903\n",
      "Val Triplet Loss:\t\t2.830953241153887\n",
      "Val Latent Consistency Loss:\t0.022126325524773945\n",
      "Val Privacy Loss:\t\t-2.1685080923092595e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626558381281081\n",
      "Val Privacy Loss Stat:\t\t3.6263415373055037\n",
      "Val Utility Loss:\t\t-3.3924809352607483\n",
      "Val Utility Loss Dyn:\t\t-4.121796778053235\n",
      "Val Utility Loss Stat:\t\t3.7825486933349803\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.546640122768136\n",
      "Adv Utility Training Loss:\t\t4.069985797598967\n",
      "Coop Privacy Training Loss:\t3.631611243624452\n",
      "Coop Utility Training Loss:\t3.7655183998957247\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18341130838131797\n",
      "Adv Utility Training Acc:\t\t0.05001399552143314\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.3584253039027511\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.0993682021753039\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t0.0001999360204734485\n",
      "Utility Acc Coop:\t\t0.37131118042226485\n",
      "Val Privacy Acc Adv:\t\t0.10439888535031847\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.0005971337579617834\n",
      "Val Utility Acc Coop:\t\t0.3405652866242038\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 269/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.3749153045419024\n",
      "Validation Loss:\t\t0.41674693563514076\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3416141991575635\n",
      "Cross Reconstruction Loss:\t2.6427128728352827\n",
      "End Effector Loss:\t\t0.009299384959766633\n",
      "Smoothing Loss:\t\t\t0.01046703020897256\n",
      "Triplet Loss:\t\t\t2.858711001511499\n",
      "Latent Consistency Loss:\t0.023619376357718682\n",
      "Privacy Loss:\t\t\t6.0312426097867435e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315809179404877\n",
      "Privacy Loss Stat:\t\t3.6316412343326014\n",
      "Utility Loss:\t\t\t-3.7081956479004843\n",
      "Utility Loss Dyn:\t\t-4.122014721463448\n",
      "Utility Loss Stat:\t\t3.7511951592360564\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.32052899593380607\n",
      "Val Cross Reconstruction Loss:\t2.6183613652636293\n",
      "Val End Effector Loss:\t\t0.007864305144472486\n",
      "Val Smoothing Loss:\t\t0.009164896505961941\n",
      "Val Triplet Loss:\t\t2.827360909455901\n",
      "Val Latent Consistency Loss:\t0.021668405028854965\n",
      "Val Privacy Loss:\t\t-2.1664010491340782e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6262596033181356\n",
      "Val Privacy Loss Stat:\t\t3.6260429628335746\n",
      "Val Utility Loss:\t\t-3.5655294770647767\n",
      "Val Utility Loss Dyn:\t\t-4.121608512416767\n",
      "Val Utility Loss Stat:\t\t3.765055569873494\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5452765446783103\n",
      "Adv Utility Training Loss:\t\t4.069167550374359\n",
      "Coop Privacy Training Loss:\t3.6316412346376796\n",
      "Coop Utility Training Loss:\t3.7638853024917767\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18616542706333974\n",
      "Adv Utility Training Acc:\t\t0.051128638835572615\n",
      "Coop Privacy Training Acc:\t\t0.0992982245681382\n",
      "Coop Utility Training Acc:\t\t0.3603396912987844\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09931821817018555\n",
      "Privacy Acc Coop:\t\t0.0992982245681382\n",
      "Utility Acc Adv:\t\t0.00021992962252079335\n",
      "Utility Acc Coop:\t\t0.3736304382597569\n",
      "Val Privacy Acc Adv:\t\t0.10459792993630573\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.0003980891719745223\n",
      "Val Utility Acc Coop:\t\t0.35658837579617836\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 270/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.3853277321106451\n",
      "Validation Loss:\t\t0.526416166454174\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3409157429112125\n",
      "Cross Reconstruction Loss:\t2.6428540740650734\n",
      "End Effector Loss:\t\t0.009300465262372831\n",
      "Smoothing Loss:\t\t\t0.010461418706237298\n",
      "Triplet Loss:\t\t\t2.857303549826946\n",
      "Latent Consistency Loss:\t0.02355023848175316\n",
      "Privacy Loss:\t\t\t6.328941688122691e-06\n",
      "Privacy Loss Dyn:\t\t-3.631547956076175\n",
      "Privacy Loss Stat:\t\t3.6316112425566787\n",
      "Utility Loss:\t\t\t-3.6942861414230257\n",
      "Utility Loss Dyn:\t\t-4.121969352375599\n",
      "Utility Loss Stat:\t\t3.7525407450365393\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.31895625154683543\n",
      "Val Cross Reconstruction Loss:\t2.6163632125611516\n",
      "Val End Effector Loss:\t\t0.00783832250815478\n",
      "Val Smoothing Loss:\t\t0.009107680774774331\n",
      "Val Triplet Loss:\t\t2.820918020928741\n",
      "Val Latent Consistency Loss:\t0.02246176619913168\n",
      "Val Privacy Loss:\t\t-2.515638709827593e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6262945339178585\n",
      "Val Privacy Loss Stat:\t\t3.626042976500882\n",
      "Val Utility Loss:\t\t-3.4538045263594124\n",
      "Val Utility Loss Dyn:\t\t-4.121852352361011\n",
      "Val Utility Loss Stat:\t\t3.7764718957767367\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5460070732382727\n",
      "Adv Utility Training Loss:\t\t4.067818902656961\n",
      "Coop Privacy Training Loss:\t3.631611242709218\n",
      "Coop Utility Training Loss:\t3.765097636712795\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18532569577735125\n",
      "Adv Utility Training Acc:\t\t0.05297804702495201\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.3591350767754319\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09934820857325656\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t0.00021992962252079335\n",
      "Utility Acc Coop:\t\t0.3719109884836852\n",
      "Val Privacy Acc Adv:\t\t0.10459792993630573\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.0003980891719745223\n",
      "Val Utility Acc Coop:\t\t0.3484275477707006\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 271/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.3741828021048184\n",
      "Validation Loss:\t\t0.4535853770460672\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3403580007039044\n",
      "Cross Reconstruction Loss:\t2.642285553065158\n",
      "End Effector Loss:\t\t0.0093011211136729\n",
      "Smoothing Loss:\t\t\t0.010465998257381063\n",
      "Triplet Loss:\t\t\t2.854487686681961\n",
      "Latent Consistency Loss:\t0.023528336323869206\n",
      "Privacy Loss:\t\t\t7.827714400190766e-06\n",
      "Privacy Loss Dyn:\t\t-3.63154295981121\n",
      "Privacy Loss Stat:\t\t3.6316212393577025\n",
      "Utility Loss:\t\t\t-3.701239746347575\n",
      "Utility Loss Dyn:\t\t-4.122016086383119\n",
      "Utility Loss Stat:\t\t3.7518921099789084\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3192135184813457\n",
      "Val Cross Reconstruction Loss:\t2.616326066339092\n",
      "Val End Effector Loss:\t\t0.007865003547423585\n",
      "Val Smoothing Loss:\t\t0.009142906591889394\n",
      "Val Triplet Loss:\t\t2.8254080061699933\n",
      "Val Latent Consistency Loss:\t0.02188451109442172\n",
      "Val Privacy Loss:\t\t-1.9794246953004484e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626240906442047\n",
      "Val Privacy Loss Stat:\t\t3.6260429673893437\n",
      "Val Utility Loss:\t\t-3.5260013167265876\n",
      "Val Utility Loss Dyn:\t\t-4.121847195230472\n",
      "Val Utility Loss Stat:\t\t3.7692470580908903\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5447195389296713\n",
      "Adv Utility Training Loss:\t\t4.067769618958749\n",
      "Coop Privacy Training Loss:\t3.6316212393577025\n",
      "Coop Utility Training Loss:\t3.7641383916692557\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18483085412667946\n",
      "Adv Utility Training Acc:\t\t0.053322936660268716\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.3602697136916187\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.0993682021753039\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t0.00018993921944977609\n",
      "Utility Acc Coop:\t\t0.3730006397952655\n",
      "Val Privacy Acc Adv:\t\t0.10469745222929937\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.0003980891719745223\n",
      "Val Utility Acc Coop:\t\t0.35370222929936307\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 272/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.3430500435771007\n",
      "Validation Loss:\t\t0.48782973040108846\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.33977711884279854\n",
      "Cross Reconstruction Loss:\t2.6421049644149273\n",
      "End Effector Loss:\t\t0.00930102042387873\n",
      "Smoothing Loss:\t\t\t0.010471189257844338\n",
      "Triplet Loss:\t\t\t2.8536105085776846\n",
      "Latent Consistency Loss:\t0.02347468694294216\n",
      "Privacy Loss:\t\t\t2.578215498384267e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315854555204443\n",
      "Privacy Loss Stat:\t\t3.631611241336366\n",
      "Utility Loss:\t\t\t-3.729789240880418\n",
      "Utility Loss Dyn:\t\t-4.121988308406837\n",
      "Utility Loss Stat:\t\t3.7490093814815686\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.31917415378959313\n",
      "Val Cross Reconstruction Loss:\t2.62164428431517\n",
      "Val End Effector Loss:\t\t0.007847952487386145\n",
      "Val Smoothing Loss:\t\t0.00913722745208129\n",
      "Val Triplet Loss:\t\t2.8195458020374273\n",
      "Val Latent Consistency Loss:\t0.022827187873375645\n",
      "Val Privacy Loss:\t\t-1.8552799893032972e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6256313627692545\n",
      "Val Privacy Loss Stat:\t\t3.6254458214826646\n",
      "Val Utility Loss:\t\t-3.4957417773593003\n",
      "Val Utility Loss Dyn:\t\t-4.1220711386127835\n",
      "Val Utility Loss Stat:\t\t3.772496950854162\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.546601474246991\n",
      "Adv Utility Training Loss:\t\t4.066485326715715\n",
      "Coop Privacy Training Loss:\t3.6316112414889052\n",
      "Coop Utility Training Loss:\t3.7615333192255433\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18455594209852846\n",
      "Adv Utility Training Acc:\t\t0.05441758637236085\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.362763915547025\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09932821497120921\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t0.00020993282149712092\n",
      "Utility Acc Coop:\t\t0.3757197696737044\n",
      "Val Privacy Acc Adv:\t\t0.10529458598726114\n",
      "Val Privacy Acc Coop:\t\t0.10549363057324841\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.352109872611465\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 273/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.34197848224541694\n",
      "Validation Loss:\t\t0.4581498764218039\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.33930247558742016\n",
      "Cross Reconstruction Loss:\t2.6422749535822363\n",
      "End Effector Loss:\t\t0.009302463965527403\n",
      "Smoothing Loss:\t\t\t0.010473486377487599\n",
      "Triplet Loss:\t\t\t2.851936879252594\n",
      "Latent Consistency Loss:\t0.023425866156740215\n",
      "Privacy Loss:\t\t\t7.341953705917622e-06\n",
      "Privacy Loss Dyn:\t\t-3.631537824125528\n",
      "Privacy Loss Stat:\t\t3.6316112414889052\n",
      "Utility Loss:\t\t\t-3.727779759402772\n",
      "Utility Loss Dyn:\t\t-4.122006339746184\n",
      "Utility Loss Stat:\t\t3.749228359870398\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3185731698373321\n",
      "Val Cross Reconstruction Loss:\t2.6119618294345344\n",
      "Val End Effector Loss:\t\t0.007868860071157195\n",
      "Val Smoothing Loss:\t\t0.00913072795352074\n",
      "Val Triplet Loss:\t\t2.8198919311450545\n",
      "Val Latent Consistency Loss:\t0.022173144374113933\n",
      "Val Privacy Loss:\t\t-1.4550177155026964e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.625591305410786\n",
      "Val Privacy Loss Stat:\t\t3.6254458169268955\n",
      "Val Utility Loss:\t\t-3.5170624848384007\n",
      "Val Utility Loss Dyn:\t\t-4.1216270300992734\n",
      "Val Utility Loss Stat:\t\t3.7699207955864584\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5452917638072123\n",
      "Adv Utility Training Loss:\t\t4.065827277403799\n",
      "Coop Privacy Training Loss:\t3.6316112417939834\n",
      "Coop Utility Training Loss:\t3.761488627868818\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18486584293026231\n",
      "Adv Utility Training Acc:\t\t0.054902431222008954\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.3626989363403711\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09935820537428024\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t0.00020993282149712092\n",
      "Utility Acc Coop:\t\t0.37508997120921306\n",
      "Val Privacy Acc Adv:\t\t0.10529458598726114\n",
      "Val Privacy Acc Coop:\t\t0.10549363057324841\n",
      "Val Utility Acc Adv:\t\t0.0007961783439490446\n",
      "Val Utility Acc Coop:\t\t0.3532046178343949\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 274/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.3090560111650388\n",
      "Validation Loss:\t\t0.37810394657882535\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.33877511023140383\n",
      "Cross Reconstruction Loss:\t2.6419801992708036\n",
      "End Effector Loss:\t\t0.009304398576945296\n",
      "Smoothing Loss:\t\t\t0.0104584593971761\n",
      "Triplet Loss:\t\t\t2.8496531427326066\n",
      "Latent Consistency Loss:\t0.02340257575739025\n",
      "Privacy Loss:\t\t\t5.2674222434856e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315785671607546\n",
      "Privacy Loss Stat:\t\t3.6316312373790387\n",
      "Utility Loss:\t\t\t-3.7570561746413023\n",
      "Utility Loss Dyn:\t\t-4.122028431065633\n",
      "Utility Loss Stat:\t\t3.7463228138150577\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3182406577335042\n",
      "Val Cross Reconstruction Loss:\t2.609839260198508\n",
      "Val End Effector Loss:\t\t0.007876605789064411\n",
      "Val Smoothing Loss:\t\t0.009156213984320498\n",
      "Val Triplet Loss:\t\t2.8176204976002883\n",
      "Val Latent Consistency Loss:\t0.022095474147587824\n",
      "Val Privacy Loss:\t\t-1.942902613597311e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626237260308235\n",
      "Val Privacy Loss Stat:\t\t3.626042965870754\n",
      "Val Utility Loss:\t\t-3.5932623504833052\n",
      "Val Utility Loss Dyn:\t\t-4.121901512145996\n",
      "Val Utility Loss Stat:\t\t3.7625752679861275\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5453863214088877\n",
      "Adv Utility Training Loss:\t\t4.0647550966979145\n",
      "Coop Privacy Training Loss:\t3.6316312373790387\n",
      "Coop Utility Training Loss:\t3.759309556037283\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1861754238643634\n",
      "Adv Utility Training Acc:\t\t0.054932421625079976\n",
      "Coop Privacy Training Acc:\t\t0.09930822136916187\n",
      "Coop Utility Training Acc:\t\t0.3647232885476647\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09931821817018555\n",
      "Privacy Acc Coop:\t\t0.09930822136916187\n",
      "Utility Acc Adv:\t\t0.00021992962252079335\n",
      "Utility Acc Coop:\t\t0.37831893793985927\n",
      "Val Privacy Acc Adv:\t\t0.10469745222929937\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.36156449044585987\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 275/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.33992905906560666\n",
      "Validation Loss:\t\t0.4187412624288896\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.33828059679715966\n",
      "Cross Reconstruction Loss:\t2.6417977477370815\n",
      "End Effector Loss:\t\t0.009304824813137394\n",
      "Smoothing Loss:\t\t\t0.010466653746102894\n",
      "Triplet Loss:\t\t\t2.8484515161447166\n",
      "Latent Consistency Loss:\t0.023376721431163358\n",
      "Privacy Loss:\t\t\t6.6247530953669045e-06\n",
      "Privacy Loss Dyn:\t\t-3.631534993305316\n",
      "Privacy Loss Stat:\t\t3.631601245145499\n",
      "Utility Loss:\t\t\t-3.7237420426830603\n",
      "Utility Loss Dyn:\t\t-4.122023335955346\n",
      "Utility Loss Stat:\t\t3.749649131442977\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3168135166737684\n",
      "Val Cross Reconstruction Loss:\t2.6192795607694395\n",
      "Val End Effector Loss:\t\t0.007851847640244634\n",
      "Val Smoothing Loss:\t\t0.00912334441331921\n",
      "Val Triplet Loss:\t\t2.8187502690940907\n",
      "Val Latent Consistency Loss:\t0.02219994130075737\n",
      "Val Privacy Loss:\t\t-1.2827526991534384e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6261712350663107\n",
      "Val Privacy Loss Stat:\t\t3.6260429522034467\n",
      "Val Utility Loss:\t\t-3.5527724490803516\n",
      "Val Utility Loss Dyn:\t\t-4.1219352096509025\n",
      "Val Utility Loss Stat:\t\t3.7666579872179944\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5451457520287843\n",
      "Adv Utility Training Loss:\t\t4.063473045406476\n",
      "Coop Privacy Training Loss:\t3.631601245145499\n",
      "Coop Utility Training Loss:\t3.7622966540599587\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18560060780550225\n",
      "Adv Utility Training Acc:\t\t0.05628198976327575\n",
      "Coop Privacy Training Acc:\t\t0.09933821177223288\n",
      "Coop Utility Training Acc:\t\t0.36205914107485604\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09935820537428024\n",
      "Privacy Acc Coop:\t\t0.09933821177223288\n",
      "Utility Acc Adv:\t\t0.0002399232245681382\n",
      "Utility Acc Coop:\t\t0.37507997440818935\n",
      "Val Privacy Acc Adv:\t\t0.10459792993630573\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.35559315286624205\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 276/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.32518702475634126\n",
      "Validation Loss:\t\t0.5424428284998722\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3375194668197815\n",
      "Cross Reconstruction Loss:\t2.6414123623323835\n",
      "End Effector Loss:\t\t0.009307115871139866\n",
      "Smoothing Loss:\t\t\t0.010468408208571598\n",
      "Triplet Loss:\t\t\t2.846720362045181\n",
      "Latent Consistency Loss:\t0.023347002653713724\n",
      "Privacy Loss:\t\t\t1.094061750215517e-05\n",
      "Privacy Loss Dyn:\t\t-3.6315218328438124\n",
      "Privacy Loss Stat:\t\t3.631631241497594\n",
      "Utility Loss:\t\t\t-3.7349068122419578\n",
      "Utility Loss Dyn:\t\t-4.1220049119804125\n",
      "Utility Loss Stat:\t\t3.7485142245326224\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.31732084065865557\n",
      "Val Cross Reconstruction Loss:\t2.6212736360586373\n",
      "Val End Effector Loss:\t\t0.007859703847414749\n",
      "Val Smoothing Loss:\t\t0.009155760949275865\n",
      "Val Triplet Loss:\t\t2.8164786244653595\n",
      "Val Latent Consistency Loss:\t0.022037296988971673\n",
      "Val Privacy Loss:\t\t-1.884626734788251e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.625932849896182\n",
      "Val Privacy Loss Stat:\t\t3.625744386843056\n",
      "Val Utility Loss:\t\t-3.4264859485018784\n",
      "Val Utility Loss Dyn:\t\t-4.121766533821252\n",
      "Val Utility Loss Stat:\t\t3.779117947171448\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5453833127281107\n",
      "Adv Utility Training Loss:\t\t4.06243276977417\n",
      "Coop Privacy Training Loss:\t3.631631241802672\n",
      "Coop Utility Training Loss:\t3.761144970901792\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18483585252719129\n",
      "Adv Utility Training Acc:\t\t0.05872620761356366\n",
      "Coop Privacy Training Acc:\t\t0.09930822136916187\n",
      "Coop Utility Training Acc:\t\t0.3631987763915547\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09937819897632758\n",
      "Privacy Acc Coop:\t\t0.09930822136916187\n",
      "Utility Acc Adv:\t\t0.0002399232245681382\n",
      "Utility Acc Coop:\t\t0.3759796865003199\n",
      "Val Privacy Acc Adv:\t\t0.10499601910828026\n",
      "Val Privacy Acc Coop:\t\t0.10519506369426751\n",
      "Val Utility Acc Adv:\t\t0.0005971337579617834\n",
      "Val Utility Acc Coop:\t\t0.34325238853503187\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 277/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.29959397281800715\n",
      "Validation Loss:\t\t0.37540435521703236\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3368914507362832\n",
      "Cross Reconstruction Loss:\t2.6418827607398296\n",
      "End Effector Loss:\t\t0.009306893781690322\n",
      "Smoothing Loss:\t\t\t0.01046742294615305\n",
      "Triplet Loss:\t\t\t2.844015732531508\n",
      "Latent Consistency Loss:\t0.02338582914804066\n",
      "Privacy Loss:\t\t\t7.0377335819920434e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315308716994252\n",
      "Privacy Loss Stat:\t\t3.631601245145499\n",
      "Utility Loss:\t\t\t-3.75696743106659\n",
      "Utility Loss Dyn:\t\t-4.122022489058384\n",
      "Utility Loss Stat:\t\t3.746325747599147\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.31461428751231757\n",
      "Val Cross Reconstruction Loss:\t2.6149485141608366\n",
      "Val End Effector Loss:\t\t0.007864155127388087\n",
      "Val Smoothing Loss:\t\t0.009173383298596948\n",
      "Val Triplet Loss:\t\t2.8165523292152743\n",
      "Val Latent Consistency Loss:\t0.021805313504805232\n",
      "Val Privacy Loss:\t\t-1.91040479453506e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6265325667751824\n",
      "Val Privacy Loss Stat:\t\t3.626341522119607\n",
      "Val Utility Loss:\t\t-3.5852897303878883\n",
      "Val Utility Loss Dyn:\t\t-4.122113167100651\n",
      "Val Utility Loss Stat:\t\t3.763584211373785\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.545225358512717\n",
      "Adv Utility Training Loss:\t\t4.06127038828776\n",
      "Coop Privacy Training Loss:\t3.631601245450577\n",
      "Coop Utility Training Loss:\t3.7591834432866738\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1850307901471529\n",
      "Adv Utility Training Acc:\t\t0.059935820537428026\n",
      "Coop Privacy Training Acc:\t\t0.09933821177223288\n",
      "Coop Utility Training Acc:\t\t0.3650181941778631\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09934820857325656\n",
      "Privacy Acc Coop:\t\t0.09933821177223288\n",
      "Utility Acc Adv:\t\t0.00020993282149712092\n",
      "Utility Acc Coop:\t\t0.3784388995521433\n",
      "Val Privacy Acc Adv:\t\t0.10429936305732485\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.3613654458598726\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 278/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.29354831862715636\n",
      "Validation Loss:\t\t0.4905417181646368\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3362968628290595\n",
      "Cross Reconstruction Loss:\t2.642114687179497\n",
      "End Effector Loss:\t\t0.009308293578289425\n",
      "Smoothing Loss:\t\t\t0.01047705064372172\n",
      "Triplet Loss:\t\t\t2.8420961141128687\n",
      "Latent Consistency Loss:\t0.023403861834616974\n",
      "Privacy Loss:\t\t\t6.349801407055601e-06\n",
      "Privacy Loss Dyn:\t\t-3.631557738864872\n",
      "Privacy Loss Stat:\t\t3.631621238595007\n",
      "Utility Loss:\t\t\t-3.7601374005630697\n",
      "Utility Loss Dyn:\t\t-4.122016864637495\n",
      "Utility Loss Stat:\t\t3.746003133092869\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.31451499424162943\n",
      "Val Cross Reconstruction Loss:\t2.6119907509749103\n",
      "Val End Effector Loss:\t\t0.0078522947729583\n",
      "Val Smoothing Loss:\t\t0.00914541117040215\n",
      "Val Triplet Loss:\t\t2.816081344701682\n",
      "Val Latent Consistency Loss:\t0.02194268222613509\n",
      "Val Privacy Loss:\t\t-2.1889331234488517e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6268589800330484\n",
      "Val Privacy Loss Stat:\t\t3.626640088998588\n",
      "Val Utility Loss:\t\t-3.4704621430415257\n",
      "Val Utility Loss Dyn:\t\t-4.122178326746461\n",
      "Val Utility Loss Stat:\t\t3.7751321033307703\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.544940692373216\n",
      "Adv Utility Training Loss:\t\t4.059681192240651\n",
      "Coop Privacy Training Loss:\t3.631621238747546\n",
      "Coop Utility Training Loss:\t3.759017856015811\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18511076455534228\n",
      "Adv Utility Training Acc:\t\t0.06023072616762636\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.3651031669865643\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09934820857325656\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t0.0001999360204734485\n",
      "Utility Acc Coop:\t\t0.37860884516954574\n",
      "Val Privacy Acc Adv:\t\t0.10410031847133758\n",
      "Val Privacy Acc Coop:\t\t0.10429936305732485\n",
      "Val Utility Acc Adv:\t\t9.952229299363058e-05\n",
      "Val Utility Acc Coop:\t\t0.3463375796178344\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 279/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.2940354147855662\n",
      "Validation Loss:\t\t0.3818467476043352\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.33572379616461573\n",
      "Cross Reconstruction Loss:\t2.6420118868236577\n",
      "End Effector Loss:\t\t0.009304862302595121\n",
      "Smoothing Loss:\t\t\t0.01046522127277315\n",
      "Triplet Loss:\t\t\t2.8394140463491624\n",
      "Latent Consistency Loss:\t0.02349848109187221\n",
      "Privacy Loss:\t\t\t4.334779252475146e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315878802816304\n",
      "Privacy Loss Stat:\t\t3.631631234175718\n",
      "Utility Loss:\t\t\t-3.7567170766097036\n",
      "Utility Loss Dyn:\t\t-4.12201910604671\n",
      "Utility Loss Stat:\t\t3.7463473991484344\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.31468028247736063\n",
      "Val Cross Reconstruction Loss:\t2.6170308483634024\n",
      "Val End Effector Loss:\t\t0.007848317206949946\n",
      "Val Smoothing Loss:\t\t0.009136779103309485\n",
      "Val Triplet Loss:\t\t2.813723369768471\n",
      "Val Latent Consistency Loss:\t0.021947058202449684\n",
      "Val Privacy Loss:\t\t-2.210269308393928e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6262639920422983\n",
      "Val Privacy Loss Stat:\t\t3.6260429643521643\n",
      "Val Utility Loss:\t\t-3.577647385323883\n",
      "Val Utility Loss Dyn:\t\t-4.12188280615837\n",
      "Val Utility Loss Stat:\t\t3.764118050314059\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.545578925638571\n",
      "Adv Utility Training Loss:\t\t4.0579707241180385\n",
      "Coop Privacy Training Loss:\t3.631631234480796\n",
      "Coop Utility Training Loss:\t3.7590648015950325\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18399612124120282\n",
      "Adv Utility Training Acc:\t\t0.06262496001279591\n",
      "Coop Privacy Training Acc:\t\t0.09930822136916187\n",
      "Coop Utility Training Acc:\t\t0.3653430902111324\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09931821817018555\n",
      "Privacy Acc Coop:\t\t0.09930822136916187\n",
      "Utility Acc Adv:\t\t0.0001999360204734485\n",
      "Utility Acc Coop:\t\t0.37816898592450415\n",
      "Val Privacy Acc Adv:\t\t0.10469745222929937\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.35897691082802546\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 280/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.27826526920625166\n",
      "Validation Loss:\t\t0.3881008288449353\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.33523211069047565\n",
      "Cross Reconstruction Loss:\t2.642317340454839\n",
      "End Effector Loss:\t\t0.009305183617523272\n",
      "Smoothing Loss:\t\t\t0.010455660791012983\n",
      "Triplet Loss:\t\t\t2.8377232100059038\n",
      "Latent Consistency Loss:\t0.023468144658073467\n",
      "Privacy Loss:\t\t\t7.524466712888204e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315260002114265\n",
      "Privacy Loss Stat:\t\t3.6316012488064366\n",
      "Utility Loss:\t\t\t-3.7695150271639637\n",
      "Utility Loss Dyn:\t\t-4.1220073333857385\n",
      "Utility Loss Stat:\t\t3.745055832011686\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3133488800495293\n",
      "Val Cross Reconstruction Loss:\t2.6198230214939\n",
      "Val End Effector Loss:\t\t0.00785165603100589\n",
      "Val Smoothing Loss:\t\t0.00917267691118607\n",
      "Val Triplet Loss:\t\t2.803214958518933\n",
      "Val Latent Consistency Loss:\t0.023120755828015364\n",
      "Val Privacy Loss:\t\t-1.7567994488272697e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626218646954579\n",
      "Val Privacy Loss Stat:\t\t3.6260429689079334\n",
      "Val Utility Loss:\t\t-3.5703538785314866\n",
      "Val Utility Loss Dyn:\t\t-4.121934289385559\n",
      "Val Utility Loss Stat:\t\t3.7648988833093338\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.544800541298708\n",
      "Adv Utility Training Loss:\t\t4.056927685850488\n",
      "Coop Privacy Training Loss:\t3.6316012492640537\n",
      "Coop Utility Training Loss:\t3.7578342455133598\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18454094689699296\n",
      "Adv Utility Training Acc:\t\t0.06363463691618682\n",
      "Coop Privacy Training Acc:\t\t0.09933821177223288\n",
      "Coop Utility Training Acc:\t\t0.3665527031349968\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.0993682021753039\n",
      "Privacy Acc Coop:\t\t0.09933821177223288\n",
      "Utility Acc Adv:\t\t0.00018993921944977609\n",
      "Utility Acc Coop:\t\t0.3793785988483685\n",
      "Val Privacy Acc Adv:\t\t0.10469745222929937\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.3577826433121019\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 281/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.253945842534256\n",
      "Validation Loss:\t\t0.3365311244514528\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.33465928937560535\n",
      "Cross Reconstruction Loss:\t2.6421444393927978\n",
      "End Effector Loss:\t\t0.009304412167521715\n",
      "Smoothing Loss:\t\t\t0.010472910330938896\n",
      "Triplet Loss:\t\t\t2.8340458793664545\n",
      "Latent Consistency Loss:\t0.023650130322554596\n",
      "Privacy Loss:\t\t\t8.186047762079416e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315393780411167\n",
      "Privacy Loss Stat:\t\t3.631621238595007\n",
      "Utility Loss:\t\t\t-3.7908656876283966\n",
      "Utility Loss Dyn:\t\t-4.122006717738019\n",
      "Utility Loss Stat:\t\t3.7429201546496333\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3125503357428654\n",
      "Val Cross Reconstruction Loss:\t2.623674404848913\n",
      "Val End Effector Loss:\t\t0.0078499546144039\n",
      "Val Smoothing Loss:\t\t0.009133602228537676\n",
      "Val Triplet Loss:\t\t2.8036262867557014\n",
      "Val Latent Consistency Loss:\t0.022685138140894047\n",
      "Val Privacy Loss:\t\t-2.3354010976803532e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.62657506298867\n",
      "Val Privacy Loss Stat:\t\t3.626341528193966\n",
      "Val Utility Loss:\t\t-3.6166420711833203\n",
      "Val Utility Loss Dyn:\t\t-4.12206075753376\n",
      "Val Utility Loss Stat:\t\t3.760396550415428\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.544775192202167\n",
      "Adv Utility Training Loss:\t\t4.055665601466759\n",
      "Coop Privacy Training Loss:\t3.631621238747546\n",
      "Coop Utility Training Loss:\t3.756115737361017\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1857855486244402\n",
      "Adv Utility Training Acc:\t\t0.06460932501599488\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.36819717690339093\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.0993682021753039\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t0.0001999360204734485\n",
      "Utility Acc Coop:\t\t0.38176783429302624\n",
      "Val Privacy Acc Adv:\t\t0.10429936305732485\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.36365445859872614\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 282/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.2770407040027266\n",
      "Validation Loss:\t\t0.39936581846018127\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.334125938062018\n",
      "Cross Reconstruction Loss:\t2.641829750435671\n",
      "End Effector Loss:\t\t0.009307732785052678\n",
      "Smoothing Loss:\t\t\t0.010464884507006852\n",
      "Triplet Loss:\t\t\t2.832869094225053\n",
      "Latent Consistency Loss:\t0.023580156210678858\n",
      "Privacy Loss:\t\t\t7.663811160750825e-06\n",
      "Privacy Loss Dyn:\t\t-3.631564588327097\n",
      "Privacy Loss Stat:\t\t3.631641227773421\n",
      "Utility Loss:\t\t\t-3.764774852125445\n",
      "Utility Loss Dyn:\t\t-4.122006956919294\n",
      "Utility Loss Stat:\t\t3.745529461273076\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3133381652604243\n",
      "Val Cross Reconstruction Loss:\t2.6165966866122687\n",
      "Val End Effector Loss:\t\t0.007852124643458682\n",
      "Val Smoothing Loss:\t\t0.009135519373853495\n",
      "Val Triplet Loss:\t\t2.8035692515646575\n",
      "Val Latent Consistency Loss:\t0.022789007337514763\n",
      "Val Privacy Loss:\t\t-1.6637668488131966e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626507904878847\n",
      "Val Privacy Loss Stat:\t\t3.6263415297125556\n",
      "Val Utility Loss:\t\t-3.5556715461099224\n",
      "Val Utility Loss Dyn:\t\t-4.121896142412902\n",
      "Val Utility Loss Stat:\t\t3.766328983246141\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.545693710227083\n",
      "Adv Utility Training Loss:\t\t4.0539573300594105\n",
      "Coop Privacy Training Loss:\t3.63164122792596\n",
      "Coop Utility Training Loss:\t3.7578563586458973\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18465091170825335\n",
      "Adv Utility Training Acc:\t\t0.06714351407549585\n",
      "Coop Privacy Training Acc:\t\t0.0992982245681382\n",
      "Coop Utility Training Acc:\t\t0.3663677623160589\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09932821497120921\n",
      "Privacy Acc Coop:\t\t0.0992982245681382\n",
      "Utility Acc Adv:\t\t0.00018993921944977609\n",
      "Utility Acc Coop:\t\t0.37870881317978244\n",
      "Val Privacy Acc Adv:\t\t0.10439888535031847\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.35688694267515925\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 283/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.24316580542938226\n",
      "Validation Loss:\t\t0.37060849162138954\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.33346016153035374\n",
      "Cross Reconstruction Loss:\t2.641116695303377\n",
      "End Effector Loss:\t\t0.009307101024201549\n",
      "Smoothing Loss:\t\t\t0.010454428149834133\n",
      "Triplet Loss:\t\t\t2.8313496985347015\n",
      "Latent Consistency Loss:\t0.023595397688939413\n",
      "Privacy Loss:\t\t\t9.445009975958084e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315267928044763\n",
      "Privacy Loss Stat:\t\t3.631621244238953\n",
      "Utility Loss:\t\t\t-3.7958496908918833\n",
      "Utility Loss Dyn:\t\t-4.12201318570001\n",
      "Utility Loss Stat:\t\t3.742428219173478\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3133961578273469\n",
      "Val Cross Reconstruction Loss:\t2.6187382245519357\n",
      "Val End Effector Loss:\t\t0.007867548502032544\n",
      "Val Smoothing Loss:\t\t0.009100091972856954\n",
      "Val Triplet Loss:\t\t2.804592196349126\n",
      "Val Latent Consistency Loss:\t0.022414874629514994\n",
      "Val Privacy Loss:\t\t-1.7954475560765356e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6259239145145297\n",
      "Val Privacy Loss Stat:\t\t3.6257443838058765\n",
      "Val Utility Loss:\t\t-3.5819484443421574\n",
      "Val Utility Loss Dyn:\t\t-4.12208806481331\n",
      "Val Utility Loss Stat:\t\t3.7638932200753765\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.546786235832512\n",
      "Adv Utility Training Loss:\t\t4.050351404640359\n",
      "Coop Privacy Training Loss:\t3.6316212445440312\n",
      "Coop Utility Training Loss:\t3.7557778207445787\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18447596769033908\n",
      "Adv Utility Training Acc:\t\t0.0698426503518874\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.3685970489443378\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09937819897632758\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t0.00022992642354446578\n",
      "Utility Acc Coop:\t\t0.38230766154830453\n",
      "Val Privacy Acc Adv:\t\t0.10499601910828026\n",
      "Val Privacy Acc Coop:\t\t0.10519506369426751\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.3586783439490446\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 284/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.24584732178458021\n",
      "Validation Loss:\t\t0.3991077444071223\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.33282199895732767\n",
      "Cross Reconstruction Loss:\t2.640752417341075\n",
      "End Effector Loss:\t\t0.009307245288630537\n",
      "Smoothing Loss:\t\t\t0.01045759530292296\n",
      "Triplet Loss:\t\t\t2.8290454880671096\n",
      "Latent Consistency Loss:\t0.023571213016135146\n",
      "Privacy Loss:\t\t\t5.477735497443553e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315464700404756\n",
      "Privacy Loss Stat:\t\t3.631601243925186\n",
      "Utility Loss:\t\t\t-3.7893150339352344\n",
      "Utility Loss Dyn:\t\t-4.122046808668687\n",
      "Utility Loss Stat:\t\t3.743115303078601\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.31154284241852487\n",
      "Val Cross Reconstruction Loss:\t2.618676824934164\n",
      "Val End Effector Loss:\t\t0.007852519657700115\n",
      "Val Smoothing Loss:\t\t0.009128770963021905\n",
      "Val Triplet Loss:\t\t2.8047950176676366\n",
      "Val Latent Consistency Loss:\t0.022004540879160737\n",
      "Val Privacy Loss:\t\t-2.4684485356519176e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.625991219927551\n",
      "Val Privacy Loss Stat:\t\t3.625744386843056\n",
      "Val Utility Loss:\t\t-3.5459001626178717\n",
      "Val Utility Loss Dyn:\t\t-4.122162642752289\n",
      "Val Utility Loss Stat:\t\t3.767572639854091\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.546044291400482\n",
      "Adv Utility Training Loss:\t\t4.049488217877945\n",
      "Coop Privacy Training Loss:\t3.631601244382803\n",
      "Coop Utility Training Loss:\t3.7563073146976267\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.1842260476647473\n",
      "Adv Utility Training Acc:\t\t0.07086732245681382\n",
      "Coop Privacy Training Acc:\t\t0.09933821177223288\n",
      "Coop Utility Training Acc:\t\t0.36788727607165705\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09933821177223288\n",
      "Privacy Acc Coop:\t\t0.09933821177223288\n",
      "Utility Acc Adv:\t\t0.00018993921944977609\n",
      "Utility Acc Coop:\t\t0.3817178502879079\n",
      "Val Privacy Acc Adv:\t\t0.10489649681528662\n",
      "Val Privacy Acc Coop:\t\t0.10519506369426751\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.3546974522292994\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 285/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.25492208071114997\n",
      "Validation Loss:\t\t0.37135967484135535\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3320065056827689\n",
      "Cross Reconstruction Loss:\t2.639981051705544\n",
      "End Effector Loss:\t\t0.009305065885062257\n",
      "Smoothing Loss:\t\t\t0.010469854539719077\n",
      "Triplet Loss:\t\t\t2.826959407718534\n",
      "Latent Consistency Loss:\t0.023457496672492147\n",
      "Privacy Loss:\t\t\t8.324762986244792e-06\n",
      "Privacy Loss Dyn:\t\t-3.631507997854505\n",
      "Privacy Loss Stat:\t\t3.6315912489546314\n",
      "Utility Loss:\t\t\t-3.7753463642610927\n",
      "Utility Loss Dyn:\t\t-4.122054424334701\n",
      "Utility Loss Stat:\t\t3.7445197881831622\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.31116709018209177\n",
      "Val Cross Reconstruction Loss:\t2.613196567365318\n",
      "Val End Effector Loss:\t\t0.00788364743303721\n",
      "Val Smoothing Loss:\t\t0.009197653250495909\n",
      "Val Triplet Loss:\t\t2.8070432031230563\n",
      "Val Latent Consistency Loss:\t0.02167959531448829\n",
      "Val Privacy Loss:\t\t-3.244827507407802e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626666000694226\n",
      "Val Privacy Loss Stat:\t\t3.626341523638197\n",
      "Val Utility Loss:\t\t-3.5715774730512293\n",
      "Val Utility Loss Dyn:\t\t-4.12204080326542\n",
      "Val Utility Loss Stat:\t\t3.764883052011964\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.545484932278946\n",
      "Adv Utility Training Loss:\t\t4.04818232091512\n",
      "Coop Privacy Training Loss:\t3.6315912495647877\n",
      "Coop Utility Training Loss:\t3.7570898066097853\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18575555822136916\n",
      "Adv Utility Training Acc:\t\t0.0729766474728087\n",
      "Coop Privacy Training Acc:\t\t0.09934820857325656\n",
      "Coop Utility Training Acc:\t\t0.3669525751759437\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09938819577735125\n",
      "Privacy Acc Coop:\t\t0.09934820857325656\n",
      "Utility Acc Adv:\t\t0.00018993921944977609\n",
      "Utility Acc Coop:\t\t0.3798584452975048\n",
      "Val Privacy Acc Adv:\t\t0.10419984076433121\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.35768312101910826\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 286/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.23034372502104908\n",
      "Validation Loss:\t\t0.3929691692209168\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.33126339422192086\n",
      "Cross Reconstruction Loss:\t2.639706880483426\n",
      "End Effector Loss:\t\t0.00930393501604959\n",
      "Smoothing Loss:\t\t\t0.010464874743016214\n",
      "Triplet Loss:\t\t\t2.8250402138161492\n",
      "Latent Consistency Loss:\t0.023352550719259874\n",
      "Privacy Loss:\t\t\t6.278508455419266e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315584568663124\n",
      "Privacy Loss Stat:\t\t3.631621237984851\n",
      "Utility Loss:\t\t\t-3.795424297232698\n",
      "Utility Loss Dyn:\t\t-4.122086510929783\n",
      "Utility Loss Stat:\t\t3.742544080992959\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3096046861569593\n",
      "Val Cross Reconstruction Loss:\t2.614886877643075\n",
      "Val End Effector Loss:\t\t0.00784507492011425\n",
      "Val Smoothing Loss:\t\t0.009104244663101283\n",
      "Val Triplet Loss:\t\t2.800278429772444\n",
      "Val Latent Consistency Loss:\t0.022232316179307782\n",
      "Val Privacy Loss:\t\t-1.962587332269948e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6265377983166154\n",
      "Val Privacy Loss Stat:\t\t3.6263415418612728\n",
      "Val Utility Loss:\t\t-3.5454686644730296\n",
      "Val Utility Loss Dyn:\t\t-4.121753203641077\n",
      "Val Utility Loss Stat:\t\t3.767206316540955\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.545318007545447\n",
      "Adv Utility Training Loss:\t\t4.045368341322671\n",
      "Coop Privacy Training Loss:\t3.6316212382899287\n",
      "Coop Utility Training Loss:\t3.755769681106831\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18548064619321816\n",
      "Adv Utility Training Acc:\t\t0.07462112124120282\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.3683871161228407\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09933821177223288\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t0.00016994561740243122\n",
      "Utility Acc Coop:\t\t0.3815778950735765\n",
      "Val Privacy Acc Adv:\t\t0.10439888535031847\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.0005971337579617834\n",
      "Val Utility Acc Coop:\t\t0.3572850318471338\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 287/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.21920940347411505\n",
      "Validation Loss:\t\t0.46959309576518216\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3305767323352249\n",
      "Cross Reconstruction Loss:\t2.638911569034603\n",
      "End Effector Loss:\t\t0.00930341429947634\n",
      "Smoothing Loss:\t\t\t0.010466526680454965\n",
      "Triplet Loss:\t\t\t2.82348216670641\n",
      "Latent Consistency Loss:\t0.0232275549622678\n",
      "Privacy Loss:\t\t\t8.801542942293622e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315332230893147\n",
      "Privacy Loss Stat:\t\t3.63162123813739\n",
      "Utility Loss:\t\t\t-3.8023047248903787\n",
      "Utility Loss Dyn:\t\t-4.122113001476246\n",
      "Utility Loss Stat:\t\t3.7418825277058803\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3103157614067102\n",
      "Val Cross Reconstruction Loss:\t2.6106608718823474\n",
      "Val End Effector Loss:\t\t0.007874176523108392\n",
      "Val Smoothing Loss:\t\t0.00914418303176381\n",
      "Val Triplet Loss:\t\t2.7989697076712443\n",
      "Val Latent Consistency Loss:\t0.02207047903352672\n",
      "Val Privacy Loss:\t\t-1.6352173629080415e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626505048411667\n",
      "Val Privacy Loss Stat:\t\t3.6263415373055037\n",
      "Val Utility Loss:\t\t-3.467069370731427\n",
      "Val Utility Loss Dyn:\t\t-4.121814114272974\n",
      "Val Utility Loss Stat:\t\t3.7751071711254727\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.54585077193633\n",
      "Adv Utility Training Loss:\t\t4.043818585016906\n",
      "Coop Privacy Training Loss:\t3.631621238442468\n",
      "Coop Utility Training Loss:\t3.755250058415145\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18474588131797826\n",
      "Adv Utility Training Acc:\t\t0.0773652431222009\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.3690369081893794\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.0993682021753039\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t0.00016994561740243122\n",
      "Utility Acc Coop:\t\t0.38248760396673065\n",
      "Val Privacy Acc Adv:\t\t0.10439888535031847\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.0005971337579617834\n",
      "Val Utility Acc Coop:\t\t0.3471337579617834\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 288/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.21615551901660665\n",
      "Validation Loss:\t\t0.32347789323728554\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.32982336002820895\n",
      "Cross Reconstruction Loss:\t2.6384379138415697\n",
      "End Effector Loss:\t\t0.009301821943443991\n",
      "Smoothing Loss:\t\t\t0.010456189535253145\n",
      "Triplet Loss:\t\t\t2.8212785543879866\n",
      "Latent Consistency Loss:\t0.023111014422541692\n",
      "Privacy Loss:\t\t\t6.368201433353827e-06\n",
      "Privacy Loss Dyn:\t\t-3.631517565715641\n",
      "Privacy Loss Stat:\t\t3.6315812497129825\n",
      "Utility Loss:\t\t\t-3.8004004514453813\n",
      "Utility Loss Dyn:\t\t-4.122139984418853\n",
      "Utility Loss Stat:\t\t3.742099934026971\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.30915682093732677\n",
      "Val Cross Reconstruction Loss:\t2.6125176757763904\n",
      "Val End Effector Loss:\t\t0.007866360855164232\n",
      "Val Smoothing Loss:\t\t0.00916829191824528\n",
      "Val Triplet Loss:\t\t2.7987043508298837\n",
      "Val Latent Consistency Loss:\t0.02190732323582385\n",
      "Val Privacy Loss:\t\t-1.6054909700041363e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.625904945810889\n",
      "Val Privacy Loss Stat:\t\t3.6257443913988245\n",
      "Val Utility Loss:\t\t-3.609220249637677\n",
      "Val Utility Loss Dyn:\t\t-4.12165262440967\n",
      "Val Utility Loss Stat:\t\t3.7607306021793634\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5449169281576967\n",
      "Adv Utility Training Loss:\t\t4.041272577687249\n",
      "Coop Privacy Training Loss:\t3.6315812497129825\n",
      "Coop Utility Training Loss:\t3.754923130408816\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18499580134357005\n",
      "Adv Utility Training Acc:\t\t0.0780700175943698\n",
      "Coop Privacy Training Acc:\t\t0.09935820537428024\n",
      "Coop Utility Training Acc:\t\t0.36915187140115163\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09937819897632758\n",
      "Privacy Acc Coop:\t\t0.09935820537428024\n",
      "Utility Acc Adv:\t\t0.00016994561740243122\n",
      "Utility Acc Coop:\t\t0.3822876679462572\n",
      "Val Privacy Acc Adv:\t\t0.10489649681528662\n",
      "Val Privacy Acc Coop:\t\t0.10519506369426751\n",
      "Val Utility Acc Adv:\t\t0.0007961783439490446\n",
      "Val Utility Acc Coop:\t\t0.361265923566879\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 289/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.186890886957094\n",
      "Validation Loss:\t\t0.35187950355421965\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.32900496693810666\n",
      "Cross Reconstruction Loss:\t2.6384010253925774\n",
      "End Effector Loss:\t\t0.009300949241756267\n",
      "Smoothing Loss:\t\t\t0.010453937553472325\n",
      "Triplet Loss:\t\t\t2.8189137677542306\n",
      "Latent Consistency Loss:\t0.023051380838243075\n",
      "Privacy Loss:\t\t\t4.103873222970993e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315602005405143\n",
      "Privacy Loss Stat:\t\t3.6316012452980377\n",
      "Utility Loss:\t\t\t-3.8250535853917373\n",
      "Utility Loss Dyn:\t\t-4.1221508781496565\n",
      "Utility Loss Stat:\t\t3.7396455201596233\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3080756010333444\n",
      "Val Cross Reconstruction Loss:\t2.6084344371868546\n",
      "Val End Effector Loss:\t\t0.007845240769682417\n",
      "Val Smoothing Loss:\t\t0.009090958088992318\n",
      "Val Triplet Loss:\t\t2.7900129564248832\n",
      "Val Latent Consistency Loss:\t0.022241568477575187\n",
      "Val Privacy Loss:\t\t-1.8576907504136396e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6259301589552764\n",
      "Val Privacy Loss Stat:\t\t3.6257443929174142\n",
      "Val Utility Loss:\t\t-3.5726433043267316\n",
      "Val Utility Loss Dyn:\t\t-4.122039336307793\n",
      "Val Utility Loss Stat:\t\t3.764775019542427\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.545750954024546\n",
      "Adv Utility Training Loss:\t\t4.039164390460238\n",
      "Coop Privacy Training Loss:\t3.6316012457556552\n",
      "Coop Utility Training Loss:\t3.752633616776323\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18560560620601407\n",
      "Adv Utility Training Acc:\t\t0.08115902911068458\n",
      "Coop Privacy Training Acc:\t\t0.09933821177223288\n",
      "Coop Utility Training Acc:\t\t0.3715660988483685\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09934820857325656\n",
      "Privacy Acc Coop:\t\t0.09933821177223288\n",
      "Utility Acc Adv:\t\t0.00016994561740243122\n",
      "Utility Acc Coop:\t\t0.38484684900831734\n",
      "Val Privacy Acc Adv:\t\t0.10499601910828026\n",
      "Val Privacy Acc Coop:\t\t0.10519506369426751\n",
      "Val Utility Acc Adv:\t\t0.00019904458598726116\n",
      "Val Utility Acc Coop:\t\t0.35718550955414013\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 290/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.16167333701259612\n",
      "Validation Loss:\t\t0.4729568545178623\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3283373543602949\n",
      "Cross Reconstruction Loss:\t2.6377690291450486\n",
      "End Effector Loss:\t\t0.00930027657659797\n",
      "Smoothing Loss:\t\t\t0.010470456568856729\n",
      "Triplet Loss:\t\t\t2.8162834246190633\n",
      "Latent Consistency Loss:\t0.023043362581083505\n",
      "Privacy Loss:\t\t\t7.455785992964673e-06\n",
      "Privacy Loss Dyn:\t\t-3.631546687866279\n",
      "Privacy Loss Stat:\t\t3.631621245916883\n",
      "Utility Loss:\t\t\t-3.8462144286679827\n",
      "Utility Loss Dyn:\t\t-4.122172644865947\n",
      "Utility Loss Stat:\t\t3.7375511972094224\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3076834306595432\n",
      "Val Cross Reconstruction Loss:\t2.6126788490137476\n",
      "Val End Effector Loss:\t\t0.007863932473074858\n",
      "Val Smoothing Loss:\t\t0.009206968875732392\n",
      "Val Triplet Loss:\t\t2.790502967348524\n",
      "Val Latent Consistency Loss:\t0.02199457605387185\n",
      "Val Privacy Loss:\t\t-1.4874396050811574e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626191693506423\n",
      "Val Privacy Loss Stat:\t\t3.6260429522034467\n",
      "Val Utility Loss:\t\t-3.4495965751113404\n",
      "Val Utility Loss Dyn:\t\t-4.1217732277645425\n",
      "Val Utility Loss Stat:\t\t3.776813551119179\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5452787549695524\n",
      "Adv Utility Training Loss:\t\t4.036976998232148\n",
      "Coop Privacy Training Loss:\t3.631621246221961\n",
      "Coop Utility Training Loss:\t3.750890250703271\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18604546545105566\n",
      "Adv Utility Training Acc:\t\t0.08425803742802303\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.37344049904030713\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09935820537428024\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t0.0001599488163787588\n",
      "Utility Acc Coop:\t\t0.38714611324376197\n",
      "Val Privacy Acc Adv:\t\t0.10459792993630573\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.0005971337579617834\n",
      "Val Utility Acc Coop:\t\t0.34544187898089174\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 291/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.1755560715173348\n",
      "Validation Loss:\t\t0.336716290539617\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3275943877639026\n",
      "Cross Reconstruction Loss:\t2.637627185039313\n",
      "End Effector Loss:\t\t0.009299406969189282\n",
      "Smoothing Loss:\t\t\t0.010471746006412092\n",
      "Triplet Loss:\t\t\t2.8143686496212323\n",
      "Latent Consistency Loss:\t0.022964372763783217\n",
      "Privacy Loss:\t\t\t2.2494175154966037e-06\n",
      "Privacy Loss Dyn:\t\t-3.631588750211993\n",
      "Privacy Loss Stat:\t\t3.631611244692226\n",
      "Utility Loss:\t\t\t-3.828124694921844\n",
      "Utility Loss Dyn:\t\t-4.122178163729794\n",
      "Utility Loss Stat:\t\t3.7393656939325313\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.30931334596151\n",
      "Val Cross Reconstruction Loss:\t2.6114502864278806\n",
      "Val End Effector Loss:\t\t0.007865182604569539\n",
      "Val Smoothing Loss:\t\t0.00914751030919943\n",
      "Val Triplet Loss:\t\t2.793893719934354\n",
      "Val Latent Consistency Loss:\t0.021950671645059327\n",
      "Val Privacy Loss:\t\t-1.8811149961629492e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626529640452877\n",
      "Val Privacy Loss Stat:\t\t3.6263415297125556\n",
      "Val Utility Loss:\t\t-3.591744781299761\n",
      "Val Utility Loss Dyn:\t\t-4.121882554072483\n",
      "Val Utility Loss Stat:\t\t3.762708094469301\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.544645812674661\n",
      "Adv Utility Training Loss:\t\t4.03430859980031\n",
      "Coop Privacy Training Loss:\t3.631611244844765\n",
      "Coop Utility Training Loss:\t3.7521085449311493\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18543566058861163\n",
      "Adv Utility Training Acc:\t\t0.08626239603326935\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.3720209532949456\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09932821497120921\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t0.00017994241842610365\n",
      "Utility Acc Coop:\t\t0.38494681701855404\n",
      "Val Privacy Acc Adv:\t\t0.10439888535031847\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.0005971337579617834\n",
      "Val Utility Acc Coop:\t\t0.3590764331210191\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 292/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.15302153855862521\n",
      "Validation Loss:\t\t0.3399284325990897\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.326874999390225\n",
      "Cross Reconstruction Loss:\t2.637075572080972\n",
      "End Effector Loss:\t\t0.009298459701812084\n",
      "Smoothing Loss:\t\t\t0.01045564939616509\n",
      "Triplet Loss:\t\t\t2.8123036033437563\n",
      "Latent Consistency Loss:\t0.022931618268005143\n",
      "Privacy Loss:\t\t\t4.210898453656939e-06\n",
      "Privacy Loss Dyn:\t\t-3.631579120114913\n",
      "Privacy Loss Stat:\t\t3.631621234628991\n",
      "Utility Loss:\t\t\t-3.846725419935933\n",
      "Utility Loss Dyn:\t\t-4.122196519672299\n",
      "Utility Loss Stat:\t\t3.737523979204096\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3070959988862846\n",
      "Val Cross Reconstruction Loss:\t2.60915962146346\n",
      "Val End Effector Loss:\t\t0.007872667442414032\n",
      "Val Smoothing Loss:\t\t0.00920263440259228\n",
      "Val Triplet Loss:\t\t2.789552299839676\n",
      "Val Latent Consistency Loss:\t0.021553703482933104\n",
      "Val Privacy Loss:\t\t-1.978133894076013e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6262407728061556\n",
      "Val Privacy Loss Stat:\t\t3.626042955240626\n",
      "Val Utility Loss:\t\t-3.575729661686405\n",
      "Val Utility Loss Dyn:\t\t-4.121995673817434\n",
      "Val Utility Loss Stat:\t\t3.7644227021818706\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5445913601897883\n",
      "Adv Utility Training Loss:\t\t4.031763535009617\n",
      "Coop Privacy Training Loss:\t3.631621234628991\n",
      "Coop Utility Training Loss:\t3.750681710258479\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18604546545105566\n",
      "Adv Utility Training Acc:\t\t0.08884656909788867\n",
      "Coop Privacy Training Acc:\t\t0.09931821817018555\n",
      "Coop Utility Training Acc:\t\t0.3737653950735765\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09931821817018555\n",
      "Privacy Acc Coop:\t\t0.09931821817018555\n",
      "Utility Acc Adv:\t\t0.00016994561740243122\n",
      "Utility Acc Coop:\t\t0.3874360204734485\n",
      "Val Privacy Acc Adv:\t\t0.10469745222929937\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.0003980891719745223\n",
      "Val Utility Acc Coop:\t\t0.3586783439490446\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 293/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.15334788095074933\n",
      "Validation Loss:\t\t0.29033419703412205\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.32619808562772057\n",
      "Cross Reconstruction Loss:\t2.63707591163296\n",
      "End Effector Loss:\t\t0.009298356162933532\n",
      "Smoothing Loss:\t\t\t0.010459053871458394\n",
      "Triplet Loss:\t\t\t2.8109875567357507\n",
      "Latent Consistency Loss:\t0.02281479919549752\n",
      "Privacy Loss:\t\t\t8.357044068651938e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315476664044652\n",
      "Privacy Loss Stat:\t\t3.631631234480796\n",
      "Utility Loss:\t\t\t-3.8425753002203358\n",
      "Utility Loss Dyn:\t\t-4.122188242596842\n",
      "Utility Loss Stat:\t\t3.737930709096917\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.30761154612917807\n",
      "Val Cross Reconstruction Loss:\t2.610085018121513\n",
      "Val End Effector Loss:\t\t0.007858167165166633\n",
      "Val Smoothing Loss:\t\t0.009161003954281472\n",
      "Val Triplet Loss:\t\t2.7844846218254915\n",
      "Val Latent Consistency Loss:\t0.021694298442097228\n",
      "Val Privacy Loss:\t\t-1.6503083478113647e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6259094317247915\n",
      "Val Privacy Loss Stat:\t\t3.6257444081033112\n",
      "Val Utility Loss:\t\t-3.6226496605356786\n",
      "Val Utility Loss Dyn:\t\t-4.12208389780324\n",
      "Val Utility Loss Stat:\t\t3.75981897912967\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.545132565025481\n",
      "Adv Utility Training Loss:\t\t4.029980756652256\n",
      "Coop Privacy Training Loss:\t3.6316312349384137\n",
      "Coop Utility Training Loss:\t3.751371291533389\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18632037747920666\n",
      "Adv Utility Training Acc:\t\t0.09094089891234805\n",
      "Coop Privacy Training Acc:\t\t0.09930822136916187\n",
      "Coop Utility Training Acc:\t\t0.3728206973768394\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09934820857325656\n",
      "Privacy Acc Coop:\t\t0.09930822136916187\n",
      "Utility Acc Adv:\t\t0.00018993921944977609\n",
      "Utility Acc Coop:\t\t0.38625639795265515\n",
      "Val Privacy Acc Adv:\t\t0.10499601910828026\n",
      "Val Privacy Acc Coop:\t\t0.10519506369426751\n",
      "Val Utility Acc Adv:\t\t0.0003980891719745223\n",
      "Val Utility Acc Coop:\t\t0.3643511146496815\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 294/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.14100759646003816\n",
      "Validation Loss:\t\t0.3418718667428015\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.32554489323632196\n",
      "Cross Reconstruction Loss:\t2.6372015873591104\n",
      "End Effector Loss:\t\t0.009296145160835635\n",
      "Smoothing Loss:\t\t\t0.010465171479787474\n",
      "Triplet Loss:\t\t\t2.8080478062327674\n",
      "Latent Consistency Loss:\t0.02281866174832377\n",
      "Privacy Loss:\t\t\t5.593074107887038e-06\n",
      "Privacy Loss Dyn:\t\t-3.63155531349353\n",
      "Privacy Loss Stat:\t\t3.631611241183827\n",
      "Utility Loss:\t\t\t-3.850734024877664\n",
      "Utility Loss Dyn:\t\t-4.122191006299859\n",
      "Utility Loss Stat:\t\t3.7371176033544753\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.304601887798613\n",
      "Val Cross Reconstruction Loss:\t2.6076387744041005\n",
      "Val End Effector Loss:\t\t0.007839604885952109\n",
      "Val Smoothing Loss:\t\t0.009103096621170354\n",
      "Val Triplet Loss:\t\t2.785275330209428\n",
      "Val Latent Consistency Loss:\t0.02173829191975343\n",
      "Val Privacy Loss:\t\t-1.633262178700441e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.6262062841160283\n",
      "Val Privacy Loss Stat:\t\t3.626042965870754\n",
      "Val Utility Loss:\t\t-3.5658865764642216\n",
      "Val Utility Loss Dyn:\t\t-4.122004527195244\n",
      "Val Utility Loss Stat:\t\t3.765415859829848\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.5440679249363836\n",
      "Adv Utility Training Loss:\t\t4.027711496090782\n",
      "Coop Privacy Training Loss:\t3.6316112414889052\n",
      "Coop Utility Training Loss:\t3.749890039917451\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18642534388995521\n",
      "Adv Utility Training Acc:\t\t0.09284029110684582\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.37437020153550865\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09933821177223288\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t0.00018993921944977609\n",
      "Utility Acc Coop:\t\t0.38755598208573255\n",
      "Val Privacy Acc Adv:\t\t0.10469745222929937\n",
      "Val Privacy Acc Coop:\t\t0.10489649681528662\n",
      "Val Utility Acc Adv:\t\t0.0003980891719745223\n",
      "Val Utility Acc Coop:\t\t0.357484076433121\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 295/295\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.15012997141440404\n",
      "Validation Loss:\t\t0.311346524151837\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.3249641953659454\n",
      "Cross Reconstruction Loss:\t2.6368176493214555\n",
      "End Effector Loss:\t\t0.009298155462322846\n",
      "Smoothing Loss:\t\t\t0.010460115908999628\n",
      "Triplet Loss:\t\t\t2.806977446843475\n",
      "Latent Consistency Loss:\t0.02274924225423554\n",
      "Privacy Loss:\t\t\t5.253483985222385e-06\n",
      "Privacy Loss Dyn:\t\t-3.6315587073354787\n",
      "Privacy Loss Stat:\t\t3.631611243471913\n",
      "Utility Loss:\t\t\t-3.838633797829226\n",
      "Utility Loss Dyn:\t\t-4.1221913861221635\n",
      "Utility Loss Stat:\t\t3.7383280084137724\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.3044776057551621\n",
      "Val Cross Reconstruction Loss:\t2.611807356974122\n",
      "Val End Effector Loss:\t\t0.00785293913250611\n",
      "Val Smoothing Loss:\t\t0.00913887921791927\n",
      "Val Triplet Loss:\t\t2.787601811111353\n",
      "Val Latent Consistency Loss:\t0.02155811426223843\n",
      "Val Privacy Loss:\t\t-1.4940075054290188e-05\n",
      "Val Privacy Loss Dyn:\t\t-3.626490916416144\n",
      "Val Privacy Loss Stat:\t\t3.626341517563838\n",
      "Val Utility Loss:\t\t-3.5972270115165954\n",
      "Val Utility Loss Dyn:\t\t-4.121974246517109\n",
      "Val Utility Loss Stat:\t\t3.762251536557629\n",
      "\n",
      "Embedding Classifers\n",
      "Adv Privacy Training Loss:\t\t3.543976898614367\n",
      "Adv Utility Training Loss:\t\t4.0264946639499675\n",
      "Coop Privacy Training Loss:\t3.6316112439295303\n",
      "Coop Utility Training Loss:\t3.751169763462557\n",
      "Discriminator Training Loss:\t0.0\n",
      "Adv Privacy Training Acc:\t\t0.18746001279590532\n",
      "Adv Utility Training Acc:\t\t0.09441978566858605\n",
      "Coop Privacy Training Acc:\t\t0.09932821497120921\n",
      "Coop Utility Training Acc:\t\t0.3729056701855406\n",
      "Discriminator Training Acc:\t0.0\n",
      "Privacy Acc Adv:\t\t0.09934820857325656\n",
      "Privacy Acc Coop:\t\t0.09932821497120921\n",
      "Utility Acc Adv:\t\t0.0001999360204734485\n",
      "Utility Acc Coop:\t\t0.38577655150351886\n",
      "Val Privacy Acc Adv:\t\t0.10439888535031847\n",
      "Val Privacy Acc Coop:\t\t0.10459792993630573\n",
      "Val Utility Acc Adv:\t\t0.0003980891719745223\n",
      "Val Utility Acc Coop:\t\t0.35947452229299365\n",
      "Discriminator Acc:\t\t0.0\n",
      "Val Discriminator Acc:\t\t0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_stages = [\n",
    "    # Pre-Train Cross to separate embeddings\n",
    "    {'epochs': 5, 'paired': True, 'ae': True, 'ee': True, 'cross': True, 'triplet': True, 'train_emb_adv': False, 'train_discrim_adv': False, 'emb_adv': False, 'discrim_adv': False, 'eval': False, 'sgn_eval': False, 'save': False},\n",
    "    \n",
    "    # Pre-Train AE\n",
    "    {'epochs': 20, 'paired': False, 'ae': True, 'ee': True, 'cross': False, 'triplet': True, 'train_emb_adv': False, 'train_discrim_adv': False, 'emb_adv': False, 'discrim_adv': False, 'eval': False, 'sgn_eval': False, 'save': False},\n",
    "    \n",
    "    # Pre-Train Adversaries (Paired)\n",
    "    {'epochs': 20, 'paired': True, 'ae': False, 'ee': False, 'cross': False, 'triplet': False, 'train_emb_adv': True, 'train_discrim_adv': False, 'emb_adv': False, 'discrim_adv': False, 'eval': False, 'sgn_eval': False, 'save': False},\n",
    "    \n",
    "    # Pre-Train Adversaries\n",
    "    {'epochs': 50, 'paired': False, 'ae': False, 'ee': False, 'cross': False, 'triplet': False, 'train_emb_adv': True, 'train_discrim_adv': False, 'emb_adv': False, 'discrim_adv': False, 'eval': False, 'sgn_eval': False, 'save': False},\n",
    "    \n",
    "    # Train AE and adversaries with adversary loss\n",
    "    {'epochs': 100, 'paired': False, 'ae': True, 'ee': True, 'cross': False, 'triplet': True, 'train_emb_adv': True, 'train_discrim_adv': False, 'emb_adv': True, 'discrim_adv': False, 'eval': True, 'sgn_eval': True, 'save': True},\n",
    "    \n",
    "    # Paired Training (Crossing)\n",
    "    {'epochs': 100, 'paired': True, 'ae': True, 'ee': True, 'cross': True, 'triplet': True, 'train_emb_adv': True, 'train_discrim_adv': False, 'emb_adv': True, 'discrim_adv': False, 'eval': True, 'sgn_eval': False, 'save': True},\n",
    "]\n",
    "sgn_stage = {'epochs': 1, 'paired': True, 'ae': False, 'ee': False, 'cross': False, 'triplet': False, 'train_emb_adv': False, 'train_discrim_adv': False, 'emb_adv': True, 'discrim_adv': True, 'eval': True, 'sgn_eval': True, 'save': False}\n",
    "total_epochs = sum([stage['epochs'] for stage in training_stages])\n",
    "cur_tot_epoch = 0\n",
    "if sgn_eval_after_each_stage: total_epochs += len(training_stages)\n",
    "\n",
    "# mlflow logging\n",
    "try: mlflow.end_run()\n",
    "except: pass\n",
    "mlflow.start_run()\n",
    "mlflow.log_param('total_epochs', total_epochs)\n",
    "mlflow.log_param('batch_size', batch_size)\n",
    "mlflow.log_param('learning_rate', lr)\n",
    "mlflow.log_param('one_dimension_conv', one_dimension_conv)\n",
    "mlflow.log_param('ntu120', ntu_120)\n",
    "mlflow.log_param('train_equal_test', str(not seperate_train_test))\n",
    "mlflow.log_param('only_use_pos', str(only_use_pos))\n",
    "mlflow.log_param('encoded_channels', str(encoded_channels))\n",
    "mlflow.log_param('cross_samples_train', cross_samples_train)\n",
    "mlflow.log_param('cross_samples_test', cross_samples_test)\n",
    "mlflow.log_param('T', T)\n",
    "mlflow.log_params(model.get_loss_params())\n",
    "\n",
    "# os.mkdir('training_stages_log')\n",
    "training_stage_name = f'training_stages_log/stages{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.json'\n",
    "with open(training_stage_name, 'w') as f:\n",
    "    json.dump(training_stages, f)\n",
    "mlflow.log_artifact(training_stage_name)\n",
    "\n",
    "stages_save_path = f'pretrained/{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "os.mkdir(stages_save_path)\n",
    "\n",
    "for i, stage in enumerate(training_stages):\n",
    "    print('\\nMoving to new stage')\n",
    "    print(stage, '\\n')\n",
    "    if stage['save']: assert stage['eval'], 'Cannot save model without evaluating'\n",
    "    for epoch in range(stage['epochs']):\n",
    "        if stage['sgn_eval']:\n",
    "            if validation_acc_freq > 0 and epoch % validation_acc_freq == 0: use_sgn = True\n",
    "            else: use_sgn = False\n",
    "        else: use_sgn = False\n",
    "        if not stage['paired']:\n",
    "            log_dict = train_unpaired(run_eval=stage['eval'], run_sgn_eval= use_sgn, save=stage['save'], ae=stage['ae'], ee=stage['ee'], triplet=stage['triplet'], use_emb_adv=stage['emb_adv'], use_discrim_adv=stage['discrim_adv'], emb_adv=stage['train_emb_adv'], discrim_adv=stage['train_discrim_adv'], k=k)\n",
    "        else: \n",
    "            log_dict = train_paired(train_ae=stage['ae'], train_cross=stage['cross'], train_discrim=stage['train_discrim_adv'], train_emb_adv=stage['train_emb_adv'], run_eval=stage['eval'], use_emb_adv=stage['emb_adv'], use_discrim_adv=stage['discrim_adv'], run_sgn_eval= use_sgn, save=stage['save'], k=k)\n",
    "        \n",
    "        for key, value in log_dict.items():\n",
    "            mlflow.log_metric(key, value, step=cur_tot_epoch-1)\n",
    "\n",
    "    # save model\n",
    "    torch.save(model.state_dict(), f'{stages_save_path}/stage_{i}.pt')\n",
    "\n",
    "    if sgn_eval_after_each_stage:\n",
    "        print('\\nEvaluating Stage\\n')\n",
    "        stage = sgn_stage\n",
    "        log_dict = train_paired(train_ae=stage['ae'], train_cross=stage['cross'], train_discrim=stage['train_discrim_adv'], train_emb_adv=stage['train_emb_adv'], run_eval=stage['eval'], use_emb_adv=stage['emb_adv'], use_discrim_adv=stage['discrim_adv'], run_sgn_eval= use_sgn, save=stage['save'], k=k)\n",
    "        cur_tot_epoch += 1\n",
    "        for key, value in log_dict.items():\n",
    "            mlflow.log_metric(key, value, step=cur_tot_epoch-1)\n",
    "\n",
    "mlflow.pytorch.log_state_dict(model.state_dict(), 'final_model')\n",
    "mlflow.end_run()\n",
    "\n",
    "torch.save(model.state_dict(), f'{tag}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retargeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 46231/46231 [1:10:14<00:00, 10.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time: 0.006617332458372323\n"
     ]
    }
   ],
   "source": [
    "def retarget_random_action():\n",
    "    X_hat_random = {}\n",
    "    X_hat_constant = {}\n",
    "\n",
    "    # const = random.sample(list(X.keys()), 1)[0]\n",
    "    const = 'S007C001P025R001A045'.encode('utf-8')\n",
    "    x2_const = X[const].float().cuda().unsqueeze(0)\n",
    "    print(const)\n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for file in tqdm(X):\n",
    "            x1 = X[file].unsqueeze(0)\n",
    "            while True:\n",
    "                sample = random.sample(list(X.keys()), 1)[0]\n",
    "                # ensure different actor\n",
    "                if sample.decode('utf-8')[9:12] != file.decode('utf-8')[9:12]:\n",
    "                    break\n",
    "            x2_random = X[sample].unsqueeze(0)\n",
    "            start = time.time()\n",
    "            X_hat_random[file] = val_model.eval(x1.float().cuda(), x2_random.float().cuda()).cpu().numpy().squeeze()\n",
    "            times.append(time.time() - start)\n",
    "            start = time.time()\n",
    "            X_hat_constant[file] = val_model.eval(x1.float().cuda(), x2_const).cpu().numpy().squeeze()\n",
    "            times.append(time.time() - start)\n",
    "            # render_video(X_hat_random[file])\n",
    "            # render_video(X_hat_constant[file])\n",
    "\n",
    "    print(f'Average time: {np.mean(times)}')\n",
    "    \n",
    "    # Save results\n",
    "    with open(f'results/{tag}_PMR_X_hat_random_RA.pkl', 'wb') as f:\n",
    "        pickle.dump(X_hat_random, f)\n",
    "    with open(f'results/{tag}_PMR_X_hat_constant_RA.pkl', 'wb') as f:\n",
    "        pickle.dump(X_hat_constant, f)\n",
    "\n",
    "def retarget_constant_action():\n",
    "    X_hat_random = {}\n",
    "    X_hat_constant = {}\n",
    "\n",
    "    const = 8\n",
    "    # x2_const = X[const].float().cuda().unsqueeze(0)\n",
    "    times = []\n",
    "\n",
    "    const_dict = {}\n",
    "    # Get a sample of each action from the constant actor\n",
    "    for file in X:\n",
    "        info = parse_file_name(file)\n",
    "        if info['P'] == const and info['A'] not in const_dict:\n",
    "            const_dict[info['A']] = X[file].float().cuda().unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for file in tqdm(X):\n",
    "            x1 = X[file].unsqueeze(0)\n",
    "            info = parse_file_name(file)\n",
    "            while True:\n",
    "                sample = random.sample(list(X.keys()), 1)[0]\n",
    "                # ensure different actor and same action\n",
    "                info_ = parse_file_name(sample)\n",
    "                if info_['P'] != info['P'] and info_['A'] == info['A']:\n",
    "                    break\n",
    "            x2_random = X[sample].unsqueeze(0)\n",
    "            start = time.time()\n",
    "            X_hat_random[file] = val_model.eval(x1.float().cuda(), x2_random.float().cuda()).cpu().numpy().squeeze()\n",
    "            times.append(time.time() - start)\n",
    "            \n",
    "            start = time.time()\n",
    "            X_hat_constant[file] = val_model.eval(x1.float().cuda(), const_dict[info['A']]).cpu().numpy().squeeze()\n",
    "            times.append(time.time() - start)\n",
    "            \n",
    "            # render_video(X_hat_random[file])\n",
    "            # render_video(X_hat_constant[file])\n",
    "\n",
    "    print(f'Average time: {np.mean(times)}')\n",
    "    \n",
    "    # Save results\n",
    "    with open(f'results/{tag}_PMR_X_hat_random_CA.pkl', 'wb') as f:\n",
    "        pickle.dump(X_hat_random, f)\n",
    "    with open(f'results/{tag}_PMR_X_hat_constant_CA.pkl', 'wb') as f:\n",
    "        pickle.dump(X_hat_constant, f)\n",
    "\n",
    "# retarget_random_action()\n",
    "retarget_constant_action()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate utility of other baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load SGN gender classification\n",
    "sgn_gender = SGN(2, None, seg, batch_size, 0).to(device)\n",
    "sgn_gender.load_state_dict(torch.load('SGN/pretrained/gender.pt')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgn_train_x, sgn_train_y, sgn_val_x, sgn_val_y = np.zeros((batch_size, 300, 150)), np.zeros((batch_size, 1)), np.zeros((batch_size, 300, 150)), np.zeros((batch_size, 1))\n",
    "\n",
    "genders = pd.read_csv('NTU\\SGN\\statistics\\Genders.csv').replace('M', 1).replace('F', 0)\n",
    "\n",
    "def anonymizer_to_sgn(t, max_frames=300):\n",
    "    xyz, frames, joints, actors = t.shape\n",
    "    \n",
    "    # Pre-allocate memory for the output array\n",
    "    X = np.zeros((max_frames, xyz * joints * actors), dtype=np.float32)\n",
    "    \n",
    "    # Reshape the input array for easier manipulation\n",
    "    t_reshaped = t.reshape((frames, -1))\n",
    "    \n",
    "    # Copy over the reshaped data to the pre-allocated output\n",
    "    X[:frames, :t_reshaped.shape[1]] = t_reshaped\n",
    "    \n",
    "    return X\n",
    "\n",
    "def eval(X_dict, gif_name=None, cameras=None, just_render=False):\n",
    "    # Remove NTU120 if needed\n",
    "    if not ntu_120:\n",
    "        X_dict = {k: v for k, v in X_dict.items() if int(k[17:20]) <= 60}\n",
    "\n",
    "    if only_ntu_120:\n",
    "        X_dict = {k: v for k, v in X_dict.items() if int(k[17:20]) > 60}\n",
    "\n",
    "    # Remove cameras if needed\n",
    "    if cameras is not None:\n",
    "        X_dict = {k: v for k, v in X_dict.items() if int(k[7]) in cameras}\n",
    "\n",
    "    print(f'Number of files: {len(X_dict)}')\n",
    "\n",
    "    if not just_render:\n",
    "        # Calculate MSE\n",
    "        anon = torch.zeros((len(X_dict), 300, 75))\n",
    "        raw = torch.zeros((len(X_dict), 75, 25, 3))\n",
    "        rem=0\n",
    "        for i, file in enumerate(X_dict):\n",
    "            if only_use_pos:\n",
    "                if type(file) != np.bytes_: file_byte = file.split('.')[0].encode('utf-8')\n",
    "                else: file_byte = file\n",
    "            else: file_byte = file\n",
    "            \n",
    "            # Ensure file exists in both dicts\n",
    "            if file_byte not in X or file not in X_dict:\n",
    "                rem+=1\n",
    "                continue\n",
    "            anon[i] = torch.tensor(X_dict[file])\n",
    "            if only_use_pos:\n",
    "                raw[i] = X[file_byte]\n",
    "            else:\n",
    "                raw[i] = X[file_byte][:, :, :3]\n",
    "\n",
    "        # Remove non existent files\n",
    "        anon = anon[:len(X_dict)-rem]\n",
    "        raw = raw[:len(X_dict)-rem]\n",
    "\n",
    "        # Remove zeros from the end of the sequence\n",
    "        for i in range(anon.shape[1]):\n",
    "            if not torch.all(anon[:, i] == 0):\n",
    "                anon = anon[:, :i+1]\n",
    "                raw = raw[:, :i+1]\n",
    "                break\n",
    "\n",
    "        # Reshape anon to be 75, 25, 3\n",
    "        if anon.shape[1] > 75: anon = anon[:, :75, :]\n",
    "        anon = anon[:, :, :75]\n",
    "        anon = anon.reshape((anon.shape[0], anon.shape[1], 25, 3))\n",
    "\n",
    "        # Calculate MSE\n",
    "        mse = torch.mean((anon - raw)**2, dim=3)\n",
    "        l2 = torch.mean(torch.sqrt(torch.sum((anon-raw)**2, dim=3)))\n",
    "        print(f'MSE:\\t\\t\\t\\t{torch.mean(mse)}\\nL2:\\t\\t\\t\\t{l2}\\n')\n",
    "\n",
    "        # Pre-allocate memory for the output array\n",
    "        x = np.zeros((len(X_dict), 300, 150), dtype=np.float32)\n",
    "        y_util = np.zeros(len(X_dict))\n",
    "        y_priv = np.zeros(len(X_dict))\n",
    "        y_gender = np.zeros(len(X_dict))\n",
    "\n",
    "        for i, file in enumerate(X_dict):\n",
    "            if X_dict[file].shape[1] == 75:\n",
    "                X_dict[file] = np.pad(X_dict[file], ((0, 0), (0, 75)), 'constant')\n",
    "\n",
    "            x[i] = np.array(X_dict[file], dtype=np.float32)\n",
    "            y_util[i] = int(file[17:20])\n",
    "            y_priv[i] = int(file[9:12])\n",
    "            y_gender[i] = genders.loc[y_priv[i]-1, 'Gender']\n",
    "\n",
    "        y_util = y_util - 1\n",
    "        y_priv = y_priv - 1\n",
    "        y_util = np.eye(utility_classes)[y_util.astype(int)]\n",
    "        y_priv = np.eye(privacy_classes)[y_priv.astype(int)]\n",
    "\n",
    "        print(x.shape)\n",
    "\n",
    "        acc, f1, prec, recall, topk = run_sgn_eval(sgn_train_x, sgn_train_y, x, y_util, sgn_val_x, sgn_val_y, 1, sgn_ar, k=k)\n",
    "        print(f'Utility Accuracy:\\t\\t{acc}\\nUtility F1:\\t\\t\\t{f1*100}\\nUtility Precision:\\t\\t{prec*100}\\nUtility Recall:\\t\\t\\t{recall*100}\\nTop-{k} Accuracy:\\t\\t\\t{topk}\\n')\n",
    "\n",
    "        acc, f1, prec, recall, topk = run_sgn_eval(sgn_train_x, sgn_train_y, x, y_priv, sgn_val_x, sgn_val_y, 1, sgn_priv, k=k)\n",
    "        print(f'Privacy Accuracy:\\t\\t{acc}\\nPrivacy F1:\\t\\t\\t{f1*100}\\nPrivacy Precision:\\t\\t{prec*100}\\nPrivacy Recall:\\t\\t\\t{recall*100}\\nTop-{k} Accuracy:\\t\\t\\t{topk}\\n')\n",
    "\n",
    "        # Gender classification\n",
    "        acc, f1 = run_sgn_gender_eval(sgn_train_x, sgn_train_y, x, y_priv, sgn_val_x, sgn_val_y, sgn_priv)\n",
    "        print(f'Gender Classificiation Accuracy:\\t{acc}\\nF1:\\t\\t\\t\\t{f1*100}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(x_pkl, from_moon=False, pad_data=True, gif_name='', cameras=None, just_render=False):\n",
    "    with open(x_pkl, 'rb') as f:\n",
    "        test_x = pickle.load(f)\n",
    "\n",
    "    if from_moon:\n",
    "        test_x = {k: v[0] for k, v in test_x.items()}\n",
    "        for file in test_x:\n",
    "            # Assuming anonymizer_to_sgn is a predefined function you have\n",
    "            test_x[file] = anonymizer_to_sgn(test_x[file])[:, :75]\n",
    "\n",
    "    if pad_data:\n",
    "        for file in test_x:\n",
    "            if test_x[file].shape[0] == 1:\n",
    "                test_x[file] = test_x[file][0]\n",
    "            test_x[file] = np.pad(test_x[file], ((0, 300-test_x[file].shape[0]), (0, 0)), 'constant')\n",
    "\n",
    "    # If keys are bytes, convert to string\n",
    "    if type(list(test_x.keys())[0]) == np.bytes_: test_x = {k.decode('utf-8'): v for k, v in test_x.items()}\n",
    "\n",
    "    eval(test_x, gif_name=gif_name, cameras=cameras, just_render=just_render)\n",
    "\n",
    "datasets = {\n",
    "    # 'pmr_random_RA': (f'results/{tag}_PMR_X_hat_random_RA.pkl', False, True),\n",
    "    # 'pmr_constant_RA': (f'results/{tag}_PMR_X_hat_constant_RA.pkl', False, True),\n",
    "    'pmr_random_CA': (f'results/{tag}_PMR_X_hat_random_CA.pkl', False, True),\n",
    "    'pmr_constant_CA': (f'results/{tag}_PMR_X_hat_constant_CA.pkl', False, True),\n",
    "    # 'dmr_random_RA': ('results/DMR_X_hat_random_RA.pkl', False, True),\n",
    "    # 'dmr_constant_RA': ('results/DMR_X_hat_constant_RA.pkl', False, True),\n",
    "    # 'dmr_random_CA': ('results/DMR_X_hat_random_CA.pkl', False, True),\n",
    "    # 'dmr_constant_CA': ('results/DMR_X_hat_constant_CA.pkl', False, True),\n",
    "    # 'moon_unet': ('C:\\\\Users\\\\Carrt\\\\OneDrive\\\\Code\\\\Linkage Attack\\\\External Repositories\\\\Skeleton-anonymization\\\\X_unet_file.pkl', True, False),\n",
    "    # 'moon_resnet': ('C:\\\\Users\\\\Carrt\\\\OneDrive\\\\Code\\\\Linkage Attack\\\\External Repositories\\\\Skeleton-anonymization\\\\X_resnet_file.pkl', True, False),\n",
    "    # 'cmr': ('C:\\\\Users\\\\Carrt\\\\OneDrive\\\\Code\\\\Motion Privacy\\\\Defense Models\\\\Mean Skeleton\\\\X_FileNameKey_SingleActor_filtered.pkl', False, False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pmr_random_CA\n",
      "Number of files: 46231\n",
      "MSE:\t\t\t\t0.01389832329005003\n",
      "L2:\t\t\t\t0.1598712056875229\n",
      "\n",
      "(46231, 300, 150)\n",
      "Utility Accuracy:\t\t29.605262756347656\n",
      "Utility F1:\t\t\t25.90290442602401\n",
      "Utility Precision:\t\t34.91678729590685\n",
      "Utility Recall:\t\t\t29.605496490687216\n",
      "Top-5 Accuracy:\t\t\t57.200050354003906\n",
      "\n",
      "Privacy Accuracy:\t\t9.301419258117676\n",
      "Privacy F1:\t\t\t3.9510347075664165\n",
      "Privacy Precision:\t\t5.993320944266171\n",
      "Privacy Recall:\t\t\t4.820885186343679\n",
      "Top-5 Accuracy:\t\t\t31.109331130981445\n",
      "\n",
      "Gender Classificiation Accuracy:\t9.362014770507812\n",
      "F1:\t\t\t\t4.042590173721269\n",
      "\n",
      "Processing pmr_constant_CA\n",
      "Number of files: 46231\n",
      "MSE:\t\t\t\t0.0123940110206604\n",
      "L2:\t\t\t\t0.15032759308815002\n",
      "\n",
      "(46231, 300, 150)\n",
      "Utility Accuracy:\t\t38.39378356933594\n",
      "Utility F1:\t\t\t32.68677115985343\n",
      "Utility Precision:\t\t39.5527323693388\n",
      "Utility Recall:\t\t\t38.384638623283365\n",
      "Top-5 Accuracy:\t\t\t66.53176879882812\n",
      "\n",
      "Privacy Accuracy:\t\t11.980608940124512\n",
      "Privacy F1:\t\t\t4.529577390887816\n",
      "Privacy Precision:\t\t6.8243984328135125\n",
      "Privacy Recall:\t\t\t5.377442994170925\n",
      "Top-5 Accuracy:\t\t\t36.64516830444336\n",
      "\n",
      "Gender Classificiation Accuracy:\t12.01523494720459\n",
      "F1:\t\t\t\t4.586280305018635\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process all datasets\n",
    "for gif_name, (x_pkl, from_moon, pad_data) in datasets.items():\n",
    "    print(f'Processing {gif_name}')\n",
    "    process_data(x_pkl, from_moon=from_moon, pad_data=pad_data, gif_name=gif_name, just_render=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
