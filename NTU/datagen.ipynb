{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import argparse\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_path', type=str, default='D:\\\\Datasets\\\\Motion Privacy\\\\NTU RGB+D 120\\\\Skeleton Data')\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load X from pickle\n",
      "Could not load X and Y, generating them now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files Parsed:  15%|█▍        | 17143/114481 [01:35<07:00, 231.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnicodeDecodeError:  /Users/thomas/Downloads/nturgb+d_skeletons/.DS_Store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files Parsed: 100%|██████████| 114481/114481 [10:01<00:00, 190.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Generated, saving to pickle...\n",
      "X Saved to pickle\n"
     ]
    }
   ],
   "source": [
    "# Attempt to load X and Y from pickle before generating them\n",
    "X = {}\n",
    "try:\n",
    "    print('Attempting to load X from pickle')\n",
    "    with open('X.pkl', 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    print('X loaded from pickle')\n",
    "except:\n",
    "    print('Could not load X and Y, generating them now')\n",
    "    \n",
    "    # Read the files\n",
    "    files = [f for f in listdir(args.data_path) if isfile(join(args.data_path, f))]\n",
    "\n",
    "    # Get stats for each file based on name\n",
    "    files_ = []\n",
    "    for file in files:\n",
    "        data = {'file': file,\n",
    "                's': file[0:4],\n",
    "                'c': file[4:8],\n",
    "                'p': file[8:12],\n",
    "                'r': file[12:16],\n",
    "                'a': file[16:20]\n",
    "                }\n",
    "        files_.append(data)\n",
    "\n",
    "    # Generate X and Y\n",
    "    for file_ in tqdm(files_, desc='Files Parsed', position=0):\n",
    "        try:\n",
    "            file = join(args.data_path, file_['file'])\n",
    "            data = open(file, 'r')\n",
    "            lines = data.readlines()\n",
    "            frames_count = int(lines.pop(0).replace('\\n', ''))\n",
    "            file_['frames'] = frames_count\n",
    "        except UnicodeDecodeError: # .DS_Store file\n",
    "            print('UnicodeDecodeError: ', file)\n",
    "            continue\n",
    "\n",
    "        # Get P and add to X if not already there\n",
    "        p = file_['file']\n",
    "        if p not in X:\n",
    "            X[p] = []\n",
    "\n",
    "        # Skip file if 2 actors\n",
    "        if lines[0].replace('\\n', '') != '1': continue\n",
    "\n",
    "        for f in tqdm(range(frames_count), desc='Frames Parsed', position=1, leave=False):\n",
    "            try:\n",
    "                # Get actor count\n",
    "                actors = int(lines.pop(0).replace('\\n', ''))\n",
    "            \n",
    "                # Get actor info\n",
    "                t = lines.pop(0)\n",
    "\n",
    "                # Get joint count\n",
    "                joint_count = int(lines.pop(0).replace('\\n', ''))\n",
    "\n",
    "                # Get joint info\n",
    "                d = []\n",
    "                for j in range(joint_count):\n",
    "                    joint = lines.pop(0).replace('\\n', '').split(' ')\n",
    "                    d.extend(joint[0:3])\n",
    "\n",
    "                # Skip if not 25 joints\n",
    "                if len(d) != 75: continue\n",
    "\n",
    "                # Convert to numpy array\n",
    "                d = np.array(d)\n",
    "\n",
    "                # Append to X and Y\n",
    "                X[p].append(d)\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        if len(X[p]) == 0: del X[p]\n",
    "        else: X[p] = np.array(X[p], dtype=np.float16)\n",
    "\n",
    "    print('X Generated, saving to pickle...')\n",
    "\n",
    "    # Save the data\n",
    "    with open('X.pkl', 'wb') as f:\n",
    "        pickle.dump(X, f)\n",
    "\n",
    "    print('X Saved to pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
