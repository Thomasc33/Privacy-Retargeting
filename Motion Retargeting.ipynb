{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NTU RGB+D 120 Skeleton\n",
    "with open('NTU/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove empty files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 85666\n"
     ]
    }
   ],
   "source": [
    "bad_files = []\n",
    "for file in X:\n",
    "    if type(X[file]) == list: \n",
    "        bad_files.append(file)\n",
    "for file in bad_files:\n",
    "    del X[file]\n",
    "\n",
    "print(f\"Number of files: {len(X.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 75)\n"
     ]
    }
   ],
   "source": [
    "for key in X:\n",
    "    print(X[key].shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define NTU Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinematic_chains = [\n",
    "    [0,1,20,2,3],\n",
    "    [0,1,20,8,9,10,11,23],\n",
    "    [0,1,20,8,9,10,11,24],\n",
    "    [0,1,20,4,5,6,7,21],\n",
    "    [0,1,20,4,5,6,7,22],\n",
    "    [0,12,13,14,15],\n",
    "    [0,16,17,18,19]\n",
    "]\n",
    "\n",
    "end_effectors = [x[-1] for x in kinematic_chains]\n",
    "root_joint = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Dynamic Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_skeleton(frames, joints = 25):\n",
    "#     static = np.zeros(joints) # (joints)\n",
    "#     dynamic = np.zeros((len(frames), joints, 3)) # (frames, joints, 3)\n",
    "    \n",
    "#     # Static Skeleton = Offset from parent joint in form of l2 norm\n",
    "#     for path in kinematic_chains:\n",
    "#         for j in range(len(path)):\n",
    "#             if j == 0: continue # root offset is always 0\n",
    "#             if static[path[j]] != 0: continue # already computed\n",
    "            \n",
    "#             # calculate l2 norm (offset) from j to j-1\n",
    "#             static[path[j]] = np.linalg.norm(frames[0][path[j]*3:path[j]*3+3]-frames[0][path[j-1]*3:path[j-1]*3+3])\n",
    "\n",
    "#     # Dynamic Skeleton = X,Y,Z rotations from parent joint, for each frame\n",
    "#     for f in range(len(frames)):\n",
    "#         for path in kinematic_chains:\n",
    "#             for j in range(len(path)):\n",
    "#                 if j == 0: continue # root offset is always 0,0,0\n",
    "#                 if not np.all(dynamic[f][path[j]]==0): continue # already computed\n",
    "\n",
    "#                 # calculate rotation from j to j-1\n",
    "#                 vec = frames[f][path[j]*3:path[j]*3+3]-frames[f][path[j-1]*3:path[j-1]*3+3]\n",
    "#                 length = np.linalg.norm(vec)\n",
    "#                 norm_vec = vec / length\n",
    "#                 x_rot = np.arctan2(norm_vec[1], norm_vec[2])\n",
    "#                 y_rot = np.arctan2(norm_vec[0], norm_vec[2])\n",
    "#                 z_rot = np.arctan2(norm_vec[0], norm_vec[1])\n",
    "#                 dynamic[f][path[j]] = np.array([x_rot, y_rot, z_rot])\n",
    "    \n",
    "#     return static, dynamic\n",
    "\n",
    "# Modified to use matrix operations to decrease computational complexity\n",
    "def extract_skeleton(frames, joints=25):\n",
    "    n_frames = len(frames)\n",
    "    frames = np.reshape(frames, (n_frames, joints, 3))\n",
    "\n",
    "    static = np.zeros(joints) # (joints)\n",
    "    dynamic = np.zeros((n_frames, joints, 3)) # (frames, joints, 3)\n",
    "    \n",
    "    # Static Skeleton = Average offset from parent joint in form of l2 norm\n",
    "    for path in kinematic_chains:\n",
    "        path = np.array(path)\n",
    "        parent_joints = frames[:, path[1:], :]\n",
    "        child_joints = frames[:, path[:-1], :]\n",
    "        norms = np.linalg.norm(parent_joints - child_joints, axis=-1) \n",
    "        static[path[1:]] = np.mean(norms, axis=0)\n",
    "\n",
    "\n",
    "    # Dynamic Skeleton = X,Y,Z rotations from parent joint, for each frame\n",
    "    for path in kinematic_chains:\n",
    "        path = np.array(path)\n",
    "        parent_joints = frames[:, path[1:], :]\n",
    "        child_joints = frames[:, path[:-1], :]\n",
    "        vec = parent_joints - child_joints\n",
    "        length = np.linalg.norm(vec, axis=-1, keepdims=True)\n",
    "        norm_vec = vec / length\n",
    "\n",
    "        dynamic[:, path[1:], 0] = np.arctan2(norm_vec[..., 1], norm_vec[..., 2])\n",
    "        dynamic[:, path[1:], 1] = np.arctan2(norm_vec[..., 0], norm_vec[..., 2])\n",
    "        dynamic[:, path[1:], 2] = np.arctan2(norm_vec[..., 0], norm_vec[..., 1])\n",
    "    \n",
    "    return static, dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing\n",
    "for key in X:\n",
    "    static, dynamic = extract_skeleton(X[key])\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skeleton Pool/Unpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkeletonPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SkeletonPool, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 1, 2, stride=2)\n",
    "        self.pool1 = nn.AvgPool1d(2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(1, 1, 2, stride=2)\n",
    "        self.pool2 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "    def forward(self, S, Q = None): # X = (batch, S or Q+S) where S = (joints, 1) and Q = (frames, joints, 3). If Q+S, tile S to (frames, joints, 1)\n",
    "        S = torch.tensor(S)\n",
    "        if Q is None:\n",
    "            x = S.unsqueeze(-1)\n",
    "        else:\n",
    "            Q = torch.tensor(Q)\n",
    "            x = torch.cat((Q, S.repeat(Q.shape[0], 1).unsqueeze(2)), dim=-1)\n",
    "        print(x.shape)\n",
    "        return self.pool2(self.conv2(self.pool1(self.conv1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [1, 1, 2], expected input[1, 25, 1] to have 1 channels, but got 25 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pool \u001b[39m=\u001b[39m SkeletonPool()\n\u001b[1;32m----> 2\u001b[0m pool(static)\u001b[39m#, dynamic)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Carrt\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[85], line 17\u001b[0m, in \u001b[0;36mSkeletonPool.forward\u001b[1;34m(self, S, Q)\u001b[0m\n\u001b[0;32m     15\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((Q, S\u001b[39m.\u001b[39mrepeat(Q\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m2\u001b[39m)), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> 17\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x))))\n",
      "File \u001b[1;32mc:\\Users\\Carrt\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Carrt\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\Carrt\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [1, 1, 2], expected input[1, 25, 1] to have 1 channels, but got 25 channels instead"
     ]
    }
   ],
   "source": [
    "pool = SkeletonPool()\n",
    "pool(static)#, dynamic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticEncoder(nn.Module):\n",
    "    def __init__(self, num_layers):\n",
    "        super(StaticEncoder, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.num_layers = num_layers\n",
    "        activation = nn.LeakyReLU(negative_slope=0.2)\n",
    "        channels = 3\n",
    "\n",
    "    def forward(self, S):\n",
    "        # Call skeleton pool with S"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward call takes S + Q as input\n",
    "# call skeleton pool with S + Q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
