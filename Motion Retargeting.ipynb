{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from SGN.model import SGN\n",
    "from SGN.data import NTUDataLoaders, AverageMeter\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "one_dimension_conv = False\n",
    "ntu_120 = False\n",
    "seperate_train_test = False\n",
    "T = 75\n",
    "dataset = 'NTU'\n",
    "device = torch.device('cuda:0')\n",
    "seg = 20\n",
    "lr = 5e-5\n",
    "if ntu_120:\n",
    "    utility_classes = 120\n",
    "    privacy_classes = 106\n",
    "else:\n",
    "    utility_classes = 60\n",
    "    privacy_classes = 40\n",
    "validation_acc_freq = 10 #-1 to disable\n",
    "encoded_channels = (512, 32)\n",
    "batch_size = 32\n",
    "workers=0\n",
    "cross_samples_train = 10000\n",
    "cross_samples_test = 5000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Organize\n",
    "\n",
    "X = (frames, joints, pos + orientation)\n",
    "    \n",
    "    (frames, 25, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40236\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "with open('ntu/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "# pad/trim data to T frames and convert to tensor\n",
    "for file, value in X.items():\n",
    "    num_frames = value.shape[0]\n",
    "\n",
    "    # Pad or trim\n",
    "    if num_frames < T:\n",
    "        padding = np.repeat(value[-1][np.newaxis, :, :], T - num_frames, axis=0)\n",
    "        value = np.concatenate((value, padding), axis=0)\n",
    "    elif num_frames > T:\n",
    "        value = value[:T]\n",
    "    \n",
    "    # Convert to tensor and store back\n",
    "    X[file] = torch.from_numpy(value).float()\n",
    "\n",
    "if not ntu_120:\n",
    "    to_rem = []\n",
    "    for file in X.keys():\n",
    "        if int(file.split('A')[1][:3]) > 60:\n",
    "            to_rem.append(file)\n",
    "    print(len(to_rem))\n",
    "    for file in to_rem:\n",
    "        del X[file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_frame(d):\n",
    "    reshaped_data = d.reshape(-1, 3)\n",
    "    x = reshaped_data[:, 0]\n",
    "    y = reshaped_data[:, 1]\n",
    "    z = reshaped_data[:, 2]\n",
    "\n",
    "    df = pd.DataFrame({'x': x, 'y': y, 'z': z})\n",
    "\n",
    "    fig = px.scatter_3d(df, x='x', y='y', z='z', color=np.linspace(1, 25, len(x)),\n",
    "                        color_continuous_scale='Rainbow', title='Interactive 3D Scatter Plot')\n",
    "\n",
    "    fig.update_traces(marker=dict(size=2))\n",
    "\n",
    "    cons = [[0, 1], [1, 20], [20, 2], [2, 3], [20, 8], [8, 9], [9, 10], [10, 11], [11, 23], [11, 24], [20, 4], [4, 5], [5, 6], [6, 7], [7, 21], [7, 22], [0, 16], [16, 17], [17, 18], [18, 19], [0, 12], [12, 13], [13, 14], [14, 15]]\n",
    "\n",
    "    for con in cons:\n",
    "        lx = [x[con[0]], x[con[1]]]\n",
    "        ly = [y[con[0]], y[con[1]]]\n",
    "        lz = [z[con[0]], z[con[1]]]\n",
    "        fig.add_trace(go.Scatter3d(x=lx, y=ly, z=lz, mode='lines', line=dict(color='black', width=2)))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def render_video(d):\n",
    "    cons = [[0, 1], [1, 20], [20, 2], [2, 3], [20, 8], [8, 9], [9, 10], [10, 11], [11, 23], [11, 24], [20, 4], [4, 5], [5, 6], [6, 7], [7, 21], [7, 22], [0, 16], [16, 17], [17, 18], [18, 19], [0, 12], [12, 13], [13, 14], [14, 15]]\n",
    "\n",
    "    frame_data = d[0].reshape(-1, 3)\n",
    "    x = frame_data[:, 0]\n",
    "    y = frame_data[:, 1]\n",
    "    z = frame_data[:, 2]\n",
    "\n",
    "    scatter = go.Scatter3d(x=x, y=y, z=z, mode='markers',\n",
    "                        marker=dict(size=2, color=np.linspace(1, 25, 25), colorscale='Rainbow'))\n",
    "\n",
    "    traces = [scatter]\n",
    "\n",
    "    for con in cons:\n",
    "        lx = [x[con[0]], x[con[1]]]\n",
    "        ly = [y[con[0]], y[con[1]]]\n",
    "        lz = [z[con[0]], z[con[1]]]\n",
    "        line_trace = go.Scatter3d(x=lx, y=ly, z=lz, mode='lines', line=dict(color='black', width=2))\n",
    "        traces.append(line_trace)\n",
    "\n",
    "    layout = go.Layout(updatemenus=[dict(type='buttons', showactive=False,\n",
    "                                        buttons=[dict(label='Play',\n",
    "                                                    method='animate',\n",
    "                                                    args=[None, dict(frame=dict(duration=100, redraw=True), fromcurrent=True)])])],\n",
    "                    sliders=[dict(steps=[])],\n",
    "                    title=\"Animated 3D Scatter Plot with Connections\"\n",
    "            )\n",
    "\n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "\n",
    "    frame_list = []\n",
    "\n",
    "    for i in range(d.shape[0]):\n",
    "        frame_data = d[i].reshape(-1, 3)\n",
    "        x, y, z = frame_data[:, 0], frame_data[:, 1], frame_data[:, 2]\n",
    "    \n",
    "        fig.data[0].x = x\n",
    "        fig.data[0].y = y\n",
    "        fig.data[0].z = z\n",
    "        \n",
    "        center_x, center_y, center_z = x[0], y[0], z[0]\n",
    "        axis_bound = 2\n",
    "\n",
    "        fig.update_layout(scene=dict(\n",
    "            xaxis=dict(range=[center_x - axis_bound, center_x + axis_bound]),\n",
    "            yaxis=dict(range=[center_y - axis_bound, center_y + axis_bound]),\n",
    "            zaxis=dict(range=[center_z - axis_bound, center_z + axis_bound])\n",
    "        ))\n",
    "\n",
    "        frame_traces = []\n",
    "\n",
    "        frame_scatter = go.Scatter3d(x=x, y=y, z=z, mode='markers',\n",
    "                                    marker=dict(size=2, color=np.linspace(1, 25, 25), colorscale='Rainbow'))\n",
    "        frame_traces.append(frame_scatter)\n",
    "\n",
    "        for con in cons:\n",
    "            lx = [x[con[0]], x[con[1]]]\n",
    "            ly = [y[con[0]], y[con[1]]]\n",
    "            lz = [z[con[0]], z[con[1]]]\n",
    "            line_trace = go.Scatter3d(x=lx, y=ly, z=lz, mode='lines', line=dict(color='black', width=2))\n",
    "            frame_traces.append(line_trace)\n",
    "\n",
    "        frame = go.Frame(data=frame_traces, name=f'Frame {i}')\n",
    "        frame_list.append(frame)\n",
    "\n",
    "    fig.frames = frame_list\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Data Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file_name(file_name):\n",
    "    \"\"\"Parses the filename into a dictionary of parts.\"\"\"\n",
    "    parts = file_name.split('C')\n",
    "    S = parts[0][1:]\n",
    "    parts = parts[1].split('P')\n",
    "    C = parts[0]\n",
    "    parts = parts[1].split('R')\n",
    "    P = parts[0]\n",
    "    parts = parts[1].split('A')\n",
    "    R = parts[0]\n",
    "    parts = parts[1].split('.')\n",
    "    A = parts[0]\n",
    "    return {'S': S, 'C': C, 'P': P, 'R': R, 'A': A}\n",
    "\n",
    "def organize_data(data):\n",
    "    organized_data = defaultdict(list)\n",
    "    for file_name, content in data.items():\n",
    "        parts = parse_file_name(file_name)\n",
    "        if not ntu_120: # NTU 60\n",
    "            if int(parts['A']) > 60:\n",
    "                continue\n",
    "        organized_data[(parts['C'], parts['R'])].append((parts['P'], parts['A'], content))\n",
    "    return organized_data\n",
    "\n",
    "def sample_data(organized_data):\n",
    "    # Pick a random (C, R) pair\n",
    "    cr_pair = random.choice(list(organized_data.keys()))\n",
    "\n",
    "    # Get all (P, A, content) tuples for this (C, R) pair\n",
    "    pa_list = organized_data[cr_pair]\n",
    "\n",
    "    # Pick 2 unique P values and 2 unique A values\n",
    "    random.shuffle(pa_list)\n",
    "    unique_p = set()\n",
    "    unique_a = set()\n",
    "    for p, a, content in pa_list:\n",
    "        if len(unique_p) < 2:\n",
    "            unique_p.add(p)\n",
    "        if len(unique_a) < 2:\n",
    "            unique_a.add(a)\n",
    "        if len(unique_p) == 2 and len(unique_a) == 2:\n",
    "            break\n",
    "\n",
    "    if len(unique_p) < 2 or len(unique_a) < 2:\n",
    "        raise Exception(f'Not enough unique P or A values for (C, R) pair {cr_pair}')\n",
    "\n",
    "    # Form all four (P, A) pairs and get the corresponding content\n",
    "    sampled_data = []\n",
    "    for p in unique_p:\n",
    "        for a in unique_a:\n",
    "            for pa_content in pa_list:\n",
    "                if pa_content[0] == p and pa_content[1] == a:\n",
    "                    sampled_data.append(pa_content)\n",
    "                    break\n",
    "\n",
    "    return sampled_data\n",
    "\n",
    "def gen_samples(samples, data):\n",
    "    d = []\n",
    "    unique_samples = set()  # Set to track unique samples\n",
    "    for _ in range(samples):\n",
    "        failed = 0\n",
    "        while True:\n",
    "            d_ = sample_data(data)\n",
    "            d_tuple = tuple(tuple(x) for x in d_)\n",
    "            if d_tuple not in unique_samples and len(d_tuple) == 4:\n",
    "                unique_samples.add(d_tuple)  # Add the unique sample to the set\n",
    "                d.append(d_)  # Add the unique sample to the dataset\n",
    "                break\n",
    "            failed += 1\n",
    "            if failed > 100:\n",
    "                print('failed to sample data')\n",
    "                break\n",
    "    return np.array(d)\n",
    "\n",
    "\n",
    "organized_data = organize_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_rec_data(X):\n",
    "    # Remove NTU 120 if needed\n",
    "    if not ntu_120:\n",
    "        X = {k: v for k, v in X.items() if int(parse_file_name(k)['A']) <= 60}\n",
    "\n",
    "    # Split data into train and test\n",
    "    X_train_keys, X_test_keys = train_test_split(list(X.keys()), test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create train and test sets\n",
    "    X_train = np.zeros((len(X_train_keys), T, 25, 7))\n",
    "    X_test = np.zeros((len(X_test_keys), T, 25, 7))\n",
    "    for i, key in enumerate(X_train_keys):\n",
    "        X_train[i] = X[key]\n",
    "    for i, key in enumerate(X_test_keys):\n",
    "        X_test[i] = X[key]\n",
    "\n",
    "    # Get actor and action names\n",
    "    train_actors = [parse_file_name(key)['P'] for key in X_train_keys]\n",
    "    test_actors = [parse_file_name(key)['P'] for key in X_test_keys]\n",
    "    train_actions = [parse_file_name(key)['A'] for key in X_train_keys]\n",
    "    test_actions = [parse_file_name(key)['A'] for key in X_test_keys]\n",
    "    \n",
    "    return X_train, X_test, train_actors, train_actions, test_actors, test_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carrt\\AppData\\Local\\Temp\\ipykernel_2700\\283437463.py:74: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(d)\n"
     ]
    }
   ],
   "source": [
    "class Cross_Data(Dataset):\n",
    "    def __init__(self, sampled_data):\n",
    "        self.data = sampled_data # the tuple is actor, action, frames\n",
    "        self.x1 = sampled_data[:, 0, 2] # P1, A1\n",
    "        self.x2 = sampled_data[:, 3, 2] # P2, A2\n",
    "        self.y1 = sampled_data[:, 1, 2] # P1, A2\n",
    "        self.y2 = sampled_data[:, 2, 2] # P2, A1\n",
    "\n",
    "    def __getitem__(self, index): # data, actors, actions\n",
    "        return  self.x1[index][:, :, 0:3], self.x1[index][:, :, 3:7],\\\n",
    "                self.x2[index][:, :, 0:3], self.x2[index][:, :, 3:7],\\\n",
    "                self.y1[index][:, :, 0:3], self.y1[index][:, :, 3:7],\\\n",
    "                self.y2[index][:, :, 0:3], self.y2[index][:, :, 3:7],\\\n",
    "                [float(self.data[index][0][0]), float(self.data[index][3][0])], [float(self.data[index][0][1]), float(self.data[index][1][1])]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class Rec_Data(Dataset):\n",
    "    def __init__(self, X, Actor, Action):\n",
    "        self.X = X\n",
    "        self.Actor = Actor\n",
    "        self.Action = Action\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], float(self.Actor[index]), float(self.Action[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "# Cross Data\n",
    "train_data = gen_samples(cross_samples_train, organized_data)\n",
    "if seperate_train_test: val_data = gen_samples(cross_samples_test, organized_data)\n",
    "else: val_data = train_data\n",
    "train_dataset = Cross_Data(train_data)\n",
    "val_dataset = Cross_Data(val_data)\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "# Rec Data\n",
    "rec_train_data, rec_val_data, t_actors, t_actions, v_actors, v_actions = sample_rec_data(X)\n",
    "rec_train_dataset = Rec_Data(rec_train_data, t_actors, t_actions)\n",
    "rec_val_dataset = Rec_Data(rec_val_data, v_actors, v_actions)\n",
    "rec_train_dl = DataLoader(rec_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "rec_val_dl = DataLoader(rec_val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input is size of latent space\n",
    "class Adversary_Emb(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Adversary_Emb, self).__init__()\n",
    "        self.channels = 64\n",
    "        self.conv = nn.ConvTranspose1d(encoded_channels[0], self.channels, 3, 1, 1)\n",
    "        self.ref = nn.ReflectionPad1d(3)\n",
    "        self.pool = nn.MaxPool1d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * (encoded_channels[1] + 6) // 2, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "    \n",
    "class Discriminator(nn.Module): # 1 = real, 0 = fake\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.enc1 = nn.Conv1d(in_channels=T, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc2 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc3 = nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc4 = nn.Conv1d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.ref1 = nn.ReflectionPad1d(3)\n",
    "        self.ref2 = nn.ReflectionPad1d(3)\n",
    "        self.ref3 = nn.ReflectionPad1d(3)\n",
    "        self.ref4 = nn.ReflectionPad1d(3)\n",
    "        self.fc1 = nn.Linear(80, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.acti = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref1(x)\n",
    "        x = self.acti(self.enc1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.ref2(x)\n",
    "        x = self.acti(self.enc2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.ref3(x)\n",
    "        x = self.acti(self.enc3(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.ref4(x)\n",
    "        x = self.acti(self.enc4(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        #flatten\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Retargeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder1D, self).__init__()\n",
    "\n",
    "        self.enc1 = nn.Conv1d(in_channels=T, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc2 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc3 = nn.Conv1d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc4 = nn.Conv1d(in_channels=512, out_channels=encoded_channels[0], kernel_size=3, stride=1, padding=1)\n",
    "        self.ref1 = nn.ReflectionPad1d(3)\n",
    "        self.ref2 = nn.ReflectionPad1d(3)\n",
    "        self.ref3 = nn.ReflectionPad1d(3)\n",
    "        self.ref4 = nn.ReflectionPad1d(3)\n",
    "\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.acti = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(encoded_channels[0], encoded_channels[0] * encoded_channels[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref1(x)\n",
    "        x = self.acti(self.enc1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.ref2(x)\n",
    "        x = self.acti(self.enc2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.ref3(x)\n",
    "        x = self.acti(self.enc3(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.ref4(x)\n",
    "        x = self.acti(self.enc4(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.squeeze(-1) \n",
    "        x = self.fc1(x)\n",
    "        x = x.view(-1, *encoded_channels)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Decoder1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder1D, self).__init__()\n",
    "\n",
    "        self.dec1 = nn.ConvTranspose1d(in_channels=encoded_channels[0]*2, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.dec2 = nn.ConvTranspose1d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.dec3 = nn.ConvTranspose1d(in_channels=128, out_channels=96, kernel_size=3, stride=1, padding=1)\n",
    "        self.dec4 = nn.ConvTranspose1d(in_channels=96, out_channels=T, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.ref1 = nn.ReflectionPad1d(3)\n",
    "        self.ref2 = nn.ReflectionPad1d(3)\n",
    "        self.ref3 = nn.ReflectionPad1d(3)\n",
    "        self.ref4 = nn.ReflectionPad1d(3)\n",
    " \n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.up75 = nn.Upsample(size=T, mode='nearest') \n",
    "\n",
    "        self.acti = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref1(x)\n",
    "        x = self.acti(self.dec1(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref2(x)\n",
    "        x = self.acti(self.dec2(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref3(x)\n",
    "        x = self.acti(self.dec3(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref4(x)\n",
    "        x = self.acti(self.dec4(x))\n",
    "        x = self.up75(x)\n",
    "        return x\n",
    "    \n",
    "class Encoder2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder2D, self).__init__()\n",
    "\n",
    "        self.enc1 = nn.Conv2d(in_channels=T, out_channels=12, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.enc2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.enc3 = nn.Conv2d(in_channels=24, out_channels=32, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.enc4 = nn.Conv2d(in_channels=32, out_channels=encoded_channels[0], kernel_size=(3,3), stride=1, padding=1)\n",
    "\n",
    "        self.ref = nn.ReflectionPad2d(1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "        self.acti = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc1 = nn.Linear(encoded_channels[0], encoded_channels[0] * encoded_channels[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.enc1(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.enc2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.enc3(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.enc4(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = x.view(-1, *encoded_channels)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Decoder2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder2D, self).__init__()\n",
    "\n",
    "        self.dec1 = nn.ConvTranspose2d(in_channels=encoded_channels[0]*2, out_channels=256, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.dec2 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.dec3 = nn.ConvTranspose2d(in_channels=128, out_channels=96, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.dec4 = nn.ConvTranspose2d(in_channels=96, out_channels=T, kernel_size=(3,3), stride=1, padding=1)\n",
    "\n",
    "        self.ref = nn.ReflectionPad2d(3)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.up75 = nn.Upsample(size=T, mode='nearest') \n",
    "        self.acti = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.dec1(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.dec2(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.dec3(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.dec4(x))\n",
    "        x = self.up75(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, adv_lr=1e-3, use_adv=True):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        # AutoEncoder Models\n",
    "        if one_dimension_conv:\n",
    "            self.static_encoder = Encoder1D()\n",
    "            self.dynamic_encoder = Encoder1D()\n",
    "            self.decoder = Decoder1D()\n",
    "        else:\n",
    "            self.static_encoder = Encoder2D()\n",
    "            self.dynamic_encoder = Encoder2D()\n",
    "            self.decoder = Decoder1D()\n",
    "\n",
    "        # Adversarial Models\n",
    "        self.use_adv = use_adv\n",
    "        if use_adv:\n",
    "            self.priv_adv = Adversary_Emb(privacy_classes)\n",
    "            self.util_adv = Adversary_Emb(utility_classes)\n",
    "            self.discriminator = Discriminator()\n",
    "\n",
    "            self.priv_optim = torch.optim.Adam(self.priv_adv.parameters(), lr=adv_lr)\n",
    "            self.util_optim = torch.optim.Adam(self.util_adv.parameters(), lr=adv_lr)\n",
    "            self.discriminator_optim = torch.optim.Adam(self.discriminator.parameters(), lr=adv_lr)\n",
    "\n",
    "            # Freeze Adversarial Models\n",
    "            self.priv_adv.eval()\n",
    "            self.util_adv.eval()\n",
    "            self.discriminator.eval()\n",
    "\n",
    "        # Loss Functions\n",
    "        self.triplet_loss = nn.TripletMarginLoss()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        \n",
    "        # Info for loss functions\n",
    "        self.end_effectors = torch.tensor([19, 15, 23, 24, 21, 22, 3]).to(device) * 3\n",
    "        self.chain_lengths = torch.tensor([5, 5, 8, 8, 8, 8, 5]).to(device)\n",
    "\n",
    "        # Lambdas for discounted loss\n",
    "        self.lambda_rec = 2\n",
    "        self.lambda_cross = 0.1\n",
    "        self.lambda_ee = 1\n",
    "        self.lambda_trip = 0.1\n",
    "        self.lambda_latent = 5\n",
    "        self.lambda_adv_util = 0.25\n",
    "        self.lambda_adv_priv = 0.25\n",
    "        self.lambda_adv_disc = 0.25\n",
    "\n",
    "        # Loss Toggles\n",
    "        self.use_rec_loss = True\n",
    "        self.use_cross_loss = True\n",
    "        self.use_ee_loss = True \n",
    "        self.use_trip_loss = False # Remove comments when re-enabling\n",
    "        self.use_latent_consistency = True\n",
    "\n",
    "    def get_loss_params(self):\n",
    "        return {\n",
    "            'lambda_rec': self.lambda_rec,\n",
    "            'lambda_cross': self.lambda_cross,\n",
    "            'lambda_ee': self.lambda_ee,\n",
    "            'lambda_trip': self.lambda_trip,\n",
    "            'lambda_latent': self.lambda_latent,\n",
    "            'lambda_adv_util': self.lambda_adv_util,\n",
    "            'lambda_adv_priv': self.lambda_adv_priv,\n",
    "            'lambda_adv_disc': self.lambda_adv_disc,\n",
    "            'use_rec_loss': self.use_rec_loss,\n",
    "            'use_cross_loss': self.use_cross_loss,\n",
    "            'use_ee_loss': self.use_ee_loss,\n",
    "            'use_trip_loss': self.use_trip_loss,\n",
    "            'use_latent_consistency': self.use_latent_consistency\n",
    "        }\n",
    "\n",
    "    def cross(self, x1, x1_rot, x2, x2_rot):\n",
    "        d1 = self.dynamic_encoder(x1_rot)\n",
    "        d2 = self.dynamic_encoder(x2_rot)\n",
    "        s1 = self.static_encoder(x1)\n",
    "        s2 = self.static_encoder(x2)\n",
    "        \n",
    "        x1_hat = self.decoder(torch.cat((d1, s1), dim=1))\n",
    "        x2_hat = self.decoder(torch.cat((d2, s2), dim=1))\n",
    "        y1_hat = self.decoder(torch.cat((d1, s2), dim=1))\n",
    "        y2_hat = self.decoder(torch.cat((d2, s1), dim=1))\n",
    "\n",
    "        return x1_hat, x2_hat, y1_hat, y2_hat\n",
    "    \n",
    "    def eval(self, x1_rot, x2):\n",
    "        dynamic = self.dynamic_encoder(x1_rot)\n",
    "        static = self.static_encoder(x2)\n",
    "        return self.decoder(torch.cat((dynamic, static), dim=1))\n",
    "\n",
    "    def rec_loss(self, x, x_rot):\n",
    "        d = self.dynamic_encoder(x_rot)\n",
    "        s = self.static_encoder(x)\n",
    "        x_hat = self.decoder(torch.cat((d, s), dim=1))\n",
    "        if not one_dimension_conv:\n",
    "            x_ = x.reshape(x.size(0), T, -1)\n",
    "        return self.reconstruction_loss(x_, x_hat)\n",
    "    \n",
    "    def loss_paired(self, x1, x1_rot, x2, x2_rot, y1, y1_rot, y2, y2_rot, actors, actions, cross = True, reconstruction = True, emb_adv = True, discrim_adv = True, verbose = False):\n",
    "        d1 = self.dynamic_encoder(x1_rot) # A1\n",
    "        d2 = self.dynamic_encoder(x2_rot) # A2\n",
    "        s1 = self.static_encoder(x1) # P1\n",
    "        s2 = self.static_encoder(x2) # P2\n",
    "\n",
    "        x1_hat = self.decoder(torch.cat((d1, s1), dim=1)) # P1, A1\n",
    "        x2_hat = self.decoder(torch.cat((d2, s2), dim=1)) # P2, A2\n",
    "        y1_hat = self.decoder(torch.cat((d1, s2), dim=1)) # P2, A1\n",
    "        y2_hat = self.decoder(torch.cat((d2, s1), dim=1)) # P1, A2\n",
    "\n",
    "        d12 = self.dynamic_encoder(y1_rot) # A1\n",
    "        d21 = self.dynamic_encoder(y2_rot) # A2\n",
    "        s12 = self.static_encoder(y1) # P2\n",
    "        s21 = self.static_encoder(y2) # P1\n",
    "\n",
    "        x1_hat_ = self.decoder(torch.cat((d12, s21), dim=1)) # P1, A1\n",
    "        x2_hat_ = self.decoder(torch.cat((d21, s12), dim=1)) # P2, A2\n",
    "        y1_hat_ = self.decoder(torch.cat((d12, s12), dim=1)) # P2, A1\n",
    "        y2_hat_ = self.decoder(torch.cat((d21, s21), dim=1)) # P1, A2\n",
    "\n",
    "        # flatten data if 2D\n",
    "        if not one_dimension_conv:\n",
    "            x1 = x1.view(x1.size(0), T, -1)\n",
    "            x2 = x2.view(x2.size(0), T, -1)\n",
    "            y1 = y1.view(y1.size(0), T, -1)\n",
    "            y2 = y2.view(y2.size(0), T, -1)\n",
    "        \n",
    "        # initialize all losses to 0 tensor\n",
    "        rec_loss = torch.zeros(1).to(device)\n",
    "        cross_loss = torch.zeros(1).to(device)\n",
    "        end_effector_loss = torch.zeros(1).to(device)\n",
    "        triplet_loss = torch.zeros(1).to(device)\n",
    "        latent_consistency_loss = torch.zeros(1).to(device)\n",
    "        privacy_loss = torch.zeros(1).to(device)\n",
    "        privacy_loss_dyn = torch.zeros(1).to(device)\n",
    "        privacy_loss_stat = torch.zeros(1).to(device)\n",
    "        privacy_acc_dyn = torch.zeros(1).to(device)\n",
    "        privacy_acc_stat = torch.zeros(1).to(device)\n",
    "        utility_loss = torch.zeros(1).to(device)\n",
    "        utility_loss_dyn = torch.zeros(1).to(device)\n",
    "        utility_loss_stat = torch.zeros(1).to(device)\n",
    "        utility_acc_dyn = torch.zeros(1).to(device)\n",
    "        utility_acc_stat = torch.zeros(1).to(device)\n",
    "        discriminator_loss = torch.zeros(1).to(device)\n",
    "        discriminator_acc = torch.zeros(1).to(device)\n",
    "                        \n",
    "        # reconstruction loss\n",
    "        if self.use_rec_loss and reconstruction:\n",
    "            rec_loss = self.reconstruction_loss(x1, x1_hat) + self.reconstruction_loss(x2, x2_hat) + self.reconstruction_loss(y1, y1_hat_) + self.reconstruction_loss(y2, y2_hat_)\n",
    "            if verbose: print('Reconstruction Loss: ', rec_loss.item())\n",
    "        \n",
    "        # cross reconstruction loss\n",
    "        if self.use_cross_loss and cross:\n",
    "            cross_loss = self.cross_loss(y1, y2, y1_hat, y2_hat) + self.cross_loss(x1, x2, x1_hat_, x2_hat_)\n",
    "            if verbose: print('Cross Reconstruction Loss: ', cross_loss.item())\n",
    "        \n",
    "        # end effector loss\n",
    "        if self.use_ee_loss:\n",
    "            if reconstruction:\n",
    "                end_effector_loss += self.end_effector_loss(x1_hat, x1) + self.end_effector_loss(x2_hat, x2)\n",
    "            if cross:\n",
    "                end_effector_loss += self.end_effector_loss(y1_hat, y1) + self.end_effector_loss(y2_hat, y2)\n",
    "            if verbose: print('End Effector Loss: ', end_effector_loss.item())\n",
    "\n",
    "        # triplet loss\n",
    "        if self.use_trip_loss:\n",
    "            triplet_loss = self.triplet_loss(d12, d1, d2) + self.triplet_loss(d21, d2, d1) + self.triplet_loss(s12, s1, s2) + self.triplet_loss(s21, s2, s1) \n",
    "            if verbose: print('Triplet Loss: ', triplet_loss.item())\n",
    "\n",
    "        # latent consistency loss\n",
    "        if self.use_latent_consistency:\n",
    "            latent_consistency_loss = self.latent_consistency_loss(d1, d12) + self.latent_consistency_loss(d2, d21) + self.latent_consistency_loss(s1, s21) + self.latent_consistency_loss(s2, s12)\n",
    "            if verbose: print('Latent Consistency Loss: ', latent_consistency_loss.item())\n",
    "\n",
    "        # adversarial loss\n",
    "        if self.use_adv and emb_adv:\n",
    "            # latent privacy loss (adversarial)\n",
    "            adv_priv_y1, adv_priv_y2 = actors[0] - 1, actors[1] - 1\n",
    "            adv_priv_y1, adv_priv_y2 = torch.eye(privacy_classes)[adv_priv_y1.long()].to(device), torch.eye(privacy_classes)[adv_priv_y2.long()].to(device)\n",
    "            privacy_loss_dyn = -(self.adv_loss(self.priv_adv, d1, adv_priv_y1) + self.adv_loss(self.priv_adv, d2, adv_priv_y2))\n",
    "            privacy_loss_stat = (self.adv_loss(self.priv_adv, s1, adv_priv_y1) + self.adv_loss(self.priv_adv, s2, adv_priv_y2))\n",
    "            privacy_loss = privacy_loss_dyn + privacy_loss_stat\n",
    "            if verbose: print('Privacy Loss Dynamic: ', privacy_loss_dyn.item(), '\\tPrivacy Loss Static: ', privacy_loss_stat.item(), '\\tPrivacy Loss: ', privacy_loss.item())\n",
    "\n",
    "            privacy_acc_dyn = (self.adv_accuracy(self.priv_adv, d1, adv_priv_y1) + self.adv_accuracy(self.priv_adv, d2, adv_priv_y2)) / 2\n",
    "            privacy_acc_stat = (self.adv_accuracy(self.priv_adv, s1, adv_priv_y1) + self.adv_accuracy(self.priv_adv, s2, adv_priv_y2)) / 2\n",
    "            if verbose: print('Privacy Accuracy Dynamic: ', privacy_acc_dyn.item(), '\\tPrivacy Accuracy Static: ', privacy_acc_stat.item())\n",
    "            \n",
    "            # latent utility loss (adversarial)\n",
    "            adv_util_y1, adv_util_y2 = actions[0] - 1, actions[1] - 1\n",
    "            adv_util_y1, adv_util_y2 = torch.eye(utility_classes)[adv_util_y1.long()].to(device), torch.eye(utility_classes)[adv_util_y2.long()].to(device)\n",
    "            utility_loss_dyn = (self.adv_loss(self.util_adv, d1, adv_util_y1) + self.adv_loss(self.util_adv, d2, adv_util_y2))\n",
    "            utility_loss_stat = -(self.adv_loss(self.util_adv, s1, adv_util_y1) + self.adv_loss(self.util_adv, s2, adv_util_y2))\n",
    "            utility_loss = utility_loss_dyn + utility_loss_stat\n",
    "            if verbose: print('Utility Loss Dynamic: ', utility_loss_dyn.item(), '\\tUtility Loss Static: ', utility_loss_stat.item(), '\\tUtility Loss: ', utility_loss.item())\n",
    "\n",
    "            utility_acc_dyn = (self.adv_accuracy(self.util_adv, d1, adv_util_y1) + self.adv_accuracy(self.util_adv, d2, adv_util_y2)) / 2\n",
    "            utility_acc_stat = (self.adv_accuracy(self.util_adv, s1, adv_util_y1) + self.adv_accuracy(self.util_adv, s2, adv_util_y2)) / 2\n",
    "            if verbose: print('Utility Accuracy Dynamic: ', utility_acc_dyn.item(), '\\tUtility Accuracy Static: ', utility_acc_stat.item())\n",
    "\n",
    "        if self.use_adv and discrim_adv:\n",
    "            # discrimnator (adversarial)\n",
    "            discrim_out_fake = self.discriminator(torch.cat((x1_hat, x2_hat, y1_hat, y2_hat, x1_hat_, x2_hat_, y1_hat_, y2_hat_)))\n",
    "            discriminator_loss = self.bce_loss(discrim_out_fake, torch.ones_like(discrim_out_fake))\n",
    "            discriminator_acc = torch.sum(torch.round(discrim_out_fake) == 0).float() / (8 * batch_size)\n",
    "            if verbose: print('Discriminator Loss: ', discriminator_loss.item(), '\\tDiscriminator Accuracy: ', discriminator_acc.item())\n",
    "\n",
    "        losses = {\n",
    "            'rec_loss': rec_loss.item(),\n",
    "            'cross_loss': cross_loss.item(),\n",
    "            'end_effector_loss': end_effector_loss.item(),\n",
    "            'triplet_loss': triplet_loss.item(),\n",
    "            'latent_consistency_loss': latent_consistency_loss.item(),\n",
    "            'privacy_loss': privacy_loss.item(),\n",
    "            'privacy_loss_dyn': privacy_loss_dyn.item(),\n",
    "            'privacy_loss_stat': privacy_loss_stat.item(),\n",
    "            'privacy_acc_dyn': privacy_acc_dyn.item(),\n",
    "            'privacy_acc_stat': privacy_acc_stat.item(),\n",
    "            'utility_loss': utility_loss.item(),\n",
    "            'utility_loss_dyn': utility_loss_dyn.item(),\n",
    "            'utility_loss_stat': utility_loss_stat.item(),\n",
    "            'utility_acc_dyn': utility_acc_dyn.item(),\n",
    "            'utility_acc_stat': utility_acc_stat.item(),\n",
    "            'discriminator_loss': discriminator_loss.item(),\n",
    "            'discriminator_acc': discriminator_acc.item()\n",
    "        }\n",
    "\n",
    "        return rec_loss * self.lambda_rec \\\n",
    "                + cross_loss * self.lambda_cross \\\n",
    "                + end_effector_loss * self.lambda_ee \\\n",
    "                + triplet_loss * self.lambda_trip \\\n",
    "                + latent_consistency_loss * self.lambda_latent \\\n",
    "                + privacy_loss * self.lambda_adv_priv \\\n",
    "                + utility_loss * self.lambda_adv_util \\\n",
    "                + discriminator_loss * self.lambda_adv_disc, \\\n",
    "                x1_hat, x2_hat, y1_hat, y2_hat, losses\n",
    "\n",
    "    def loss_unpaired(self, x_pos, x_rot, actors, actions, reconstruction = True, emb_adv = False, discrim_adv = False, ee = False, triplet = False, verbose = False):\n",
    "        d = self.dynamic_encoder(x_rot)\n",
    "        s = self.static_encoder(x_pos)\n",
    "        x_hat = self.decoder(torch.cat((d, s), dim=1))\n",
    "\n",
    "        if not one_dimension_conv:\n",
    "            x = x_pos.reshape(x_pos.size(0), T, -1)\n",
    "\n",
    "        # initialize all losses to 0 tensor\n",
    "        rec_loss = torch.zeros(1).to(device)\n",
    "        end_effector_loss = torch.zeros(1).to(device)\n",
    "        triplet_loss = torch.zeros(1).to(device)\n",
    "        privacy_loss = torch.zeros(1).to(device)\n",
    "        privacy_loss_dyn = torch.zeros(1).to(device)\n",
    "        privacy_loss_stat = torch.zeros(1).to(device)\n",
    "        privacy_acc_dyn = torch.zeros(1).to(device)\n",
    "        privacy_acc_stat = torch.zeros(1).to(device)\n",
    "        utility_loss = torch.zeros(1).to(device)\n",
    "        utility_loss_dyn = torch.zeros(1).to(device)\n",
    "        utility_loss_stat = torch.zeros(1).to(device)\n",
    "        utility_acc_dyn = torch.zeros(1).to(device)\n",
    "        utility_acc_stat = torch.zeros(1).to(device)\n",
    "        discriminator_loss = torch.zeros(1).to(device)\n",
    "        discriminator_acc = torch.zeros(1).to(device)\n",
    "\n",
    "        # Reconstruction Loss\n",
    "        if self.use_rec_loss and reconstruction:\n",
    "            rec_loss = self.reconstruction_loss(x, x_hat)\n",
    "            if verbose: print('Reconstruction Loss: ', rec_loss.item())\n",
    "\n",
    "        # End Effector Loss\n",
    "        if self.use_ee_loss and ee:\n",
    "            end_effector_loss = self.end_effector_loss(x_hat, x)\n",
    "            if verbose: print('End Effector Loss: ', end_effector_loss.item())\n",
    "\n",
    "        # Triplet Loss\n",
    "        if self.use_trip_loss and triplet:\n",
    "            triplet_loss = 1 # idk what to use for anchor\n",
    "            if verbose: print('Triplet Loss: ', triplet_loss.item())\n",
    "\n",
    "        # Adversarial Loss\n",
    "        if self.use_adv and emb_adv:\n",
    "            # latent privacy loss (adversarial)\n",
    "            adv_priv_y = actors - 1\n",
    "            adv_priv_y = torch.eye(privacy_classes)[adv_priv_y.long()].to(device)\n",
    "            privacy_loss_dyn = -(self.adv_loss(self.priv_adv, d, adv_priv_y))\n",
    "            privacy_loss_stat = (self.adv_loss(self.priv_adv, s, adv_priv_y))\n",
    "            privacy_loss = privacy_loss_dyn + privacy_loss_stat\n",
    "            if verbose: print('Privacy Loss Dynamic: ', privacy_loss_dyn.item(), '\\tPrivacy Loss Static: ', privacy_loss_stat.item(), '\\tPrivacy Loss: ', privacy_loss.item())\n",
    "\n",
    "            privacy_acc_dyn = (self.adv_accuracy(self.priv_adv, d, adv_priv_y))\n",
    "            privacy_acc_stat = (self.adv_accuracy(self.priv_adv, s, adv_priv_y))\n",
    "            if verbose: print('Privacy Accuracy Dynamic: ', privacy_acc_dyn.item(), '\\tPrivacy Accuracy Static: ', privacy_acc_stat.item())\n",
    "            \n",
    "            # latent utility loss (adversarial)\n",
    "            adv_util_y = actions - 1\n",
    "            adv_util_y = torch.eye(utility_classes)[adv_util_y.long()].to(device)\n",
    "            utility_loss_dyn = (self.adv_loss(self.util_adv, d, adv_util_y))\n",
    "            utility_loss_stat = -(self.adv_loss(self.util_adv, s, adv_util_y))\n",
    "            utility_loss = utility_loss_dyn + utility_loss_stat\n",
    "            if verbose: print('Utility Loss Dynamic: ', utility_loss_dyn.item(), '\\tUtility Loss Static: ', utility_loss_stat.item(), '\\tUtility Loss: ', utility_loss.item())\n",
    "\n",
    "            utility_acc_dyn = (self.adv_accuracy(self.util_adv, d, adv_util_y))\n",
    "            utility_acc_stat = (self.adv_accuracy(self.util_adv, s, adv_util_y))\n",
    "            if verbose: print('Utility Accuracy Dynamic: ', utility_acc_dyn.item(), '\\tUtility Accuracy Static: ', utility_acc_stat.item())\n",
    "\n",
    "        if self.use_adv and discrim_adv:\n",
    "            # discrimnator (adversarial)\n",
    "            discrim_out_fake = self.discriminator(x_hat)\n",
    "            discriminator_loss = self.bce_loss(discrim_out_fake, torch.ones_like(discrim_out_fake))\n",
    "            discriminator_acc = torch.sum(torch.round(discrim_out_fake) == 0).float() / (batch_size)\n",
    "            if verbose: print('Discriminator Loss: ', discriminator_loss.item(), '\\tDiscriminator Accuracy: ', discriminator_acc.item())\n",
    "\n",
    "        losses = {\n",
    "            'rec_loss': rec_loss.item(),\n",
    "            'end_effector_loss': end_effector_loss.item(),\n",
    "            'triplet_loss': triplet_loss.item(),\n",
    "            'privacy_loss': privacy_loss.item(),\n",
    "            'privacy_loss_dyn': privacy_loss_dyn.item(),\n",
    "            'privacy_loss_stat': privacy_loss_stat.item(),\n",
    "            'privacy_acc_dyn': privacy_acc_dyn.item(),\n",
    "            'privacy_acc_stat': privacy_acc_stat.item(),\n",
    "            'utility_loss': utility_loss.item(),\n",
    "            'utility_loss_dyn': utility_loss_dyn.item(),\n",
    "            'utility_loss_stat': utility_loss_stat.item(),\n",
    "            'utility_acc_dyn': utility_acc_dyn.item(),\n",
    "            'utility_acc_stat': utility_acc_stat.item(),\n",
    "            'discriminator_loss': discriminator_loss.item(),\n",
    "            'discriminator_acc': discriminator_acc.item()\n",
    "        }\n",
    "\n",
    "        return rec_loss * self.lambda_rec \\\n",
    "                + end_effector_loss * self.lambda_ee \\\n",
    "                + triplet_loss * self.lambda_trip \\\n",
    "                + privacy_loss * self.lambda_adv_priv \\\n",
    "                + utility_loss * self.lambda_adv_util \\\n",
    "                + discriminator_loss * self.lambda_adv_disc, \\\n",
    "                x_hat, losses\n",
    "\n",
    "    def reconstruction_loss(self, x, y):\n",
    "        # return torch.square(torch.norm(x - y, dim=1)).mean()\n",
    "        return F.mse_loss(x, y)\n",
    "    \n",
    "    def cross_loss(self, x1, x2, y1, y2):\n",
    "        # return torch.square(torch.norm(x1 - y2, dim=1)).mean() + torch.square(torch.norm(x2 - y1, dim=1)).mean()\n",
    "        return F.mse_loss(x1, y1) + F.mse_loss(x2, y2)\n",
    "    \n",
    "    def latent_consistency_loss(self, x, y):\n",
    "        return F.mse_loss(x, y)\n",
    "    \n",
    "    def end_effector_loss(self, x, y):\n",
    "        # slice to get the end effector joints\n",
    "        x_ee = x[:, :, self.end_effectors.unsqueeze(-1) + torch.arange(3).to(device)] \n",
    "        y_ee = y[:, :, self.end_effectors.unsqueeze(-1) + torch.arange(3).to(device)]\n",
    "\n",
    "        # calculate velocities\n",
    "        x_vel = torch.norm(x_ee[:, 1:] - x_ee[:, :-1], dim=-1) / self.chain_lengths.unsqueeze(0)\n",
    "        y_vel = torch.norm(y_ee[:, 1:] - y_ee[:, :-1], dim=-1) / self.chain_lengths.unsqueeze(0)\n",
    "        \n",
    "        # compute mse loss for each joint\n",
    "        losses = F.mse_loss(x_vel, y_vel, reduction='none')\n",
    "\n",
    "        # take sum over end effectors\n",
    "        loss = losses.sum(dim=1)\n",
    "\n",
    "        # take mean over batch\n",
    "        loss = loss.mean()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def adv_loss(self, model, x, y):\n",
    "        return F.cross_entropy(model(x), y)\n",
    "    \n",
    "    def adv_accuracy(self, model, x, y):\n",
    "        return (model(x).argmax(dim=1) == y.argmax(dim=1)).float().mean()\n",
    "\n",
    "    def train_adv_paired(self, x1, x1_rot, x2, x2_rot, y1, y1_rot, y2, y2_rot, actors, actions, train_emb = True, train_discrim = True):\n",
    "        if not self.use_adv: return 0,0\n",
    "        # freeze encoders/decoder\n",
    "        self.dynamic_encoder.eval()\n",
    "        self.static_encoder.eval()\n",
    "        self.decoder.eval()\n",
    "\n",
    "        # unfreeze adversaries\n",
    "        self.priv_adv.train()\n",
    "        self.util_adv.train()\n",
    "        self.discriminator.train()\n",
    "\n",
    "        # zero out gradients\n",
    "        self.priv_optim.zero_grad()\n",
    "        self.util_optim.zero_grad()\n",
    "        self.discriminator_optim.zero_grad()\n",
    "\n",
    "        # encode\n",
    "        d1 = self.dynamic_encoder(x1_rot)\n",
    "        d2 = self.dynamic_encoder(x2_rot)\n",
    "        d3 = self.dynamic_encoder(y1_rot)\n",
    "        d4 = self.dynamic_encoder(y2_rot)\n",
    "        s1 = self.static_encoder(x1)\n",
    "        s2 = self.static_encoder(x2)\n",
    "        s3 = self.static_encoder(y1)\n",
    "        s4 = self.static_encoder(y2)\n",
    "\n",
    "        # decode\n",
    "        x1_hat = self.decoder(torch.cat((d1, s1), dim=1))\n",
    "        x2_hat = self.decoder(torch.cat((d2, s2), dim=1))\n",
    "        y1_hat = self.decoder(torch.cat((d3, s3), dim=1))\n",
    "        y2_hat = self.decoder(torch.cat((d4, s4), dim=1))\n",
    "\n",
    "        # instantiate losses\n",
    "        priv_loss = torch.zeros(1).to(device)\n",
    "        util_loss = torch.zeros(1).to(device)\n",
    "        discriminator_loss = torch.zeros(1).to(device)\n",
    "\n",
    "        if train_emb:\n",
    "            # train privacy adversary\n",
    "            p1, p2 = actors[0] - 1, actors[1] - 1\n",
    "            p1, p2 = torch.eye(privacy_classes)[p1.long()].to(device), torch.eye(privacy_classes)[p2.long()].to(device)\n",
    "            priv_loss = F.cross_entropy(self.priv_adv(s1), p1) + F.cross_entropy(self.priv_adv(s2), p2) + F.cross_entropy(self.priv_adv(s3), p2) + F.cross_entropy(self.priv_adv(s4), p1)\n",
    "            priv_loss.backward(retain_graph=True)\n",
    "            self.priv_optim.step()\n",
    "            \n",
    "            # train utility adversary\n",
    "            a1, a2 = actions[0] - 1, actions[1] - 1\n",
    "            a1, a2 = torch.eye(utility_classes)[a1.long()].to(device), torch.eye(utility_classes)[a2.long()].to(device)\n",
    "            util_loss = F.cross_entropy(self.util_adv(d1), a1) + F.cross_entropy(self.util_adv(d2), a2) + F.cross_entropy(self.util_adv(d3), a1) + F.cross_entropy(self.util_adv(d4), a2)\n",
    "            util_loss.backward(retain_graph=True)\n",
    "            self.util_optim.step()\n",
    "\n",
    "        if train_discrim:\n",
    "            # train discriminator\n",
    "            output_real = self.discriminator(torch.cat((x1.view(x1.size(0), T, -1), x2.view(x2.size(0), T, -1), y1.view(y1.size(0), T, -1), y2.view(y1.size(0), T, -1))))\n",
    "            output_fake = self.discriminator(torch.cat((x1_hat, x2_hat, y1_hat, y2_hat)))\n",
    "            discriminator_loss = self.bce_loss(output_real, torch.ones_like(output_real)) + self.bce_loss(output_fake, torch.zeros_like(output_fake))\n",
    "            discriminator_loss.backward()\n",
    "            self.discriminator_optim.step()\n",
    "\n",
    "        # unfreeze encoders/decoder\n",
    "        self.dynamic_encoder.train()\n",
    "        self.static_encoder.train()\n",
    "        self.decoder.train()\n",
    "\n",
    "        # freeze adversaries\n",
    "        self.priv_adv.eval()\n",
    "        self.util_adv.eval()\n",
    "        self.discriminator.eval()\n",
    "\n",
    "        return priv_loss.item(), util_loss.item(), discriminator_loss.item()\n",
    "\n",
    "    def train_adv_unpaired(self, x_pos, x_rot, actor, action, train_emb = True, train_discrim = True):\n",
    "        # ensure one training method is enabled\n",
    "        assert train_emb or train_discrim, 'At least one training method must be enabled'\n",
    "\n",
    "        # freeze encoders/decoder\n",
    "        self.dynamic_encoder.eval()\n",
    "        self.static_encoder.eval()\n",
    "        self.decoder.eval()\n",
    "\n",
    "        # unfreeze adversaries\n",
    "        self.priv_adv.train()\n",
    "        self.util_adv.train()\n",
    "        self.discriminator.train()\n",
    "\n",
    "        # zero out gradients\n",
    "        self.priv_optim.zero_grad()\n",
    "        self.util_optim.zero_grad()\n",
    "        self.discriminator_optim.zero_grad()\n",
    "\n",
    "        # encode\n",
    "        d = self.dynamic_encoder(x_rot)\n",
    "        s = self.static_encoder(x_pos)\n",
    "\n",
    "        # decode\n",
    "        x_hat = self.decoder(torch.cat((d, s), dim=1))\n",
    "\n",
    "        # instantiate losses\n",
    "        priv_loss = torch.zeros(1).to(device)\n",
    "        util_loss = torch.zeros(1).to(device)\n",
    "        discriminator_loss = torch.zeros(1).to(device)\n",
    "\n",
    "        if train_emb:\n",
    "            # train privacy adversary\n",
    "            p = actor - 1\n",
    "            p = torch.eye(privacy_classes)[p.long()].to(device)\n",
    "            priv_loss = F.cross_entropy(self.priv_adv(s), p)\n",
    "            priv_loss.backward(retain_graph=True)\n",
    "            self.priv_optim.step()\n",
    "            \n",
    "            # train utility adversary\n",
    "            a = action - 1\n",
    "            a = torch.eye(utility_classes)[a.long()].to(device)\n",
    "            util_loss = F.cross_entropy(self.util_adv(d), a)\n",
    "            util_loss.backward(retain_graph=True)\n",
    "            self.util_optim.step()\n",
    "\n",
    "        if train_discrim:\n",
    "            # train discriminator\n",
    "            output_real = self.discriminator(x_pos.reshape(x_pos.size(0), T, -1))\n",
    "            output_fake = self.discriminator(x_hat)\n",
    "            discriminator_loss = self.bce_loss(output_real, torch.ones_like(output_real)) + self.bce_loss(output_fake, torch.zeros_like(output_fake))\n",
    "            discriminator_loss.backward()\n",
    "            self.discriminator_optim.step()\n",
    "\n",
    "        # unfreeze encoders/decoder\n",
    "        self.dynamic_encoder.train()\n",
    "        self.static_encoder.train()\n",
    "        self.decoder.train()\n",
    "\n",
    "        # freeze adversaries\n",
    "        self.priv_adv.eval()\n",
    "        self.util_adv.eval()\n",
    "        self.discriminator.eval()\n",
    "\n",
    "        return priv_loss.item(), util_loss.item(), discriminator_loss.item()\n",
    "\n",
    "    def forward(self, x, x_rot):\n",
    "        dyn = self.dynamic_encoder(x_rot)\n",
    "        sta = self.static_encoder(x)\n",
    "        x = self.decoder(torch.cat((dyn, sta), dim=1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility/Privacy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, k=3):\n",
    "    acces = AverageMeter()\n",
    "    topk_acces = AverageMeter()\n",
    "    # load learnt model that obtained best performance on validation set\n",
    "    model.eval()\n",
    "\n",
    "    label_output = list()\n",
    "    pred_output = list()\n",
    "\n",
    "    for i, t in enumerate(test_loader):\n",
    "        inputs = t[0]\n",
    "        target = t[1]\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs.cuda())\n",
    "            output = output.view(\n",
    "                (-1, inputs.size(0)//target.size(0), output.size(1)))\n",
    "            output = output.mean(1)\n",
    "\n",
    "        label_output.append(target.cpu().numpy())\n",
    "        pred_output.append(output.cpu().numpy())\n",
    "\n",
    "        acc = accuracy(output.data, target.cuda())\n",
    "        acces.update(acc[0], inputs.size(0))\n",
    "        topk_acc = top_k_accuracy(output.data, target.cuda(), k=3)\n",
    "        topk_acces.update(topk_acc[0], inputs.size(0))\n",
    "\n",
    "    label_output = np.concatenate(label_output, axis=0)\n",
    "    pred_output = np.concatenate(pred_output, axis=0)\n",
    "\n",
    "    label_index = np.argmax(label_output, axis=1)\n",
    "    pred_index = np.argmax(pred_output, axis=1)\n",
    "\n",
    "    f1 = f1_score(label_index, pred_index, average='macro', zero_division=0)\n",
    "    precision = precision_score(label_index, pred_index, average='macro', zero_division=0)\n",
    "    recall = recall_score(label_index, pred_index, average='macro', zero_division=0)\n",
    "\n",
    "    return acces.avg, f1, precision, recall, topk_acces.avg\n",
    "    \n",
    "def accuracy(output, target):\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    target = torch.argmax(target, dim=1)  # Add this line to convert one-hot targets to class indices\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    correct = correct.view(-1).float().sum(0, keepdim=True)\n",
    "    return correct.mul_(100.0 / batch_size)\n",
    "\n",
    "def top_k_accuracy(output, target, k=3):\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(k, 1, True, True) \n",
    "    pred = pred.t()\n",
    "    target = torch.argmax(target, dim=1) \n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "    return correct_k.mul_(100.0 / batch_size)\n",
    "    \n",
    "def run_sgn_eval(train_x, train_y, test_x, test_y, val_x, val_y, case, model, k=3):\n",
    "    # Data loading\n",
    "    ntu_loaders = NTUDataLoaders(dataset, case, seg=20, train_X=train_x, train_Y=train_y, test_X=test_x, test_Y=test_y, val_X=val_x, val_Y=val_y, aug=0)\n",
    "    test_loader = ntu_loaders.get_test_loader(batch_size, 16)\n",
    "\n",
    "    # Test\n",
    "    return test(test_loader, model, k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = True\n",
    "if load_model:\n",
    "    # model.load_state_dict(torch.load('pretrained/MR.pt'))\n",
    "    model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_util = True\n",
    "train_util = False\n",
    "sgn_ar = SGN(utility_classes, None, seg, batch_size, 0).to(device)\n",
    "sgn_priv = SGN(privacy_classes, None, seg, batch_size, 0).to(device)\n",
    "\n",
    "if load_util:\n",
    "    if ntu_120:\n",
    "        sgn_priv.load_state_dict(torch.load('SGN/pretrained/privacy.pt')['state_dict'])\n",
    "        sgn_ar.load_state_dict(torch.load('SGN/pretrained/action.pt')['state_dict'])\n",
    "    else:\n",
    "        sgn_priv.load_state_dict(torch.load('SGN/pretrained/privacy_60.pt')['state_dict'])\n",
    "        sgn_ar.load_state_dict(torch.load('SGN/pretrained/action_60.pt')['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Motion Retargeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgn_train_x, sgn_train_y, sgn_val_x, sgn_val_y = np.zeros((batch_size, 300, 150)), np.zeros((batch_size, 1)), np.zeros((batch_size, 300, 150)), np.zeros((batch_size, 1))\n",
    "\n",
    "best_loss = float('inf')\n",
    "total_epochs = -1\n",
    "cur_tot_epoch = 0\n",
    "\n",
    "def train_paired(epoch, train_ae = True, train_cross = True, train_discrim = True, train_emb_adv = True, run_eval = True, use_emb_adv = True, use_discrim_adv = True, run_sgn_eval = False, save = True, k=3):\n",
    "    global best_loss\n",
    "    global total_epochs\n",
    "    global cur_tot_epoch\n",
    "    # Assertions\n",
    "    assert train_ae or train_cross or train_discrim or train_emb_adv, \"At least one of the training objectives must be True\"\n",
    "    assert not (run_sgn_eval and not run_eval), \"If run_sgn_eval is True, then run_eval must be True\"\n",
    "    \n",
    "    # Store eval values for validation\n",
    "    eval_X_known, eval_Y_known_action, eval_Y_known_actor, eval_X_rec, eval_Y_rec_action, eval_Y_rec_actor, eval_X, eval_Y_action, eval_Y_actor = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "    # Losses for printing\n",
    "    losses = []\n",
    "    rec_loss, cross_loss, end_effector_loss, triplet_loss, latent_consistency_loss, privacy_loss, privacy_loss_dyn, privacy_loss_stat, privacy_acc_dyn, privacy_acc_stat, priv_training_loss, utility_loss, utility_loss_dyn, utility_loss_stat, utility_acc_dyn, utility_acc_stat, util_training_loss, discriminator_loss, discriminator_train_losses, discriminator_training_acc = [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "    for (x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot, actors, actions) in train_dl:\n",
    "        # Move tensors to the configured device\n",
    "        x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot = x1_pos.float().to(device), x1_rot.float().to(device), x2_pos.float().to(device), x2_rot.float().to(device), y1_pos.float().to(device), y1_rot.float().to(device), y2_pos.float().to(device), y2_rot.float().to(device)\n",
    "        \n",
    "        # For 1D convolutions, flatten the data\n",
    "        if one_dimension_conv:\n",
    "            x1_pos = x1_pos.view(x1_pos.size(0), T, -1)\n",
    "            x1_rot = x1_rot.view(x1_rot.size(0), T, -1)\n",
    "            x2_pos = x2_pos.view(x2_pos.size(0), T, -1)\n",
    "            x2_rot = x2_rot.view(x2_rot.size(0), T, -1)\n",
    "            y1_pos = y1_pos.view(y1_pos.size(0), T, -1)\n",
    "            y1_rot = y1_rot.view(y1_rot.size(0), T, -1)\n",
    "            y2_pos = y2_pos.view(y2_pos.size(0), T, -1)\n",
    "            y2_rot = y2_rot.view(y2_rot.size(0), T, -1)\n",
    "\n",
    "        \n",
    "        if train_discrim or train_emb_adv:\n",
    "            # Train the discriminator\n",
    "            priv_train_loss, util_train_loss, discriminator_train_loss = model.train_adv_paired(x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot, actors, actions, train_emb=train_emb_adv, train_discrim=train_discrim)\n",
    "            \n",
    "            # Track the loss\n",
    "            priv_training_loss.append(priv_train_loss)\n",
    "            util_training_loss.append(util_train_loss)\n",
    "            discriminator_train_losses.append(discriminator_train_loss)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Train the autoencoder/cross reconstruction\n",
    "        if train_ae or train_cross:\n",
    "            # Forward pass\n",
    "            loss, _, _, _, _, losses_ = model.loss_paired(x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot, actors, actions, cross=train_cross, reconstruction=train_ae, emb_adv=use_emb_adv, discrim_adv=use_discrim_adv)\n",
    "\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track the loss\n",
    "            losses.append(loss.item())\n",
    "            rec_loss.append(losses_['rec_loss'])\n",
    "            cross_loss.append(losses_['cross_loss'])\n",
    "            end_effector_loss.append(losses_['end_effector_loss'])\n",
    "            latent_consistency_loss.append(losses_['latent_consistency_loss'])\n",
    "            # triplet_loss.append(losses_['triplet_loss'])\n",
    "            privacy_loss.append(losses_['privacy_loss'])\n",
    "            privacy_loss_dyn.append(losses_['privacy_loss_dyn'])\n",
    "            privacy_loss_stat.append(losses_['privacy_loss_stat'])\n",
    "            privacy_acc_dyn.append(losses_['privacy_acc_dyn'])\n",
    "            privacy_acc_stat.append(losses_['privacy_acc_stat'])\n",
    "            utility_loss.append(losses_['utility_loss'])\n",
    "            utility_loss_dyn.append(losses_['utility_loss_dyn'])\n",
    "            utility_loss_stat.append(losses_['utility_loss_stat'])\n",
    "            utility_acc_dyn.append(losses_['utility_acc_dyn'])\n",
    "            utility_acc_stat.append(losses_['utility_acc_stat'])\n",
    "            discriminator_loss.append(losses_['discriminator_loss'])\n",
    "            discriminator_training_acc.append(losses_['discriminator_acc'])\n",
    "        \n",
    "    # Decay learning rate (disabled for training stages)\n",
    "    # scheduler.step() \n",
    "\n",
    "    # Validation\n",
    "    if run_eval:\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "            val_rec_loss, val_cross_loss, val_end_effector_loss, val_triplet_loss, val_latent_consistency_loss, val_privacy_loss, val_privacy_loss_dyn, val_privacy_loss_stat, val_privacy_acc_dyn, val_privacy_acc_stat, val_utility_loss, val_utility_loss_dyn, val_utility_loss_stat, val_utility_acc_dyn, val_utility_acc_stat, val_discriminator_loss, val_discriminator_acc = [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "            \n",
    "            for (x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot, actors, actions) in val_dl:\n",
    "                x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot = x1_pos.float().to(device), x1_rot.float().to(device), x2_pos.float().to(device), x2_rot.float().to(device), y1_pos.float().to(device), y1_rot.float().to(device), y2_pos.float().to(device), y2_rot.float().to(device)\n",
    "\n",
    "                # For 1D convolutions, flatten the data\n",
    "                if one_dimension_conv:\n",
    "                    x1_pos = x1_pos.view(x1_pos.size(0), T, -1)\n",
    "                    x1_rot = x1_rot.view(x1_rot.size(0), T, -1)\n",
    "                    x2_pos = x2_pos.view(x2_pos.size(0), T, -1)\n",
    "                    x2_rot = x2_rot.view(x2_rot.size(0), T, -1)\n",
    "                    y1_pos = y1_pos.view(y1_pos.size(0), T, -1)\n",
    "                    y1_rot = y1_rot.view(y1_rot.size(0), T, -1)\n",
    "                    y2_pos = y2_pos.view(y2_pos.size(0), T, -1)\n",
    "                    y2_rot = y2_rot.view(y2_rot.size(0), T, -1)\n",
    "                \n",
    "                loss, x1_hat, x2_hat, y1_hat, y2_hat, losses_ = model.loss_paired(x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot, actors, actions, cross=train_cross, reconstruction=train_ae, emb_adv=use_emb_adv, discrim_adv=use_discrim_adv)\n",
    "                val_losses.append(loss.item())\n",
    "                val_rec_loss.append(losses_['rec_loss'])\n",
    "                val_cross_loss.append(losses_['cross_loss'])\n",
    "                val_end_effector_loss.append(losses_['end_effector_loss'])\n",
    "                # val_triplet_loss.append(losses_['triplet_loss'])\n",
    "                val_latent_consistency_loss.append(losses_['latent_consistency_loss'])\n",
    "                val_privacy_loss.append(losses_['privacy_loss'])\n",
    "                val_privacy_loss_dyn.append(losses_['privacy_loss_dyn'])\n",
    "                val_privacy_loss_stat.append(losses_['privacy_loss_stat'])\n",
    "                val_privacy_acc_dyn.append(losses_['privacy_acc_dyn'])\n",
    "                val_privacy_acc_stat.append(losses_['privacy_acc_stat'])\n",
    "                val_utility_loss.append(losses_['utility_loss'])\n",
    "                val_utility_loss_dyn.append(losses_['utility_loss_dyn'])\n",
    "                val_utility_loss_stat.append(losses_['utility_loss_stat'])\n",
    "                val_utility_acc_dyn.append(losses_['utility_acc_dyn'])\n",
    "                val_utility_acc_stat.append(losses_['utility_acc_stat'])\n",
    "                val_discriminator_loss.append(losses_['discriminator_loss'])\n",
    "                val_discriminator_acc.append(losses_['discriminator_acc'])\n",
    "\n",
    "                if run_sgn_eval:\n",
    "                    if not one_dimension_conv:\n",
    "                        x1_pos = x1_pos.view(x1_pos.size(0), T, -1)\n",
    "                        x2_pos = x2_pos.view(x2_pos.size(0), T, -1)\n",
    "                        y1_pos = y1_pos.view(y1_pos.size(0), T, -1)\n",
    "                        y2_pos = y2_pos.view(y2_pos.size(0), T, -1)\n",
    "                        \n",
    "                    eval_X_known.append(x1_pos.cpu().numpy())\n",
    "                    eval_X_known.append(x2_pos.cpu().numpy())\n",
    "                    eval_X_known.append(y1_pos.cpu().numpy())\n",
    "                    eval_X_known.append(y2_pos.cpu().numpy())\n",
    "\n",
    "                    eval_Y_known_action.append(actions[0].cpu().numpy())\n",
    "                    eval_Y_known_action.append(actions[1].cpu().numpy())\n",
    "                    eval_Y_known_action.append(actions[0].cpu().numpy())\n",
    "                    eval_Y_known_action.append(actions[1].cpu().numpy())\n",
    "\n",
    "                    eval_Y_known_actor.append(actors[0].cpu().numpy())\n",
    "                    eval_Y_known_actor.append(actors[1].cpu().numpy())\n",
    "                    eval_Y_known_actor.append(actors[1].cpu().numpy())\n",
    "                    eval_Y_known_actor.append(actors[0].cpu().numpy())\n",
    "\n",
    "                    eval_X_rec.append(x1_hat.cpu().numpy())\n",
    "                    eval_X_rec.append(x2_hat.cpu().numpy())\n",
    "                    eval_X.append(y1_hat.cpu().numpy())\n",
    "                    eval_X.append(y2_hat.cpu().numpy())\n",
    "\n",
    "                    eval_Y_rec_action.append(actions[0].cpu().numpy())\n",
    "                    eval_Y_rec_action.append(actions[1].cpu().numpy())\n",
    "                    eval_Y_action.append(actions[0].cpu().numpy())\n",
    "                    eval_Y_action.append(actions[1].cpu().numpy())\n",
    "\n",
    "                    eval_Y_rec_actor.append(actors[0].cpu().numpy())\n",
    "                    eval_Y_rec_actor.append(actors[1].cpu().numpy())\n",
    "                    eval_Y_actor.append(actors[1].cpu().numpy())\n",
    "                    eval_Y_actor.append(actors[0].cpu().numpy())\n",
    "\n",
    "    # Print loss/accuracy\n",
    "    print(f'--------------------\\nEpoch {cur_tot_epoch+1}/{total_epochs}\\n--------------------')\n",
    "    cur_tot_epoch += 1\n",
    "    \n",
    "    if train_ae or train_cross:\n",
    "        print(f'Training Loss:\\t\\t\\t{np.mean(losses)}\\nValidation Loss:\\t\\t{np.mean(val_losses)}')\n",
    "        print('\\nTraining Losses:')\n",
    "        print(f'Reconstruction Loss:\\t\\t{np.mean(rec_loss)}\\nCross Reconstruction Loss:\\t{np.mean(cross_loss)}\\nEnd Effector Loss:\\t\\t{np.mean(end_effector_loss)}\\nTriplet Loss:\\t\\t\\t{np.mean(triplet_loss)}\\nLatent Consistency Loss:\\t{np.mean(latent_consistency_loss)}')\n",
    "        print(f'Privacy Loss:\\t\\t\\t{np.mean(privacy_loss)}\\nPrivacy Loss Dyn:\\t\\t{np.mean(privacy_loss_dyn)}\\nPrivacy Loss Stat:\\t\\t{np.mean(privacy_loss_stat)}')\n",
    "        print(f'Utility Loss:\\t\\t\\t{np.mean(utility_loss)}\\nUtility Loss Dyn:\\t\\t{np.mean(utility_loss_dyn)}\\nUtility Loss Stat:\\t\\t{np.mean(utility_loss_stat)}')\n",
    "        print(f'Discriminator Loss:\\t\\t{np.mean(discriminator_loss)}')\n",
    "\n",
    "    if run_eval:\n",
    "        print('\\nValidation Losses:')\n",
    "        print(f'Val Reconstruction Loss:\\t{np.mean(val_rec_loss)}\\nVal Cross Reconstruction Loss:\\t{np.mean(val_cross_loss)}\\nVal End Effector Loss:\\t\\t{np.mean(val_end_effector_loss)}\\nVal Triplet Loss:\\t\\t{np.mean(val_triplet_loss)}\\nVal Latent Consistency Loss:\\t{np.mean(val_latent_consistency_loss)}')\n",
    "        print(f'Val Privacy Loss:\\t\\t{np.mean(val_privacy_loss)}\\nVal Privacy Loss Dyn:\\t\\t{np.mean(val_privacy_loss_dyn)}\\nVal Privacy Loss Stat:\\t\\t{np.mean(val_privacy_loss_stat)}')\n",
    "        print(f'Val Utility Loss:\\t\\t{np.mean(val_utility_loss)}\\nVal Utility Loss Dyn:\\t\\t{np.mean(val_utility_loss_dyn)}\\nVal Utility Loss Stat:\\t\\t{np.mean(val_utility_loss_stat)}')\n",
    "        print(f'Val Discriminator Loss:\\t\\t{np.mean(val_discriminator_loss)}')\n",
    "    \n",
    "    if train_emb_adv or train_discrim:\n",
    "        print('\\nAdversary Losses')\n",
    "        if train_emb_adv:\n",
    "            print(f'Privacy Training Loss:\\t\\t{np.mean(priv_training_loss)}\\nUtility Training Loss:\\t\\t{np.mean(util_training_loss)}\\nDiscriminator Training Loss:\\t{np.mean(discriminator_train_losses)}')\n",
    "            if train_ae or train_cross:\n",
    "                print(f'Privacy Acc Dyn:\\t\\t{np.mean(privacy_acc_dyn)}\\nPrivacy Acc Stat:\\t\\t{np.mean(privacy_acc_stat)}')\n",
    "                print(f'Utility Acc Dyn:\\t\\t{np.mean(utility_acc_dyn)}\\nUtility Acc Stat:\\t\\t{np.mean(utility_acc_stat)}')\n",
    "            print(f'Val Privacy Acc Dyn:\\t\\t{np.mean(val_privacy_acc_dyn)}\\nVal Privacy Acc Stat:\\t\\t{np.mean(val_privacy_acc_stat)}')\n",
    "            print(f'Val Utility Acc Dyn:\\t\\t{np.mean(val_utility_acc_dyn)}\\nVal Utility Acc Stat:\\t\\t{np.mean(val_utility_acc_stat)}')\n",
    "    \n",
    "    if train_ae or train_cross: print(f'Discriminator Acc:\\t\\t{np.mean(discriminator_training_acc)}')\n",
    "    if run_eval: print(f'Val Discriminator Acc:\\t\\t{np.mean(val_discriminator_acc)}')\n",
    "\n",
    "    # Save model\n",
    "    if save and np.mean(val_losses) < best_loss:\n",
    "        best_loss = np.mean(val_losses)\n",
    "        torch.save(model.state_dict(), 'pretrained/MR.pt')\n",
    "\n",
    "    # Test Accuracy\n",
    "    if run_sgn_eval and run_eval:\n",
    "        print('\\n')\n",
    "        sgn_acc_known_acc, sgn_acc_known_f1, sgn_acc_known_prec, sgn_acc_known_recall, sgn_acc_known_topk = sgn_eval(eval_X_known, eval_Y_known_action, 'Known Action', is_action=True, k=k)\n",
    "        sgn_acc_rec_acc, sgn_acc_rec_f1, sgn_acc_rec_prec, sgn_acc_rec_recall, sgn_acc_rec_topk = sgn_eval(eval_X_rec, eval_Y_rec_action, 'Reconstructed Action', is_action=True, k=k)\n",
    "        sgn_acc_cross_acc, sgn_acc_cross_f1, sgn_acc_cross_prec, sgn_acc_cross_recall, sgn_acc_cross_topk = sgn_eval(eval_X, eval_Y_action, 'Generated Action', is_action=True, k=k)\n",
    "        print('\\n')\n",
    "        sgn_priv_known_acc, sgn_priv_known_f1, sgn_priv_known_prec, sgn_priv_known_recall, sgn_priv_known_topk = sgn_eval(eval_X_known, eval_Y_known_actor, 'Known Actor', is_actor=True, k=k)\n",
    "        sgn_priv_rec_acc, sgn_priv_rec_f1, sgn_priv_rec_prec, sgn_priv_rec_recall, sgn_priv_rec_topk = sgn_eval(eval_X_rec, eval_Y_rec_actor, 'Reconstructed Actor', is_actor=True, k=k)\n",
    "        sgn_priv_cross_acc, sgn_priv_cross_f1, sgn_priv_cross_prec, sgn_priv_cross_recall, sgn_priv_cross_topk = sgn_eval(eval_X, eval_Y_actor, 'Generated Actor', is_actor=True, k=k)\n",
    "    else: print('\\n')\n",
    "\n",
    "    # Return dict with all losses and accuracies for plotting\n",
    "    losses_dict = {}\n",
    "    if train_ae or train_cross:\n",
    "        losses_dict['loss'] = np.mean(losses)\n",
    "        losses_dict['val_loss'] = np.mean(val_losses)\n",
    "        losses_dict['rec_loss'] = np.mean(rec_loss)\n",
    "        losses_dict['cross_loss'] = np.mean(cross_loss)\n",
    "        losses_dict['end_effector_loss'] = np.mean(end_effector_loss)\n",
    "        losses_dict['triplet_loss'] = np.mean(triplet_loss)\n",
    "        losses_dict['latent_consistency_loss'] = np.mean(latent_consistency_loss)\n",
    "        losses_dict['privacy_loss'] = np.mean(privacy_loss)\n",
    "        losses_dict['privacy_loss_dyn'] = np.mean(privacy_loss_dyn)\n",
    "        losses_dict['privacy_loss_stat'] = np.mean(privacy_loss_stat)\n",
    "        losses_dict['utility_loss'] = np.mean(utility_loss)\n",
    "        losses_dict['utility_loss_dyn'] = np.mean(utility_loss_dyn)\n",
    "        losses_dict['utility_loss_stat'] = np.mean(utility_loss_stat)\n",
    "        losses_dict['discriminator_loss'] = np.mean(discriminator_loss)\n",
    "    if run_eval:\n",
    "        losses_dict['val_rec_loss'] = np.mean(val_rec_loss)\n",
    "        losses_dict['val_cross_loss'] = np.mean(val_cross_loss)\n",
    "        losses_dict['val_end_effector_loss'] = np.mean(val_end_effector_loss)\n",
    "        losses_dict['val_triplet_loss'] = np.mean(val_triplet_loss)\n",
    "        losses_dict['val_latent_consistency_loss'] = np.mean(val_latent_consistency_loss)\n",
    "        losses_dict['val_privacy_loss'] = np.mean(val_privacy_loss)\n",
    "        losses_dict['val_privacy_loss_dyn'] = np.mean(val_privacy_loss_dyn)\n",
    "        losses_dict['val_privacy_loss_stat'] = np.mean(val_privacy_loss_stat)\n",
    "        losses_dict['val_utility_loss'] = np.mean(val_utility_loss)\n",
    "        losses_dict['val_utility_loss_dyn'] = np.mean(val_utility_loss_dyn)\n",
    "        losses_dict['val_utility_loss_stat'] = np.mean(val_utility_loss_stat)\n",
    "        losses_dict['val_discriminator_loss'] = np.mean(val_discriminator_loss)\n",
    "    if train_emb_adv or train_discrim:\n",
    "        losses_dict['priv_training_loss'] = np.mean(priv_training_loss)\n",
    "        losses_dict['util_training_loss'] = np.mean(util_training_loss)\n",
    "        losses_dict['discriminator_train_loss'] = np.mean(discriminator_train_losses)\n",
    "        if train_ae or train_cross:\n",
    "            losses_dict['privacy_acc_dyn'] = np.mean(privacy_acc_dyn)\n",
    "            losses_dict['privacy_acc_stat'] = np.mean(privacy_acc_stat)\n",
    "            losses_dict['utility_acc_dyn'] = np.mean(utility_acc_dyn)\n",
    "            losses_dict['utility_acc_stat'] = np.mean(utility_acc_stat)\n",
    "        losses_dict['val_privacy_acc_dyn'] = np.mean(val_privacy_acc_dyn)\n",
    "        losses_dict['val_privacy_acc_stat'] = np.mean(val_privacy_acc_stat)\n",
    "        losses_dict['val_utility_acc_dyn'] = np.mean(val_utility_acc_dyn)\n",
    "        losses_dict['val_utility_acc_stat'] = np.mean(val_utility_acc_stat)\n",
    "    if train_ae or train_cross:\n",
    "        losses_dict['discriminator_acc'] = np.mean(discriminator_training_acc)\n",
    "    if run_eval:\n",
    "        losses_dict['val_discriminator_acc'] = np.mean(val_discriminator_acc)\n",
    "    if run_sgn_eval and run_eval:\n",
    "        losses_dict['sgn_acc_known_acc'] = sgn_acc_known_acc\n",
    "        losses_dict['sgn_acc_known_f1'] = sgn_acc_known_f1\n",
    "        losses_dict['sgn_acc_known_prec'] = sgn_acc_known_prec\n",
    "        losses_dict['sgn_acc_known_recall'] = sgn_acc_known_recall\n",
    "        losses_dict['sgn_acc_rec_acc'] = sgn_acc_rec_acc\n",
    "        losses_dict['sgn_acc_rec_f1'] = sgn_acc_rec_f1\n",
    "        losses_dict['sgn_acc_rec_prec'] = sgn_acc_rec_prec\n",
    "        losses_dict['sgn_acc_rec_recall'] = sgn_acc_rec_recall\n",
    "        losses_dict['sgn_acc_cross_acc'] = sgn_acc_cross_acc\n",
    "        losses_dict['sgn_acc_cross_f1'] = sgn_acc_cross_f1\n",
    "        losses_dict['sgn_acc_cross_prec'] = sgn_acc_cross_prec\n",
    "        losses_dict['sgn_acc_cross_recall'] = sgn_acc_cross_recall\n",
    "        losses_dict['sgn_priv_known_acc'] = sgn_priv_known_acc\n",
    "        losses_dict['sgn_priv_known_f1'] = sgn_priv_known_f1\n",
    "        losses_dict['sgn_priv_known_prec'] = sgn_priv_known_prec\n",
    "        losses_dict['sgn_priv_known_recall'] = sgn_priv_known_recall\n",
    "        losses_dict['sgn_priv_rec_acc'] = sgn_priv_rec_acc\n",
    "        losses_dict['sgn_priv_rec_f1'] = sgn_priv_rec_f1\n",
    "        losses_dict['sgn_priv_rec_prec'] = sgn_priv_rec_prec\n",
    "        losses_dict['sgn_priv_rec_recall'] = sgn_priv_rec_recall\n",
    "        losses_dict['sgn_priv_cross_acc'] = sgn_priv_cross_acc\n",
    "        losses_dict['sgn_priv_cross_f1'] = sgn_priv_cross_f1\n",
    "        losses_dict['sgn_priv_cross_prec'] = sgn_priv_cross_prec\n",
    "        losses_dict['sgn_priv_cross_recall'] = sgn_priv_cross_recall\n",
    "        losses_dict['sgn_acc_known_topk'] = sgn_acc_known_topk\n",
    "        losses_dict['sgn_acc_rec_topk'] = sgn_acc_rec_topk\n",
    "        losses_dict['sgn_acc_cross_topk'] = sgn_acc_cross_topk\n",
    "        losses_dict['sgn_priv_known_topk'] = sgn_priv_known_topk\n",
    "        losses_dict['sgn_priv_rec_topk'] = sgn_priv_rec_topk\n",
    "        losses_dict['sgn_priv_cross_topk'] = sgn_priv_cross_topk\n",
    "    \n",
    "    return losses_dict\n",
    "\n",
    "\n",
    "def sgn_eval(X, Y, label='Undefined', is_actor=False, is_action=False, k=3):\n",
    "    assert is_actor != is_action, \"is_actor and is_action cannot both be True\"\n",
    "    assert is_actor or is_action, \"Either is_actor or is_action must be True\"\n",
    "\n",
    "    if is_actor:\n",
    "        classes = privacy_classes\n",
    "        sgn = sgn_priv\n",
    "    elif is_action:\n",
    "        classes = utility_classes\n",
    "        sgn = sgn_ar\n",
    "\n",
    "    X = np.concatenate(X)\n",
    "    X = np.pad(X, ((0,0), (0,225), (0,75)), 'constant')\n",
    "\n",
    "    Y = np.concatenate(Y) - 1\n",
    "    Y = np.eye(classes)[Y.astype(int)]\n",
    "\n",
    "    acc, f1, prec, recall, topk = run_sgn_eval(sgn_train_x, sgn_train_y, X, Y, sgn_val_x, sgn_val_y, 1, sgn, k=k)\n",
    "    print(f'\\n{label} Accuracy:\\t\\t{acc}\\n{label} F1:\\t\\t\\t{f1*100}\\n{label} Precision:\\t\\t{prec*100}\\n{label} Recall:\\t\\t{recall*100}\\n{label} Top-{k} Accuracy:\\t{topk}\\n')\n",
    "    return acc, f1, prec, recall, topk\n",
    "\n",
    "# Simplified training loop for only AE\n",
    "def train_unpaired(epoch, run_eval=True, run_sgn_eval=True, save=True, ae=True, ee=False, triplet=False, use_emb_adv=False, use_discrim_adv=False, emb_adv=False, discrim_adv=False, k=3):\n",
    "    global best_loss\n",
    "    global total_epochs\n",
    "\n",
    "    # Store eval values for validation\n",
    "    eval_X_known, eval_Y_known_action, eval_Y_known_actor, eval_X_rec, eval_Y_rec_action, eval_Y_rec_actor = [], [], [], [], [], []\n",
    "    \n",
    "    # Losses for printing\n",
    "    rec_loss, end_effector_loss, triplet_loss, privacy_loss, privacy_loss_dyn, privacy_loss_stat, privacy_acc_dyn, privacy_acc_stat, priv_training_loss, utility_loss, utility_loss_dyn, utility_loss_stat, utility_acc_dyn, utility_acc_stat, util_training_loss, discriminator_loss, discriminator_train_losses, discriminator_acc = [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "    val_rec_loss, val_end_effector_loss, val_triplet_loss, val_privacy_loss, val_privacy_loss_dyn, val_privacy_loss_stat, val_privacy_acc_dyn, val_privacy_acc_stat, val_utility_loss, val_utility_loss_dyn, val_utility_loss_stat, val_utility_acc_dyn, val_utility_acc_stat, val_discriminator_loss, val_discriminator_acc = [], [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "    losses, val_losses = [], []\n",
    "\n",
    "    for (x, actors, actions) in rec_train_dl:\n",
    "        # Move tensors to the configured device\n",
    "        x = x.float().to(device)\n",
    "\n",
    "        # Split into position and rotation\n",
    "        x_pos = x[:, :, :, :3]\n",
    "        x_rot = x[:, :, :, 3:]\n",
    "\n",
    "        # Train adversaries\n",
    "        if emb_adv or discrim_adv:\n",
    "            # Train the discriminator\n",
    "            priv_train_loss, util_train_loss, discriminator_train_loss = model.train_adv_unpaired(x_pos, x_rot, actors, actions, train_emb=emb_adv, train_discrim=discrim_adv)\n",
    "            \n",
    "            # Track the loss\n",
    "            priv_training_loss.append(priv_train_loss)\n",
    "            util_training_loss.append(util_train_loss)\n",
    "            discriminator_train_losses.append(discriminator_train_loss)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        loss, _, losses_ = model.loss_unpaired(x_pos, x_rot, actors, actions, reconstruction=ae, emb_adv=use_emb_adv, discrim_adv=use_discrim_adv, ee=ee, triplet=triplet)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        rec_loss.append(losses_['rec_loss'])\n",
    "        end_effector_loss.append(losses_['end_effector_loss'])\n",
    "        triplet_loss.append(losses_['triplet_loss'])\n",
    "        privacy_loss.append(losses_['privacy_loss'])\n",
    "        privacy_loss_dyn.append(losses_['privacy_loss_dyn'])\n",
    "        privacy_loss_stat.append(losses_['privacy_loss_stat'])\n",
    "        privacy_acc_dyn.append(losses_['privacy_acc_dyn'])\n",
    "        privacy_acc_stat.append(losses_['privacy_acc_stat'])\n",
    "        utility_loss.append(losses_['utility_loss'])\n",
    "        utility_loss_dyn.append(losses_['utility_loss_dyn'])\n",
    "        utility_loss_stat.append(losses_['utility_loss_stat'])\n",
    "        utility_acc_dyn.append(losses_['utility_acc_dyn'])\n",
    "        utility_acc_stat.append(losses_['utility_acc_stat'])\n",
    "        discriminator_loss.append(losses_['discriminator_loss'])\n",
    "        discriminator_acc.append(losses_['discriminator_acc'])\n",
    "\n",
    "\n",
    "    # Decay learning rate\n",
    "    # scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    if run_eval:\n",
    "        with torch.no_grad():\n",
    "            for (x, actors, actions) in rec_val_dl:\n",
    "                x = x.float().to(device)\n",
    "\n",
    "                # Split into position and rotation\n",
    "                x_pos = x[:, :, :, :3]\n",
    "                x_rot = x[:, :, :, 3:]\n",
    "                \n",
    "                loss, _, losses_ = model.loss_unpaired(x_pos, x_rot, actors, actions, reconstruction=ae, emb_adv=use_emb_adv, discrim_adv=use_discrim_adv, ee=ee, triplet=triplet)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "                if run_sgn_eval:\n",
    "                    eval_X_known.append(x_pos.contiguous().view(x_pos.size(0), T, -1).cpu().numpy())\n",
    "                    eval_Y_known_action.append(np.array(actions))\n",
    "                    eval_Y_known_actor.append(np.array(actors))\n",
    "\n",
    "                    eval_X_rec.append(model(x_pos, x_rot).cpu().numpy())\n",
    "                    eval_Y_rec_action.append(np.array(actions))\n",
    "                    eval_Y_rec_actor.append(np.array(actors))\n",
    "                \n",
    "                val_rec_loss.append(losses_['rec_loss'])\n",
    "                val_end_effector_loss.append(losses_['end_effector_loss'])\n",
    "                val_triplet_loss.append(losses_['triplet_loss'])\n",
    "                val_privacy_loss.append(losses_['privacy_loss'])\n",
    "                val_privacy_loss_dyn.append(losses_['privacy_loss_dyn'])\n",
    "                val_privacy_loss_stat.append(losses_['privacy_loss_stat'])\n",
    "                val_privacy_acc_dyn.append(losses_['privacy_acc_dyn'])\n",
    "                val_privacy_acc_stat.append(losses_['privacy_acc_stat'])\n",
    "                val_utility_loss.append(losses_['utility_loss'])\n",
    "                val_utility_loss_dyn.append(losses_['utility_loss_dyn'])\n",
    "                val_utility_loss_stat.append(losses_['utility_loss_stat'])\n",
    "                val_utility_acc_dyn.append(losses_['utility_acc_dyn'])\n",
    "                val_utility_acc_stat.append(losses_['utility_acc_stat'])\n",
    "                val_discriminator_loss.append(losses_['discriminator_loss'])\n",
    "                val_discriminator_acc.append(losses_['discriminator_acc'])\n",
    "\n",
    "    # Print loss/accuracy\n",
    "    print(f'--------------------\\nEpoch {epoch+1}/{total_epochs}\\n--------------------')\n",
    "    print(f'Training Loss:\\t\\t\\t{np.mean(losses)}\\nValidation Loss:\\t\\t{np.mean(val_losses)}\\n')\n",
    "    print('Training Losses:')\n",
    "    print(f'Reconstruction Loss:\\t\\t{np.mean(rec_loss)}\\nEnd Effector Loss:\\t\\t{np.mean(end_effector_loss)}\\nTriplet Loss:\\t\\t\\t{np.mean(triplet_loss)}')\n",
    "    print(f'Privacy Loss:\\t\\t\\t{np.mean(privacy_loss)}\\nPrivacy Loss Dyn:\\t\\t{np.mean(privacy_loss_dyn)}\\nPrivacy Loss Stat:\\t\\t{np.mean(privacy_loss_stat)}')\n",
    "    print(f'Utility Loss:\\t\\t\\t{np.mean(utility_loss)}\\nUtility Loss Dyn:\\t\\t{np.mean(utility_loss_dyn)}\\nUtility Loss Stat:\\t\\t{np.mean(utility_loss_stat)}')\n",
    "    print(f'Discriminator Loss:\\t\\t{np.mean(discriminator_loss)}')\n",
    "    if run_eval:\n",
    "        print('\\nValidation Losses:')\n",
    "        print(f'Val Reconstruction Loss:\\t{np.mean(val_rec_loss)}\\nVal End Effector Loss:\\t\\t{np.mean(val_end_effector_loss)}\\nVal Triplet Loss:\\t\\t{np.mean(val_triplet_loss)}')\n",
    "        print(f'Val Privacy Loss:\\t\\t{np.mean(val_privacy_loss)}\\nVal Privacy Loss Dyn:\\t\\t{np.mean(val_privacy_loss_dyn)}\\nVal Privacy Loss Stat:\\t\\t{np.mean(val_privacy_loss_stat)}')\n",
    "        print(f'Val Utility Loss:\\t\\t{np.mean(val_utility_loss)}\\nVal Utility Loss Dyn:\\t\\t{np.mean(val_utility_loss_dyn)}\\nVal Utility Loss Stat:\\t\\t{np.mean(val_utility_loss_stat)}')\n",
    "        print(f'Val Discriminator Loss:\\t\\t{np.mean(val_discriminator_loss)}')\n",
    "    if emb_adv or discrim_adv:\n",
    "        print('\\nAdversary Losses')\n",
    "        print(f'Privacy Training Loss:\\t\\t{np.mean(priv_training_loss)}\\nUtility Training Loss:\\t\\t{np.mean(util_training_loss)}\\nDiscriminator Training Loss:\\t{np.mean(discriminator_train_losses)}')\n",
    "        if emb_adv:\n",
    "            print(f'Privacy Acc Dyn:\\t\\t{np.mean(privacy_acc_dyn)}\\nPrivacy Acc Stat:\\t\\t{np.mean(privacy_acc_stat)}')\n",
    "            print(f'Utility Acc Dyn:\\t\\t{np.mean(utility_acc_dyn)}\\nUtility Acc Stat:\\t\\t{np.mean(utility_acc_stat)}')\n",
    "            print(f'Val Privacy Acc Dyn:\\t\\t{np.mean(val_privacy_acc_dyn)}\\nVal Privacy Acc Stat:\\t\\t{np.mean(val_privacy_acc_stat)}')\n",
    "            print(f'Val Utility Acc Dyn:\\t\\t{np.mean(val_utility_acc_dyn)}\\nVal Utility Acc Stat:\\t\\t{np.mean(val_utility_acc_stat)}')\n",
    "        if discrim_adv:\n",
    "            print(f'Discriminator Acc:\\t\\t{np.mean(discriminator_acc)}')\n",
    "            print(f'Val Discriminator Acc:\\t\\t{np.mean(val_discriminator_acc)}')\n",
    "\n",
    "    # Save model\n",
    "    if save and np.mean(val_losses) < best_loss:\n",
    "        best_loss = np.mean(val_losses)\n",
    "        torch.save(model.state_dict(), 'pretrained/MR.pt')\n",
    "\n",
    "    # Test Accuracy\n",
    "    if run_sgn_eval and run_eval:\n",
    "        print('\\n')\n",
    "        sgn_acc_known_acc, sgn_acc_known_f1, sgn_acc_known_prec, sgn_acc_known_recall, sgn_acc_known_topk = sgn_eval(eval_X_known, eval_Y_known_action, 'Known Action', is_action=True, k=k)\n",
    "        sgn_acc_rec_acc, sgn_acc_rec_f1, sgn_acc_rec_prec, sgn_acc_rec_recall, sgn_acc_rec_topk = sgn_eval(eval_X_rec, eval_Y_rec_action, 'Reconstructed Action', is_action=True, k=k)\n",
    "        print('\\n')\n",
    "        sgn_priv_known_acc, sgn_priv_known_f1, sgn_priv_known_prec, sgn_priv_known_recall, sgn_priv_known_topk = sgn_eval(eval_X_known, eval_Y_known_actor, 'Known Actor', is_actor=True, k=k)\n",
    "        sgn_priv_rec_acc, sgn_priv_rec_f1, sgn_priv_rec_prec, sgn_priv_rec_recall, sgn_priv_rec_topk = sgn_eval(eval_X_rec, eval_Y_rec_actor, 'Reconstructed Actor', is_actor=True, k=k)\n",
    "        print('\\n')\n",
    "    else: print('\\n')\n",
    "\n",
    "    losses_dict = {}\n",
    "    losses_dict['loss'] = np.mean(losses)\n",
    "\n",
    "    if ae: losses_dict['rec_loss'] = np.mean(rec_loss)\n",
    "    if ee: losses_dict['end_effector_loss'] = np.mean(end_effector_loss)\n",
    "    if triplet: losses_dict['triplet_loss'] = np.mean(triplet_loss)\n",
    "    if run_eval:\n",
    "        losses_dict['val_loss'] = np.mean(val_losses)\n",
    "        if ae: losses_dict['val_rec_loss'] = np.mean(val_rec_loss)\n",
    "        if ee: losses_dict['val_end_effector_loss'] = np.mean(val_end_effector_loss)\n",
    "        if triplet: losses_dict['val_triplet_loss'] = np.mean(val_triplet_loss)\n",
    "        if run_sgn_eval:\n",
    "            losses_dict['sgn_acc_known_acc'] = sgn_acc_known_acc\n",
    "            losses_dict['sgn_acc_known_f1'] = sgn_acc_known_f1\n",
    "            losses_dict['sgn_acc_known_prec'] = sgn_acc_known_prec\n",
    "            losses_dict['sgn_acc_known_recall'] = sgn_acc_known_recall\n",
    "            losses_dict['sgn_acc_rec_acc'] = sgn_acc_rec_acc\n",
    "            losses_dict['sgn_acc_rec_f1'] = sgn_acc_rec_f1\n",
    "            losses_dict['sgn_acc_rec_prec'] = sgn_acc_rec_prec\n",
    "            losses_dict['sgn_acc_rec_recall'] = sgn_acc_rec_recall\n",
    "            losses_dict['sgn_acc_known_topk'] = sgn_acc_known_topk\n",
    "            losses_dict['sgn_acc_rec_topk'] = sgn_acc_rec_topk\n",
    "            losses_dict['sgn_priv_known_acc'] = sgn_priv_known_acc\n",
    "            losses_dict['sgn_priv_known_f1'] = sgn_priv_known_f1\n",
    "            losses_dict['sgn_priv_known_prec'] = sgn_priv_known_prec\n",
    "            losses_dict['sgn_priv_known_recall'] = sgn_priv_known_recall\n",
    "            losses_dict['sgn_priv_rec_acc'] = sgn_priv_rec_acc\n",
    "            losses_dict['sgn_priv_rec_f1'] = sgn_priv_rec_f1\n",
    "            losses_dict['sgn_priv_rec_prec'] = sgn_priv_rec_prec\n",
    "            losses_dict['sgn_priv_rec_recall'] = sgn_priv_rec_recall\n",
    "            losses_dict['sgn_priv_known_topk'] = sgn_priv_known_topk\n",
    "            losses_dict['sgn_priv_rec_topk'] = sgn_priv_rec_topk\n",
    "    if use_emb_adv:\n",
    "        losses_dict['privacy_loss'] = np.mean(privacy_loss)\n",
    "        losses_dict['privacy_loss_dyn'] = np.mean(privacy_loss_dyn)\n",
    "        losses_dict['privacy_loss_stat'] = np.mean(privacy_loss_stat)\n",
    "        losses_dict['utility_loss'] = np.mean(utility_loss)\n",
    "        losses_dict['utility_loss_dyn'] = np.mean(utility_loss_dyn)\n",
    "        losses_dict['utility_loss_stat'] = np.mean(utility_loss_stat)\n",
    "        losses_dict['privacy_acc_dyn'] = np.mean(privacy_acc_dyn)\n",
    "        losses_dict['privacy_acc_stat'] = np.mean(privacy_acc_stat)\n",
    "        losses_dict['utility_acc_dyn'] = np.mean(utility_acc_dyn)\n",
    "        losses_dict['utility_acc_stat'] = np.mean(utility_acc_stat)\n",
    "        if run_eval:    \n",
    "            losses_dict['val_privacy_acc_dyn'] = np.mean(val_privacy_acc_dyn)\n",
    "            losses_dict['val_privacy_acc_stat'] = np.mean(val_privacy_acc_stat)\n",
    "            losses_dict['val_utility_acc_dyn'] = np.mean(val_utility_acc_dyn)\n",
    "            losses_dict['val_utility_acc_stat'] = np.mean(val_utility_acc_stat)\n",
    "            losses_dict['val_privacy_loss'] = np.mean(val_privacy_loss)\n",
    "            losses_dict['val_privacy_loss_dyn'] = np.mean(val_privacy_loss_dyn)\n",
    "            losses_dict['val_privacy_loss_stat'] = np.mean(val_privacy_loss_stat)\n",
    "            losses_dict['val_utility_loss'] = np.mean(val_utility_loss)\n",
    "            losses_dict['val_utility_loss_dyn'] = np.mean(val_utility_loss_dyn)\n",
    "            losses_dict['val_utility_loss_stat'] = np.mean(val_utility_loss_stat)\n",
    "    if emb_adv:\n",
    "        losses_dict['priv_training_loss'] = np.mean(priv_training_loss)\n",
    "        losses_dict['util_training_loss'] = np.mean(util_training_loss)\n",
    "    if use_discrim_adv:\n",
    "        losses_dict['discriminator_loss'] = np.mean(discriminator_loss)\n",
    "        losses_dict['discriminator_acc'] = np.mean(discriminator_acc)\n",
    "        if run_eval:\n",
    "            losses_dict['val_discriminator_loss'] = np.mean(val_discriminator_loss)\n",
    "            losses_dict['val_discriminator_acc'] = np.mean(val_discriminator_acc)\n",
    "    if discrim_adv:\n",
    "        losses_dict['discriminator_train_loss'] = np.mean(discriminator_train_losses)\n",
    "    return losses_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Moving to new stage\n",
      "{'epochs': 500, 'paired': False, 'ae': True, 'ee': True, 'cross': False, 'triplet': False, 'train_emb_adv': False, 'train_discrim_adv': False, 'emb_adv': False, 'discrim_adv': False, 'eval': True, 'sgn_eval': True, 'save': True} \n",
      "\n",
      "--------------------\n",
      "Epoch 1/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.011131992805469946\n",
      "Validation Loss:\t\t0.0094847207524958\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.003566723280463933\n",
      "End Effector Loss:\t\t0.003998546241256991\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0027581836629009637\n",
      "Val End Effector Loss:\t\t0.003968353407018044\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "\n",
      "Known Action Accuracy:\t\t77.88206481933594\n",
      "Known Action F1:\t\t\t66.86862728533092\n",
      "Known Action Precision:\t\t68.39044112190419\n",
      "Known Action Recall:\t\t67.2679677182874\n",
      "Known Action Top-3 Accuracy:\t90.11705017089844\n",
      "\n",
      "\n",
      "Reconstructed Action Accuracy:\t\t46.98542404174805\n",
      "Reconstructed Action F1:\t\t\t38.57178573969858\n",
      "Reconstructed Action Precision:\t\t48.35845434832274\n",
      "Reconstructed Action Recall:\t\t40.42003598550331\n",
      "Reconstructed Action Top-3 Accuracy:\t67.43595123291016\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Known Actor Accuracy:\t\t91.79549407958984\n",
      "Known Actor F1:\t\t\t91.81704509163829\n",
      "Known Actor Precision:\t\t93.47956886906482\n",
      "Known Actor Recall:\t\t90.41375673719646\n",
      "Known Actor Top-3 Accuracy:\t97.31669616699219\n",
      "\n",
      "\n",
      "Reconstructed Actor Accuracy:\t\t41.16607666015625\n",
      "Reconstructed Actor F1:\t\t\t30.700230573081704\n",
      "Reconstructed Actor Precision:\t\t45.40808572168945\n",
      "Reconstructed Actor Recall:\t\t35.36836571923806\n",
      "Reconstructed Actor Top-3 Accuracy:\t62.61042404174805\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 2/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.008770924823677308\n",
      "Validation Loss:\t\t0.008572833043601836\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.00247514489656265\n",
      "End Effector Loss:\t\t0.0038206350059138455\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0023438824024248186\n",
      "Val End Effector Loss:\t\t0.003885068250229766\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 3/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.008208120275433365\n",
      "Validation Loss:\t\t0.008223799399992215\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0022278943262719984\n",
      "End Effector Loss:\t\t0.003752331604410745\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0021900266243315395\n",
      "Val End Effector Loss:\t\t0.003843746158707572\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 4/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.007882544407834556\n",
      "Validation Loss:\t\t0.008062725394806812\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0020897720267583912\n",
      "End Effector Loss:\t\t0.003703000359861361\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.002119373141551836\n",
      "Val End Effector Loss:\t\t0.003823979065792871\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 5/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.007643136465215704\n",
      "Validation Loss:\t\t0.007864177425418206\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.00199140237301023\n",
      "End Effector Loss:\t\t0.003660331722275014\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0020414261208047016\n",
      "Val End Effector Loss:\t\t0.0037813251715114104\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 6/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.007468173159631314\n",
      "Validation Loss:\t\t0.007709377264918786\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0019217754479717772\n",
      "End Effector Loss:\t\t0.003624622257117583\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.001972001325093131\n",
      "Val End Effector Loss:\t\t0.0037653745958765206\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 7/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0073364672893280495\n",
      "Validation Loss:\t\t0.0075707340048967115\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0018698926122959316\n",
      "End Effector Loss:\t\t0.0035966820680212747\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0019115573451132842\n",
      "Val End Effector Loss:\t\t0.0037476193081115335\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 8/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.007230734837781868\n",
      "Validation Loss:\t\t0.0074660720247906485\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0018238052440399872\n",
      "End Effector Loss:\t\t0.003583124339435992\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0018665251313072537\n",
      "Val End Effector Loss:\t\t0.00373302176463562\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 9/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.007114240038988872\n",
      "Validation Loss:\t\t0.007341767935095433\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0017786083505423231\n",
      "End Effector Loss:\t\t0.0035570233422159044\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0018150428302658222\n",
      "Val End Effector Loss:\t\t0.0037116822954693573\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 10/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0070229277254543815\n",
      "Validation Loss:\t\t0.007276938642821157\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0017423440902033982\n",
      "End Effector Loss:\t\t0.003538239544226313\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0017947877374392422\n",
      "Val End Effector Loss:\t\t0.0036873631679426723\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 11/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006943916127486466\n",
      "Validation Loss:\t\t0.007262887028177125\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001712666114264971\n",
      "End Effector Loss:\t\t0.003518583900804387\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0017891174479892713\n",
      "Val End Effector Loss:\t\t0.003684652155973542\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "\n",
      "Known Action Accuracy:\t\t78.11395263671875\n",
      "Known Action F1:\t\t\t67.0248921981724\n",
      "Known Action Precision:\t\t68.4449081971897\n",
      "Known Action Recall:\t\t67.47966238956244\n",
      "Known Action Top-3 Accuracy:\t89.9955825805664\n",
      "\n",
      "\n",
      "Reconstructed Action Accuracy:\t\t53.754417419433594\n",
      "Reconstructed Action F1:\t\t\t44.85625259349694\n",
      "Reconstructed Action Precision:\t\t53.45258059206308\n",
      "Reconstructed Action Recall:\t\t46.40309733116199\n",
      "Reconstructed Action Top-3 Accuracy:\t73.59761047363281\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Known Actor Accuracy:\t\t91.79549407958984\n",
      "Known Actor F1:\t\t\t91.64942186590372\n",
      "Known Actor Precision:\t\t93.39829120160239\n",
      "Known Actor Recall:\t\t90.17454604965293\n",
      "Known Actor Top-3 Accuracy:\t97.2835693359375\n",
      "\n",
      "\n",
      "Reconstructed Actor Accuracy:\t\t60.33568572998047\n",
      "Reconstructed Actor F1:\t\t\t54.41507303943594\n",
      "Reconstructed Actor Precision:\t\t59.09391027514328\n",
      "Reconstructed Actor Recall:\t\t54.616051540527536\n",
      "Reconstructed Actor Top-3 Accuracy:\t82.05609130859375\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 12/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006872868636373358\n",
      "Validation Loss:\t\t0.00720084584678825\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0016852279324178967\n",
      "End Effector Loss:\t\t0.003502412765070047\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0017612396868955816\n",
      "Val End Effector Loss:\t\t0.003678366452501431\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 13/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006806295457488251\n",
      "Validation Loss:\t\t0.007167681559762904\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0016590360960860718\n",
      "End Effector Loss:\t\t0.003488223262646973\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0017424813725060823\n",
      "Val End Effector Loss:\t\t0.0036827188139309137\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 14/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006765532537693621\n",
      "Validation Loss:\t\t0.007103674361337973\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0016408545455593136\n",
      "End Effector Loss:\t\t0.003483823440210135\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.001721598644508049\n",
      "Val End Effector Loss:\t\t0.0036604770567451772\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 15/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006694212758739527\n",
      "Validation Loss:\t\t0.007145307782683259\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0016155287959511069\n",
      "End Effector Loss:\t\t0.0034631551697117654\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0017365724226282779\n",
      "Val End Effector Loss:\t\t0.0036721629382465296\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 16/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006652272593006623\n",
      "Validation Loss:\t\t0.0070834718824980755\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0015981987887021068\n",
      "End Effector Loss:\t\t0.0034558750156024093\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0017053142975373063\n",
      "Val End Effector Loss:\t\t0.003672843299720856\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 17/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006601547879024\n",
      "Validation Loss:\t\t0.007013801267226292\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001580146705461551\n",
      "End Effector Loss:\t\t0.003441254471180668\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0016867918754324422\n",
      "Val End Effector Loss:\t\t0.0036402175270191487\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 18/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006557490504995593\n",
      "Validation Loss:\t\t0.0069747356399500245\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0015627219508208229\n",
      "End Effector Loss:\t\t0.003432046595346544\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0016567497934349223\n",
      "Val End Effector Loss:\t\t0.0036612360321746115\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 19/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006522843751783698\n",
      "Validation Loss:\t\t0.0069344657896296446\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0015512027508662143\n",
      "End Effector Loss:\t\t0.003420438254670925\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.001651199592743069\n",
      "Val End Effector Loss:\t\t0.0036320665787288944\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 20/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006487254989193835\n",
      "Validation Loss:\t\t0.0069448534484532936\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0015336201481362624\n",
      "End Effector Loss:\t\t0.003420014694050559\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0016486213922100536\n",
      "Val End Effector Loss:\t\t0.0036476106910874515\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 21/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0064305899590023875\n",
      "Validation Loss:\t\t0.006917770338756308\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0015170921903552004\n",
      "End Effector Loss:\t\t0.003396405569463311\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0016259274902117346\n",
      "Val End Effector Loss:\t\t0.0036659153468552716\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "\n",
      "Known Action Accuracy:\t\t77.87102508544922\n",
      "Known Action F1:\t\t\t67.09283946922399\n",
      "Known Action Precision:\t\t68.5920873068294\n",
      "Known Action Recall:\t\t67.41951482240029\n",
      "Known Action Top-3 Accuracy:\t90.09496307373047\n",
      "\n",
      "\n",
      "Reconstructed Action Accuracy:\t\t52.650177001953125\n",
      "Reconstructed Action F1:\t\t\t43.521811556907494\n",
      "Reconstructed Action Precision:\t\t53.14463902309504\n",
      "Reconstructed Action Recall:\t\t45.61854174768046\n",
      "Reconstructed Action Top-3 Accuracy:\t71.5437240600586\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Known Actor Accuracy:\t\t91.7844467163086\n",
      "Known Actor F1:\t\t\t91.70839223481669\n",
      "Known Actor Precision:\t\t93.43732582361147\n",
      "Known Actor Recall:\t\t90.2628865729069\n",
      "Known Actor Top-3 Accuracy:\t97.34982299804688\n",
      "\n",
      "\n",
      "Reconstructed Actor Accuracy:\t\t65.54769897460938\n",
      "Reconstructed Actor F1:\t\t\t59.98857758589704\n",
      "Reconstructed Actor Precision:\t\t67.0128120202382\n",
      "Reconstructed Actor Recall:\t\t58.56883960925173\n",
      "Reconstructed Actor Top-3 Accuracy:\t84.73939514160156\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 22/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006395697058835502\n",
      "Validation Loss:\t\t0.006892695991014144\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0015039609920075804\n",
      "End Effector Loss:\t\t0.003387775072767161\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0016349660844253507\n",
      "Val End Effector Loss:\t\t0.003622763845938402\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 23/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006362387030081564\n",
      "Validation Loss:\t\t0.006838868480359374\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0014920741207963364\n",
      "End Effector Loss:\t\t0.0033782387839718943\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0016028159134037479\n",
      "Val End Effector Loss:\t\t0.003633236641254486\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 24/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006328140635526291\n",
      "Validation Loss:\t\t0.006872530577337028\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0014805807897326662\n",
      "End Effector Loss:\t\t0.0033669790608859317\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0016186741108163325\n",
      "Val End Effector Loss:\t\t0.0036351823733306267\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 25/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006299039117361187\n",
      "Validation Loss:\t\t0.00682341286004193\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0014688184026364283\n",
      "End Effector Loss:\t\t0.0033614023094191963\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0016014615227927414\n",
      "Val End Effector Loss:\t\t0.0036204898308529717\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 26/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0062674034764247785\n",
      "Validation Loss:\t\t0.006817806656406799\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0014587627553707071\n",
      "End Effector Loss:\t\t0.0033498779700977016\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0016051175586820226\n",
      "Val End Effector Loss:\t\t0.0036075715226462296\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 27/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0062473770327508005\n",
      "Validation Loss:\t\t0.006791448830561319\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001448557041876997\n",
      "End Effector Loss:\t\t0.00335026294755958\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015904279019926268\n",
      "Val End Effector Loss:\t\t0.0036105930437924155\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 28/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.00621195511467019\n",
      "Validation Loss:\t\t0.006811256300736691\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0014394631361296464\n",
      "End Effector Loss:\t\t0.0033330288442587593\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.001597794806617509\n",
      "Val End Effector Loss:\t\t0.003615666694060283\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 29/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0061886530115747105\n",
      "Validation Loss:\t\t0.006766441697910638\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0014288853303175354\n",
      "End Effector Loss:\t\t0.0033308823512476168\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015807484752501846\n",
      "Val End Effector Loss:\t\t0.0036049447502796606\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 30/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006147819092190074\n",
      "Validation Loss:\t\t0.006841024192883043\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0014175974174769762\n",
      "End Effector Loss:\t\t0.0033126242426585414\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.001605770958121866\n",
      "Val End Effector Loss:\t\t0.003629482297954792\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 31/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006141114973206881\n",
      "Validation Loss:\t\t0.00672428178171378\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0014130341144101251\n",
      "End Effector Loss:\t\t0.003315046742230792\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015635394032562518\n",
      "Val End Effector Loss:\t\t0.003597202971102145\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "\n",
      "Known Action Accuracy:\t\t78.04769897460938\n",
      "Known Action F1:\t\t\t66.9966465835896\n",
      "Known Action Precision:\t\t68.4807506299226\n",
      "Known Action Recall:\t\t67.39325486281619\n",
      "Known Action Top-3 Accuracy:\t90.19434356689453\n",
      "\n",
      "\n",
      "Reconstructed Action Accuracy:\t\t55.2672233581543\n",
      "Reconstructed Action F1:\t\t\t45.85424506465328\n",
      "Reconstructed Action Precision:\t\t54.665928345070604\n",
      "Reconstructed Action Recall:\t\t47.753881148308345\n",
      "Reconstructed Action Top-3 Accuracy:\t75.19876098632812\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Known Actor Accuracy:\t\t91.88383483886719\n",
      "Known Actor F1:\t\t\t91.73496730080953\n",
      "Known Actor Precision:\t\t93.46011570307034\n",
      "Known Actor Recall:\t\t90.27471504903903\n",
      "Known Actor Top-3 Accuracy:\t97.405029296875\n",
      "\n",
      "\n",
      "Reconstructed Actor Accuracy:\t\t67.94390106201172\n",
      "Reconstructed Actor F1:\t\t\t62.567999661578355\n",
      "Reconstructed Actor Precision:\t\t67.69057093971192\n",
      "Reconstructed Actor Recall:\t\t61.21605362832041\n",
      "Reconstructed Actor Top-3 Accuracy:\t87.48895263671875\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 32/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.00610473481700074\n",
      "Validation Loss:\t\t0.006690486375255589\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0014022516340881296\n",
      "End Effector Loss:\t\t0.0033002315398931465\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015494841217345387\n",
      "Val End Effector Loss:\t\t0.0035915181076016382\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 33/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006089305577428463\n",
      "Validation Loss:\t\t0.006715949683804327\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0013943915553592191\n",
      "End Effector Loss:\t\t0.0033005224692764998\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.001560752586671479\n",
      "Val End Effector Loss:\t\t0.0035944445202992837\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 34/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0060533645463864295\n",
      "Validation Loss:\t\t0.006777213276429495\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0013846494497158901\n",
      "End Effector Loss:\t\t0.0032840656486998526\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015805261443257595\n",
      "Val End Effector Loss:\t\t0.003616160973021105\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 35/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.006045379343925527\n",
      "Validation Loss:\t\t0.006701652565643086\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001378800692309821\n",
      "End Effector Loss:\t\t0.0032877779625909735\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015512157465629674\n",
      "Val End Effector Loss:\t\t0.0035992210827649794\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 36/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0060096632307756696\n",
      "Validation Loss:\t\t0.006713962010239107\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0013712633853779064\n",
      "End Effector Loss:\t\t0.003267136460533152\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015572649480046993\n",
      "Val End Effector Loss:\t\t0.0035994321322658845\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 37/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005991661931409433\n",
      "Validation Loss:\t\t0.006685357727766247\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0013636534367737277\n",
      "End Effector Loss:\t\t0.003264355052318391\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015490261319709916\n",
      "Val End Effector Loss:\t\t0.003587305436769999\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 38/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005971468837046421\n",
      "Validation Loss:\t\t0.006692877372162758\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0013575122297069672\n",
      "End Effector Loss:\t\t0.003256444374552716\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015484590553121091\n",
      "Val End Effector Loss:\t\t0.00359595924309245\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 39/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005955310841255231\n",
      "Validation Loss:\t\t0.006673152001023712\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001350966930737213\n",
      "End Effector Loss:\t\t0.0032533769769063532\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015370969153927561\n",
      "Val End Effector Loss:\t\t0.0035989581669588953\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 40/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005927756234282395\n",
      "Validation Loss:\t\t0.006664771332510445\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001343262799571201\n",
      "End Effector Loss:\t\t0.0032412306403756023\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.001536124242013845\n",
      "Val End Effector Loss:\t\t0.003592522824707795\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 41/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005911091783180886\n",
      "Validation Loss:\t\t0.0066617101703075245\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0013374609263828172\n",
      "End Effector Loss:\t\t0.0032361699263088904\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015318746291983112\n",
      "Val End Effector Loss:\t\t0.003597960911500989\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "\n",
      "Known Action Accuracy:\t\t78.1691665649414\n",
      "Known Action F1:\t\t\t67.12070467289456\n",
      "Known Action Precision:\t\t68.84642711202535\n",
      "Known Action Recall:\t\t67.44787902405771\n",
      "Known Action Top-3 Accuracy:\t90.06183624267578\n",
      "\n",
      "\n",
      "Reconstructed Action Accuracy:\t\t55.20096969604492\n",
      "Reconstructed Action F1:\t\t\t46.08461416013805\n",
      "Reconstructed Action Precision:\t\t56.3166731776193\n",
      "Reconstructed Action Recall:\t\t47.94675862740231\n",
      "Reconstructed Action Top-3 Accuracy:\t74.43683624267578\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Known Actor Accuracy:\t\t91.7844467163086\n",
      "Known Actor F1:\t\t\t91.87049701762682\n",
      "Known Actor Precision:\t\t93.63037571934198\n",
      "Known Actor Recall:\t\t90.38257195721864\n",
      "Known Actor Top-3 Accuracy:\t97.39398956298828\n",
      "\n",
      "\n",
      "Reconstructed Actor Accuracy:\t\t70.17446899414062\n",
      "Reconstructed Actor F1:\t\t\t64.806491987022\n",
      "Reconstructed Actor Precision:\t\t72.34060781203314\n",
      "Reconstructed Actor Recall:\t\t63.071010587119446\n",
      "Reconstructed Actor Top-3 Accuracy:\t87.74292755126953\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 42/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005889711425002382\n",
      "Validation Loss:\t\t0.00666030050209448\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0013306707559963213\n",
      "End Effector Loss:\t\t0.0032283699067475395\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015298047006248273\n",
      "Val End Effector Loss:\t\t0.003600691109043087\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 43/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005873249143787464\n",
      "Validation Loss:\t\t0.006628711921044849\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001323817169081873\n",
      "End Effector Loss:\t\t0.003225614804083833\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015193391906943592\n",
      "Val End Effector Loss:\t\t0.0035900335494940443\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 44/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005852313470579947\n",
      "Validation Loss:\t\t0.0067098564320755465\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0013195649099436045\n",
      "End Effector Loss:\t\t0.003213183645970423\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015473798274810255\n",
      "Val End Effector Loss:\t\t0.0036150967959694986\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 45/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005836109626246534\n",
      "Validation Loss:\t\t0.006649648675590124\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0013130322593856419\n",
      "End Effector Loss:\t\t0.0032100451065513193\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.001525445403260651\n",
      "Val End Effector Loss:\t\t0.0035987578850554328\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 46/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005816132747371085\n",
      "Validation Loss:\t\t0.006627568046227885\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0013080543120444228\n",
      "End Effector Loss:\t\t0.003200024130673688\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015177681860120468\n",
      "Val End Effector Loss:\t\t0.003592031671334399\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 47/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005800863366362161\n",
      "Validation Loss:\t\t0.00665142739349058\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001301750376376256\n",
      "End Effector Loss:\t\t0.003197362608374039\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015267375167983938\n",
      "Val End Effector Loss:\t\t0.003597952352515356\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 48/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005781427808877942\n",
      "Validation Loss:\t\t0.00664088923097129\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0012972307979392883\n",
      "End Effector Loss:\t\t0.0031869662128967058\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015225864265976526\n",
      "Val End Effector Loss:\t\t0.003595716381465203\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 49/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005769768887079555\n",
      "Validation Loss:\t\t0.006608262849958535\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001291900964499397\n",
      "End Effector Loss:\t\t0.003185966959107352\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015058266777794442\n",
      "Val End Effector Loss:\t\t0.0035966094780031225\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 50/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005747392063433177\n",
      "Validation Loss:\t\t0.006635987385123653\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0012862107410987534\n",
      "End Effector Loss:\t\t0.0031749705870872335\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015192898426903412\n",
      "Val End Effector Loss:\t\t0.003597407696873579\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 51/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.00572975295122772\n",
      "Validation Loss:\t\t0.006600710718308799\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0012815995448814275\n",
      "End Effector Loss:\t\t0.003166553864852612\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014976055132189083\n",
      "Val End Effector Loss:\t\t0.00360549968900159\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "\n",
      "Known Action Accuracy:\t\t78.23542022705078\n",
      "Known Action F1:\t\t\t67.10821336609581\n",
      "Known Action Precision:\t\t68.34825403723924\n",
      "Known Action Recall:\t\t67.60086811131691\n",
      "Known Action Top-3 Accuracy:\t90.2605972290039\n",
      "\n",
      "\n",
      "Reconstructed Action Accuracy:\t\t55.697879791259766\n",
      "Reconstructed Action F1:\t\t\t46.88464032659104\n",
      "Reconstructed Action Precision:\t\t57.08885717860161\n",
      "Reconstructed Action Recall:\t\t48.6444296124582\n",
      "Reconstructed Action Top-3 Accuracy:\t74.80123138427734\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Known Actor Accuracy:\t\t91.83966064453125\n",
      "Known Actor F1:\t\t\t91.78376083769668\n",
      "Known Actor Precision:\t\t93.4659689735444\n",
      "Known Actor Recall:\t\t90.36984528897506\n",
      "Known Actor Top-3 Accuracy:\t97.25044250488281\n",
      "\n",
      "\n",
      "Reconstructed Actor Accuracy:\t\t71.31183624267578\n",
      "Reconstructed Actor F1:\t\t\t66.27394454693143\n",
      "Reconstructed Actor Precision:\t\t71.84517062921142\n",
      "Reconstructed Actor Recall:\t\t64.4921446434396\n",
      "Reconstructed Actor Top-3 Accuracy:\t88.48277282714844\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 52/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005717472217622257\n",
      "Validation Loss:\t\t0.006661697413811696\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0012773148159802821\n",
      "End Effector Loss:\t\t0.0031628425935664372\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.001525822597306589\n",
      "Val End Effector Loss:\t\t0.0036100522150993874\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 53/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005705967012709056\n",
      "Validation Loss:\t\t0.006579802860177948\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0012723849408781875\n",
      "End Effector Loss:\t\t0.0031611971325952253\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014962801987692242\n",
      "Val End Effector Loss:\t\t0.0035872424589502823\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 54/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005681107715683836\n",
      "Validation Loss:\t\t0.0066174735695543425\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001266760788356961\n",
      "End Effector Loss:\t\t0.0031475861350688723\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015120680729242067\n",
      "Val End Effector Loss:\t\t0.0035933374187869715\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 55/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.00566825182058042\n",
      "Validation Loss:\t\t0.0066193789899559085\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0012625467553804587\n",
      "End Effector Loss:\t\t0.0031431583067397318\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015113799233058415\n",
      "Val End Effector Loss:\t\t0.0035966191306369194\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 56/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005651762703888618\n",
      "Validation Loss:\t\t0.006599937739427871\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0012581183780309116\n",
      "End Effector Loss:\t\t0.0031355259409486407\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014993702955084893\n",
      "Val End Effector Loss:\t\t0.003601197123816106\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 57/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005643161246347745\n",
      "Validation Loss:\t\t0.006599179405102532\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0012545497760314633\n",
      "End Effector Loss:\t\t0.00313406169726193\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.001501788349754938\n",
      "Val End Effector Loss:\t\t0.0035956027166603108\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 58/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005625060570386864\n",
      "Validation Loss:\t\t0.006595162787920677\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.00124994646289716\n",
      "End Effector Loss:\t\t0.003125167637303754\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.001500946367946519\n",
      "Val End Effector Loss:\t\t0.0035932700553069443\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 59/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0056118274007380215\n",
      "Validation Loss:\t\t0.006580540026590543\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001246161769576226\n",
      "End Effector Loss:\t\t0.003119503873083379\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014918591065945523\n",
      "Val End Effector Loss:\t\t0.003596821828568223\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 60/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005594227293824919\n",
      "Validation Loss:\t\t0.006600394162913443\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0012411213065399024\n",
      "End Effector Loss:\t\t0.0031119846823876576\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015028190725683039\n",
      "Val End Effector Loss:\t\t0.003594756030484142\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 61/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005584942444878083\n",
      "Validation Loss:\t\t0.006593130963434741\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0012383440850677078\n",
      "End Effector Loss:\t\t0.0031082542780277566\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.001495491667990048\n",
      "Val End Effector Loss:\t\t0.0036021476196662957\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "\n",
      "Known Action Accuracy:\t\t77.99249267578125\n",
      "Known Action F1:\t\t\t67.37600862150906\n",
      "Known Action Precision:\t\t68.94347775104683\n",
      "Known Action Recall:\t\t67.69395481883035\n",
      "Known Action Top-3 Accuracy:\t89.96245574951172\n",
      "\n",
      "\n",
      "Reconstructed Action Accuracy:\t\t56.5150146484375\n",
      "Reconstructed Action F1:\t\t\t47.21707484940977\n",
      "Reconstructed Action Precision:\t\t55.847134942783015\n",
      "Reconstructed Action Recall:\t\t48.87343187712637\n",
      "Reconstructed Action Top-3 Accuracy:\t75.64045715332031\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Known Actor Accuracy:\t\t91.8507080078125\n",
      "Known Actor F1:\t\t\t91.83525663869216\n",
      "Known Actor Precision:\t\t93.57998655201713\n",
      "Known Actor Recall:\t\t90.36035132174078\n",
      "Known Actor Top-3 Accuracy:\t97.34982299804688\n",
      "\n",
      "\n",
      "Reconstructed Actor Accuracy:\t\t71.74249267578125\n",
      "Reconstructed Actor F1:\t\t\t67.89047123966921\n",
      "Reconstructed Actor Precision:\t\t72.22119129032276\n",
      "Reconstructed Actor Recall:\t\t65.68681891798576\n",
      "Reconstructed Actor Top-3 Accuracy:\t88.7257080078125\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 62/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005575463863999651\n",
      "Validation Loss:\t\t0.0065989459349944345\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001236307388541126\n",
      "End Effector Loss:\t\t0.0031028490903051457\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015005189480676486\n",
      "Val End Effector Loss:\t\t0.0035979080507466178\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 63/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005563443548799981\n",
      "Validation Loss:\t\t0.00657684054934013\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0012312355232416822\n",
      "End Effector Loss:\t\t0.003100972510529337\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014910936957343258\n",
      "Val End Effector Loss:\t\t0.0035946531726283506\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 64/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005543137914903554\n",
      "Validation Loss:\t\t0.0065809326249660115\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001226890102280156\n",
      "End Effector Loss:\t\t0.0030893577061342223\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014892654226187775\n",
      "Val End Effector Loss:\t\t0.0036024017633319323\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 65/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.00553031346651461\n",
      "Validation Loss:\t\t0.006636148961392087\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001222169136423601\n",
      "End Effector Loss:\t\t0.0030859751970551555\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.001508180403542495\n",
      "Val End Effector Loss:\t\t0.003619788150207966\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 66/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005523353911578209\n",
      "Validation Loss:\t\t0.006571559695376109\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001220639581328859\n",
      "End Effector Loss:\t\t0.0030820747434795624\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014880181550094203\n",
      "Val End Effector Loss:\t\t0.003595523382077964\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 67/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005510570484294016\n",
      "Validation Loss:\t\t0.006590884224787145\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001216100950097514\n",
      "End Effector Loss:\t\t0.003078368584612283\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014913305099135343\n",
      "Val End Effector Loss:\t\t0.0036082232229962524\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 68/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005491250355167863\n",
      "Validation Loss:\t\t0.006613369875351413\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0012123738224593499\n",
      "End Effector Loss:\t\t0.0030665027034736682\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0015015415216035302\n",
      "Val End Effector Loss:\t\t0.003610286839522789\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 69/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005480453443247004\n",
      "Validation Loss:\t\t0.006605246647024973\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0012090161123589778\n",
      "End Effector Loss:\t\t0.003062421216989163\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014995589295261158\n",
      "Val End Effector Loss:\t\t0.003606128786743002\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 70/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005468147240145497\n",
      "Validation Loss:\t\t0.006594095972668327\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0012059108486786696\n",
      "End Effector Loss:\t\t0.0030563255425828397\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014863287836139444\n",
      "Val End Effector Loss:\t\t0.0036214384033908726\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 71/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005457963944967948\n",
      "Validation Loss:\t\t0.006594224811636541\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001203315504331789\n",
      "End Effector Loss:\t\t0.0030513329323006684\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014938181715043472\n",
      "Val End Effector Loss:\t\t0.0036065884702674994\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "\n",
      "Known Action Accuracy:\t\t77.9814453125\n",
      "Known Action F1:\t\t\t67.2644928434981\n",
      "Known Action Precision:\t\t68.80688651050733\n",
      "Known Action Recall:\t\t67.70247782099203\n",
      "Known Action Top-3 Accuracy:\t90.16121673583984\n",
      "\n",
      "\n",
      "Reconstructed Action Accuracy:\t\t56.647525787353516\n",
      "Reconstructed Action F1:\t\t\t47.435631733012116\n",
      "Reconstructed Action Precision:\t\t56.970310624059564\n",
      "Reconstructed Action Recall:\t\t49.13163787980576\n",
      "Reconstructed Action Top-3 Accuracy:\t75.77296447753906\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Known Actor Accuracy:\t\t91.7844467163086\n",
      "Known Actor F1:\t\t\t91.70725647668483\n",
      "Known Actor Precision:\t\t93.37350125874949\n",
      "Known Actor Recall:\t\t90.29649770296959\n",
      "Known Actor Top-3 Accuracy:\t97.38294982910156\n",
      "\n",
      "\n",
      "Reconstructed Actor Accuracy:\t\t71.67623138427734\n",
      "Reconstructed Actor F1:\t\t\t67.14004114053843\n",
      "Reconstructed Actor Precision:\t\t70.87791300359292\n",
      "Reconstructed Actor Recall:\t\t66.15582594139366\n",
      "Reconstructed Actor Top-3 Accuracy:\t88.26192474365234\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 72/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005454163510735086\n",
      "Validation Loss:\t\t0.006606273527722806\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001202171377320667\n",
      "End Effector Loss:\t\t0.0030498207562990698\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014974842846974023\n",
      "Val End Effector Loss:\t\t0.003611304968985742\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 73/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005442442690068281\n",
      "Validation Loss:\t\t0.0065790754136249\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011975931535874093\n",
      "End Effector Loss:\t\t0.0030472563844333475\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014851287457826351\n",
      "Val End Effector Loss:\t\t0.003608817924929022\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 74/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005422312412139954\n",
      "Validation Loss:\t\t0.006590232697420452\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011932685712251379\n",
      "End Effector Loss:\t\t0.0030357752726667903\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014918206766260866\n",
      "Val End Effector Loss:\t\t0.0036065913277717543\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 75/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005408584700348726\n",
      "Validation Loss:\t\t0.006588073717889336\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011902137097329348\n",
      "End Effector Loss:\t\t0.0030281572747233158\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014840080148645375\n",
      "Val End Effector Loss:\t\t0.003620057701277481\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 76/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0053959098575567755\n",
      "Validation Loss:\t\t0.006607135995553518\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011870363487297836\n",
      "End Effector Loss:\t\t0.0030218371618424117\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014907632889652389\n",
      "Val End Effector Loss:\t\t0.0036256094061454733\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 77/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0053882618447867545\n",
      "Validation Loss:\t\t0.006583126021621251\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011843245242319088\n",
      "End Effector Loss:\t\t0.003019612796220278\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014840031174277151\n",
      "Val End Effector Loss:\t\t0.003615119802752431\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 78/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005376026969784098\n",
      "Validation Loss:\t\t0.006597951271007179\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011815314772567586\n",
      "End Effector Loss:\t\t0.0030129640120881524\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014883248298592918\n",
      "Val End Effector Loss:\t\t0.0036213015973515492\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 79/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0053730974028484875\n",
      "Validation Loss:\t\t0.0066111956544312265\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001179423076026733\n",
      "End Effector Loss:\t\t0.0030142512563386082\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014953540107661622\n",
      "Val End Effector Loss:\t\t0.0036204876107635946\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 80/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005354622513018023\n",
      "Validation Loss:\t\t0.0065744886548638765\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011761224751871545\n",
      "End Effector Loss:\t\t0.0030023775768106575\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014752584343946632\n",
      "Val End Effector Loss:\t\t0.0036239718000115957\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 81/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005344495760372181\n",
      "Validation Loss:\t\t0.006604407922181131\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011732073847123962\n",
      "End Effector Loss:\t\t0.002998080993616523\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014892445434898163\n",
      "Val End Effector Loss:\t\t0.0036259188175752338\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "\n",
      "Known Action Accuracy:\t\t77.7605972290039\n",
      "Known Action F1:\t\t\t67.0224311560597\n",
      "Known Action Precision:\t\t68.9827490561503\n",
      "Known Action Recall:\t\t67.30462093430583\n",
      "Known Action Top-3 Accuracy:\t90.09496307373047\n",
      "\n",
      "\n",
      "Reconstructed Action Accuracy:\t\t57.68551254272461\n",
      "Reconstructed Action F1:\t\t\t48.17516257030082\n",
      "Reconstructed Action Precision:\t\t56.19335565890251\n",
      "Reconstructed Action Recall:\t\t49.80098464844157\n",
      "Reconstructed Action Top-3 Accuracy:\t76.1263198852539\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Known Actor Accuracy:\t\t91.82862091064453\n",
      "Known Actor F1:\t\t\t91.63699094901845\n",
      "Known Actor Precision:\t\t93.294382033091\n",
      "Known Actor Recall:\t\t90.23100584333619\n",
      "Known Actor Top-3 Accuracy:\t97.3277359008789\n",
      "\n",
      "\n",
      "Reconstructed Actor Accuracy:\t\t72.57067108154297\n",
      "Reconstructed Actor F1:\t\t\t67.71609163427439\n",
      "Reconstructed Actor Precision:\t\t72.54697206276748\n",
      "Reconstructed Actor Recall:\t\t65.9765270369439\n",
      "Reconstructed Actor Top-3 Accuracy:\t88.73674774169922\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 82/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005335236005600036\n",
      "Validation Loss:\t\t0.006587437795094726\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011716420276971728\n",
      "End Effector Loss:\t\t0.0029919519444567854\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.001484456742026607\n",
      "Val End Effector Loss:\t\t0.0036185243106315987\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 83/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005331213958273975\n",
      "Validation Loss:\t\t0.006574574797283071\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011683994369512355\n",
      "End Effector Loss:\t\t0.002994415096998563\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014731705456834392\n",
      "Val End Effector Loss:\t\t0.0036282337247721956\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 84/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0053158315470215505\n",
      "Validation Loss:\t\t0.006600828680642684\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011661191001461368\n",
      "End Effector Loss:\t\t0.0029835933442654604\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014828895120291223\n",
      "Val End Effector Loss:\t\t0.0036350496344491313\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 85/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0053094115150957725\n",
      "Validation Loss:\t\t0.00660139774988917\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011639198000568279\n",
      "End Effector Loss:\t\t0.0029815719159060473\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014879836247492792\n",
      "Val End Effector Loss:\t\t0.0036254305110483523\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 86/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005297508761919115\n",
      "Validation Loss:\t\t0.006612817689605897\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011614907150628206\n",
      "End Effector Loss:\t\t0.002974527335181221\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014850191409620916\n",
      "Val End Effector Loss:\t\t0.003642779396204147\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 87/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005285777376202548\n",
      "Validation Loss:\t\t0.006617124298994075\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011574223082606242\n",
      "End Effector Loss:\t\t0.0029709327607078894\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014886984978327003\n",
      "Val End Effector Loss:\t\t0.0036397273143963286\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 88/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0052787460866376\n",
      "Validation Loss:\t\t0.006601744019885508\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011566074541338753\n",
      "End Effector Loss:\t\t0.0029655311780618717\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014815466692851542\n",
      "Val End Effector Loss:\t\t0.0036386506882837228\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 89/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005268987474143439\n",
      "Validation Loss:\t\t0.006635858793742955\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011532124151628484\n",
      "End Effector Loss:\t\t0.0029625626509012146\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014885072848467734\n",
      "Val End Effector Loss:\t\t0.003658844231017931\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 90/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005258453178557861\n",
      "Validation Loss:\t\t0.006585149715890662\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011516832682916753\n",
      "End Effector Loss:\t\t0.0029550866426931235\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014718256558334244\n",
      "Val End Effector Loss:\t\t0.0036414984226699025\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 91/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005249011201777444\n",
      "Validation Loss:\t\t0.006616791334777126\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011480553738848426\n",
      "End Effector Loss:\t\t0.002952900443331222\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014915069832440308\n",
      "Val End Effector Loss:\t\t0.003633777369928717\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "\n",
      "Known Action Accuracy:\t\t78.11395263671875\n",
      "Known Action F1:\t\t\t67.0360145109934\n",
      "Known Action Precision:\t\t68.4033463645557\n",
      "Known Action Recall:\t\t67.49993727477789\n",
      "Known Action Top-3 Accuracy:\t90.13912963867188\n",
      "\n",
      "\n",
      "Reconstructed Action Accuracy:\t\t57.35424041748047\n",
      "Reconstructed Action F1:\t\t\t48.28108932928767\n",
      "Reconstructed Action Precision:\t\t55.703949849626014\n",
      "Reconstructed Action Recall:\t\t49.78572362895745\n",
      "Reconstructed Action Top-3 Accuracy:\t76.24778747558594\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Known Actor Accuracy:\t\t91.76236724853516\n",
      "Known Actor F1:\t\t\t91.7428084363867\n",
      "Known Actor Precision:\t\t93.3496430992658\n",
      "Known Actor Recall:\t\t90.39374603563142\n",
      "Known Actor Top-3 Accuracy:\t97.3277359008789\n",
      "\n",
      "\n",
      "Reconstructed Actor Accuracy:\t\t72.19522857666016\n",
      "Reconstructed Actor F1:\t\t\t67.09814078445915\n",
      "Reconstructed Actor Precision:\t\t73.10145421529256\n",
      "Reconstructed Actor Recall:\t\t64.97211857931732\n",
      "Reconstructed Actor Top-3 Accuracy:\t88.89134216308594\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 92/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0052382240393831405\n",
      "Validation Loss:\t\t0.006598064333239806\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011466571201309166\n",
      "End Effector Loss:\t\t0.002944909811543048\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014802342275416637\n",
      "Val End Effector Loss:\t\t0.0036375958884043067\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 93/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0052300838998320135\n",
      "Validation Loss:\t\t0.0066135687094417885\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011442099756711513\n",
      "End Effector Loss:\t\t0.002941663948079075\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014819865158847598\n",
      "Val End Effector Loss:\t\t0.003649595696938185\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 94/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005220037875360295\n",
      "Validation Loss:\t\t0.006616916188570133\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011425344626081703\n",
      "End Effector Loss:\t\t0.0029349689409046433\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014876346837591485\n",
      "Val End Effector Loss:\t\t0.0036416468296600114\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 95/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0052137613028363445\n",
      "Validation Loss:\t\t0.006590204682319202\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011402486437090673\n",
      "End Effector Loss:\t\t0.0029332640149049146\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014746733111063754\n",
      "Val End Effector Loss:\t\t0.003640858085930977\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 96/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005202358199293336\n",
      "Validation Loss:\t\t0.006599778118444948\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011380312694737613\n",
      "End Effector Loss:\t\t0.0029262956659920594\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014779317144773454\n",
      "Val End Effector Loss:\t\t0.0036439146882605174\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 97/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005193878483434571\n",
      "Validation Loss:\t\t0.006634159787544902\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011353802000689016\n",
      "End Effector Loss:\t\t0.0029231180838100623\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014935854076765294\n",
      "Val End Effector Loss:\t\t0.003646988970962104\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 98/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005184717188101439\n",
      "Validation Loss:\t\t0.006594823430698942\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011345840396866289\n",
      "End Effector Loss:\t\t0.002915549105340434\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014750422697930767\n",
      "Val End Effector Loss:\t\t0.00364473887676583\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 99/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.00517996904527279\n",
      "Validation Loss:\t\t0.0066145226018319665\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.001131989091090247\n",
      "End Effector Loss:\t\t0.00291599086165507\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014812411426018898\n",
      "Val End Effector Loss:\t\t0.003652040322776884\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 100/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005164949031221488\n",
      "Validation Loss:\t\t0.006627206324147139\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011290191186446618\n",
      "End Effector Loss:\t\t0.002906910789415168\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014826602537781788\n",
      "Val End Effector Loss:\t\t0.0036618858272485224\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 101/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005159437322555475\n",
      "Validation Loss:\t\t0.006607096530759419\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011272979721100918\n",
      "End Effector Loss:\t\t0.0029048413828522872\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014787574141273197\n",
      "Val End Effector Loss:\t\t0.0036495817008651266\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "\n",
      "Known Action Accuracy:\t\t78.08082580566406\n",
      "Known Action F1:\t\t\t67.25164451102079\n",
      "Known Action Precision:\t\t69.0651361168688\n",
      "Known Action Recall:\t\t67.54763110605792\n",
      "Known Action Top-3 Accuracy:\t89.98453521728516\n",
      "\n",
      "\n",
      "Reconstructed Action Accuracy:\t\t57.70759582519531\n",
      "Reconstructed Action F1:\t\t\t48.294488209158985\n",
      "Reconstructed Action Precision:\t\t55.13006145658378\n",
      "Reconstructed Action Recall:\t\t49.78338142049301\n",
      "Reconstructed Action Top-3 Accuracy:\t76.91033172607422\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Known Actor Accuracy:\t\t91.76236724853516\n",
      "Known Actor F1:\t\t\t91.75945308187269\n",
      "Known Actor Precision:\t\t93.46126431911618\n",
      "Known Actor Recall:\t\t90.30565854333157\n",
      "Known Actor Top-3 Accuracy:\t97.31669616699219\n",
      "\n",
      "\n",
      "Reconstructed Actor Accuracy:\t\t72.27252197265625\n",
      "Reconstructed Actor F1:\t\t\t67.42186538453029\n",
      "Reconstructed Actor Precision:\t\t73.3451363651614\n",
      "Reconstructed Actor Recall:\t\t65.62104894864564\n",
      "Reconstructed Actor Top-3 Accuracy:\t88.54902648925781\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 102/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.005155842127097767\n",
      "Validation Loss:\t\t0.006600948278529858\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011271720697094787\n",
      "End Effector Loss:\t\t0.0029014979872681737\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.00147259298344733\n",
      "Val End Effector Loss:\t\t0.003655762309175719\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n",
      "--------------------\n",
      "Epoch 103/901\n",
      "--------------------\n",
      "Training Loss:\t\t\t0.0051457247449614016\n",
      "Validation Loss:\t\t0.006635518590460571\n",
      "\n",
      "Training Losses:\n",
      "Reconstruction Loss:\t\t0.0011234036457890765\n",
      "End Effector Loss:\t\t0.0028989174552311106\n",
      "Triplet Loss:\t\t\t0.0\n",
      "Privacy Loss:\t\t\t0.0\n",
      "Privacy Loss Dyn:\t\t0.0\n",
      "Privacy Loss Stat:\t\t0.0\n",
      "Utility Loss:\t\t\t0.0\n",
      "Utility Loss Dyn:\t\t0.0\n",
      "Utility Loss Stat:\t\t0.0\n",
      "Discriminator Loss:\t\t0.0\n",
      "\n",
      "Validation Losses:\n",
      "Val Reconstruction Loss:\t0.0014832790172002999\n",
      "Val End Effector Loss:\t\t0.0036689605339246634\n",
      "Val Triplet Loss:\t\t0.0\n",
      "Val Privacy Loss:\t\t0.0\n",
      "Val Privacy Loss Dyn:\t\t0.0\n",
      "Val Privacy Loss Stat:\t\t0.0\n",
      "Val Utility Loss:\t\t0.0\n",
      "Val Utility Loss Dyn:\t\t0.0\n",
      "Val Utility Loss Stat:\t\t0.0\n",
      "Val Discriminator Loss:\t\t0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_stages = [\n",
    "    {'epochs': 500, 'paired': False, 'ae': True, 'ee': True, 'cross': False, 'triplet': False, 'train_emb_adv': False, 'train_discrim_adv': False, 'emb_adv': False, 'discrim_adv': False, 'eval': True, 'sgn_eval': True, 'save': True},\n",
    "    {'epochs': 100, 'paired': False, 'ae': True, 'ee': True, 'cross': False, 'triplet': False, 'train_emb_adv': True, 'train_discrim_adv': True, 'emb_adv': False, 'discrim_adv': False, 'eval': True, 'sgn_eval': True, 'save': True},\n",
    "    {'epochs': 200, 'paired': False, 'ae': True, 'ee': True, 'cross': False, 'triplet': False, 'train_emb_adv': True, 'train_discrim_adv': True, 'emb_adv': True, 'discrim_adv': True, 'eval': True, 'sgn_eval': True, 'save': True},\n",
    "    {'epochs': 100, 'paired': True, 'ae': True, 'ee': True, 'cross': True, 'triplet': False, 'train_emb_adv': True, 'train_discrim_adv': True, 'emb_adv': True, 'discrim_adv': True, 'eval': True, 'sgn_eval': True, 'save': True},\n",
    "    {'epochs': 1, 'paired': True, 'ae': True, 'ee': False, 'cross': False, 'triplet': False, 'train_emb_adv': False, 'train_discrim_adv': False, 'emb_adv': False, 'discrim_adv': False, 'eval': True, 'sgn_eval': True, 'save': True},\n",
    "]\n",
    "total_epochs = sum([stage['epochs'] for stage in training_stages])\n",
    "\n",
    "# mlflow logging\n",
    "try: mlflow.end_run()\n",
    "except: pass\n",
    "mlflow.start_run()\n",
    "mlflow.log_param('total_epochs', total_epochs)\n",
    "mlflow.log_param('batch_size', batch_size)\n",
    "mlflow.log_param('learning_rate', lr)\n",
    "mlflow.log_param('one_dimension_conv', one_dimension_conv)\n",
    "mlflow.log_param('ntu120', ntu_120)\n",
    "mlflow.log_param('train_equal_test', str(not seperate_train_test))\n",
    "mlflow.log_params(model.get_loss_params())\n",
    "\n",
    "# os.mkdir('training_stages_log')\n",
    "training_stage_name = f'training_stages_log/stages{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.json'\n",
    "with open(training_stage_name, 'w') as f:\n",
    "    json.dump(training_stages, f)\n",
    "mlflow.log_artifact(training_stage_name)\n",
    "\n",
    "k=3\n",
    "\n",
    "stages_save_path = f'pretrained/{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "os.mkdir(stages_save_path)\n",
    "\n",
    "for i, stage in enumerate(training_stages):\n",
    "    print('\\nMoving to new stage')\n",
    "    print(stage, '\\n')\n",
    "    for epoch in range(stage['epochs']):\n",
    "        if stage['sgn_eval']:\n",
    "            if validation_acc_freq > 0 and epoch % validation_acc_freq == 0: use_sgn = True\n",
    "            else: use_sgn = False\n",
    "        else: use_sgn = False\n",
    "        if not stage['paired']:\n",
    "            log_dict = train_unpaired(epoch, run_eval=stage['eval'], run_sgn_eval= use_sgn, save=stage['save'], ae=stage['ae'], ee=stage['ee'], triplet=stage['triplet'], use_emb_adv=stage['emb_adv'], use_discrim_adv=stage['discrim_adv'], emb_adv=stage['train_emb_adv'], discrim_adv=stage['train_discrim_adv'], k=k)\n",
    "        else: \n",
    "            log_dict = train_paired(epoch, train_ae=stage['ae'], train_cross=stage['cross'], train_discrim=stage['train_discrim_adv'], train_emb_adv=stage['train_emb_adv'], run_eval=stage['eval'], use_emb_adv=stage['emb_adv'], use_discrim_adv=stage['discrim_adv'], run_sgn_eval= use_sgn, save=stage['save'], k=k)\n",
    "        \n",
    "        for key, value in log_dict.items():\n",
    "            mlflow.log_metric(key, value, step=epoch)\n",
    "\n",
    "    # save model\n",
    "    torch.save(model.state_dict(), f'{stages_save_path}/stage_{i}.pt')\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_video(val_data[0][0][2][:, :, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_video(model(val_data[0][0][2][:, :, :3].unsqueeze(0).to(device), val_data[0][0][2][:, :, 3:].unsqueeze(0).to(device)).squeeze(0).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retargeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retarget():\n",
    "    X_hat_random = {}\n",
    "    X_hat_constant = {}\n",
    "\n",
    "    x2_const = X[random.sample(list(X.keys()), 1)[0]].float().cuda().unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        for file in X:\n",
    "            x1 = X[file].unsqueeze(0)\n",
    "            x2_random = X[random.sample(list(X.keys()), 1)[0]].unsqueeze(0)\n",
    "            X_hat_random[file] = model.eval(x1.float().cuda(), x2_random.float().cuda()).cpu().numpy().squeeze()\n",
    "            X_hat_constant[file] = model.eval(x1.float().cuda(), x2_const).cpu().numpy().squeeze()\n",
    "\n",
    "    # Save results\n",
    "    with open('results/X_hat_random.pkl', 'wb') as f:\n",
    "        pickle.dump(X_hat_random, f)\n",
    "    with open('results/X_hat_constant.pkl', 'wb') as f:\n",
    "        pickle.dump(X_hat_constant, f)\n",
    "\n",
    "# retarget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate utility of other baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymizer_to_sgn(t, max_frames=300):\n",
    "    xyz, frames, joints, actors = t.shape\n",
    "    \n",
    "    # Pre-allocate memory for the output array\n",
    "    X = np.zeros((max_frames, xyz * joints * actors), dtype=np.float32)\n",
    "    \n",
    "    # Reshape the input array for easier manipulation\n",
    "    t_reshaped = t.reshape((frames, -1))\n",
    "    \n",
    "    # Copy over the reshaped data to the pre-allocated output\n",
    "    X[:frames, :t_reshaped.shape[1]] = t_reshaped\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classical MR\n",
    "x_pkl = 'C:\\\\Users\\\\Carrt\\\\OneDrive\\\\Code\\\\Motion Privacy\\\\Defense Models\\\\Mean Skeleton\\\\X_FileNameKey_SingleActor_filtered.pkl'\n",
    "from_moon = False\n",
    "pad_data = False\n",
    "# trim the data to 75 joints\n",
    "\n",
    "# DMR\n",
    "# x_pkl = 'C:\\\\Users\\\\Carrt\\\\OneDrive\\\\Code\\\\Motion Retargeting\\\\results\\\\X_hat_constant.pkl'\n",
    "# from_moon = False\n",
    "# pad_data = True\n",
    "\n",
    "# Moon ResNet\n",
    "# x_pkl = 'C:\\\\Users\\\\Carrt\\\\OneDrive\\\\Code\\\\Motion Privacy\\\\External Repositories\\\\Skeleton-anonymization\\\\X_resnet_file.pkl'\n",
    "# from_moon = True\n",
    "# pad_data = False\n",
    "\n",
    "# Moon UNet\n",
    "# x_pkl = 'C:\\\\Users\\\\Carrt\\\\OneDrive\\\\Code\\\\Motion Privacy\\\\External Repositories\\\\Skeleton-anonymization\\\\X_unet_file.pkl'\n",
    "# from_moon = True\n",
    "# pad_data = False\n",
    "\n",
    "with open(x_pkl, 'rb') as f:\n",
    "    test_x = pickle.load(f)\n",
    "\n",
    "if from_moon:\n",
    "    test_x = {k: v[0] for k, v in test_x.items()}\n",
    "\n",
    "    for file in test_x:\n",
    "        test_x[file] = anonymizer_to_sgn(test_x[file])[:, :75]\n",
    "\n",
    "if pad_data:\n",
    "    # pad data to 300 frames\n",
    "    for file in test_x:\n",
    "        if test_x[file].shape[0] == 1:\n",
    "            test_x[file] = test_x[file][0]\n",
    "        test_x[file] = np.pad(test_x[file], ((0, 300-test_x[file].shape[0]), (0, 0)), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgn_train_x, sgn_train_y, sgn_val_x, sgn_val_y = np.zeros((batch_size, 300, 150)), np.zeros((batch_size, 1)), np.zeros((batch_size, 300, 150)), np.zeros((batch_size, 1))\n",
    "\n",
    "def eval(X_dict):\n",
    "    # Remove NTU120 if needed\n",
    "    if not ntu_120:\n",
    "        X_dict = {k: v for k, v in X_dict.items() if int(k[17:20]) <= 60}\n",
    "\n",
    "    # Convert to tensor\n",
    "    x = np.zeros((len(X_dict), 300, 150), dtype=np.float32)\n",
    "    y_util = np.zeros(len(X_dict))\n",
    "    y_priv = np.zeros(len(X_dict))\n",
    "\n",
    "    for i, file in enumerate(X_dict):\n",
    "        if X_dict[file].shape[1] == 75:\n",
    "            X_dict[file] = np.pad(X_dict[file], ((0, 0), (0, 75)), 'constant')\n",
    "\n",
    "        x[i] = np.array(X_dict[file], dtype=np.float32)\n",
    "        y_util[i] = int(file[17:20])\n",
    "        y_priv[i] = int(file[9:12])\n",
    "\n",
    "    y_util = y_util - 1\n",
    "    y_priv = y_priv - 1\n",
    "    y_util = np.eye(utility_classes)[y_util.astype(int)]\n",
    "    y_priv = np.eye(privacy_classes)[y_priv.astype(int)]\n",
    "\n",
    "    acc, f1, prec, recall, topk = run_sgn_eval(sgn_train_x, sgn_train_y, x, y_util, sgn_val_x, sgn_val_y, 1, sgn_ar, k=3)\n",
    "    print(f'Utility Accuracy:\\t\\t{acc}\\nUtility F1:\\t\\t\\t{f1*100}\\nUtility Precision:\\t\\t{prec*100}\\nUtility Recall:\\t\\t\\t{recall*100}\\n')\n",
    "\n",
    "    acc, f1, prec, recall, topk = run_sgn_eval(sgn_train_x, sgn_train_y, x, y_priv, sgn_val_x, sgn_val_y, 1, sgn_priv, k=3)\n",
    "    print(f'Privacy Accuracy:\\t\\t{acc}\\nPrivacy F1:\\t\\t\\t{f1*100}\\nPrivacy Precision:\\t\\t{prec*100}\\nPrivacy Recall:\\t\\t\\t{recall*100}\\n')\n",
    "\n",
    "# eval(cmr)\n",
    "# eval(resnet)\n",
    "# eval(test_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
