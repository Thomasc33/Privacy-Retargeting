{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from SGN.model import SGN\n",
    "from SGN.data import NTUDataLoaders, AverageMeter\n",
    "from SGN.util import make_dir, get_num_classes\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "one_dimension_conv = False\n",
    "T = 75\n",
    "dataset = 'NTU'\n",
    "device = torch.device('cuda:0')\n",
    "# device = torch.device('cpu')\n",
    "seg = 20\n",
    "lr = 1e-3\n",
    "epochs = 500\n",
    "utility_classes = 120\n",
    "privacy_classes = 106\n",
    "validation_acc_freq = 10 #-1 to disable\n",
    "encoded_channels = (256, 16)\n",
    "batch_size = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Organize\n",
    "\n",
    "X = (frames, joints, pos + orientation)\n",
    "    \n",
    "    (frames, 25, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open('ntu/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "# pad/trim data to T frames and convert to tensor\n",
    "for file, value in X.items():\n",
    "    num_frames = value.shape[0]\n",
    "\n",
    "    # Pad or trim\n",
    "    if num_frames < T:\n",
    "        padding = np.repeat(value[-1][np.newaxis, :, :], T - num_frames, axis=0)\n",
    "        value = np.concatenate((value, padding), axis=0)\n",
    "    elif num_frames > T:\n",
    "        value = value[:T]\n",
    "    \n",
    "    # Convert to tensor and store back\n",
    "    X[file] = torch.from_numpy(value).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_frame(d):\n",
    "    reshaped_data = d.reshape(-1, 3)\n",
    "    x = reshaped_data[:, 0]\n",
    "    y = reshaped_data[:, 1]\n",
    "    z = reshaped_data[:, 2]\n",
    "\n",
    "    df = pd.DataFrame({'x': x, 'y': y, 'z': z})\n",
    "\n",
    "    fig = px.scatter_3d(df, x='x', y='y', z='z', color=np.linspace(1, 25, len(x)),\n",
    "                        color_continuous_scale='Rainbow', title='Interactive 3D Scatter Plot')\n",
    "\n",
    "    fig.update_traces(marker=dict(size=2))\n",
    "\n",
    "    cons = [[0, 1], [1, 20], [20, 2], [2, 3], [20, 8], [8, 9], [9, 10], [10, 11], [11, 23], [11, 24], [20, 4], [4, 5], [5, 6], [6, 7], [7, 21], [7, 22], [0, 16], [16, 17], [17, 18], [18, 19], [0, 12], [12, 13], [13, 14], [14, 15]]\n",
    "\n",
    "    for con in cons:\n",
    "        lx = [x[con[0]], x[con[1]]]\n",
    "        ly = [y[con[0]], y[con[1]]]\n",
    "        lz = [z[con[0]], z[con[1]]]\n",
    "        fig.add_trace(go.Scatter3d(x=lx, y=ly, z=lz, mode='lines', line=dict(color='black', width=2)))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def render_video(d):\n",
    "    cons = [[0, 1], [1, 20], [20, 2], [2, 3], [20, 8], [8, 9], [9, 10], [10, 11], [11, 23], [11, 24], [20, 4], [4, 5], [5, 6], [6, 7], [7, 21], [7, 22], [0, 16], [16, 17], [17, 18], [18, 19], [0, 12], [12, 13], [13, 14], [14, 15]]\n",
    "\n",
    "    frame_data = d[0].reshape(-1, 3)\n",
    "    x = frame_data[:, 0]\n",
    "    y = frame_data[:, 1]\n",
    "    z = frame_data[:, 2]\n",
    "\n",
    "    scatter = go.Scatter3d(x=x, y=y, z=z, mode='markers',\n",
    "                        marker=dict(size=2, color=np.linspace(1, 25, 25), colorscale='Rainbow'))\n",
    "\n",
    "    traces = [scatter]\n",
    "\n",
    "    for con in cons:\n",
    "        lx = [x[con[0]], x[con[1]]]\n",
    "        ly = [y[con[0]], y[con[1]]]\n",
    "        lz = [z[con[0]], z[con[1]]]\n",
    "        line_trace = go.Scatter3d(x=lx, y=ly, z=lz, mode='lines', line=dict(color='black', width=2))\n",
    "        traces.append(line_trace)\n",
    "\n",
    "    layout = go.Layout(updatemenus=[dict(type='buttons', showactive=False,\n",
    "                                        buttons=[dict(label='Play',\n",
    "                                                    method='animate',\n",
    "                                                    args=[None, dict(frame=dict(duration=100, redraw=True), fromcurrent=True)])])],\n",
    "                    sliders=[dict(steps=[])],\n",
    "                    title=\"Animated 3D Scatter Plot with Connections\"\n",
    "            )\n",
    "\n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "\n",
    "    frame_list = []\n",
    "\n",
    "    for i in range(d.shape[0]):\n",
    "        frame_data = d[i].reshape(-1, 3)\n",
    "        x, y, z = frame_data[:, 0], frame_data[:, 1], frame_data[:, 2]\n",
    "    \n",
    "        fig.data[0].x = x\n",
    "        fig.data[0].y = y\n",
    "        fig.data[0].z = z\n",
    "        \n",
    "        center_x, center_y, center_z = x[0], y[0], z[0]\n",
    "        axis_bound = 2\n",
    "\n",
    "        fig.update_layout(scene=dict(\n",
    "            xaxis=dict(range=[center_x - axis_bound, center_x + axis_bound]),\n",
    "            yaxis=dict(range=[center_y - axis_bound, center_y + axis_bound]),\n",
    "            zaxis=dict(range=[center_z - axis_bound, center_z + axis_bound])\n",
    "        ))\n",
    "\n",
    "        frame_traces = []\n",
    "\n",
    "        frame_scatter = go.Scatter3d(x=x, y=y, z=z, mode='markers',\n",
    "                                    marker=dict(size=2, color=np.linspace(1, 25, 25), colorscale='Rainbow'))\n",
    "        frame_traces.append(frame_scatter)\n",
    "\n",
    "        for con in cons:\n",
    "            lx = [x[con[0]], x[con[1]]]\n",
    "            ly = [y[con[0]], y[con[1]]]\n",
    "            lz = [z[con[0]], z[con[1]]]\n",
    "            line_trace = go.Scatter3d(x=lx, y=ly, z=lz, mode='lines', line=dict(color='black', width=2))\n",
    "            frame_traces.append(line_trace)\n",
    "\n",
    "        frame = go.Frame(data=frame_traces, name=f'Frame {i}')\n",
    "        frame_list.append(frame)\n",
    "\n",
    "    fig.frames = frame_list\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Data Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file_name(file_name):\n",
    "    \"\"\"Parses the filename into a dictionary of parts.\"\"\"\n",
    "    parts = file_name.split('C')\n",
    "    S = parts[0][1:]\n",
    "    parts = parts[1].split('P')\n",
    "    C = parts[0]\n",
    "    parts = parts[1].split('R')\n",
    "    P = parts[0]\n",
    "    parts = parts[1].split('A')\n",
    "    R = parts[0]\n",
    "    parts = parts[1].split('.')\n",
    "    A = parts[0]\n",
    "    return {'S': S, 'C': C, 'P': P, 'R': R, 'A': A}\n",
    "\n",
    "def organize_data(data):\n",
    "    organized_data = defaultdict(list)\n",
    "    for file_name, content in data.items():\n",
    "        parts = parse_file_name(file_name)\n",
    "        organized_data[(parts['C'], parts['R'])].append((parts['P'], parts['A'], content))\n",
    "    return organized_data\n",
    "\n",
    "def sample_data(organized_data):\n",
    "    # Pick a random (C, R) pair\n",
    "    cr_pair = random.choice(list(organized_data.keys()))\n",
    "\n",
    "    # Get all (P, A, content) tuples for this (C, R) pair\n",
    "    pa_list = organized_data[cr_pair]\n",
    "\n",
    "    # Pick 2 unique P values and 2 unique A values\n",
    "    random.shuffle(pa_list)\n",
    "    unique_p = set()\n",
    "    unique_a = set()\n",
    "    for p, a, content in pa_list:\n",
    "        if len(unique_p) < 2:\n",
    "            unique_p.add(p)\n",
    "        if len(unique_a) < 2:\n",
    "            unique_a.add(a)\n",
    "        if len(unique_p) == 2 and len(unique_a) == 2:\n",
    "            break\n",
    "\n",
    "    if len(unique_p) < 2 or len(unique_a) < 2:\n",
    "        raise Exception(f'Not enough unique P or A values for (C, R) pair {cr_pair}')\n",
    "\n",
    "    # Form all four (P, A) pairs and get the corresponding content\n",
    "    sampled_data = []\n",
    "    for p in unique_p:\n",
    "        for a in unique_a:\n",
    "            for pa_content in pa_list:\n",
    "                if pa_content[0] == p and pa_content[1] == a:\n",
    "                    sampled_data.append(pa_content)\n",
    "                    break\n",
    "\n",
    "    return sampled_data\n",
    "\n",
    "def gen_samples(samples, data):\n",
    "    d = []\n",
    "    for _ in range(samples):\n",
    "        failed = 0\n",
    "        d_ = []\n",
    "        while len(d_) != 4:\n",
    "            d_ = sample_data(data)\n",
    "            failed += 1\n",
    "            if failed > 100:\n",
    "                print('failed to sample data')\n",
    "                break\n",
    "        d.append(d_)\n",
    "    return np.array(d)\n",
    "\n",
    "organized_data = organize_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_rec_data(X):\n",
    "    # Split data into train and test\n",
    "    X_train_keys, X_test_keys = train_test_split(list(X.keys()), test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create train and test sets\n",
    "    X_train = np.zeros((len(X_train_keys), T, 25, 7))\n",
    "    X_test = np.zeros((len(X_test_keys), T, 25, 7))\n",
    "    for i, key in enumerate(X_train_keys):\n",
    "        X_train[i] = X[key]\n",
    "    for i, key in enumerate(X_test_keys):\n",
    "        X_test[i] = X[key]\n",
    "\n",
    "    # Get actor and action names\n",
    "    train_actors = [parse_file_name(key)['P'] for key in X_train_keys]\n",
    "    test_actors = [parse_file_name(key)['P'] for key in X_test_keys]\n",
    "    train_actions = [parse_file_name(key)['A'] for key in X_train_keys]\n",
    "    test_actions = [parse_file_name(key)['A'] for key in X_test_keys]\n",
    "    \n",
    "    return X_train, X_test, train_actors, train_actions, test_actors, test_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cross_Data(Dataset):\n",
    "    def __init__(self, sampled_data):\n",
    "        self.data = sampled_data\n",
    "        self.x1 = sampled_data[:, 0, 2]\n",
    "        self.x2 = sampled_data[:, 1, 2]\n",
    "        self.y1 = sampled_data[:, 2, 2]\n",
    "        self.y2 = sampled_data[:, 3, 2]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return  self.x1[index][:, :, 0:3], self.x1[index][:, :, 3:7],\\\n",
    "                self.x2[index][:, :, 0:3], self.x2[index][:, :, 3:7],\\\n",
    "                self.y1[index][:, :, 0:3], self.y1[index][:, :, 3:7],\\\n",
    "                self.y2[index][:, :, 0:3], self.y2[index][:, :, 3:7],\\\n",
    "                [float(self.data[index][0][0]), float(self.data[index][3][0])], [float(self.data[index][0][1]), float(self.data[index][1][1])]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class Rec_Data(Dataset):\n",
    "    def __init__(self, X, Actor, Action):\n",
    "        self.X = X\n",
    "        self.Actor = Actor\n",
    "        self.Action = Action\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], float(self.Actor[index]), float(self.Action[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "# Cross Data\n",
    "train_data = gen_samples(1000, organized_data)\n",
    "val_data = gen_samples(200, organized_data)\n",
    "train_dataset = Cross_Data(train_data)\n",
    "val_dataset = Cross_Data(val_data)\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Rec Data\n",
    "rec_train_data, rec_val_data, t_actors, t_actions, v_actors, v_actions = sample_rec_data(X)\n",
    "rec_train_dataset = Rec_Data(rec_train_data, t_actors, t_actions)\n",
    "rec_val_dataset = Rec_Data(rec_val_data, v_actors, v_actions)\n",
    "rec_train_dl = DataLoader(rec_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "rec_val_dl = DataLoader(rec_val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input is size of latent space\n",
    "class Adversary_Emb(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Adversary_Emb, self).__init__()\n",
    "        self.channels = 64\n",
    "        self.conv = nn.ConvTranspose1d(encoded_channels[0], self.channels, 3, 1, 1)\n",
    "        self.ref = nn.ReflectionPad1d(3)\n",
    "        self.pool = nn.MaxPool1d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * (encoded_channels[1] + 6) // 2, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "    \n",
    "class Discriminator(nn.Module): # 1 = real, 0 = fake\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.enc1 = nn.Conv1d(in_channels=T, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc2 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc3 = nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc4 = nn.Conv1d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.ref1 = nn.ReflectionPad1d(3)\n",
    "        self.ref2 = nn.ReflectionPad1d(3)\n",
    "        self.ref3 = nn.ReflectionPad1d(3)\n",
    "        self.ref4 = nn.ReflectionPad1d(3)\n",
    "        self.fc1 = nn.Linear(80, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.acti = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref1(x)\n",
    "        x = self.acti(self.enc1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.ref2(x)\n",
    "        x = self.acti(self.enc2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.ref3(x)\n",
    "        x = self.acti(self.enc3(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.ref4(x)\n",
    "        x = self.acti(self.enc4(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        #flatten\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Retargeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder1D, self).__init__()\n",
    "\n",
    "        self.enc1 = nn.Conv1d(in_channels=T, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc2 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc3 = nn.Conv1d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.enc4 = nn.Conv1d(in_channels=512, out_channels=encoded_channels[0], kernel_size=3, stride=1, padding=1)\n",
    "        self.ref1 = nn.ReflectionPad1d(3)\n",
    "        self.ref2 = nn.ReflectionPad1d(3)\n",
    "        self.ref3 = nn.ReflectionPad1d(3)\n",
    "        self.ref4 = nn.ReflectionPad1d(3)\n",
    "\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.acti = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(encoded_channels[0], encoded_channels[0] * encoded_channels[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref1(x)\n",
    "        x = self.acti(self.enc1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.ref2(x)\n",
    "        x = self.acti(self.enc2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.ref3(x)\n",
    "        x = self.acti(self.enc3(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.ref4(x)\n",
    "        x = self.acti(self.enc4(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.squeeze(-1) \n",
    "        x = self.fc1(x)\n",
    "        x = x.view(-1, *encoded_channels)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Decoder1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder1D, self).__init__()\n",
    "\n",
    "        self.dec1 = nn.ConvTranspose1d(in_channels=encoded_channels[0]*2, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.dec2 = nn.ConvTranspose1d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.dec3 = nn.ConvTranspose1d(in_channels=128, out_channels=96, kernel_size=3, stride=1, padding=1)\n",
    "        self.dec4 = nn.ConvTranspose1d(in_channels=96, out_channels=T, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.ref1 = nn.ReflectionPad1d(3)\n",
    "        self.ref2 = nn.ReflectionPad1d(3)\n",
    "        self.ref3 = nn.ReflectionPad1d(3)\n",
    "        self.ref4 = nn.ReflectionPad1d(3)\n",
    " \n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.up75 = nn.Upsample(size=T, mode='nearest') \n",
    "\n",
    "        self.acti = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref1(x)\n",
    "        x = self.acti(self.dec1(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref2(x)\n",
    "        x = self.acti(self.dec2(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref3(x)\n",
    "        x = self.acti(self.dec3(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref4(x)\n",
    "        x = self.acti(self.dec4(x))\n",
    "        x = self.up75(x)\n",
    "        return x\n",
    "    \n",
    "class Encoder2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder2D, self).__init__()\n",
    "\n",
    "        self.enc1 = nn.Conv2d(in_channels=T, out_channels=12, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.enc2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.enc3 = nn.Conv2d(in_channels=24, out_channels=32, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.enc4 = nn.Conv2d(in_channels=32, out_channels=encoded_channels[0], kernel_size=(3,3), stride=1, padding=1)\n",
    "\n",
    "        self.ref = nn.ReflectionPad2d(1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "        self.acti = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc1 = nn.Linear(encoded_channels[0], encoded_channels[0] * encoded_channels[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.enc1(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.enc2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.enc3(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.enc4(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = x.view(-1, *encoded_channels)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Decoder2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder2D, self).__init__()\n",
    "\n",
    "        self.dec1 = nn.ConvTranspose2d(in_channels=encoded_channels[0]*2, out_channels=256, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.dec2 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.dec3 = nn.ConvTranspose2d(in_channels=128, out_channels=96, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.dec4 = nn.ConvTranspose2d(in_channels=96, out_channels=T, kernel_size=(3,3), stride=1, padding=1)\n",
    "\n",
    "        self.ref = nn.ReflectionPad2d(3)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.up75 = nn.Upsample(size=T, mode='nearest') \n",
    "        self.acti = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.dec1(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.dec2(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.dec3(x))\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.ref(x)\n",
    "        x = self.acti(self.dec4(x))\n",
    "        x = self.up75(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, adv_lr=1e-3, use_adv=True):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        # AutoEncoder Models\n",
    "        if one_dimension_conv:\n",
    "            self.static_encoder = Encoder1D()\n",
    "            self.dynamic_encoder = Encoder1D()\n",
    "            self.decoder = Decoder1D()\n",
    "        else:\n",
    "            self.static_encoder = Encoder2D()\n",
    "            self.dynamic_encoder = Encoder2D()\n",
    "            self.decoder = Decoder1D()\n",
    "\n",
    "        # Adversarial Models\n",
    "        self.use_adv = use_adv\n",
    "        if use_adv:\n",
    "            self.priv_adv = Adversary_Emb(privacy_classes)\n",
    "            self.util_adv = Adversary_Emb(utility_classes)\n",
    "            self.discriminator = Discriminator()\n",
    "\n",
    "            self.priv_optim = torch.optim.Adam(self.priv_adv.parameters(), lr=adv_lr)\n",
    "            self.util_optim = torch.optim.Adam(self.util_adv.parameters(), lr=adv_lr)\n",
    "            self.discriminator_optim = torch.optim.Adam(self.discriminator.parameters(), lr=adv_lr)\n",
    "\n",
    "            # Freeze Adversarial Models\n",
    "            self.priv_adv.eval()\n",
    "            self.util_adv.eval()\n",
    "            self.discriminator.eval()\n",
    "\n",
    "        # Loss Functions\n",
    "        self.triplet_loss = nn.TripletMarginLoss()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        \n",
    "        # Info for loss functions\n",
    "        self.end_effectors = torch.tensor([19, 15, 23, 24, 21, 22, 3]).to(device) * 3\n",
    "        self.chain_lengths = torch.tensor([5, 5, 8, 8, 8, 8, 5]).to(device)\n",
    "\n",
    "        # Lambdas for discounted loss\n",
    "        self.lambda_rec = 3\n",
    "        self.lambda_cross = 1\n",
    "        self.lambda_ee = 2\n",
    "        self.lambda_trip = 0.1\n",
    "        self.lambda_latent = 2\n",
    "        self.lambda_adv_util = 2\n",
    "        self.lambda_adv_priv = 2\n",
    "        self.lambda_adv_disc = 3\n",
    "\n",
    "        # Loss Toggles\n",
    "        self.use_rec_loss = True\n",
    "        self.use_cross_loss = True\n",
    "        self.use_ee_loss = True\n",
    "        self.use_trip_loss = True\n",
    "        self.use_latent_consistency = True\n",
    "\n",
    "    def cross(self, x1, x1_rot, x2, x2_rot):\n",
    "        d1 = self.dynamic_encoder(x1_rot)\n",
    "        d2 = self.dynamic_encoder(x2_rot)\n",
    "        s1 = self.static_encoder(x1)\n",
    "        s2 = self.static_encoder(x2)\n",
    "        \n",
    "        x1_hat = self.decoder(torch.cat((d1, s1), dim=1))\n",
    "        x2_hat = self.decoder(torch.cat((d2, s2), dim=1))\n",
    "        y1_hat = self.decoder(torch.cat((d1, s2), dim=1))\n",
    "        y2_hat = self.decoder(torch.cat((d2, s1), dim=1))\n",
    "\n",
    "        return x1_hat, x2_hat, y1_hat, y2_hat\n",
    "    \n",
    "    def eval(self, x1_rot, x2):\n",
    "        dynamic = self.dynamic_encoder(x1_rot)\n",
    "        static = self.static_encoder(x2)\n",
    "        return self.decoder(torch.cat((dynamic, static), dim=1))\n",
    "\n",
    "    def rec_loss(self, x, x_rot):\n",
    "        d = self.dynamic_encoder(x_rot)\n",
    "        s = self.static_encoder(x)\n",
    "        x_hat = self.decoder(torch.cat((d, s), dim=1))\n",
    "        return self.reconstruction_loss(x, x_hat)\n",
    "    \n",
    "    def loss(self, x1, x1_rot, x2, x2_rot, y1, y1_rot, y2, y2_rot, actors, actions, cross = True, reconstruction = True, emb_adv = True, discrim_adv = True):\n",
    "        d1 = self.dynamic_encoder(x1_rot) # A1\n",
    "        d2 = self.dynamic_encoder(x2_rot) # A2\n",
    "        s1 = self.static_encoder(x1) # P1\n",
    "        s2 = self.static_encoder(x2) # P2\n",
    "\n",
    "        x1_hat = self.decoder(torch.cat((d1, s1), dim=1)) # P1, A1\n",
    "        x2_hat = self.decoder(torch.cat((d2, s2), dim=1)) # P2, A2\n",
    "        y1_hat = self.decoder(torch.cat((d1, s2), dim=1)) # P2, A1\n",
    "        y2_hat = self.decoder(torch.cat((d2, s1), dim=1)) # P1, A2\n",
    "\n",
    "        d12 = self.dynamic_encoder(y1_rot) # A1\n",
    "        d21 = self.dynamic_encoder(y2_rot) # A2\n",
    "        s12 = self.static_encoder(y1) # P2\n",
    "        s21 = self.static_encoder(y2) # P1\n",
    "\n",
    "        x1_hat_ = self.decoder(torch.cat((d12, s21), dim=1)) # P1, A1\n",
    "        x2_hat_ = self.decoder(torch.cat((d21, s12), dim=1)) # P2, A2\n",
    "        y1_hat_ = self.decoder(torch.cat((d12, s12), dim=1)) # P2, A1\n",
    "        y2_hat_ = self.decoder(torch.cat((d21, s21), dim=1)) # P1, A2\n",
    "\n",
    "        # flatten data if 2D\n",
    "        if not one_dimension_conv:\n",
    "            x1 = x1.view(x1.size(0), T, -1)\n",
    "            x2 = x2.view(x2.size(0), T, -1)\n",
    "            y1 = y1.view(y1.size(0), T, -1)\n",
    "            y2 = y2.view(y2.size(0), T, -1)\n",
    "        \n",
    "        # initialize all losses to 0 tensor\n",
    "        rec_loss = torch.zeros(1).to(device)\n",
    "        cross_loss = torch.zeros(1).to(device)\n",
    "        end_effector_loss = torch.zeros(1).to(device)\n",
    "        triplet_loss = torch.zeros(1).to(device)\n",
    "        latent_consistency_loss = torch.zeros(1).to(device)\n",
    "        privacy_loss = torch.zeros(1).to(device)\n",
    "        privacy_loss_dyn = torch.zeros(1).to(device)\n",
    "        privacy_loss_stat = torch.zeros(1).to(device)\n",
    "        privacy_acc_dyn = torch.zeros(1).to(device)\n",
    "        privacy_acc_stat = torch.zeros(1).to(device)\n",
    "        utility_loss = torch.zeros(1).to(device)\n",
    "        utility_loss_dyn = torch.zeros(1).to(device)\n",
    "        utility_loss_stat = torch.zeros(1).to(device)\n",
    "        utility_acc_dyn = torch.zeros(1).to(device)\n",
    "        utility_acc_stat = torch.zeros(1).to(device)\n",
    "        discriminator_loss = torch.zeros(1).to(device)\n",
    "        discriminator_acc = torch.zeros(1).to(device)\n",
    "                        \n",
    "        # reconstruction loss\n",
    "        if self.use_rec_loss and reconstruction:\n",
    "            rec_loss = self.reconstruction_loss(x1, x1_hat) + self.reconstruction_loss(x2, x2_hat) + self.reconstruction_loss(y1, y1_hat_) + self.reconstruction_loss(y2, y2_hat_)\n",
    "            # print('Reconstruction Loss: ', rec_loss.item())\n",
    "        \n",
    "        # cross reconstruction loss\n",
    "        if self.use_cross_loss and cross:\n",
    "            cross_loss = self.cross_loss(y1, y2, y1_hat, y2_hat) + self.cross_loss(x1, x2, x1_hat_, x2_hat_)\n",
    "            # print('Cross Reconstruction Loss: ', cross_loss.item())\n",
    "        \n",
    "        # end effector loss\n",
    "        if self.use_ee_loss:\n",
    "            if reconstruction:\n",
    "                end_effector_loss += self.end_effector_loss(x1_hat, x1) + self.end_effector_loss(x2_hat, x2)\n",
    "            if cross:\n",
    "                end_effector_loss += self.end_effector_loss(y1_hat, y1) + self.end_effector_loss(y2_hat, y2)\n",
    "            # print('End Effector Loss: ', end_effector_loss.item())\n",
    "\n",
    "        # triplet loss\n",
    "        if self.use_trip_loss:\n",
    "            triplet_loss = self.triplet_loss(d12, d1, d2) + self.triplet_loss(d21, d2, d1) + self.triplet_loss(s12, s1, s2) + self.triplet_loss(s21, s2, s1) \n",
    "            # print('Triplet Loss: ', triplet_loss.item())\n",
    "\n",
    "        # latent consistency loss\n",
    "        if self.use_latent_consistency:\n",
    "            latent_consistency_loss = self.latent_consistency_loss(d1, d12) + self.latent_consistency_loss(d2, d21) + self.latent_consistency_loss(s1, s21) + self.latent_consistency_loss(s2, s12)\n",
    "            # print('Latent Consistency Loss: ', latent_consistency_loss.item())\n",
    "\n",
    "        # adversarial loss\n",
    "        if self.use_adv and emb_adv:\n",
    "            # sgn latent privacy loss (adversarial)\n",
    "            adv_priv_y1, adv_priv_y2 = actors[0] - 1, actors[1] - 1\n",
    "            adv_priv_y1, adv_priv_y2 = torch.eye(privacy_classes)[adv_priv_y1.long()].to(device), torch.eye(privacy_classes)[adv_priv_y2.long()].to(device)\n",
    "            privacy_loss_dyn = -(self.adv_loss(self.priv_adv, d1, adv_priv_y1) + self.adv_loss(self.priv_adv, d2, adv_priv_y2))\n",
    "            privacy_loss_stat = (self.adv_loss(self.priv_adv, s1, adv_priv_y1) + self.adv_loss(self.priv_adv, s2, adv_priv_y2))\n",
    "            privacy_loss = privacy_loss_dyn + privacy_loss_stat\n",
    "            # print('Privacy Loss Dynamic: ', privacy_loss_dyn.item(), '\\tPrivacy Loss Static: ', privacy_loss_stat.item(), '\\tPrivacy Loss: ', privacy_loss.item())\n",
    "\n",
    "            privacy_acc_dyn = (self.adv_accuracy(self.priv_adv, d1, adv_priv_y1) + self.adv_accuracy(self.priv_adv, d2, adv_priv_y2)) / 2\n",
    "            privacy_acc_stat = (self.adv_accuracy(self.priv_adv, s1, adv_priv_y1) + self.adv_accuracy(self.priv_adv, s2, adv_priv_y2)) / 2\n",
    "            # print('Privacy Accuracy Dynamic: ', privacy_acc_dyn.item(), '\\tPrivacy Accuracy Static: ', privacy_acc_stat.item())\n",
    "            \n",
    "            # sgn latent utility loss (adversarial)\n",
    "            adv_util_y1, adv_util_y2 = actions[0] - 1, actions[1] - 1\n",
    "            adv_util_y1, adv_util_y2 = torch.eye(utility_classes)[adv_util_y1.long()].to(device), torch.eye(utility_classes)[adv_util_y2.long()].to(device)\n",
    "            utility_loss_dyn = (self.adv_loss(self.util_adv, d1, adv_util_y1) + self.adv_loss(self.util_adv, d2, adv_util_y2))\n",
    "            utility_loss_stat = -(self.adv_loss(self.util_adv, s1, adv_util_y1) + self.adv_loss(self.util_adv, s2, adv_util_y2))\n",
    "            utility_loss = utility_loss_dyn + utility_loss_stat\n",
    "            # print('Utility Loss Dynamic: ', utility_loss_dyn.item(), '\\tUtility Loss Static: ', utility_loss_stat.item(), '\\tUtility Loss: ', utility_loss.item())\n",
    "\n",
    "            utility_acc_dyn = (self.adv_accuracy(self.util_adv, d1, adv_util_y1) + self.adv_accuracy(self.util_adv, d2, adv_util_y2)) / 2\n",
    "            utility_acc_stat = (self.adv_accuracy(self.util_adv, s1, adv_util_y1) + self.adv_accuracy(self.util_adv, s2, adv_util_y2)) / 2\n",
    "            # print('Utility Accuracy Dynamic: ', utility_acc_dyn.item(), '\\tUtility Accuracy Static: ', utility_acc_stat.item())\n",
    "\n",
    "        if self.use_adv and discrim_adv:\n",
    "            # discrimnator (adversarial)\n",
    "            discrim_out_fake = self.discriminator(torch.cat((x1_hat, x2_hat, y1_hat, y2_hat, x1_hat_, x2_hat_, y1_hat_, y2_hat_)))\n",
    "            discriminator_loss = self.bce_loss(discrim_out_fake, torch.ones_like(discrim_out_fake))\n",
    "            discriminator_acc = torch.sum(torch.round(discrim_out_fake) == 0).float() / (8 * batch_size)\n",
    "            # print('Discriminator Loss: ', discriminator_loss.item(), '\\tDiscriminator Accuracy: ', discriminator_acc.item())\n",
    "\n",
    "        losses = {\n",
    "            'rec_loss': rec_loss.item(),\n",
    "            'cross_loss': cross_loss.item(),\n",
    "            'end_effector_loss': end_effector_loss.item(),\n",
    "            'triplet_loss': triplet_loss.item(),\n",
    "            'latent_consistency_loss': latent_consistency_loss.item(),\n",
    "            'privacy_loss': privacy_loss.item(),\n",
    "            'privacy_loss_dyn': privacy_loss_dyn.item(),\n",
    "            'privacy_loss_stat': privacy_loss_stat.item(),\n",
    "            'privacy_acc_dyn': privacy_acc_dyn.item(),\n",
    "            'privacy_acc_stat': privacy_acc_stat.item(),\n",
    "            'utility_loss': utility_loss.item(),\n",
    "            'utility_loss_dyn': utility_loss_dyn.item(),\n",
    "            'utility_loss_stat': utility_loss_stat.item(),\n",
    "            'utility_acc_dyn': utility_acc_dyn.item(),\n",
    "            'utility_acc_stat': utility_acc_stat.item(),\n",
    "            'discriminator_loss': discriminator_loss.item(),\n",
    "            'discriminator_acc': discriminator_acc.item()\n",
    "        }\n",
    "\n",
    "        return rec_loss * self.lambda_rec \\\n",
    "                + cross_loss * self.lambda_cross \\\n",
    "                + end_effector_loss * self.lambda_ee \\\n",
    "                + triplet_loss * self.lambda_trip \\\n",
    "                + latent_consistency_loss * self.lambda_latent \\\n",
    "                + privacy_loss * self.lambda_adv_priv \\\n",
    "                + utility_loss * self.lambda_adv_util \\\n",
    "                + discriminator_loss * self.lambda_adv_disc, \\\n",
    "                x1_hat, x2_hat, y1_hat, y2_hat, losses\n",
    "\n",
    "    def reconstruction_loss(self, x, y):\n",
    "        # return torch.square(torch.norm(x - y, dim=1)).mean()\n",
    "        return F.mse_loss(x, y)\n",
    "    \n",
    "    def cross_loss(self, x1, x2, y1, y2):\n",
    "        # return torch.square(torch.norm(x1 - y2, dim=1)).mean() + torch.square(torch.norm(x2 - y1, dim=1)).mean()\n",
    "        return F.mse_loss(x1, y1) + F.mse_loss(x2, y2)\n",
    "    \n",
    "    def latent_consistency_loss(self, x, y):\n",
    "        return F.mse_loss(x, y)\n",
    "    \n",
    "    def end_effector_loss(self, x, y):\n",
    "        # slice to get the end effector joints\n",
    "        x_ee = x[:, :, self.end_effectors.unsqueeze(-1) + torch.arange(3).to(device)] \n",
    "        y_ee = y[:, :, self.end_effectors.unsqueeze(-1) + torch.arange(3).to(device)]\n",
    "\n",
    "        # calculate velocities\n",
    "        x_vel = torch.norm(x_ee[:, 1:] - x_ee[:, :-1], dim=-1) / self.chain_lengths.unsqueeze(0)\n",
    "        y_vel = torch.norm(y_ee[:, 1:] - y_ee[:, :-1], dim=-1) / self.chain_lengths.unsqueeze(0)\n",
    "        \n",
    "        # compute mse loss for each joint\n",
    "        losses = F.mse_loss(x_vel, y_vel, reduction='none')\n",
    "\n",
    "        # take sum over end effectors\n",
    "        loss = losses.sum(dim=1)\n",
    "\n",
    "        # take mean over batch\n",
    "        loss = loss.mean()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def adv_loss(self, model, x, y):\n",
    "        return F.cross_entropy(model(x), y)\n",
    "    \n",
    "    def adv_accuracy(self, model, x, y):\n",
    "        return (model(x).argmax(dim=1) == y.argmax(dim=1)).float().mean()\n",
    "\n",
    "    def train_adv(self, x1, x1_rot, x2, x2_rot, y1, y1_rot, y2, y2_rot, actors, actions, train_emb = True, train_discrim = True):\n",
    "        if not self.use_adv: return 0,0\n",
    "        # freeze encoders/decoder\n",
    "        self.dynamic_encoder.eval()\n",
    "        self.static_encoder.eval()\n",
    "        self.decoder.eval()\n",
    "\n",
    "        # unfreeze adversaries\n",
    "        self.priv_adv.train()\n",
    "        self.util_adv.train()\n",
    "        self.discriminator.train()\n",
    "\n",
    "        # zero out gradients\n",
    "        self.priv_optim.zero_grad()\n",
    "        self.util_optim.zero_grad()\n",
    "        self.discriminator_optim.zero_grad()\n",
    "\n",
    "        # encode\n",
    "        d1 = self.dynamic_encoder(x1_rot)\n",
    "        d2 = self.dynamic_encoder(x2_rot)\n",
    "        d3 = self.dynamic_encoder(y1_rot)\n",
    "        d4 = self.dynamic_encoder(y2_rot)\n",
    "        s1 = self.static_encoder(x1)\n",
    "        s2 = self.static_encoder(x2)\n",
    "        s3 = self.static_encoder(y1)\n",
    "        s4 = self.static_encoder(y2)\n",
    "\n",
    "        # decode\n",
    "        x1_hat = self.decoder(torch.cat((d1, s1), dim=1))\n",
    "        x2_hat = self.decoder(torch.cat((d2, s2), dim=1))\n",
    "        y1_hat = self.decoder(torch.cat((d3, s3), dim=1))\n",
    "        y2_hat = self.decoder(torch.cat((d4, s4), dim=1))\n",
    "\n",
    "        # instantiate losses\n",
    "        priv_loss = torch.zeros(1).to(device)\n",
    "        util_loss = torch.zeros(1).to(device)\n",
    "        discriminator_loss = torch.zeros(1).to(device)\n",
    "\n",
    "        if train_emb:\n",
    "            # train privacy adversary\n",
    "            p1, p2 = actors[0] - 1, actors[1] - 1\n",
    "            p1, p2 = torch.eye(privacy_classes)[p1.long()].to(device), torch.eye(privacy_classes)[p2.long()].to(device)\n",
    "            priv_loss = F.cross_entropy(self.priv_adv(s1), p1) + F.cross_entropy(self.priv_adv(s2), p2) + F.cross_entropy(self.priv_adv(s3), p2) + F.cross_entropy(self.priv_adv(s4), p1)\n",
    "            priv_loss.backward(retain_graph=True)\n",
    "            self.priv_optim.step()\n",
    "            \n",
    "            # train utility adversary\n",
    "            a1, a2 = actions[0] - 1, actions[1] - 1\n",
    "            a1, a2 = torch.eye(utility_classes)[a1.long()].to(device), torch.eye(utility_classes)[a2.long()].to(device)\n",
    "            util_loss = F.cross_entropy(self.util_adv(d1), a1) + F.cross_entropy(self.util_adv(d2), a2) + F.cross_entropy(self.util_adv(d3), a1) + F.cross_entropy(self.util_adv(d4), a2)\n",
    "            util_loss.backward(retain_graph=True)\n",
    "            self.util_optim.step()\n",
    "\n",
    "        if train_discrim:\n",
    "            # train discriminator\n",
    "            output_real = self.discriminator(torch.cat((x1.view(x1.size(0), T, -1), x2.view(x2.size(0), T, -1), y1.view(y1.size(0), T, -1), y2.view(y1.size(0), T, -1))))\n",
    "            output_fake = self.discriminator(torch.cat((x1_hat, x2_hat, y1_hat, y2_hat)))\n",
    "            discriminator_loss = self.bce_loss(output_real, torch.ones_like(output_real)) + self.bce_loss(output_fake, torch.zeros_like(output_fake))\n",
    "            discriminator_loss.backward()\n",
    "            self.discriminator_optim.step()\n",
    "\n",
    "        # unfreeze encoders/decoder\n",
    "        self.dynamic_encoder.train()\n",
    "        self.static_encoder.train()\n",
    "        self.decoder.train()\n",
    "\n",
    "        # freeze adversaries\n",
    "        self.priv_adv.eval()\n",
    "        self.util_adv.eval()\n",
    "        self.discriminator.eval()\n",
    "\n",
    "        return priv_loss.item(), util_loss.item(), discriminator_loss.item()\n",
    "\n",
    "    def forward(self, x, x_rot):\n",
    "        dyn = self.dynamic_encoder(x_rot)\n",
    "        sta = self.static_encoder(x)\n",
    "        x = self.decoder(torch.cat((dyn, sta), dim=1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility/Privacy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model):\n",
    "    acces = AverageMeter()\n",
    "    # load learnt model that obtained best performance on validation set\n",
    "    model.eval()\n",
    "\n",
    "    label_output = list()\n",
    "    pred_output = list()\n",
    "\n",
    "    for i, t in enumerate(test_loader):\n",
    "        inputs = t[0]\n",
    "        target = t[1]\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs.cuda())\n",
    "            output = output.view(\n",
    "                (-1, inputs.size(0)//target.size(0), output.size(1)))\n",
    "            output = output.mean(1)\n",
    "\n",
    "        label_output.append(target.cpu().numpy())\n",
    "        pred_output.append(output.cpu().numpy())\n",
    "\n",
    "        acc = accuracy(output.data, target.cuda())\n",
    "        acces.update(acc[0], inputs.size(0))\n",
    "\n",
    "    label_output = np.concatenate(label_output, axis=0)\n",
    "    pred_output = np.concatenate(pred_output, axis=0)\n",
    "\n",
    "    label_index = np.argmax(label_output, axis=1)\n",
    "    pred_index = np.argmax(pred_output, axis=1)\n",
    "\n",
    "    f1 = f1_score(label_index, pred_index, average='macro', zero_division=0)\n",
    "    precision = precision_score(label_index, pred_index, average='macro', zero_division=0)\n",
    "    recall = recall_score(label_index, pred_index, average='macro', zero_division=0)\n",
    "\n",
    "    return acces.avg, f1, precision, recall\n",
    "    \n",
    "def accuracy(output, target):\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    target = torch.argmax(target, dim=1)  # Add this line to convert one-hot targets to class indices\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    correct = correct.view(-1).float().sum(0, keepdim=True)\n",
    "    return correct.mul_(100.0 / batch_size)\n",
    "    \n",
    "def run_sgn_eval(train_x, train_y, test_x, test_y, val_x, val_y, case, model):\n",
    "    # Data loading\n",
    "    ntu_loaders = NTUDataLoaders(dataset, case, seg=20, train_X=train_x, train_Y=train_y, test_X=test_x, test_Y=test_y, val_X=val_x, val_Y=val_y, aug=0)\n",
    "    test_loader = ntu_loaders.get_test_loader(batch_size, 16)\n",
    "\n",
    "    # Test\n",
    "    return test(test_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "if load_model:\n",
    "    model.load_state_dict(torch.load('pretrained/MR.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_util = True\n",
    "train_util = False\n",
    "sgn_ar = SGN(utility_classes, None, seg, batch_size, 0).to(device)\n",
    "sgn_priv = SGN(privacy_classes, None, seg, batch_size, 0).to(device)\n",
    "\n",
    "if load_util:\n",
    "    sgn_priv.load_state_dict(torch.load('SGN/pretrained/privacy.pt')['state_dict'])\n",
    "    sgn_ar.load_state_dict(torch.load('SGN/pretrained/action.pt')['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Motion Retargeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgn_train_x, sgn_train_y, sgn_val_x, sgn_val_y = np.zeros((batch_size, 300, 150)), np.zeros((batch_size, 1)), np.zeros((batch_size, 300, 150)), np.zeros((batch_size, 1))\n",
    "\n",
    "best_loss = float('inf')\n",
    "total_epochs = -1\n",
    "cur_tot_epoch = 0\n",
    "\n",
    "def train(epoch, train_ae = True, train_cross = True, train_discrim = True, train_emb_adv = True, run_eval = True, use_adv_loss = True, run_sgn_eval = False, save = True):\n",
    "    global best_loss\n",
    "    global total_epochs\n",
    "    global cur_tot_epoch\n",
    "    # Assertions\n",
    "    assert train_ae or train_cross or train_discrim or train_emb_adv, \"At least one of the training objectives must be True\"\n",
    "    assert not (run_sgn_eval and not run_eval), \"If run_sgn_eval is True, then run_eval must be True\"\n",
    "    \n",
    "    # Store eval values for validation\n",
    "    eval_X_known, eval_Y_known_action, eval_Y_known_actor, eval_X_rec, eval_Y_rec_action, eval_Y_rec_actor, eval_X, eval_Y_action, eval_Y_actor = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "    # Losses for printing\n",
    "    losses = []\n",
    "    rec_loss, cross_loss, end_effector_loss, triplet_loss, latent_consistency_loss, privacy_loss, privacy_loss_dyn, privacy_loss_stat, privacy_acc_dyn, privacy_acc_stat, priv_training_loss, utility_loss, utility_loss_dyn, utility_loss_stat, utility_acc_dyn, utility_acc_stat, util_training_loss, discriminator_loss, discriminator_train_losses, discriminator_training_acc = [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "    for (x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot, actors, actions) in train_dl:\n",
    "        # Move tensors to the configured device\n",
    "        x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot = x1_pos.float().to(device), x1_rot.float().to(device), x2_pos.float().to(device), x2_rot.float().to(device), y1_pos.float().to(device), y1_rot.float().to(device), y2_pos.float().to(device), y2_rot.float().to(device)\n",
    "        \n",
    "        # For 1D convolutions, flatten the data\n",
    "        if one_dimension_conv:\n",
    "            x1_pos = x1_pos.view(x1_pos.size(0), T, -1)\n",
    "            x1_rot = x1_rot.view(x1_rot.size(0), T, -1)\n",
    "            x2_pos = x2_pos.view(x2_pos.size(0), T, -1)\n",
    "            x2_rot = x2_rot.view(x2_rot.size(0), T, -1)\n",
    "            y1_pos = y1_pos.view(y1_pos.size(0), T, -1)\n",
    "            y1_rot = y1_rot.view(y1_rot.size(0), T, -1)\n",
    "            y2_pos = y2_pos.view(y2_pos.size(0), T, -1)\n",
    "            y2_rot = y2_rot.view(y2_rot.size(0), T, -1)\n",
    "\n",
    "        \n",
    "        if train_discrim or train_emb_adv:\n",
    "            # Train the discriminator\n",
    "            priv_train_loss, util_train_loss, discriminator_train_loss = model.train_adv(x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot, actors, actions, train_emb=train_emb_adv, train_discrim=train_discrim)\n",
    "            \n",
    "            # Track the loss\n",
    "            priv_training_loss.append(priv_train_loss)\n",
    "            util_training_loss.append(util_train_loss)\n",
    "            discriminator_train_losses.append(discriminator_train_loss)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Train the autoencoder/cross reconstruction\n",
    "        if train_ae or train_cross:\n",
    "            # Forward pass\n",
    "            loss, _, _, _, _, losses_ = model.loss(x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot, actors, actions, cross=train_cross, reconstruction=train_ae, emb_adv=(train_emb_adv and use_adv_loss), discrim_adv=(train_discrim and use_adv_loss))\n",
    "\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track the loss\n",
    "            losses.append(loss.item())\n",
    "            rec_loss.append(losses_['rec_loss'])\n",
    "            cross_loss.append(losses_['cross_loss'])\n",
    "            end_effector_loss.append(losses_['end_effector_loss'])\n",
    "            latent_consistency_loss.append(losses_['latent_consistency_loss'])\n",
    "            triplet_loss.append(losses_['triplet_loss'])\n",
    "            privacy_loss.append(losses_['privacy_loss'])\n",
    "            privacy_loss_dyn.append(losses_['privacy_loss_dyn'])\n",
    "            privacy_loss_stat.append(losses_['privacy_loss_stat'])\n",
    "            privacy_acc_dyn.append(losses_['privacy_acc_dyn'])\n",
    "            privacy_acc_stat.append(losses_['privacy_acc_stat'])\n",
    "            utility_loss.append(losses_['utility_loss'])\n",
    "            utility_loss_dyn.append(losses_['utility_loss_dyn'])\n",
    "            utility_loss_stat.append(losses_['utility_loss_stat'])\n",
    "            utility_acc_dyn.append(losses_['utility_acc_dyn'])\n",
    "            utility_acc_stat.append(losses_['utility_acc_stat'])\n",
    "            discriminator_loss.append(losses_['discriminator_loss'])\n",
    "            discriminator_training_acc.append(losses_['discriminator_acc'])\n",
    "        \n",
    "    # Decay learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    if run_eval:\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "            val_rec_loss, val_cross_loss, val_end_effector_loss, val_triplet_loss, val_latent_consistency_loss, val_privacy_loss, val_privacy_loss_dyn, val_privacy_loss_stat, val_privacy_acc_dyn, val_privacy_acc_stat, val_utility_loss, val_utility_loss_dyn, val_utility_loss_stat, val_utility_acc_dyn, val_utility_acc_stat, val_discriminator_loss, val_discriminator_acc = [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "            \n",
    "            for (x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot, actors, actions) in val_dl:\n",
    "                x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot = x1_pos.float().to(device), x1_rot.float().to(device), x2_pos.float().to(device), x2_rot.float().to(device), y1_pos.float().to(device), y1_rot.float().to(device), y2_pos.float().to(device), y2_rot.float().to(device)\n",
    "\n",
    "                # For 1D convolutions, flatten the data\n",
    "                if one_dimension_conv:\n",
    "                    x1_pos = x1_pos.view(x1_pos.size(0), T, -1)\n",
    "                    x1_rot = x1_rot.view(x1_rot.size(0), T, -1)\n",
    "                    x2_pos = x2_pos.view(x2_pos.size(0), T, -1)\n",
    "                    x2_rot = x2_rot.view(x2_rot.size(0), T, -1)\n",
    "                    y1_pos = y1_pos.view(y1_pos.size(0), T, -1)\n",
    "                    y1_rot = y1_rot.view(y1_rot.size(0), T, -1)\n",
    "                    y2_pos = y2_pos.view(y2_pos.size(0), T, -1)\n",
    "                    y2_rot = y2_rot.view(y2_rot.size(0), T, -1)\n",
    "                \n",
    "                loss, x1_hat, x2_hat, y1_hat, y2_hat, losses_ = model.loss(x1_pos, x1_rot, x2_pos, x2_rot, y1_pos, y1_rot, y2_pos, y2_rot, actors, actions, cross=train_cross, reconstruction=train_ae, emb_adv=(train_emb_adv and use_adv_loss), discrim_adv=(train_discrim and use_adv_loss))\n",
    "                val_losses.append(loss.item())\n",
    "                val_rec_loss.append(losses_['rec_loss'])\n",
    "                val_cross_loss.append(losses_['cross_loss'])\n",
    "                val_end_effector_loss.append(losses_['end_effector_loss'])\n",
    "                val_triplet_loss.append(losses_['triplet_loss'])\n",
    "                val_latent_consistency_loss.append(losses_['latent_consistency_loss'])\n",
    "                val_privacy_loss.append(losses_['privacy_loss'])\n",
    "                val_privacy_loss_dyn.append(losses_['privacy_loss_dyn'])\n",
    "                val_privacy_loss_stat.append(losses_['privacy_loss_stat'])\n",
    "                val_privacy_acc_dyn.append(losses_['privacy_acc_dyn'])\n",
    "                val_privacy_acc_stat.append(losses_['privacy_acc_stat'])\n",
    "                val_utility_loss.append(losses_['utility_loss'])\n",
    "                val_utility_loss_dyn.append(losses_['utility_loss_dyn'])\n",
    "                val_utility_loss_stat.append(losses_['utility_loss_stat'])\n",
    "                val_utility_acc_dyn.append(losses_['utility_acc_dyn'])\n",
    "                val_utility_acc_stat.append(losses_['utility_acc_stat'])\n",
    "                val_discriminator_loss.append(losses_['discriminator_loss'])\n",
    "                val_discriminator_acc.append(losses_['discriminator_acc'])\n",
    "\n",
    "                if run_sgn_eval:\n",
    "                    if not one_dimension_conv:\n",
    "                        x1_pos = x1_pos.view(x1_pos.size(0), T, -1)\n",
    "                        x2_pos = x2_pos.view(x2_pos.size(0), T, -1)\n",
    "                        y1_pos = y1_pos.view(y1_pos.size(0), T, -1)\n",
    "                        y2_pos = y2_pos.view(y2_pos.size(0), T, -1)\n",
    "                        \n",
    "                    eval_X_known.append(x1_pos.cpu().numpy())\n",
    "                    eval_X_known.append(x2_pos.cpu().numpy())\n",
    "                    eval_X_known.append(y1_pos.cpu().numpy())\n",
    "                    eval_X_known.append(y2_pos.cpu().numpy())\n",
    "\n",
    "                    eval_Y_known_action.append(actions[0].cpu().numpy())\n",
    "                    eval_Y_known_action.append(actions[1].cpu().numpy())\n",
    "                    eval_Y_known_action.append(actions[0].cpu().numpy())\n",
    "                    eval_Y_known_action.append(actions[1].cpu().numpy())\n",
    "\n",
    "                    eval_Y_known_actor.append(actors[0].cpu().numpy())\n",
    "                    eval_Y_known_actor.append(actors[1].cpu().numpy())\n",
    "                    eval_Y_known_actor.append(actors[1].cpu().numpy())\n",
    "                    eval_Y_known_actor.append(actors[0].cpu().numpy())\n",
    "\n",
    "                    eval_X_rec.append(x1_hat.cpu().numpy())\n",
    "                    eval_X_rec.append(x2_hat.cpu().numpy())\n",
    "                    eval_X.append(y1_hat.cpu().numpy())\n",
    "                    eval_X.append(y2_hat.cpu().numpy())\n",
    "\n",
    "                    eval_Y_rec_action.append(actions[0].cpu().numpy())\n",
    "                    eval_Y_rec_action.append(actions[1].cpu().numpy())\n",
    "                    eval_Y_action.append(actions[0].cpu().numpy())\n",
    "                    eval_Y_action.append(actions[1].cpu().numpy())\n",
    "\n",
    "                    eval_Y_rec_actor.append(actors[0].cpu().numpy())\n",
    "                    eval_Y_rec_actor.append(actors[1].cpu().numpy())\n",
    "                    eval_Y_actor.append(actors[1].cpu().numpy())\n",
    "                    eval_Y_actor.append(actors[0].cpu().numpy())\n",
    "\n",
    "    # Print loss/accuracy\n",
    "    print(f'--------------------\\nEpoch {cur_tot_epoch+1}/{total_epochs}\\n--------------------')\n",
    "    cur_tot_epoch += 1\n",
    "    \n",
    "    if train_ae or train_cross:\n",
    "        print(f'Training Loss:\\t\\t\\t{np.mean(losses)}\\nValidation Loss:\\t\\t{np.mean(val_losses)}')\n",
    "        print('\\nTraining Losses:')\n",
    "        print(f'Reconstruction Loss:\\t\\t{np.mean(rec_loss)}\\nCross Reconstruction Loss:\\t{np.mean(cross_loss)}\\nEnd Effector Loss:\\t\\t{np.mean(end_effector_loss)}\\nTriplet Loss:\\t\\t\\t{np.mean(triplet_loss)}\\nLatent Consistency Loss:\\t{np.mean(latent_consistency_loss)}')\n",
    "        print(f'Privacy Loss:\\t\\t\\t{np.mean(privacy_loss)}\\nPrivacy Loss Dyn:\\t\\t{np.mean(privacy_loss_dyn)}\\nPrivacy Loss Stat:\\t\\t{np.mean(privacy_loss_stat)}')\n",
    "        print(f'Utility Loss:\\t\\t\\t{np.mean(utility_loss)}\\nUtility Loss Dyn:\\t\\t{np.mean(utility_loss_dyn)}\\nUtility Loss Stat:\\t\\t{np.mean(utility_loss_stat)}')\n",
    "        print(f'Discriminator Loss:\\t\\t{np.mean(discriminator_loss)}')\n",
    "\n",
    "    if run_eval:\n",
    "        print('\\nValidation Losses:')\n",
    "        print(f'Val Reconstruction Loss:\\t{np.mean(val_rec_loss)}\\nVal Cross Reconstruction Loss:\\t{np.mean(val_cross_loss)}\\nVal End Effector Loss:\\t\\t{np.mean(val_end_effector_loss)}\\nVal Triplet Loss:\\t\\t{np.mean(val_triplet_loss)}\\nVal Latent Consistency Loss:\\t{np.mean(val_latent_consistency_loss)}')\n",
    "        print(f'Val Privacy Loss:\\t\\t{np.mean(val_privacy_loss)}\\nVal Privacy Loss Dyn:\\t\\t{np.mean(val_privacy_loss_dyn)}\\nVal Privacy Loss Stat:\\t\\t{np.mean(val_privacy_loss_stat)}')\n",
    "        print(f'Val Utility Loss:\\t\\t{np.mean(val_utility_loss)}\\nVal Utility Loss Dyn:\\t\\t{np.mean(val_utility_loss_dyn)}\\nVal Utility Loss Stat:\\t\\t{np.mean(val_utility_loss_stat)}')\n",
    "        print(f'Val Discriminator Loss:\\t\\t{np.mean(val_discriminator_loss)}')\n",
    "    \n",
    "    if train_emb_adv or train_discrim:\n",
    "        print('\\nAdversary Losses')\n",
    "        if train_emb_adv:\n",
    "            print(f'Privacy Training Loss:\\t\\t{np.mean(priv_training_loss)}\\nUtility Training Loss:\\t\\t{np.mean(util_training_loss)}\\nDiscriminator Training Loss:\\t{np.mean(discriminator_train_losses)}')\n",
    "            if train_ae or train_cross:\n",
    "                print(f'Privacy Acc Dyn:\\t\\t{np.mean(privacy_acc_dyn)}\\nPrivacy Acc Stat:\\t\\t{np.mean(privacy_acc_stat)}')\n",
    "                print(f'Utility Acc Dyn:\\t\\t{np.mean(utility_acc_dyn)}\\nUtility Acc Stat:\\t\\t{np.mean(utility_acc_stat)}')\n",
    "            print(f'Val Privacy Acc Dyn:\\t\\t{np.mean(val_privacy_acc_dyn)}\\nVal Privacy Acc Stat:\\t\\t{np.mean(val_privacy_acc_stat)}')\n",
    "            print(f'Val Utility Acc Dyn:\\t\\t{np.mean(val_utility_acc_dyn)}\\nVal Utility Acc Stat:\\t\\t{np.mean(val_utility_acc_stat)}')\n",
    "    \n",
    "    if train_ae or train_cross: print(f'Discriminator Acc:\\t\\t{np.mean(discriminator_training_acc)}')\n",
    "    if run_eval: print(f'Val Discriminator Acc:\\t\\t{np.mean(val_discriminator_acc)}')\n",
    "\n",
    "    # Save model\n",
    "    if save and np.mean(val_losses) < best_loss:\n",
    "        best_loss = np.mean(val_losses)\n",
    "        torch.save(model.state_dict(), 'pretrained/MR.pt')\n",
    "\n",
    "    # Test Accuracy\n",
    "    if run_sgn_eval and run_eval:\n",
    "        print('\\n')\n",
    "        sgn_eval(eval_X_known, eval_Y_known_action, 'Known Action', is_action=True)\n",
    "        sgn_eval(eval_X_rec, eval_Y_rec_action, 'Reconstructed Action', is_action=True)\n",
    "        sgn_eval(eval_X, eval_Y_action, 'Generated Action', is_action=True)\n",
    "        print('\\n')\n",
    "        sgn_eval(eval_X_known, eval_Y_known_actor, 'Known Actor', is_actor=True)\n",
    "        sgn_eval(eval_X_rec, eval_Y_rec_actor, 'Reconstructed Actor', is_actor=True)\n",
    "        sgn_eval(eval_X, eval_Y_actor, 'Generated Actor', is_actor=True)\n",
    "    else: print('\\n')\n",
    "\n",
    "def sgn_eval(X, Y, label='Undefined', is_actor=False, is_action=False):\n",
    "    assert is_actor != is_action, \"is_actor and is_action cannot both be True\"\n",
    "    assert is_actor or is_action, \"Either is_actor or is_action must be True\"\n",
    "\n",
    "    if is_actor:\n",
    "        classes = privacy_classes\n",
    "        sgn = sgn_priv\n",
    "    elif is_action:\n",
    "        classes = utility_classes\n",
    "        sgn = sgn_ar\n",
    "\n",
    "    X = np.concatenate(X)\n",
    "    X = np.pad(X, ((0,0), (0,225), (0,75)), 'constant')\n",
    "\n",
    "    Y = np.concatenate(Y) - 1\n",
    "    Y = np.eye(classes)[Y.astype(int)]\n",
    "\n",
    "    acc, f1, prec, recall = run_sgn_eval(sgn_train_x, sgn_train_y, X, Y, sgn_val_x, sgn_val_y, 1, sgn)\n",
    "    print(f'\\n{label} Accuracy:\\t\\t{acc}\\n{label} F1:\\t\\t\\t{f1*100}\\n{label} Precision:\\t\\t{prec*100}\\n{label} Recall:\\t\\t{recall*100}\\n')\n",
    "\n",
    "# Simplified training loop for only AE\n",
    "def ae_only_train(epoch, run_eval=True, run_sgn_eval=True, save=True):\n",
    "    global best_loss\n",
    "    global total_epochs\n",
    "\n",
    "    # Store eval values for validation\n",
    "    eval_X_known, eval_Y_known_action, eval_Y_known_actor, eval_X_rec, eval_Y_rec_action, eval_Y_rec_actor = [], [], [], [], [], []\n",
    "    \n",
    "    # Losses for printing\n",
    "    losses, val_losses = [], []\n",
    "\n",
    "    for (x, actors, actions) in rec_train_dl:\n",
    "        # Move tensors to the configured device\n",
    "        x = x.float().to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        loss = model.rec_loss(x)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # Decay learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    if run_eval:\n",
    "        with torch.no_grad():\n",
    "            for (x, actors, actions) in rec_val_dl:\n",
    "                x = x.float().to(device)\n",
    "                \n",
    "                loss = model.rec_loss(x)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "                if run_sgn_eval:\n",
    "                    eval_X_known.append(x.cpu().numpy())\n",
    "                    eval_Y_known_action.append(np.array(actions))\n",
    "                    eval_Y_known_actor.append(np.array(actors))\n",
    "\n",
    "                    eval_X_rec.append(model(x).cpu().numpy())\n",
    "                    eval_Y_rec_action.append(np.array(actions))\n",
    "                    eval_Y_rec_actor.append(np.array(actors))\n",
    "\n",
    "    # Print loss/accuracy\n",
    "    print(f'--------------------\\nEpoch {epoch+1}/{total_epochs}\\n--------------------')\n",
    "    print(f'Training Loss:\\t\\t\\t{np.mean(losses)}\\nValidation Loss:\\t\\t{np.mean(val_losses)}\\n')\n",
    "\n",
    "    # Save model\n",
    "    if save and np.mean(val_losses) < best_loss:\n",
    "        best_loss = np.mean(val_losses)\n",
    "        torch.save(model.state_dict(), 'pretrained/MR.pt')\n",
    "\n",
    "    # Test Accuracy\n",
    "    if run_sgn_eval and run_eval:\n",
    "        print('\\n')\n",
    "        sgn_eval(eval_X_known, eval_Y_known_action, 'Known Action', is_action=True)\n",
    "        sgn_eval(eval_X_rec, eval_Y_rec_action, 'Reconstructed Action', is_action=True)\n",
    "        print('\\n')\n",
    "        sgn_eval(eval_X_known, eval_Y_known_actor, 'Known Actor', is_actor=True)\n",
    "        sgn_eval(eval_X_rec, eval_Y_rec_actor, 'Reconstructed Actor', is_actor=True)\n",
    "        print('\\n')\n",
    "    else: print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_stages = [\n",
    "    {'epochs': 500, 'ae': True, 'cross': False, 'discrim': False, 'emb': False, 'eval': True, 'use_adv_loss': False, 'sgn_eval': False, 'save': False},\n",
    "    {'epochs': 1000, 'ae': False, 'cross': False, 'discrim': False, 'emb': True, 'eval': True, 'use_adv_loss': True, 'sgn_eval': False, 'save': False},\n",
    "    {'epochs': 500, 'ae': False, 'cross': False, 'discrim': True, 'emb': False, 'eval': True, 'use_adv_loss': False, 'sgn_eval': False, 'save': False},\n",
    "    {'epochs': 1000, 'ae': True, 'cross': True, 'discrim': True, 'emb': False, 'eval': True, 'use_adv_loss': True, 'sgn_eval': True, 'save': True},\n",
    "    {'epochs': 1000, 'ae': True, 'cross': True, 'discrim': False, 'emb': True, 'eval': True, 'use_adv_loss': True, 'sgn_eval': True, 'save': True},\n",
    "]\n",
    "\n",
    "total_epochs = sum([stage['epochs'] for stage in training_stages])\n",
    "\n",
    "for stage in training_stages:\n",
    "    print('\\n\\nMoving to new stage\\n')\n",
    "    print(stage, '\\n')\n",
    "    for epoch in range(stage['epochs']):\n",
    "        if stage['sgn_eval']:\n",
    "            if validation_acc_freq > 0 and epoch % validation_acc_freq == 0: use_sgn = True\n",
    "            else: use_sgn = False\n",
    "        else: use_sgn = False\n",
    "        # if stage['ae'] and not stage['cross'] and not stage['discrim'] and not stage['emb']:\n",
    "        #     ae_only_train(epoch, run_eval=stage['eval'], run_sgn_eval=use_sgn, save=stage['save'])\n",
    "        #else: \n",
    "        train(epoch, train_ae=stage['ae'], train_cross=stage['cross'], train_discrim=stage['discrim'], train_emb_adv=stage['emb'], run_eval=stage['eval'], use_adv_loss=stage['use_adv_loss'], run_sgn_eval= use_sgn, save=stage['save'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SGN eval\n",
    "train(501, run_sgn_eval=True)\n",
    "\n",
    "# manual save\n",
    "#torch.save(model.state_dict(), 'pretrained/MR.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_video(val_data[0][0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_video(model(val_data[0][0][2].unsqueeze(0).to(device)).squeeze(0).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retargeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retarget():\n",
    "    X_hat_random = {}\n",
    "    X_hat_constant = {}\n",
    "\n",
    "    x2_const = X[random.sample(list(X.keys()), 1)[0]].float().cuda().unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        for file in X:\n",
    "            x1 = X[file].unsqueeze(0)\n",
    "            x2_random = X[random.sample(list(X.keys()), 1)[0]].unsqueeze(0)\n",
    "            X_hat_random[file] = model.eval(x1.float().cuda(), x2_random.float().cuda()).cpu().numpy().squeeze()\n",
    "            X_hat_constant[file] = model.eval(x1.float().cuda(), x2_const).cpu().numpy().squeeze()\n",
    "\n",
    "    # Save results\n",
    "    with open('results/X_hat_random.pkl', 'wb') as f:\n",
    "        pickle.dump(X_hat_random, f)\n",
    "    with open('results/X_hat_constant.pkl', 'wb') as f:\n",
    "        pickle.dump(X_hat_constant, f)\n",
    "\n",
    "# retarget()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
